<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/html">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Report ClayRS</title>
</head>
<body>
<h1>Report ClayRS</h1>
<p>This HTML document was generated from YAML files for the purpose
  of replicability of experiments done with <a href="https://github.com/swapUniba/ClayRS" target="_blank">ClayRS</a>.
  It contains information about the dataset, preprocessing methods, analysis algorithms,
  and the results of the experimental evaluation.</p>

<!-- apertura CONTENT ANALYZER REPORT STYLE -->
{% if my_dict['source_file'] is defined and my_dict['source_file'] %}
 <!-- ClayRS configurations of the experiment -->
 <h2 id="sec-clayrs-configurations-of-the-experiment">ClayRS configurations of the experiment</h2>

<!-- Dataset sotto sezione di h2 -->
<h3 id="subsec-dataset">Dataset</h3>
<p>In this experiment, the {% if dict['id_each_content'] == ['movielens_id'] %} <strong>Movielens</strong> {% endif %}
    <strong>Dataset</strong> was used.</p>

{% if 'interactions' in my_dict %}
<!-- Questo blocco if controlla la tabella sulle statiche del dataset -->
<!-- Statistics of the dataset -->
<p>The statistics of the dataset used are reported in the following
    <a href="#stat-table">Table of iteractions</a>:</p>

<div style="text-align: center;">
    <table id="stat-table" style="margin: auto;">
        <tr>
             <th>Parameter</th>
             <th>Value</th>
        </tr>
         <tr>
             <td>n_users</td>
             <td>{{ my_dict['interactions']['n_users']|safe_text }}</td>
         </tr>
         <tr>
            <td>n_items</td>
            <td>{{ my_dict['interactions']['n_items']|safe_text }}</td>
        </tr>
         <tr>
            <td>total_interactions</td>
            <td>{{ my_dict['interactions']['total_interactions']|safe_text }}</td>
         </tr>
        <tr>
            <td>min_score</td>
            <td>{{ my_dict['interactions']['min_score']|safe_text }}</td>
         </tr>
        <tr>
            <td>max_score</td>
            <td>{{ my_dict['interactions']['max_score']|safe_text }}</td>
        </tr>
        <tr>
            <td>mean_score</td>
            <td>{{ my_dict['interactions']['mean_score']|safe_text }}</td>
        </tr>
        <tr>
            <td>sparsity</td>
            <td>{{ dict['interactions']['sparsity']|truncate|safe_text }}</td>
        </tr>
         <caption>Table of the Interactions</caption>
     </table>
</div>
<!-- chiusura blocco controllo tabella dataset -->
{% endif %}

{% if 'WordEmbeddingTechnique' in my_dict['field_representations']['genres_0'] or
    'SentenceEmbeddingTechnique' in my_dict['field_representations']['genres_1'] %}
<!-- Field representations -->
<p>The embendding techniques used during the processing of the document are the following:
    {% if 'WordEmbeddingTechnique' in my_dict['field_representations']['genres_0'] %}
    {{ my_dict['field_representations']['genres_0']['WordEmbeddingTechnique']['embedding_source']|safe_text }}
    {% endif %}
    {% if 'SentenceEmbeddingTechnique' in my_dict['field_representations']['genres_1'] %}
    {{ my_dict['field_representations']['genres_1']['SentenceEmbeddingTechnique']['embedding_source']|safe_text }}
    {% endif %}</p>
<!-- closing the OR condition -->
{% endif %}

<!-- Preprocessing -->
<h3 id="subsec-preprocessing">Preprocessing</h3>
<!--  Beginning OF THE dict['field_representations']['plot_0']['SkLearnTfIdf'] -->
{% if 'plot_0' in my_dict['field_representations'] %}
{% if 'NLTK' in my_dict['field_representations']['plot_0']['preprocessing'] %}
<p>The preprocessing used is NLTK, a leading platform for building Python programs to work with human language data.
    It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet,
    along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing,
    and semantic reasoning.</p>

<!-- potremmo gestire questi paragrafi come lista numerata  -->
<p>In this experiment, those operations of NLTK were used:</p>
{% if my_dict.get('field_representations', {}).get('plot_0', {}).get('preprocessing', {}).get('NLTK', {}).get('strip_multiple_whitespace') == True %}
<p> <strong> Strip multiple whitespace </strong>, an operation that removes multiple whitspaces between words.</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('plot_0', {}).get('preprocessing', {}).get('NLTK', {}).get('remove_punctuation') == True %}
<p> <strong> Remove punctuation </strong>, used to remove the punctuation occurring in the text.</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('plot_0', {}).get('preprocessing', {}).get('NLTK', {}).get('stopwords_removal') == True %}
<p> <strong> Stopwords removal </strong>, used to remove the stopwords occurring in the text.</p>
{% endif %}
{%  if my_dict.get('field_representations', {}).get('plot_0', {}).get('preprocessing', {}).get('NLTK', {}).get('url_tagging') == True %}
<p> <strong> Url tagging </strong>, tags the urls occuring in the text, replacing them with "&lt URL &gt".</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('plot_0', {}).get('preprocessing', {}).get('NLTK', {}).get('lemmatization') == True %}
<p> <strong> Lemmatization </strong>, an operation that determines the lemma of a word based on its intended meaning, for example "troubled" becomes "trouble" after lemmatization.</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('plot_0', {}).get('preprocessing', {}).get('NLTK', {}).get('stemming') == True %}
<p> <strong> Stemming </strong>, an operation that reduces a word to its root, for example "Flying" becomes "Fly" after the stemming operations is applied.</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('plot_0', {}).get('preprocessing', {}).get('NLTK', {}).get('named_entity_recognition') == True %}
<p> <strong>Named entity recognition</strong>, an operation that detects the named entities such as person names, location names, company names, etc., from the text.</p>
{% endif %}
 <!-- chiusura dei primi due blocchi di flusso aperti
     sotto il tag header h3 id="subsec-preprocessing" -->
{% endif %}
{% endif %}


<!-- NLTK REPORTING STYLE -->
{% if 'genres_0' in my_dict['field_representations'] %}
{% if 'NLTK' in my_dict['field_representations']['genres_0']['preprocessing'] %}
<p>
   The preprocessing used is NLTK, a leading platform for building Python programs to work with human language data.
   It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet,
   along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing,
   and semantic reasoning.
</p>
<p>In this experiment, those operations of NLTK were used:</p>
{% if dict.get('field_representations', {}).get('genres_0', {}).get('preprocessing', {}).get('NLTK', {}).get('strip_multiple_whitespace') == True %}
<p> <strong>Strip multiple whitespace</strong>,an operation that removes multiple whitspaces between words. </p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('genres_0', {}).get('preprocessing', {}).get('NLTK', {}).get('remove_punctuation') == True %}
<p> <strong>Remove punctuation</strong>, an operation that removes the punctuation characters occuring in the text. </p>
 {% endif %}
 {% if my_dict.get('field_representations', {}).get('genres_0', {}).get('preprocessing', {}).get('NLTK', {}).get('stopwords_removal') == True %}
 <p> <strong>Stopwords removal</strong>, used to remove the stopwords occurring in the text.</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('genres_0', {}).get('preprocessing', {}).get('NLTK', {}).get('url_tagging') == True %}
 <p> <strong>Url tagging</strong>, tags the urls occuring in the text, replacing them with "&lt URL &gt"</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('genres_0', {}).get('preprocessing', {}).get('NLTK', {}).get('lemmatization') == True %}
<p> <strong>Lemmatization</strong>, an operation that determines the lemma of a word based on its intended meaning, for example "troubled" becomes "trouble" after lemmatization.</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('genres_0', {}).get('preprocessing', {}).get('NLTK', {}).get('stemming') == True %}
<p> <strong>Stemming</strong>, an operation that reduces a word to its root,for example "Flying" becomes "Fly" after the stemming operations is applied.</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('genres_0', {}).get('preprocessing', {}).get('NLTK', {}).get('named_entity_recognition') == True %}
<p> <strong>Named entity recognition</strong>, an operation that detects the named entities such as person names, location names, company names, etc., from the text.</p>
{% endif %}
<!-- chiusura dei blocchi di controllo aperti all'inizio di
     NLTK REPORTING STYLE -->
{% endif %}
{% endif %}

    <!-- EKPHRASYS REPORTING STYLE -->
    {% if 'genres_0' in my_dict['field_representations'] %}
        {% if 'Ekphrasis' in my_dict['field_representations']['genres_0']['preprocessing'] %}
            <p>
                The preprocessing used is Ekphrasis, ........................
            </p>
            <p>
                The Ekphrasis configuration for this experiment is:
            </p>
            <!-- NEED TO BE CONTINUED -->
        <!-- chiusura dei blocchi di controllo aperti all'inizio di
             EKPHRASYS REPORTING STYLE -->
        {% endif %}
    {% endif %}

<!-- SPACY reporting style -->
{% if 'genres_0' in my_dict['field_representations']  %}
{% if 'Spacy' in my_dict['field_representations']['genres_0']['preprocessing'] %}
<p>
    spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python.
    spaCy is designed specifically for production use and helps you build applications that process
    and 'understand' large volumes of text. It can be used to build information extraction or natural
    language understanding systems, or to pre-process text for deep learning.
</p>
<p>In this experiment, those spaCy operations have been used:</p>
{% if my_dict.get('field_representations', {}).get('genres_0', {}).get('preprocessing', {}).get('Spacy', {}).get('strip_multiple_whitespace') == True %}
<p><strong>Strip multiple whitespace</strong>, an operation that removes multiple whitspaces between words.</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('genres_0', {}).get('preprocessing', {}).get('Spacy', {}).get('remove_punctuation') == True %}
<p><strong>Remove punctuation</strong>, an operation that removes the punctuation characters occuring in the text.</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('genres_0', {}).get('preprocessing', {}).get('Spacy', {}).get('stopwords_removal') == True %}
<p><strong>Stopwords removal</strong>, used to remove the stopwords occurring in the text.</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('genres_0', {}).get('preprocessing', {}).get('Spacy', {}).get('url_tagging') == True %}
<p><strong>Url tagging</strong>, tags the urls occuring in the text, replacing them with "&lt URL &gt".</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('genres_0', {}).get('preprocessing', {}).get('Spacy', {}).get('lemmatization') == True %}
<p><strong>Lemmatization</strong>, an operation that determines the lemma of a word based on its intended
    meaning, for example "troubled" becomes "trouble" after lemmatization.</p>
{% endif %}
{% if my_dict.get('field_representations', {}).get('genres_0', {}).get('preprocessing', {}).get('Spacy', {}).get('named_entity_recognition') == True %}
<p><strong>Named entity recognition</strong>, an operation that detects the named entities such as person names,
    location names, company names, etc., from the text.</p>
{% endif %}
<!-- chiusura dei blocchi di controllo aperti all'inizio di
     SPACY reporting style -->
{% endif %}
{% endif %}
<!-- chiusura della sezione del content analyzer -->
{% endif %}

</body>
</html>