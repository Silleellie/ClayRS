

%! Author = DIEGO
%! Date = 21/12/2023

% Preamble
\documentclass[11pt]{article}

% Packages
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{comment}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{url}
\usepackage{listings}

\title{Report Experiment ClayRS Framework}
\author{SWAP research group UniBa}
\date{08-01-2024}

% -------------------- DOCUMENT: REPORT ON THE ExPERIMENT WITH CLAYRS FRAMEWORK STARTED -------------------------------
\begin{document}

\maketitle
This LaTex document was generated automatically from yaml files for the purpose of replicability of experiments done with
\href{https://github.com/swapUniba/ClayRS}{ClayRS},
it contains information about the experiment that has been conducted and the results obtained.
The report is divided in 3 principal section dedicated each one for the 3 principal module of the ClayRS framework
and a conclusion section to highlights what have been achieved from the experiment.
\hfill\break
\hfill\break



% ----------------------------------------- OPENING CONTENT ANALYZER SECTION -----------------------------------------
\section{Content Analyzer Module}\label{sec:ca}
The content analyzer module will deal with raw source document or more in general data which could be
video or audio data and give a representation of these data which will be used by the other two module.
The text data source could be represented with exogenous technique or with a specified representation
and each field given could be treated with preprocessing techniques and postprocessing technique.
In this experiment the following techniques have been used on specific field in order to achieve the
representation wanted:
\hfill\break
\hfill\break
% --- TECNIQUE USED TO REPPRESENT DATA FIELD ---



% field: plot0 representation subsection
\textbf{\lstinline[style=verbatim-text]| plot0 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on plot0

\begin{itemize}
                                                            
            \item
        \verb| OriginalData | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| dtype: <class 'str'>|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ plot0 ____



% preprocessing on plot0
No preprocessing techniques have been used to preprocess data \lstinline[style=verbatim-text]| plot0 | has been represented with the following techniques:
 during the experiment.
% _preprocessing on plot0 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| plot0 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ plot0 ___



% field: plot1 representation subsection
\textbf{\lstinline[style=verbatim-text]| plot1 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on plot1

\begin{itemize}
                                                            
            \item
        \verb| WhooshTfIdf | used as content representation technique with following parameters:
        \begin{itemize}
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ plot1 ____



% preprocessing on plot1
    % dictionary 'preprocessing' not empty
\begin{itemize}
    \item
     \verb| Spacy | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| lemmatization: True|
             \item
            \verb| model: en_core_web_sm|
             \item
            \verb| named_entity_recognition: False|
             \item
            \verb| new_stopwords: None|
             \item
            \verb| not_stopwords: None|
             \item
            \verb| remove_punctuation: False|
             \item
            \verb| stopwords_removal: True|
             \item
            \verb| strip_multiple_whitespace: True|
             \item
            \verb| url_tagging: False|
           \end{itemize}
\end{itemize}
% _preprocessing on plot1 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| plot1 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ plot1 ___



% field: plot2 representation subsection
\textbf{\lstinline[style=verbatim-text]| plot2 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on plot2

\begin{itemize}
                                                            
            \item
        \verb| SkLearnTfIdf | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| binary: False|
                            \item
                \verb| dtype: <class 'numpy.float64'>|
                            \item
                \verb| max_df: 1.0|
                            \item
                \verb| max_features: None|
                            \item
                \verb| min_df: 1|
                            \item
                \verb| norm: l2|
                            \item
                \verb| smooth_idf: True|
                            \item
                \verb| sublinear_tf: False|
                            \item
                \verb| use_idf: True|
                            \item
                \verb| vocabulary: None|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ plot2 ____



% preprocessing on plot2
    % dictionary 'preprocessing' not empty
\begin{itemize}
    \item
     \verb| Ekphrasis | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| all_caps_tag: None|
             \item
            \verb| annotate: None|
             \item
            \verb| corrector: None|
             \item
            \verb| dicts: None|
             \item
            \verb| normalize: None|
             \item
            \verb| omit: None|
             \item
            \verb| segmentation: False|
             \item
            \verb| segmenter: None|
             \item
            \verb| spell_correct_elong: True|
             \item
            \verb| spell_correction: True|
             \item
            \verb| tokenizer: <bound method SocialTokenizer.tokenize of <ekphrasis.classes.tokenizer.SocialTokenizer object at 0x00000234F0BDBD00>>|
             \item
            \verb| unpack_contractions: False|
             \item
            \verb| unpack_hashtags: False|
           \end{itemize}
    \item
     \verb| NLTK | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| lang: english|
             \item
            \verb| lemmatization: True|
             \item
            \verb| pos_tag: False|
             \item
            \verb| remove_punctuation: False|
             \item
            \verb| stemming: False|
             \item
            \verb| stopwords_removal: True|
             \item
            \verb| strip_multiple_whitespace: True|
             \item
            \verb| url_tagging: False|
           \end{itemize}
\end{itemize}
% _preprocessing on plot2 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| plot2 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ plot2 ___



% field: plot3 representation subsection
\textbf{\lstinline[style=verbatim-text]| plot3 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on plot3

\begin{itemize}
                                                            
            \item
        \verb| WordEmbeddingTechnique | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| embedding_source: Gensim glove-twitter-25|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ plot3 ____



% preprocessing on plot3
No preprocessing techniques have been used to preprocess data \lstinline[style=verbatim-text]| plot3 | has been represented with the following techniques:
 during the experiment.
% _preprocessing on plot3 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| plot3 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ plot3 ___



% field: plot4 representation subsection
\textbf{\lstinline[style=verbatim-text]| plot4 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on plot4

\begin{itemize}
                                                            
            \item
        \verb| SentenceEmbeddingTechnique | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| embedding_source: Sbert paraphrase-distilroberta-base-v1|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ plot4 ____



% preprocessing on plot4
No preprocessing techniques have been used to preprocess data \lstinline[style=verbatim-text]| plot4 | has been represented with the following techniques:
 during the experiment.
% _preprocessing on plot4 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| plot4 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ plot4 ___



% field: plot5 representation subsection
\textbf{\lstinline[style=verbatim-text]| plot5 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on plot5

\begin{itemize}
                                                            
            \item
        \verb| DocumentEmbeddingTechnique | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| embedding_source: Sbert paraphrase-distilroberta-base-v1|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ plot5 ____



% preprocessing on plot5
No preprocessing techniques have been used to preprocess data \lstinline[style=verbatim-text]| plot5 | has been represented with the following techniques:
 during the experiment.
% _preprocessing on plot5 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| plot5 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ plot5 ___



% field: plot6 representation subsection
\textbf{\lstinline[style=verbatim-text]| plot6 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on plot6

\begin{itemize}
                                                            
            \item
        \verb| Word2SentenceEmbedding | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| combining_technique: Centroid|
                            \item
                \verb| embedding_source: Gensim glove-twitter-25|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ plot6 ____



% preprocessing on plot6
No preprocessing techniques have been used to preprocess data \lstinline[style=verbatim-text]| plot6 | has been represented with the following techniques:
 during the experiment.
% _preprocessing on plot6 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| plot6 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ plot6 ___



% field: plot7 representation subsection
\textbf{\lstinline[style=verbatim-text]| plot7 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on plot7

\begin{itemize}
                                                            
            \item
        \verb| Word2DocEmbedding | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| combining_technique: Centroid|
                            \item
                \verb| embedding_source: Gensim glove-twitter-25|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ plot7 ____



% preprocessing on plot7
No preprocessing techniques have been used to preprocess data \lstinline[style=verbatim-text]| plot7 | has been represented with the following techniques:
 during the experiment.
% _preprocessing on plot7 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| plot7 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ plot7 ___



% field: plot8 representation subsection
\textbf{\lstinline[style=verbatim-text]| plot8 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on plot8

\begin{itemize}
                                                            
            \item
        \verb| Sentence2DocEmbedding | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| combining_technique: Centroid|
                            \item
                \verb| embedding_source: Sbert paraphrase-distilroberta-base-v1|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ plot8 ____



% preprocessing on plot8
No preprocessing techniques have been used to preprocess data \lstinline[style=verbatim-text]| plot8 | has been represented with the following techniques:
 during the experiment.
% _preprocessing on plot8 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| plot8 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ plot8 ___



% field: plot9 representation subsection
\textbf{\lstinline[style=verbatim-text]| plot9 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on plot9

\begin{itemize}
                                                            
            \item
        \verb| PyWSDSynsetDocumentFrequency | used as content representation technique with following parameters:
        \begin{itemize}
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ plot9 ____



% preprocessing on plot9
No preprocessing techniques have been used to preprocess data \lstinline[style=verbatim-text]| plot9 | has been represented with the following techniques:
 during the experiment.
% _preprocessing on plot9 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| plot9 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ plot9 ___



% field: plot10 representation subsection
\textbf{\lstinline[style=verbatim-text]| plot10 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on plot10

\begin{itemize}
                                                            
            \item
        \verb| OriginalData | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| dtype: <class 'str'>|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ plot10 ____



% preprocessing on plot10
No preprocessing techniques have been used to preprocess data \lstinline[style=verbatim-text]| plot10 | has been represented with the following techniques:
 during the experiment.
% _preprocessing on plot10 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| plot10 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ plot10 ___



% field: plot11 representation subsection
\textbf{\lstinline[style=verbatim-text]| plot11 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on plot11

\begin{itemize}
                                                            
            \item
        \verb| OriginalData | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| dtype: <class 'str'>|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ plot11 ____



% preprocessing on plot11
No preprocessing techniques have been used to preprocess data \lstinline[style=verbatim-text]| plot11 | has been represented with the following techniques:
 during the experiment.
% _preprocessing on plot11 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| plot11 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ plot11 ___



% field: idx0 representation subsection
\textbf{\lstinline[style=verbatim-text]| idx0 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on idx0

\begin{itemize}
                                                            
            \item
        \verb| FromNPY | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| npy_file_path: report_stuff\report.npy|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ idx0 ____



% preprocessing on idx0
No preprocessing techniques have been used to preprocess data \lstinline[style=verbatim-text]| idx0 | has been represented with the following techniques:
 during the experiment.
% _preprocessing on idx0 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| idx0 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ idx0 ___



% field: video_path0 representation subsection
\textbf{\lstinline[style=verbatim-text]| video_path0 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on video_path0

\begin{itemize}
                                                            
            \item
        \verb| SkImageHogDescriptor | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| block_norm: L2-Hys|
                            \item
                \verb| cells_per_block: [3, 3]|
                            \item
                \verb| contents_dirs: contents_dirs|
                            \item
                \verb| flatten: False|
                            \item
                \verb| max_retries: 5|
                            \item
                \verb| max_timeout: 2|
                            \item
                \verb| max_workers: 0|
                            \item
                \verb| orientations: 9|
                            \item
                \verb| pixels_per_cell: [8, 8]|
                            \item
                \verb| time_tuple: [0, None]|
                            \item
                \verb| transform_sqrt: False|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ video_path0 ____



% preprocessing on video_path0
    % dictionary 'preprocessing' not empty
\begin{itemize}
    \item
     \verb| TorchUniformTemporalSubSampler | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| num_samples: 8|
           \end{itemize}
\end{itemize}
% _preprocessing on video_path0 ____
\hfill\break
\hfill\break



% This block is rendered if no post processing technique has been applied
No postprocessing techniques have been used on the data \lstinline[style=verbatim-text]| video_path0 | in this experiment.
\hfill\break
\hfill\break
% postprocessing_on_ video_path0 ___



% field: video_path1 representation subsection
\textbf{\lstinline[style=verbatim-text]| video_path1 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on video_path1

\begin{itemize}
                                                            
            \item
        \verb| MFCC | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| contents_dirs: contents_dirs|
                            \item
                \verb| dct_type: 2|
                            \item
                \verb| flatten: False|
                            \item
                \verb| log_mels: False|
                            \item
                \verb| max_retries: 5|
                            \item
                \verb| max_timeout: 2|
                            \item
                \verb| max_workers: 0|
                            \item
                \verb| mean: False|
                            \item
                \verb| melkwargs: None|
                            \item
                \verb| n_mfcc: 40|
                            \item
                \verb| norm: ortho|
                            \item
                \verb| time_tuple: [0, None]|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ video_path1 ____



% preprocessing on video_path1
    % dictionary 'preprocessing' not empty
\begin{itemize}
    \item
     \verb| ConvertToMono | used as preprocessing technique with following settings:
     \begin{itemize}
           \end{itemize}
    \item
     \verb| TorchResample | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| beta: None|
             \item
            \verb| lowpass_filter_width: 6|
             \item
            \verb| new_freq: 16000|
             \item
            \verb| resampling_method: sinc_interp_hann|
             \item
            \verb| rolloff: 0.99|
           \end{itemize}
\end{itemize}
% _preprocessing on video_path1 ____
\hfill\break
\hfill\break



    % dictionary 'preprocessing' not empty
On th field \verb| video_path1 | have been applied the following postprocessing techniques:
\begin{itemize}
    \item
     \verb| 0 :|
     \begin{itemize}
           \end{itemize}
    \item
     \verb| 1 :|
     \begin{itemize}
             \item
            \verb| FVGMM: |

                   \begin{itemize}
                                    \item
                        \verb| alpha: 0.5 |
                                    \item
                        \verb| covariance_type: diag |
                                    \item
                        \verb| improved: True |
                                    \item
                        \verb| init_params: kmeans |
                                    \item
                        \verb| max_iter: 100 |
                                    \item
                        \verb| means_init: None |
                                    \item
                        \verb| n_components: 2 |
                                    \item
                        \verb| n_init: 1 |
                                    \item
                        \verb| precisions_init: None |
                                    \item
                        \verb| random_state: None |
                                    \item
                        \verb| reg_covar: 1e-06 |
                                    \item
                        \verb| tol: 0.001 |
                                    \item
                        \verb| verbose: 0 |
                                    \item
                        \verb| verbose_interval: 10 |
                                    \item
                        \verb| warm_start: False |
                                    \item
                        \verb| weights_init: None |
                                    \item
                        \verb| with_mean: False |
                                    \item
                        \verb| with_std: False |
                            \end{itemize}
       
           \end{itemize}
    \item
     \verb| 2 :|
     \begin{itemize}
             \item
            \verb| VLADGMM: |

                   \begin{itemize}
                                    \item
                        \verb| alpha: 0.5 |
                                    \item
                        \verb| covariance_type: diag |
                                    \item
                        \verb| improved: False |
                                    \item
                        \verb| init_params: kmeans |
                                    \item
                        \verb| max_iter: 100 |
                                    \item
                        \verb| means_init: None |
                                    \item
                        \verb| n_components: 2 |
                                    \item
                        \verb| n_init: 1 |
                                    \item
                        \verb| precisions_init: None |
                                    \item
                        \verb| random_state: None |
                                    \item
                        \verb| reg_covar: 1e-06 |
                                    \item
                        \verb| tol: 0.001 |
                                    \item
                        \verb| verbose: 0 |
                                    \item
                        \verb| verbose_interval: 10 |
                                    \item
                        \verb| warm_start: False |
                                    \item
                        \verb| weights_init: None |
                                    \item
                        \verb| with_mean: False |
                                    \item
                        \verb| with_std: False |
                            \end{itemize}
       
           \end{itemize}
    \item
     \verb| 3 :|
     \begin{itemize}
             \item
            \verb| SkLearnPCA: |

                   \begin{itemize}
                                    \item
                        \verb| copy: True |
                                    \item
                        \verb| iterated_power: auto |
                                    \item
                        \verb| n_components: 1 |
                                    \item
                        \verb| random_state: None |
                                    \item
                        \verb| svd_solver: auto |
                                    \item
                        \verb| tol: 0.0 |
                                    \item
                        \verb| whiten: False |
                            \end{itemize}
       
           \end{itemize}
\end{itemize}
\hfill\break
\hfill\break
% postprocessing_on_ video_path1 ___



% field: video_path2 representation subsection
\textbf{\lstinline[style=verbatim-text]| video_path2 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on video_path2

\begin{itemize}
                                                            
            \item
        \verb| VGGISH | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| apply_on_output: None|
                            \item
                \verb| batch_size: 1|
                            \item
                \verb| contents_dirs: contents_dirs|
                            \item
                \verb| device: cuda:0|
                            \item
                \verb| feature_layer: embedding_network.5|
                            \item
                \verb| flatten: True|
                            \item
                \verb| max_retries: 5|
                            \item
                \verb| max_timeout: 2|
                            \item
                \verb| max_workers: 0|
                            \item
                \verb| time_tuple: [0, None]|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ video_path2 ____



% preprocessing on video_path2
    % dictionary 'preprocessing' not empty
\begin{itemize}
    \item
     \verb| ConvertToMono | used as preprocessing technique with following settings:
     \begin{itemize}
           \end{itemize}
    \item
     \verb| TorchResample | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| beta: None|
             \item
            \verb| lowpass_filter_width: 6|
             \item
            \verb| new_freq: 16000|
             \item
            \verb| resampling_method: sinc_interp_hann|
             \item
            \verb| rolloff: 0.99|
           \end{itemize}
\end{itemize}
% _preprocessing on video_path2 ____
\hfill\break
\hfill\break



    % dictionary 'preprocessing' not empty
On th field \verb| video_path2 | have been applied the following postprocessing techniques:
\begin{itemize}
    \item
     \verb| 0 :|
     \begin{itemize}
           \end{itemize}
    \item
     \verb| 1 :|
     \begin{itemize}
             \item
            \verb| FVGMM: |

                   \begin{itemize}
                                    \item
                        \verb| alpha: 0.5 |
                                    \item
                        \verb| covariance_type: diag |
                                    \item
                        \verb| improved: True |
                                    \item
                        \verb| init_params: kmeans |
                                    \item
                        \verb| max_iter: 100 |
                                    \item
                        \verb| means_init: None |
                                    \item
                        \verb| n_components: 2 |
                                    \item
                        \verb| n_init: 1 |
                                    \item
                        \verb| precisions_init: None |
                                    \item
                        \verb| random_state: None |
                                    \item
                        \verb| reg_covar: 1e-06 |
                                    \item
                        \verb| tol: 0.001 |
                                    \item
                        \verb| verbose: 0 |
                                    \item
                        \verb| verbose_interval: 10 |
                                    \item
                        \verb| warm_start: False |
                                    \item
                        \verb| weights_init: None |
                                    \item
                        \verb| with_mean: False |
                                    \item
                        \verb| with_std: False |
                            \end{itemize}
       
           \end{itemize}
    \item
     \verb| 2 :|
     \begin{itemize}
             \item
            \verb| VLADGMM: |

                   \begin{itemize}
                                    \item
                        \verb| alpha: 0.5 |
                                    \item
                        \verb| covariance_type: diag |
                                    \item
                        \verb| improved: False |
                                    \item
                        \verb| init_params: kmeans |
                                    \item
                        \verb| max_iter: 100 |
                                    \item
                        \verb| means_init: None |
                                    \item
                        \verb| n_components: 2 |
                                    \item
                        \verb| n_init: 1 |
                                    \item
                        \verb| precisions_init: None |
                                    \item
                        \verb| random_state: None |
                                    \item
                        \verb| reg_covar: 1e-06 |
                                    \item
                        \verb| tol: 0.001 |
                                    \item
                        \verb| verbose: 0 |
                                    \item
                        \verb| verbose_interval: 10 |
                                    \item
                        \verb| warm_start: False |
                                    \item
                        \verb| weights_init: None |
                                    \item
                        \verb| with_mean: False |
                                    \item
                        \verb| with_std: False |
                            \end{itemize}
       
           \end{itemize}
    \item
     \verb| 3 :|
     \begin{itemize}
             \item
            \verb| SkLearnPCA: |

                   \begin{itemize}
                                    \item
                        \verb| copy: True |
                                    \item
                        \verb| iterated_power: auto |
                                    \item
                        \verb| n_components: 1 |
                                    \item
                        \verb| random_state: None |
                                    \item
                        \verb| svd_solver: auto |
                                    \item
                        \verb| tol: 0.0 |
                                    \item
                        \verb| whiten: False |
                            \end{itemize}
       
           \end{itemize}
\end{itemize}
\hfill\break
\hfill\break
% postprocessing_on_ video_path2 ___



% field: video_path3 representation subsection
\textbf{\lstinline[style=verbatim-text]| video_path3 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on video_path3

\begin{itemize}
                                                            
            \item
        \verb| PytorchImageModels | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| apply_on_output: None|
                            \item
                \verb| batch_size: 4|
                            \item
                \verb| contents_dirs: contents_dirs|
                            \item
                \verb| custom_weights_path: None|
                            \item
                \verb| device: cuda:0|
                            \item
                \verb| feature_layer: head_drop|
                            \item
                \verb| flatten: True|
                            \item
                \verb| max_retries: 5|
                            \item
                \verb| max_timeout: 2|
                            \item
                \verb| max_workers: 0|
                            \item
                \verb| model_name: densenet161|
                            \item
                \verb| num_classes: None|
                            \item
                \verb| time_tuple: [0, 10]|
                            \item
                \verb| use_default_transforms: False|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ video_path3 ____



% preprocessing on video_path3
    % dictionary 'preprocessing' not empty
\begin{itemize}
    \item
     \verb| CenterCrop | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| size: [224, 224]|
           \end{itemize}
    \item
     \verb| Lambda | used as preprocessing technique with following settings:
     \begin{itemize}
           \end{itemize}
    \item
     \verb| Normalize | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| mean: [0.485, 0.456, 0.406]|
             \item
            \verb| std: [0.229, 0.224, 0.225]|
           \end{itemize}
    \item
     \verb| Resize | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| antialias: None|
             \item
            \verb| interpolation: bilinear|
             \item
            \verb| max_size: None|
             \item
            \verb| size: [256, 256]|
           \end{itemize}
    \item
     \verb| TorchUniformTemporalSubSampler | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| num_samples: 8|
           \end{itemize}
\end{itemize}
% _preprocessing on video_path3 ____
\hfill\break
\hfill\break



    % dictionary 'preprocessing' not empty
On th field \verb| video_path3 | have been applied the following postprocessing techniques:
\begin{itemize}
    \item
     \verb| 0 :|
     \begin{itemize}
           \end{itemize}
    \item
     \verb| 1 :|
     \begin{itemize}
             \item
            \verb| FVGMM: |

                   \begin{itemize}
                                    \item
                        \verb| alpha: 0.5 |
                                    \item
                        \verb| covariance_type: diag |
                                    \item
                        \verb| improved: True |
                                    \item
                        \verb| init_params: kmeans |
                                    \item
                        \verb| max_iter: 100 |
                                    \item
                        \verb| means_init: None |
                                    \item
                        \verb| n_components: 2 |
                                    \item
                        \verb| n_init: 1 |
                                    \item
                        \verb| precisions_init: None |
                                    \item
                        \verb| random_state: None |
                                    \item
                        \verb| reg_covar: 1e-06 |
                                    \item
                        \verb| tol: 0.001 |
                                    \item
                        \verb| verbose: 0 |
                                    \item
                        \verb| verbose_interval: 10 |
                                    \item
                        \verb| warm_start: False |
                                    \item
                        \verb| weights_init: None |
                                    \item
                        \verb| with_mean: False |
                                    \item
                        \verb| with_std: False |
                            \end{itemize}
       
           \end{itemize}
    \item
     \verb| 2 :|
     \begin{itemize}
             \item
            \verb| VLADGMM: |

                   \begin{itemize}
                                    \item
                        \verb| alpha: 0.5 |
                                    \item
                        \verb| covariance_type: diag |
                                    \item
                        \verb| improved: False |
                                    \item
                        \verb| init_params: kmeans |
                                    \item
                        \verb| max_iter: 100 |
                                    \item
                        \verb| means_init: None |
                                    \item
                        \verb| n_components: 2 |
                                    \item
                        \verb| n_init: 1 |
                                    \item
                        \verb| precisions_init: None |
                                    \item
                        \verb| random_state: None |
                                    \item
                        \verb| reg_covar: 1e-06 |
                                    \item
                        \verb| tol: 0.001 |
                                    \item
                        \verb| verbose: 0 |
                                    \item
                        \verb| verbose_interval: 10 |
                                    \item
                        \verb| warm_start: False |
                                    \item
                        \verb| weights_init: None |
                                    \item
                        \verb| with_mean: False |
                                    \item
                        \verb| with_std: False |
                            \end{itemize}
       
           \end{itemize}
    \item
     \verb| 3 :|
     \begin{itemize}
             \item
            \verb| SkLearnPCA: |

                   \begin{itemize}
                                    \item
                        \verb| copy: True |
                                    \item
                        \verb| iterated_power: auto |
                                    \item
                        \verb| n_components: 1 |
                                    \item
                        \verb| random_state: None |
                                    \item
                        \verb| svd_solver: auto |
                                    \item
                        \verb| tol: 0.0 |
                                    \item
                        \verb| whiten: False |
                            \end{itemize}
       
           \end{itemize}
\end{itemize}
\hfill\break
\hfill\break
% postprocessing_on_ video_path3 ___



% field: video_path4 representation subsection
\textbf{\lstinline[style=verbatim-text]| video_path4 |} has been represented with the following techniques:
\hfill\break
\hfill\break
% content representation on video_path4

\begin{itemize}
                                                            
            \item
        \verb| TorchVisionVideoModels | used as content representation technique with following parameters:
        \begin{itemize}
                            \item
                \verb| apply_on_output: None|
                            \item
                \verb| batch_size: 4|
                            \item
                \verb| contents_dirs: contents_dirs|
                            \item
                \verb| device: cuda:0|
                            \item
                \verb| feature_layer: avgpool|
                            \item
                \verb| flatten: True|
                            \item
                \verb| max_retries: 5|
                            \item
                \verb| max_timeout: 2|
                            \item
                \verb| max_workers: 0|
                            \item
                \verb| mini_batch_size: 10|
                            \item
                \verb| model_name: r2plus1d_18|
                            \item
                \verb| time_tuple: [0, 10]|
                            \item
                \verb| weights: DEFAULT|
                    \end{itemize}
    \end{itemize}
\hfill\break
\hfill\break
% content_representation_field_ video_path4 ____



% preprocessing on video_path4
    % dictionary 'preprocessing' not empty
\begin{itemize}
    \item
     \verb| CenterCrop | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| size: [112, 112]|
           \end{itemize}
    \item
     \verb| ClipSampler | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| num_clips: 5|
             \item
            \verb| num_frames_for_clip: 16|
             \item
            \verb| selection_strategy: sequential|
           \end{itemize}
    \item
     \verb| Lambda | used as preprocessing technique with following settings:
     \begin{itemize}
           \end{itemize}
    \item
     \verb| Normalize | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| mean: [0.43216, 0.394666, 0.37645]|
             \item
            \verb| std: [0.22803, 0.22145, 0.216989]|
           \end{itemize}
    \item
     \verb| Resize | used as preprocessing technique with following settings:
     \begin{itemize}
             \item
            \verb| antialias: None|
             \item
            \verb| interpolation: bilinear|
             \item
            \verb| max_size: None|
             \item
            \verb| size: [128, 171]|
           \end{itemize}
\end{itemize}
% _preprocessing on video_path4 ____
\hfill\break
\hfill\break



    % dictionary 'preprocessing' not empty
On th field \verb| video_path4 | have been applied the following postprocessing techniques:
\begin{itemize}
    \item
     \verb| 0 :|
     \begin{itemize}
           \end{itemize}
    \item
     \verb| 1 :|
     \begin{itemize}
             \item
            \verb| FVGMM: |

                   \begin{itemize}
                                    \item
                        \verb| alpha: 0.5 |
                                    \item
                        \verb| covariance_type: diag |
                                    \item
                        \verb| improved: True |
                                    \item
                        \verb| init_params: kmeans |
                                    \item
                        \verb| max_iter: 100 |
                                    \item
                        \verb| means_init: None |
                                    \item
                        \verb| n_components: 2 |
                                    \item
                        \verb| n_init: 1 |
                                    \item
                        \verb| precisions_init: None |
                                    \item
                        \verb| random_state: None |
                                    \item
                        \verb| reg_covar: 1e-06 |
                                    \item
                        \verb| tol: 0.001 |
                                    \item
                        \verb| verbose: 0 |
                                    \item
                        \verb| verbose_interval: 10 |
                                    \item
                        \verb| warm_start: False |
                                    \item
                        \verb| weights_init: None |
                                    \item
                        \verb| with_mean: False |
                                    \item
                        \verb| with_std: False |
                            \end{itemize}
       
           \end{itemize}
    \item
     \verb| 2 :|
     \begin{itemize}
             \item
            \verb| VLADGMM: |

                   \begin{itemize}
                                    \item
                        \verb| alpha: 0.5 |
                                    \item
                        \verb| covariance_type: diag |
                                    \item
                        \verb| improved: False |
                                    \item
                        \verb| init_params: kmeans |
                                    \item
                        \verb| max_iter: 100 |
                                    \item
                        \verb| means_init: None |
                                    \item
                        \verb| n_components: 2 |
                                    \item
                        \verb| n_init: 1 |
                                    \item
                        \verb| precisions_init: None |
                                    \item
                        \verb| random_state: None |
                                    \item
                        \verb| reg_covar: 1e-06 |
                                    \item
                        \verb| tol: 0.001 |
                                    \item
                        \verb| verbose: 0 |
                                    \item
                        \verb| verbose_interval: 10 |
                                    \item
                        \verb| warm_start: False |
                                    \item
                        \verb| weights_init: None |
                                    \item
                        \verb| with_mean: False |
                                    \item
                        \verb| with_std: False |
                            \end{itemize}
       
           \end{itemize}
    \item
     \verb| 3 :|
     \begin{itemize}
             \item
            \verb| SkLearnPCA: |

                   \begin{itemize}
                                    \item
                        \verb| copy: True |
                                    \item
                        \verb| iterated_power: auto |
                                    \item
                        \verb| n_components: 1 |
                                    \item
                        \verb| random_state: None |
                                    \item
                        \verb| svd_solver: auto |
                                    \item
                        \verb| tol: 0.0 |
                                    \item
                        \verb| whiten: False |
                            \end{itemize}
       
           \end{itemize}
\end{itemize}
\hfill\break
\hfill\break
% postprocessing_on_ video_path4 ___






% ----------------------------------------- START RECSYS MODULE ------------------------------------------------------
\section{Recommender System module: RecSys}\label{sec:recsys}
The \textbf{RecSys module} allows to instantiate a recommender system and make it work on items and users serialized
by the Content Analyzer module, despite this is also possible using other serialization made with other framework and
give them as input to the recommender system and obtain score prediction or recommend items for the active user(s).
In particular this module allows has to get some general statistics on the data used, the scheme used to split the data
and train the recommender system and the settings belonging to the algorithm chosen.
\hfill\break
\hfill\break

\subsection{Statistics on data used}\label{subsec:stats}
% --- DATA STATS ---
In this experiment the statistics of the dataset used are reported in the following table:~\ref{tab:dataset_table}:
\begin{table}[ht]
    \centering
  \begin{tabular}{|c|c|}
    \hline
    \textbf{Parameter}& \textbf{Value} \\ \hline
    n\_users  & 2\\ \hline
    n\_items  & 6\\ \hline
    total\_interactions  & 6\\ \hline
    min\_score  & 1.0\\ \hline
    max\_score  & 4.0\\ \hline
    mean\_score  & 2.66667\\ \hline
    sparsity  & 0.5\\ \hline
  \end{tabular}
   \caption{Table of the Interactions}\label{tab:dataset_table}
\end{table}
\hfill\break
\hfill\break


% ------------------------------ START SUBSECTION OF PARTITIONING OF RECSYS --------------------------------------------
\subsection{Partitioning techinque used}\label{subsec:partitioning}
% KFOLD PARTITIONING TECNIQUE
K-fold cross-validation is a technique used in machine learning to assess the performance of a predictive model.
The basic idea is to divide the dataset into K subsets, or folds.
The model is then trained K times, each time using K-1 folds for training and the remaining fold for validation.
This process is repeated K times, with a different fold used as the validation set in each iteration.
\hfill\break
\hfill\break
The KFoldPartitioning has been used with the following setting:
\hfill\break
\hfill\break
The data has been shuffled before being split into batches.
The partitioning technique has been executed with the following settings:
\begin{itemize}
    \item number of splits: 2
    \item shuffle: True
    \item random state: None
    \item skip user error: True
\end{itemize}
\hfill\break
\hfill\break
% KFOLD PARTITIONING TECNIQUE ended


% end partitioning section___________


% ---------------------------------- ALGORITHM FOR RECOMMENDER SYSTEM -------------------------------------------------
\subsection{Algorithm used for the recommender system}\label{subsec:algo}
% ---RECSYS ALGORITHM ---
The framework of ClayRs allows to instantiate a recommender system in order to make list of recommendation, to achieve
this target the system need to be based on a chosen algorithm that will work with the representation of data that
we have.
In this section we will analyse which algorithm has been used for the experiment and what are the settings
given.
\hfill\break
\hfill\break

% Dealing with the principal class where the algorithm used belong to.
The recommender system is based on content.
\hfill\break
\hfill\break

% ----------------------------------------- CONTENT BASE ALGO ---------------------------------------------------------


% CENTROID VECTOR ALGO
The algorithm used is the centroid vector with the following settings:
\begin{itemize}
        \item \begin{verbatim}
     embedding_combiner: Centroid
\end{verbatim}
    \item \begin{verbatim}
     item_field: {'plot': ['tfidf_sk']}
\end{verbatim}
    \item \begin{verbatim}
     similarity: CosineSimilarity
\end{verbatim}
    \item \begin{verbatim}
     threshold: 4
\end{verbatim}
\end{itemize}
\hfill\break
\hfill\break
The mode used is rank and the number of recommendation given is
10.
The methodology used:
\begin{itemize}
    \item
     \verb| TestRatingsMethodology:|
     \begin{itemize}
            \item
            \verb| only_greater_eq: None |
          \end{itemize}
\end{itemize}
\hfill\break
\hfill\break
% centroid vector end____








% ------------------------ GRAPH BASED ALGO ------------------------------------------


% In case of the RecSys in not been used



% -------------------------------------- OPENING THE EVALUATION MODULE SECTION ---------------------------------------
\section{Evaluation Module}\label{sec:eva-module}
The \textbf{EvalModel} which is the abbreviation for Evaluation Model has the task of evaluating a recommender system,
using several state-of-the-art metrics, this allows to compare different recommender system and different algorithm of
recommendation and find out which are the strength points and which the weak ones.

\subsection{Metrics}\label{subsec:metrics}
% --- Metrics ---
During the experiment a bunch of formal metrics have been performed on the recommendation produced in order to evaluate
the performance of the system.
The metrics used are the followings:
\hfill\break
\hfill\break

% ---------------------------------------- CLASSIFICATION METRICS STARTED --------------------------------------------
% Precision report start
\subsubsection{Precision}\label{subsubsec:precision}
In ClayRS, the Precision metric is calculated as such for the \textbf{single user}:
\hfill\break
\hfill\break
    \[
         Precision_u = \frac{tp_u}{tp_u + fp_u}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $tp_u$ is the number of items which are in the recommendation list of the user and have a
       $\geq$         \textbf{2.6666666666666665}.
            \item $fp_u$ is the number of items which are in the recommendation list of the user and have a
      rating $<$         \textbf{no relevant threshold used}.
        \end{itemize}
\hfill\break
\hfill\break
In ClayRS, Precision needs those parameters:
the \textbf{relevant\_threshold}, is a parameter needed to discern relevant items and non-relevant items for every user.
If not specified, the mean rating score of every user will be used, in this experiment it has been set to
\textbf{None}.
\hfill\break
\hfill\break
% precision report ended___

% Recall report start
\subsubsection{Recall}\label{subsubsec:recall}
The Recall metric is calculated as such for the \textbf{single user}:
\hfill\break
\hfill\break
    \[
        Recall_u = \frac{tp_u}{tp_u + fn_u}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $tp_u$ is the number of items which are in the recommendation list of the user and have a
      rating $>=$         \textbf{2.6666666666666665}.
            \item $fn_u$ is the number of items which are not in the recommendation list of the user and have a
      rating $>=$         \textbf{no relevant threshold used}.
        \end{itemize}
\hfill\break
\hfill\break
In ClayRS, Recall needs those parameters:
the \textbf{relevant\_threshold}, is a parameter needed to discern relevant items and non-relevant items for every user.
If not specified, the mean rating score of every user will be used, in this experiment it has been set to
\textbf{None}.
\hfill\break
\hfill\break
% recall report end___

%FMeasure report start
\subsubsection{FMeasure}\label{subsubsec:f-meas}
The FMeasure metric combines Precision and Recall into a single metric.
It is calculated as such for the \textbf{single user}:
\hfill\break
\hfill\break
    \[
        FMeasure_u = (1 + \beta^2) \cdot \frac{P_u \cdot R_u}{(\beta^2 \cdot P_u) + R_u}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $P_u$ is the Precision calculated for the user \textbf{u}.
    \item $R_u$ is the Recall calculated for the user \textbf{u}.
    \item $\beta$ is a real factor which could weight differently Recall or Precision based on its value:
    \begin{itemize}
        \item $\beta = 1$: Equally weight Precision and Recall.
        \item $\beta > 1$: Weight Recall more.
        \item $\beta < 1$: Weight Precision more.
    \end{itemize}
\end{itemize}
\hfill\break
\hfill\break
A famous FMeasure is the F1 Metric, where $\beta = 1$, which basically is the harmonic mean of recall and
precision:
\hfill\break
\hfill\break
    \[
         F1_u = \frac{2 \cdot P_u \cdot R_u}{P_u + R_u}
    \]
\hfill\break
\hfill\break
The FMeasure metric is calculated as such for the entire system, depending on if \textbf{macro} average or
\textbf{micro} average has been chosen:
\hfill\break
\hfill\break
    \[
        FMeasure_{sys} - micro = (1 + \beta^2) \cdot \frac{P_u \cdot R_u}{(\beta^2 \cdot P_u) + R_u}
    \]
\hfill\break
\hfill\break
    \[
        FMeasure_{sys} - macro = \frac{\sum_{u \in U} FMeasure_u}{|U|}
    \]
\hfill\break
\hfill\break
During the experiment the FMeasure has been calculated with $\beta = $
1 and the relevant threshold is
\textbf{None}.
\hfill\break
\hfill\break
% FMeasure report end___

% PRECISION @K REPORT start
\subsubsection{Precision@K}\label{subsubsec:prec-k}
The Precision@K metric is calculated as such for the \textbf{single user}:
\hfill\break
\hfill\break
    \[
        Precision@K_u = \frac{tp@K_u}{tp@K_u + fp@K_u}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $tp@K_u$ is the number of items which are in the recommendation list of the user
      cutoff to the first K items and have a rating $>=$ relevant threshold in its ground truth.
    \item $tp@K_u$ is the number of items which are in the recommendation list of the user
      cutoff to the first K items** and have a rating $<$ relevant threshold in its ground truth.
\end{itemize}
\hfill\break
\hfill\break
And it is calculated as such for the entire system, depending on if \textbf{macro} average or \textbf{micro} average
has been chosen:
\hfill\break
\hfill\break
   \[
       Precision@K_{sys} - micro = \frac{\sum_{u \in U} tp@K_u}{\sum_{u \in U} tp@K_u + \sum_{u \in U} fp@K_u}
   \]
\hfill\break
\hfill\break
    \[
       Precision@K_{sys} - macro = \frac{\sum_{u \in U} Precision@K_u}{|U|}
   \]
\hfill\break
\hfill\break
During the experiment Precision@K has been used with the following settings:
\begin{itemize}
    \item \textbf{K: 5 }
    \item \textbf{relevant threshold:None }
    \item \textbf{sys average: macro }
\end{itemize}
\hfill\break
\hfill\break
% precision@k report end___

% RECALL @K REPORT start
\subsubsection{Recall@K}\label{subsubsec:rec-k}
The Recall@K metric is calculated as such for the \textbf{single user}:
\hfill\break
\hfill\break
    \[
        Recall@K_u = \frac{tp@K_u}{tp@K_u + fn@K_u}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $tp@K_u$ is the number of items which are in the recommendation list of the user
      \textbf{cutoff to the first K items} and have a rating $>=$ relevant threshold in its ground truth
    \item $tp@K_u$ is the number of items which are NOT in the recommendation list of the user
      \textbf{cutoff to the first K items} and have a rating $>=$ relevant threshold in its ground truth
\end{itemize}
\hfill\break
\hfill\break
And it is calculated as such for the entire system, depending on if \textbf{macro} average or \textbf{micro} average
has been chosen:
\hfill\break
\hfill\break
    \[
        Recall@K_{sys} - micro = \frac{\sum_{u \in U} tp@K_u}{\sum_{u \in U} tp@K_u + \sum_{u \in U} fn@K_u}
    \]
\hfill\break
\hfill\break
    \[
        Recall@K_{sys} - macro = \frac{\sum_{u \in U} Recall@K_u}{|U|}
    \]
\hfill\break
\hfill\break
During the experiment Recall@K has been used with the following settings:
\begin{itemize}
    \item \textbf{K: 5 }
    \item \textbf{relevant threshold: None }
    \item \textbf{sys average: macro }
\end{itemize}
\hfill\break
\hfill\break
% recall@k report end___

% FMEASURE @K REPORT start
\subsubsection{FMeasure@K}\label{subsubsec:f-meas-k}
The FMeasure@K metric combines Precision@K and Recall@K into a single metric.
It is calculated as such for the \textbf{single user}:
\hfill\break
\hfill\break
    \[
        FMeasure@K_u = (1 + \beta^2) \cdot \frac{P@K_u \cdot R@K_u}{(\beta^2 \cdot P@K_u) + R@K_u}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $P@K_u$ is the Precision at K calculated for the user \textbf{u}.
    \item $R@K_u$ is the Recall at K calculated for the user \textbf{u}.
    \item $\beta$ is a real factor which could weight differently Recall or Precision based on its value:
    \begin{itemize}
        \item $\beta = 1$: Equally weight Precision and Recall.
        \item $\beta > 1$: Weight Recall more.
        \item $\beta < 1$: Weight Precision more.
    \end{itemize}
\end{itemize}
\hfill\break
\hfill\break
A famous FMeasure@K is the F1@K Metric, where $\beta = 1$, which basically is the harmonic mean of recall and
precision:
\hfill\break
\hfill\break
    \[
        F1@K_u = \frac{2 \cdot P@K_u \cdot R@K_u}{P@K_u + R@K_u}
    \]
\hfill\break
\hfill\break
The FMeasure@K metric is calculated as such for the entire system, depending on if \textbf{macro} average or
\textbf{micro} average has been chosen:
\hfill\break
\hfill\break
    \[
        FMeasure@K_{sys} - micro = (1 + \beta^2) \cdot \frac{P@K_u \cdot R@K_u}{(\beta^2 \cdot P@K_u) + R@K_u}
    \]
\hfill\break
\hfill\break
    \[
        FMeasure@K_{sys} - macro = \frac{\sum_{u \in U} FMeasure@K_u}{|U|}
    \]
\hfill\break
\hfill\break
During the experiment FMeasure@K has been used with the following settings:
\begin{itemize}
    \item \textbf{K: 5}
    \item  \textbf{$\beta$: 1}
    \item \textbf{relevant threshold: None }
    \item \textbf{sys average: micro }
\end{itemize}
\hfill\break
\hfill\break
% fmeasure@k report end___

% R-PRECISION REPORT start
\subsubsection{R-Precision}\label{subsubsec:r-prec}
The R-Precision metric is calculated as such for the \textbf{single user}:
\hfill\break
\hfill\break
    \[
        R-Precision_u = \frac{tp@R_u}{tp@R_u + fp@R_u}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $R$ it's the number of relevant items for the user \textbf{u}.
    \item $tp@R_u$ is the number of items in the recommendation list of the user, up to the first   $R$ items,
        that have a rating $\geq$ the relevant threshold in its ground truth.
    \item $tp@R_u$ is the number of items in the recommendation list of the user, up to the first $R$ items,
        that have a rating $<$ \texttt{relevant\_threshold} in their ground truth.
\end{itemize}
\hfill\break
\hfill\break
And it is calculated as such for the entire system, depending on if \textbf{macro} average or \textbf{micro} average
has been chosen:
\hfill\break
\hfill\break
    \[
        Precision@R_{sys} - micro = \frac{\sum_{u \in U} tp@R_u}{\sum_{u \in U} tp@R_u + \sum_{u \in U} fp@R_u}
    \]
\hfill\break
\hfill\break
    \[
        Precision@R_{sys} - macro = \frac{\sum_{u \in U} R-Precision_u}{|U|}
    \]
\hfill\break
\hfill\break
During the experiment R-Precision has been used with the following settings:
\begin{itemize}
    \item \textbf{relevant threshold:None }
    \item \textbf{sys average: macro }
\end{itemize}
\hfill\break
\hfill\break
% r-precision report end___
% <----- classification metrics end ------->

% -------------------------------------------- ERROR METRICS STARTED ------------------------------------------------
% MSE REPORT start
\subsubsection{MSE}\label{subsubsec:mse}
The MSE abbreviation Mean Squared Error metric is calculated as such for the \textbf{single user}:
\hfill\break
\hfill\break
    \[
        MSE_u = \sum_{i \in T_u} \frac{(r_{u,i} - \hat{r}_{u,i})^2}{|T_u|}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $T_u$ is the test set of the user \textbf{u}.
    \item $r_{u, i}$ is the actual score give by user \textbf{u} to item \textbf{i}.
    \item $\hat{r}_{u, i}$ is the predicted score give by user \textbf{u} to item \textbf{i}.
\end{itemize}
\hfill\break
\hfill\break
It is calculated as such for the entire system:
\hfill\break
\hfill\break
    \[
        MSE_{sys} = \sum_{u \in T} \frac{MSE_u}{|T|}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $T$ is the \textbf{test set}.
    \item $MSE_u$ is the MSE calculated for user \textbf{u}.
\end{itemize}
\hfill\break
\hfill\break
There may be cases in which some items of the test set of the user could not be predicted
\textit{e.g. a CBRS was chosen and items were not present locally}.
In those cases, the $MSE_u$ formula becomes:
\hfill\break
\hfill\break
    \[
        MSE_u = \sum_{i \in T_u} \frac{(r_{u,i} - \hat{r}_{u,i})^2}{|T_u| - unk}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $unk$ stay for unknown is the number of items of the user test set that could not be predicted.
\end{itemize}
\hfill\break
\hfill\break
If no items of the user test set have been predicted $|T_u| - unk = 0$, then:
\hfill\break
\hfill\break
    \[
        MSE_u = NaN
    \]
\hfill\break
\hfill\break
% mse report end___

% RMSE REPORT start
\subsubsection{RMSE}\label{subsubsec:rmse}
The RMSE (Root Mean Squared Error) metric is calculated as such for the \textbf{single user}:
\hfill\break
\hfill\break
    \[
        RMSE_u = \sqrt{\sum_{i \in T_u} \frac{(r_{u,i} - \hat{r}_{u,i})^2}{|T_u|}}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $T_u$ is the test set of the user $u$.
    \item $r_{u, i}$ is the actual score give by user $u$ to item $i$.
    \item $\hat{r}_{u, i}$ is the predicted score give by user $u$ to item $i$.
\end{itemize}
\hfill\break
\hfill\break
It is calculated as such for the entire system:
\hfill\break
\hfill\break
    \[
        RMSE_{sys} = \sum_{u \in T} \frac{RMSE_u}{|T|}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $T$ is the test set.
    \item $RMSE_u$ is the RMSE calculated for user $u$.
\end{itemize}
\hfill\break
\hfill\break
There may be cases in which some items of the test set of the user could not be predicted
\textit{e.g. a CBRS was chosen and items were not present locally, a methodology different from TestRatings was chosen}.
In those cases, the $RMSE_u$ formula becomes:
\hfill\break
\hfill\break
    \[
        RMSE_u = \sqrt{\sum_{i \in T_u} \frac{(r_{u,i} - \hat{r}_{u,i})^2}{|T_u| - unk}}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $unk$ (unknown) is the number of items of the user test set that could not be predicted.
\end{itemize}
\hfill\break
\hfill\break
If no items of the user test set have been predicted $|T_u| - unk = 0$, then:
\hfill\break
\hfill\break
    \[
        RMSE_u = NaN
    \]
\hfill\break
\hfill\break
% rmse report end___

% MAE REPORT start
\subsubsection{MAE}\label{subsubsec:mae}
The MAE abbreviation of Mean Absolute Error metric is calculated as such for the \textbf{single user}:
\hfill\break
\hfill\break
    \[
        MAE_u = \sum_{i \in T_u} \frac{|r_{u,i} - \hat{r}_{u,i}|}{|T_u|}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $T_u$ is the test set of the user $u$.
    \item $r_{u, i}$ is the actual score give by user $u$ to item $i$.
    \item $\hat{r}_{u, i}$ is the predicted score give by user $u$ to item $i$.
\end{itemize}
\hfill\break
\hfill\break
It is calculated as such for the entire system:
\hfill\break
\hfill\break
    \[
        MAE_{sys} = \sum_{u \in T} \frac{MAE_u}{|T|}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $T$ is the test set.
    \item $MAE_u$ is the MAE calculated for user $u$.
\end{itemize}
\hfill\break
\hfill\break
There may be cases in which some items of the test set of the user could not be predicted
\textit{e.g. a CBRS was chosen and items were not present locally, a methodology different from TestRatings was chosen}.
In those cases, the $MAE_u$ formula becomes:
\hfill\break
\hfill\break
    \[
        MAE_u = \sum_{i \in T_u} \frac{|r_{u,i} - \hat{r}_{u,i}|}{|T_u| - unk}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $unk$ (unknown) is the number of items of the user test set that could not be predicted.
\end{itemize}
\hfill\break
\hfill\break
If no items of the user test set have been predicted $|T_u| - unk = 0$, then:
\hfill\break
\hfill\break
    \[
        MAE_u = NaN
    \]
\hfill\break
\hfill\break
% mae report end___
% <------ error metrics ended -------->

% ------------------------------------------- RANKING METRICS STARTED -----------------------------------------------
% Normalized Discounted Cumulative Gain REPORT start
\subsubsection{NDCG}\label{subsubsec:ndcg}
The NDCG abbreviation of Normalized Discounted Cumulative Gain metric is calculated for the \textbf{single user}
by first computing the DCG score using the following formula:
\hfill\break
\hfill\break
    \[
        DCG_{u}(scores_{u}) = \sum_{r\in scores_{u}}{\frac{f(r)}{log_x(2 + i)}}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $scores_{u}$ are the ground truth scores for predicted items, ordered according to the order of said items in the
        ranking for the user $u$.
    \item $f$ is a gain function \textit{linear or exponential, in particular}.
    \item $x$ is the base of the logarithm.
    \item $i$ is the index of the truth score $r$ in the list of scores $scores_{u}$.
\end{itemize}
\hfill\break
\hfill\break
If $f$ is "linear", then the truth score $r$ is returned as is.
Otherwise, in the "exponentia" case, the following formula is applied to $r$:
\hfill\break
\hfill\break
    \[
        f(r) = 2^{r} - 1
    \]
\hfill\break
\hfill\break
The NDCG for a single user is then calculated using the following formula:
\hfill\break
\hfill\break
    \[
        NDCG_u(scores_{u}) = \frac{DCG_{u}(scores_{u})}{IDCG_{u}(scores_{u})}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $IDCG_{u}$ is the DCG of the ideal ranking for the truth scores.
\end{itemize}
\hfill\break
\hfill\break
So the basic idea is to compare the actual ranking with the ideal one.
Finally, the NDCG of the entire system is calculated instead as such:
\hfill\break
\hfill\break
    \[
        NDCG_{sys} = \frac{\sum_{u} NDCG_u}{|U|}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $NDCG_u$ is the NDCG calculated for user $u$.
    \item $U$ is the set of all users.
\end{itemize}
\hfill\break
\hfill\break
The system average excludes NaN values.
\hfill\break
\hfill\break
% ndcg report end___

% NDCG@K REPORT start
\subsubsection{NDCG@k}\label{subsubsec:ndcg-k}
The NDCG@K abbreviation of Normalized Discounted Cumulative Gain at K metric is calculated for the \textbf{single user}
by using the [framework implementation of the NDCG][clayrs.evaluation.NDCG] but considering $scores_{u}$ cut at the
first $k$ predictions.
The K used for the experiment is .
\hfill\break
\hfill\break
% ndcg@k report end___

% MRR REPORT start
\subsubsection{MRR}\label{subsubsec:mrr}
The MRR abbreviation of Mean Reciprocal Rank metric is a system-wide metric, so only its result it will be returned
and not those of every user.
MRR is calculated as such:
\hfill\break
\hfill\break
    \[
        MRR_{sys} = \frac{1}{|Q|}\cdot\sum_{i=1}^{|Q|}\frac{1}{rank(i)}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $Q$ is the set of recommendation lists.
    \item $rank(i)$ is the position of the first relevant item in the i-th recommendation list.
\end{itemize}
\hfill\break
\hfill\break
% ATTENTION here we modified with \_ in case change
The MRR metric needs to discern relevant items from the not relevant ones.
To achieve this, one could pass a custom \texttt{relevant\_threshold} parameter that will be applied to every user.
If the rating of an item is $\geq$ \texttt{relevant\_threshold}, then it is considered relevant; otherwise, it is not.
If no \texttt{relevant\_threshold} parameter is passed, then for every user, its mean rating score will be used.
In this experiment, the relevant threshold used is
None.
\hfill\break
\hfill\break
% mrr report end___

% MRR@K REPORT start
\subsubsection{MRR@K}\label{subsubsec:mrr-k}
The MRR@K abbreviation of Mean Reciprocal Rank at K metric is a system-wide metric, so only its result will be returned
and not those of every user.
MRR@K is calculated as such:
\hfill\break
\hfill\break
    \[
        MRR@K_{sys} = \frac{1}{|Q|}\cdot\sum_{i=1}^{K}\frac{1}{rank(i)}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $K$ is the cutoff parameter.
    \item $Q$ is the set of recommendation lists.
    \item $rank(i)$ is the position of the first relevant item in the i-th recommendation list.
\end{itemize}
\hfill\break
\hfill\break
In this experiment, the relevant threshold used is
None.
\hfill\break
\hfill\break
% mrr@k report end___

% MAP REPORT start
\subsubsection{MAP}\label{subsubsec:map}
The MAP metric abbreviation of Mean average Precision is a ranking metric computed by first calculating the AP
abbreviation of Average Precision for each user and then taking its mean.
The AP is calculated as such for the \textbf{single user}:
\hfill\break
\hfill\break
    \[
        AP_u = \frac{1}{m_u}\sum_{i=1}^{N_u}P(i)\cdot rel(i)
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $m_u$ is the number of relevant items for the user $u$.
    \item $N_u$ is the number of recommended items for the user $u$.
    \item $P(i)$ is the precision computed at cutoff $i$.
    \item $rel(i)$ is an indicator variable that says whether the i-th item is relevant ($rel(i)=1$) or not ($rel(i)=0$).
\end{itemize}
\hfill\break
\hfill\break
After computing the AP for each user, we can compute the MAP for the whole system:
\hfill\break
\hfill\break
    \[
        MAP_{sys} = \frac{1}{|U|}\sum_{u}AP_u
    \]
\hfill\break
\hfill\break
This metric will return the AP computed for each user in the dataframe containing users results, and the MAP
computed for the whole system in the dataframe containing system results.
In this experiment the MAP has been calculated using a relevant threshold:
None.
\hfill\break
\hfill\break
% map report end___


% CORRELATION REPORT start
\subsubsection{Correlation}\label{subsubsec:corr}
The Correlation metric calculates the correlation between the ranking of a user and its ideal ranking.
The current correlation methods implemented are:
\begin{itemize}
    \item `pearson`
    \item `kendall`
    \item `spearman`
\end{itemize}
\hfill\break
\hfill\break
Every correlation method is implemented by the pandas library, so refer to its
\href{https://pandas.pydata.org/docs/reference/api/pandas.Series.corr.html}{documentation} for more information.
\hfill\break
\hfill\break
The correlation metric is calculated as such for the \textbf{single user}:
\hfill\break
\hfill\break
    \[
        Corr_u = Corr(ranking_u, ideal_ranking_u)
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $ranking_u$ is ranking of the user.
    \item $ideal_ranking_u$ is the ideal ranking for the user.
\end{itemize}
\hfill\break
\hfill\break
The ideal ranking is calculated based on the rating inside the ground truth of the user.
The Correlation metric calculated for the entire system is simply the average of every $Corr$:
\hfill\break
\hfill\break
    \[
        Corr_{sys} = \frac{\sum_{u} Corr_u}{|U|}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $Corr_u$ is the correlation of the user $u$.
    \item $U$ is the set of all users.
\end{itemize}
\hfill\break
\hfill\break
% ATTETNION here there are already \_
The system average excludes NaN values.
It's also possible to specify a cutoff parameter using the \texttt{top\_n} parameter.
If specified, only the first $n$ results of the recommendation list will be used to calculate the correlation.
For this experiment, the settings for the correlation metrics are:
\begin{itemize}
    \item method: pearson.
    \item top\_n: None.
\end{itemize}
\hfill\break
\hfill\break
% correlation report end___
% <------- ranking metrics ended ------->

% -------------------------------------------- FAIRNESS METRICS ------------------------------------------------------
% Gini Index REPORT start
\subsubsection{Gini Index}\label{subsubsec:gini}
The Gini Index metric measures inequality in recommendation lists.
It's a system-wide metric, so only its result it will be returned and not those of every user.
The metric is calculated as such:
\hfill\break
\hfill\break
    \[
        Gini_{sys} = \frac{\sum_i(2i - n - 1)x_i}{n\cdot\sum_i x_i}
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $n$ is the total number of distinct items that are being recommended.
    \item $x_i$ is the number of times that the item $i$ has been recommended.
\end{itemize}
\hfill\break
\hfill\break
A perfectly equal recommender system should recommend every item the same number of times, in which case the Gini
index would be equal to 0.
The more the recsys is "unequal", the more the Gini Index is closer to 1.
If the \texttt{'top\_n'} parameter is specified, then the Gini index will measure inequality considering only
the first $n$ items of every recommendation list of all users.
For this experiment, the \texttt{top\_n}:
None.
\hfill\break
\hfill\break
% gini index report end___

% PREDICTION COVERAGE REPORT start
\subsubsection{Prediction Coverage}\label{subsubsec:pred_cov}
The Prediction Coverage metric measures in percentage how many distinct items are being recommended in relation
to all available items.
It's a system wise metric, so only its result it will be returned and not those of every user.
The metric is calculated as such:
\hfill\break
\hfill\break
    \[
         Prediction Coverage_{sys} = (\frac{|I_p|}{|I|})\cdot100
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $I$ is the set of all available items.
    \item $I_p$ is the set of recommended items.
\end{itemize}
\hfill\break
\hfill\break
The $I$ must be specified through the 'catalog' parameter.
\hfill\break
\hfill\break
% prediction coverage report end___

% CATALOG COVERAGE REPORT start
\subsubsection{Catalog Coverage}\label{subsubsec:cat_cov}
The Catalog Coverage metric measures in percentage how many distinct items are being recommended in relation
to all available items.
It's a system-wide metric, so only its result it will be returned and not those of every user.
It differs from the Prediction Coverage since it allows for different parameters to come into play.
If no parameter is passed then it's a simple Prediction Coverage.
The metric is calculated as such:
\hfill\break
\hfill\break
    \[
         Catalog Coverage_{sys} = (\frac{|\bigcup_{j=1...N}reclist(u_j)|}{|I|})\cdot100
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $N$ is the total number of users.
    \item $reclist(u_j)$ is the set of items contained in the recommendation list of user $j$.
    \item $I$ is the set of all available items.
\end{itemize}
\hfill\break
\hfill\break
The $I$ must be specified through the 'catalog' parameter.
The recommendation list of every user ($reclist(u_j)$) can be reduced to the first n parameter with the top-n parameter,
so that catalog coverage is measured considering only the highest ranked items.
With the 'k' parameter one could specify the number of users that will be used to
calculate catalog coverage: k users will be randomly sampled and their recommendation lists will be used.
The formula above becomes:
\hfill\break
\hfill\break
    \[
        Catalog Coverage_{\text{sys}} = \left(\frac{|\bigcup_{j=1\ldots k} \text{reclist}(u_j)|}{|I|}\right) \cdot 100
    \]
\hfill\break
\hfill\break
    Where:
\begin{itemize}
    \item $k$ is the parameter specified.
\end{itemize}
\hfill\break
\hfill\break
Obviously 'k' $<$ N, else simply recommendation lists of all users will be used.
\hfill\break
\hfill\break
% catalog coverage report end___

% <------- fairness metrics end ------>

% ------------------------------------------------ PLOT METRICS STARTED ----------------------------------------------
% LONG TAIL DISTIBUTION REPORT start
\subsubsection{Long Tail Distribution}\label{subsubsec:ltd}
This metric generates the Long Tail Distribution plot and saves it in the output directory with the file name
specified.
The plot can be generated both for the truth set or the predictions set based on the on parameter:
\begin{itemize}
    \item \textbf{on = 'truth'}: in this case the long tail distribution is useful to see which are the most popular items
       the most rated ones.
    \item \textbf{on = 'pred'}: in this case the long tail distribution is useful to see which are the most recommended
        items.
\end{itemize}
\hfill\break
\hfill\break
The plot file will be saved as \texttt{out\_dir/file\_name.format}.
Since multiple splits could be evaluated at once, the overwrite parameter comes into play:
if set to \texttt{False}, files with the same name will be saved as \texttt{file\_name\_(1).format}, \texttt{file\_name\_(2).format}, etc.
so that for every split a plot is generated without overwriting any previously generated files.
\hfill\break
\hfill\break
For this experiment the Long Tail Distribution has been used with the following settings:
\begin{itemize}
    \item on: truth.
    \item format: png.
    \item overwrite: False.
\end{itemize}
\hfill\break
\hfill\break
% LTD report end___


% PopRecsCorrelation REPORT start
\subsubsection{Pop Recs Correlation}\label{subsubsec:poprc}
This metric generates a plot which has as the X-axis the popularity of each item and as Y-axis the recommendation
frequency, so that it can be easily seen the correlation between popular niche items and how many times are being
recommended.
The popularity of an item is defined as the number of times it is rated in the 'original\_ratings' parameter
divided by the total number of users in the 'original\_ratings'.
\begin{itemize}
    \item The plot file will be saved as out\_dir/file\_name.format'
\end{itemize}
\hfill\break
\hfill\break
Since multiple splits could be evaluated at once, the overwrite parameter comes into play: if set to \texttt{False},
files with the same name will be saved as \texttt{'file\_name\_(1).format'}, \texttt{'file\_name\_(2).format'}, etc.,
so that for every split, a plot is generated without overwriting any previously generated files.
\hfill\break
\hfill\break
There exists cases in which some items are not recommended even once, so in the graph could appear
zero recommendations.
One could change this behaviour thanks to the 'mode' parameter:
\begin{itemize}
    \item \textbf{mode='both'}: Two graphs will be created, the first one containing eventual zero recommendations, the
      second one where zero recommendations are excluded. This additional graph will be stored as
      \texttt{out\_dir/file\_name\_no\_zeros.format} \textit{the string '\_no\_zeros' will be added to the file\_name chosen automatically}.
    \item \textbf{mode='w\_zeros'}: Only a graph containing eventual zero recommendations will be created.
    \item \textbf{mode='no\_zeros'}: Only a graph excluding eventual zero recommendations will be created. The graph will be
      saved as \texttt{out\_dir/file\_name\_no\_zeros.format} \textit{the string '\_no\_zeros' will be added to the file\_name chosen automatically}.
\end{itemize}
\hfill\break
\hfill\break
For this experiment the PopRecsCorrelation has been used with the following settings:
\begin{itemize}
    \item mode: both.
    \item format: png.
    \item overwrite: False.
\end{itemize}
\hfill\break
\hfill\break
% PopRecsCorrelation report end___
% <------- plot metric end ----------->

% <---------------------- closing the only metric section ------------------------->



% ------------------------------- RESULT OF PERFORMACE OF THE SYSTEM ON THE FOLD -------------------------------------
\subsection{sys - fold1}\label{subsec:sys - fold1}
In the following table, we present the results of the evaluation~\ref{tab:results_table_sys - fold1}

\begin{center}
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Metric} & \textbf{Value} \\ \hline
                CatalogCoverage (PredictionCov) & 16.67 \\ \hline
                F1 - macro & 1.0 \\ \hline
                F1@5 - micro & 1.0 \\ \hline
                Gini & 0.0 \\ \hline
                MAE & 3.0 \\ \hline
                MAP & 1.0 \\ \hline
                MRR & 1.0 \\ \hline
                MRR@5 & 1.0 \\ \hline
                MSE & 9.0 \\ \hline
                NDCG & 1.0 \\ \hline
                NDCG@5 & 1.0 \\ \hline
                Precision - macro & 1.0 \\ \hline
                Precision@5 - macro & 1.0 \\ \hline
                PredictionCoverage & 16.67 \\ \hline
                R-Precision - macro & 1.0 \\ \hline
                RMSE & 3.0 \\ \hline
                Recall - macro & 1.0 \\ \hline
                Recall@5 - macro & 1.0 \\ \hline
             \end{tabular}
    \captionsetup{type=table}
    \caption{Table of the results}
    \label{tab:results_table_sys - fold1}
\end{center}
\hfill\break
\hfill\break
% end table of performance on the fold___



% ------------------------------- RESULT OF PERFORMACE OF THE SYSTEM ON THE FOLD -------------------------------------
\subsection{sys - mean}\label{subsec:sys - mean}
In the following table, we present the results of the evaluation~\ref{tab:results_table_sys - mean}

\begin{center}
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Metric} & \textbf{Value} \\ \hline
                CatalogCoverage (PredictionCov) & 16.67 \\ \hline
                F1 - macro & 1.0 \\ \hline
                F1@5 - micro & 1.0 \\ \hline
                Gini & 0.0 \\ \hline
                MAE & 3.0 \\ \hline
                MAP & 1.0 \\ \hline
                MRR & 1.0 \\ \hline
                MRR@5 & 1.0 \\ \hline
                MSE & 9.0 \\ \hline
                NDCG & 1.0 \\ \hline
                NDCG@5 & 1.0 \\ \hline
                Precision - macro & 1.0 \\ \hline
                Precision@5 - macro & 1.0 \\ \hline
                PredictionCoverage & 16.67 \\ \hline
                R-Precision - macro & 1.0 \\ \hline
                RMSE & 3.0 \\ \hline
                Recall - macro & 1.0 \\ \hline
                Recall@5 - macro & 1.0 \\ \hline
             \end{tabular}
    \captionsetup{type=table}
    \caption{Table of the results}
    \label{tab:results_table_sys - mean}
\end{center}
\hfill\break
\hfill\break
% end table of performance on the fold___



% In case of eval module is not used



\section{Conclusion on the experiment}\label{sec:conclution}
This part is for conclusion to be sum up as needed.
\hfill\break
\hfill\break

% ------------------- END OF THE REPORT COMPLETED ---------------
% closing the document
\end{document}
