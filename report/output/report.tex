\documentclass[12pt, a4paper]{article}
\title{Report ClayRS}
\author{Semantic Web Access and Personalization Research Group}
\usepackage{hyperref}
\usepackage{amsmath}


\begin{document}
\maketitle
This \LaTeX{} document was generated from yaml files for the purpose of replicability of experiments done with
\href{https://github.com/swapUniba/ClayRS}{ClayRS},
it contains information about the dataset, preprocessing methods, analysis algorithms and
the results of the experimental evaluation.
True

\section{ClayRS configurations of the experiment}\label{sec:clayrs-configurations-of-the-experiment}

\subsection{Dataset}\label{subsec:dataset}
In this experiment, the  \textbf{Movielens} \textbf{Dataset} was used.

\hfill\break
The statistics of the dataset used are reported in the following table \ref{tab:dataset_table}:

\begin{table}[ht]
    \centering
  \begin{tabular}{|c|c|}
    \hline
    \textbf{Parameter}& \textbf{Value} \\ \hline
    n\_users  & 943\\ \hline
    n\_items  & 1682\\ \hline
    total\_interactions  & 100000\\ \hline
    min\_score  & 1.0\\ \hline
    max\_score  & 5.0\\ \hline
    mean\_score  & 3.52986\\ \hline
    sparsity  & 0.93695\\ \hline
  \end{tabular}
   \caption{Table of the Interactions}\label{tab:dataset_table}
\end{table}

\hfill\break
\hfill\break

The following techniques have been used:
Gensim glove-twitter-25
has been used as word embedding.
Sbert
has been used as sentence embedding
\hfill\break

\subsection{Preprocessing}\label{subsec:preprocessing}
 %# Beginning OF THE dict['field_representations']['plot_0']['SkLearnTfIdf']
The preprocessing used is NLTK, a leading platform for building Python programs to work with human language data.
It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet,
along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing,
and semantic reasoning.

\hfill\break
In this experiment, those operations of NLTK were used:

\textbf{Strip multiple whitespace}, an operation that removes multiple whitspaces between words.




\textbf{Stopwords removal}, used to remove the stopwords occurring in the text.








\hfill\break





 %# Beginning OF THE dict['field_representations']['plot_0']['SkLearnTfIdf']
 %# END OF THE dict['field_representations']['plot_0']['Ekphrasis']




 %# Beginning OF THE dict['field_representations']['plot_0']['SkLearnTfIdf']

 %# END OF THE dict['field_representations']['plot_0']['Ekphrasis']

 %# Beginning OF THE dict['field_representations']['plot_0']['SkLearnTfIdf']

 %# END OF THE dict['field_representations']['plot_0']['Ekphrasis']

 %# Beginning OF THE dict['field_representations']['plot_0']['SkLearnTfIdf']

spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python.
spaCy is designed specifically for production use and helps you build applications that process and “understand”
large volumes of text. It can be used to build information extraction or natural language understanding systems,
or to pre-process text for deep learning.
In this experiment, those spaCy operations have been used:

\hfill\break
In this experiment, those spaCy operations were used:

\textbf{Strip multiple whitespace}, an operation that removes multiple whitspaces between words.



\textbf{Stopwords removal}, used to remove the stopwords occurring in the text.









 %# END OF THE dict['field_representations']['plot_0']['SkLearnTfIdf']

 %end of the content analyzer section

 %beginning of the recommender system section recsys
%\subsection{Interactions}

%\newpage
\subsection{Partitioning}\label{subsec:partitioning}
%\subsection{Partitioning}

The partitioning used is the Hold-Out Partitioning.
This approach splits the dataset in use into a ‘train’ set and a ‘test’ set.
The training set is what the model is trained on, and the test set is used to see how
well the model will perform on new, unseen data.
\hfill\break
\hfill\break
The train set size of this experiment is the 80.0\%
of the original dataset, while the test set is the remaining 20.0\%.
\hfill\break
\hfill\break
The data has been shuffled before being splitted into batches.


%The Hold-Out Partitioning has been used in this experiment with the following configuration:
%\begin{table}[ht]
%    \centering
%  \begin{tabular}{|c|c|}
%    \hline
%    \textbf{Parameter}& \textbf{Value} \\ \hline
%    train\_set\_size  & 0.8\\ \hline
%    shuffle  & True\\ \hline
    %\VAR total\_interactions  & None\\
    %\VAR skip\_user\_error  & True\\
%  \end{tabular}
%    \caption{Table of Hold-Out Partitioning}
%\end{table}

% end of the partitioning section

% end of the partitioning section


 %beginning recsys graph based area
\subsection{Algorithm Used}
In this experiment a Graph Based Recommender Algorithm has been used.
Specifically the NXPageRank algorithm, a Page Rank algorithm based on the networkx implementation
The PageRank can be 'personalized', in this case the PageRank will be calculated with Priors.
The alpha value used was: 0.85


% %# Beginning OF THE dict['field_representations']['plot_0']['SkLearnTfIdf']

%\begin{table}[htpb]
%    \centering
%  \begin{tabular}{|c|c|}

%    \hline
%    \textbf{Parameter}& \textbf{Value} \\ \hline
%    max\_df  & 1.0 \\ \hline
%    min\_df  & 1\\ \hline
%    max\_features  & None\\ \hline
%    vocabulary  & None\\ \hline
%    binary  & False\\ \hline
    %\VAR dtype  & <class 'numpy.float64'>\\
%    norm  & l2\\ \hline
%    use\_idf  & True\\ \hline
%    smooth\_idf  & True\\ \hline
%    sublinear\_tf  & False\\ \hline
%  \end{tabular}
%    \caption{Table of the parameters used with SkLearnTfIdf}
%\end{table}
% %# END OF THE dict['field_representations']['plot_0']['SkLearnTfIdf']



 %end recsys area
\\
 %end of the recsys section
%\newpage
 %beginning of the eval model section
\subsection{Metrics}


 %beginning of the precision section
%\subsection{Precision}



\hfill\break
In ClayRS the Precision metric is calculated as such for the \textbf{single user}:

    \[
    Precision_u = \frac{tp_u}{tp_u + fp_u}
    \]

    Where:

    - $tp_u$ is the number of items which are in the recommendation list of the user and have a
      ratingasdjiasd $\geq$                 \textbf{3.52986}

    - $fp_u$ is the number of items which are in the recommendation list of the user and have a
      rating $<$                 \textbf{3.52986}    \hfill\break



In ClayRS, Precision needs those parameters:
\hfill\break
the \textbf{relevant\_threshold}, is a parameter needed to discern relevant items and non-relevant items for every user.
If not specified, the mean rating score of every user will be used, in this experiment it has been set to
\textbf{None}.
\hfill\break\hfill\break
\textbf{sys\_average}, a parameter that specifies how the system average must be computed the default value is 'macro',
in this experiment the value of the sys\_average is \textbf{macro}.
%\begin{table}[ht]
%    \centering
%  \begin{tabular}{|c|c|}
%    \hline
%    \textbf{Parameter}& \textbf{Value} \\ \hline
%    relevant\_threshold  & None\\ \hline
%    sys\_average  & macro\\ \hline
    %\VAR precision  & <class 'numpy.float64'>\\
%  \end{tabular}
%    \caption{Table of the precision configuration}
%\end{table}

 %end of the precision section



 %beginning of the precision at k section
%\subsection{Metrics: Precision at K}
\hfill\break
\textbf{Precision at k} is the proportion of recommended items in the top-k set that are relevant.
 The Precision@K metric is calculated as such for the \textbf{single user}:

    \[
    Precision@K_u = \frac{tp@K_u}{tp@K_u + fp@K_u}
    \]

    Where:

    - $tp@K_u$ is the number of items which are in the recommendation list  of the user
      \textbf{cutoff to the first K items} and have a rating $\geq$
                        \textbf{3.52986}

    - $tp@K_u$ is the number of items which are in the recommendation list  of the user
      \textbf{cutoff to the first K items} and have a rating $<$
                        \textbf{3.52986}


In this experiment the value \textbf{k is 2},
the sys\_average is \textbf{macro}


%\begin{table}[ht]
%    \centering
%  \begin{tabular}{|c|c|}
%    \hline
%    \textbf{Parameter}& \textbf{Value} \\ \hline
%    k  & 2\\ \hline
%    sys\_average  & macro\\ \hline
    %\VAR precision  & <class 'numpy.float64'>\\
%  \end{tabular}
%   \caption{Table of the precision at k configuration}
%\end{table}
 %end of the precision at ksection

 %beginning of the fmeasure at k section
%\subsection{Metrics: F - measure at K}
\hfill\break\hfill\break
 The FMeasure@K metric combines Precision@K and Recall@K into a single metric.
 It is calculated as such for the
    \textbf{single user}:

    \[
    FMeasure_u = (1 + \beta^2) \cdot \frac{P@K_u \cdot R@K_u}{(\beta^2 \cdot P@K_u) + R@K_u}
    \]

    Where:

    - $P@K_u$ is the Precision at K calculated for the user \textbf{u}
    - $R@K_u$ is the Recall at K calculated for the user \textbf{u}
    - $\beta$ is a real factor which could weight differently Recall or Precision based on its value:

        - $\beta = 1$: Equally weight Precision and Recall
        - $\beta > 1$: Weight Recall more
        - $\beta < 1$: Weight Precision more

    A famous FMeasure@K is the F1@K Metric, where $\beta$ = 1, which basically is the harmonic mean of recall and
    precision:
    \hfill\break\hfill\break


    \[
    F1@K_u = \frac{2 \cdot P@K_u \cdot R@K_u}{P@K_u + R@K_u}
    \]




\hfill\break
\hfill\break
In this experiment \textbf{k = 1},
\text{\boldmath$\beta$} = \textbf{1} and
\textbf{sys\_average} is \textbf{macro}.

%\begin{table}[ht]
%    \centering
%  \begin{tabular}{|c|c|}
%    \hline
%    \textbf{Parameter}& \textbf{Value} \\ \hline
%    k  & 1\\ \hline
%    $\beta$  & 1\\ \hline
%    sys\_average  & macro\\ \hline
%    \end{tabular}
%    \caption{Table of the fmeasure at k configuration}
%\end{table}
% %end of the fmeasure at k section

 %beginning of sysfold 1 results
%\subsection{Sys Results fold1 :}
%\newpage
\subsection{Results}\label{sec:results}
In the following table, we present the results of the evaluation \ref{tab:results_table}
\begin{table}[!hbp]\label{tab:results_table}
    \centering
  \begin{tabular}{|c|c|}
    \hline
    \textbf{Metric}& \textbf{Value} \\ \hline
    Precision - macro & 0.55697\\ \hline
    Precision@2 - macro  & 0.6527\\ \hline
    NDCG  & 0.93529\\ \hline
    MRR  & 0.79602\\ \hline
    F1@1 - macro  & 0.04221\\ \hline
  \end{tabular}
  \caption{Table of the results}
\end{table}
 % end of sysfold 1 results

 %end of the recsys section


\end{document}