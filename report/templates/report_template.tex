\documentclass[12pt, a4paper]{article}
\title{Report ClayRS}
\author{Semantic Web Access and Personalization Research Group}
\usepackage{hyperref}


\begin{document}
\maketitle
This \LaTeX{} document was generated from yaml files for the purpose of replicability of experiments done with
\href{https://github.com/swapUniba/ClayRS}{ClayRS},
it contains information about the dataset, preprocessing methods, analysis algorithms and
the results of the experimental evaluation.

\BLOCK{ if dict['source_file'] is defined }
%\section{Report Content Analyzer}\label{sec:report-content-analyzer}
\section{ClayRS configurations of the experiment}
%The data source for the Content Analyzer is: source\_file = \VAR{dict['source_file']|safe_text}\\
\subsection{Dataset}
In this experiment, \BLOCK{ if dict['id_each_content'] == ['movielens_id']} \textbf{Movielens}\BLOCK{endif}
\textbf{Dataset} was used.


The statistics of the dataset used are reported in the following table:

\begin{table}[ht]
    \centering
  \begin{tabular}{|c|c|}
    \hline
    \textbf{Parameter}& \textbf{Value} \\ \hline
    n\_users  & \VAR{dict['interactions']['n_users']|safe_text}\\ \hline
    n\_items  & \VAR{dict['interactions']['n_items']|safe_text}\\ \hline
    total\_interactions  & \VAR{dict['interactions']['total_interactions']|safe_text}\\ \hline
    min\_score  & \VAR{dict['interactions']['min_score']|safe_text}\\ \hline
    max\_score  & \VAR{dict['interactions']['max_score']|safe_text}\\ \hline
    mean\_score  & \VAR{dict['interactions']['mean_score']|safe_text}\\ \hline
    sparsity  & \VAR{dict['interactions']['sparsity']|safe_text}\\ \hline
  \end{tabular}
   \caption{Table of the Interactions}\label{tab:table4}
\end{table}


The following techniques have been used:


\VAR{dict['field_representations']['genres_0']['WordEmbeddingTechnique']['embedding_source']|safe_text}
has been used as word embedding


\VAR{dict['field_representations']['genres_1']['SentenceEmbeddingTechnique']['embedding_source']|safe_text}
has been used as sentence embedding


\clearpage

\subsection{Preprocessing}
\BLOCK{if dict['field_representations']['plot_0']['preprocessing']['NLTK'] is defined} %# Beginning OF THE dict['field_representations']['plot_0']['SkLearnTfIdf']
The preprocessing used is NLTK, a leading platform for building Python programs to work with human language data.
It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet,
along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing,
and semantic reasoning.


The NLTK configuration for this experiment is reported in the following table:
\begin{table}[ht]
    \centering
  \begin{tabular}{|c|c|}

    \hline
    \textbf{Parameter}& \textbf{Value} \\ \hline
    strip\_multiple\_whitespace  & \VAR{dict['field_representations']['plot_0']['preprocessing']['NLTK']['strip_multiple_whitespace']|safe_text}\\ \hline
    remove\_punctuation  & \VAR{dict['field_representations']['plot_0']['preprocessing']['NLTK']['remove_punctuation']|safe_text}\\ \hline
    stopwords\_removal  & \VAR{dict['field_representations']['plot_0']['preprocessing']['NLTK']['stopwords_removal']|safe_text}\\ \hline
    url\_tagging  & \VAR{dict['field_representations']['plot_0']['preprocessing']['NLTK']['url_tagging']|safe_text}\\ \hline
    lemmatization  & \VAR{dict['field_representations']['plot_0']['preprocessing']['NLTK']['lemmatization']|safe_text}\\ \hline
    stemming  & \VAR{dict['field_representations']['plot_0']['preprocessing']['NLTK']['stemming']|safe_text}\\ \hline
    named\_entity\_recognition  & \VAR{dict['field_representations']['plot_0']['preprocessing']['NLTK']['named_entity_recognition']|safe_text}\\ \hline
    lang  & \VAR{dict['field_representations']['plot_0']['preprocessing']['NLTK']['lang']|safe_text}\\ \hline
    \end{tabular}
  \caption{Table of the parameters used with NLTK}\label{tab:table}
\end{table}


\BLOCK{if dict['field_representations']['plot_0']['SkLearnTfIdf'] is defined} %# Beginning OF THE dict['field_representations']['plot_0']['SkLearnTfIdf']

\begin{table}[htpb]
    \centering
  \begin{tabular}{|c|c|}

    \hline
    \textbf{Parameter}& \textbf{Value} \\ \hline
    max\_df  & \VAR{dict['field_representations']['plot_0']['SkLearnTfIdf']['max_df']|safe_text} \\ \hline
    min\_df  & \VAR{dict['field_representations']['plot_0']['SkLearnTfIdf']['min_df']|safe_text}\\ \hline
    max\_features  & \VAR{dict['field_representations']['plot_0']['SkLearnTfIdf']['max_features']|safe_text}\\ \hline
    vocabulary  & \VAR{dict['field_representations']['plot_0']['SkLearnTfIdf']['vocabulary']|safe_text}\\ \hline
    binary  & \VAR{dict['field_representations']['plot_0']['SkLearnTfIdf']['binary']|safe_text}\\ \hline
    %\VAR dtype  & \VAR{dict['field_representations']['plot_0']['SkLearnTfIdf']['dtype']|safe_text}\\
    norm  & \VAR{dict['field_representations']['plot_0']['SkLearnTfIdf']['norm']|safe_text}\\ \hline
    use\_idf  & \VAR{dict['field_representations']['plot_0']['SkLearnTfIdf']['use_idf']|safe_text}\\ \hline
    smooth\_idf  & \VAR{dict['field_representations']['plot_0']['SkLearnTfIdf']['smooth_idf']|safe_text}\\ \hline
    sublinear\_tf  & \VAR{dict['field_representations']['plot_0']['SkLearnTfIdf']['sublinear_tf']|safe_text}\\ \hline
  \end{tabular}
    \caption{Table of the parameters used with SkLearnTfIdf}\label{tab:table2}
\end{table}
\BLOCK{ endif } %# END OF THE dict['field_representations']['plot_0']['SkLearnTfIdf']

\BLOCK{ endif } %# END OF THE dict['field_representations']['plot_0']['NLTK']


%#\{\BLOCK{for dict_item in dict['field_representations']['plot_0']['SkLearnTfIdf'] }
%#\VAR{dict_item|safe_text} = \VAR{ dict['field_representations']['plot_0']['SkLearnTfIdf'][dict_item]|safe_text }\\
%#\BLOCK{ endfor }



 \BLOCK{if dict['field_representations']['genres_0']['preprocessing']['Spacy'] is defined} %# Beginning OF THE dict['field_representations']['plot_0']['SkLearnTfIdf']
spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python.
spaCy is designed specifically for production use and helps you build applications that process and “understand”
large volumes of text. It can be used to build information extraction or natural language understanding systems,
or to pre-process text for deep learning.
spaCy has been used in this experiment with this configuration:

\begin{table}[ht]
    \centering
  \begin{tabular}{|c|c|}

    \hline
    \textbf{Parameter}& \textbf{Value} \\ \hline
    model  & \VAR{dict['field_representations']['genres_0']['preprocessing']['Spacy']['model']|safe_text}\\ \hline
    strip\_multiple\_whitespace  & \VAR{dict['field_representations']['genres_0']['preprocessing']['Spacy']['strip_multiple_whitespace']|safe_text}\\ \hline
    remove\_punctuation  & \VAR{dict['field_representations']['genres_0']['preprocessing']['Spacy']['remove_punctuation']|safe_text}\\ \hline
    stopwords\_removal  & \VAR{dict['field_representations']['genres_0']['preprocessing']['Spacy']['stopwords_removal']|safe_text}\\ \hline
    new\_stopwords  & \VAR{dict['field_representations']['genres_0']['preprocessing']['Spacy']['new_stopwords']|safe_text}\\ \hline
    not\_stopwords  & \VAR{dict['field_representations']['genres_0']['preprocessing']['Spacy']['not_stopwords']|safe_text}\\ \hline
    lemmatization  & \VAR{dict['field_representations']['genres_0']['preprocessing']['Spacy']['lemmatization']|safe_text}\\ \hline
    url\_tagging  & \VAR{dict['field_representations']['genres_0']['preprocessing']['Spacy']['url_tagging']|safe_text}\\ \hline
    named\_entity\_recognition  & \VAR{dict['field_representations']['genres_0']['preprocessing']['Spacy']['named_entity_recognition']|safe_text}\\ \hline
  \end{tabular}
    \caption{Table of the parameters used with Spacy}\label{tab:table3}
\end{table}

\BLOCK{ endif } %# END OF THE dict['field_representations']['plot_0']['SkLearnTfIdf']

\BLOCK{ endif } %end of the content analyzer section

\BLOCK{ if dict['interactions'] is defined } %beginning of the recommender system section recsys
%\subsection{Interactions}


\subsection{Partitioning}
\BLOCK{ if dict['partitioning']['HoldOutPartitioning'] is defined}
%\subsection{Partitioning}

The partitioning used is the Hold-Out Partitioning.
This approach splits the dataset in use into a ‘train’ set and a ‘test’ set.
The training set is what the model is trained on, and the test set is used to see how
well the model will perform on new, unseen data.



The train set size of this experiment is the \VAR{dict['partitioning']['HoldOutPartitioning']['train_set_size'] * 100}\%
of the original dataset, while the test set is the remaining \VAR{(100 - (dict['partitioning']['HoldOutPartitioning']['train_set_size'] * 100))}\%.

\BLOCK{if dict['partitioning']['HoldOutPartitioning']['shuffle'] == True}
The data has been shuffled before being splitted into batches.
\BLOCK{endif}


%The Hold-Out Partitioning has been used in this experiment with the following configuration:
%\begin{table}[ht]
%    \centering
%  \begin{tabular}{|c|c|}
%    \hline
%    \textbf{Parameter}& \textbf{Value} \\ \hline
%    train\_set\_size  & \VAR{dict['partitioning']['HoldOutPartitioning']['train_set_size']|safe_text}\\ \hline
%    shuffle  & \VAR{dict['partitioning']['HoldOutPartitioning']['shuffle']|safe_text}\\ \hline
    %\VAR total\_interactions  & \VAR{dict['partitioning']['HoldOutPartitioning']['random_state']|safe_text}\\
    %\VAR skip\_user\_error  & \VAR{dict['partitioning']['HoldOutPartitioning']['skip_user_error']|safe_text}\\
%  \end{tabular}
%    \caption{Table of Hold-Out Partitioning}
%\end{table}

\BLOCK{endif}% end of the partitioning section

\BLOCK{if dict['recsys']['GraphBasedRS']['algorithm']['NXPageRank'] is defined} %beginning recsys graph based area
%\subsection{Algorithm Graph Based}
In this experiment a Graph Based Recommender Algorithm has been used.
Specifically the NXPageRank algorithm, a Page Rank algorithm based on the networkx implementation
The PageRank can be 'personalized', in this case the PageRank will be calculated with Priors.
The alpha value used was: \VAR{dict['recsys']['GraphBasedRS']['algorithm']['NXPageRank']['alpha']|safe_text}




\BLOCK{endif} %end recsys area
\\
\BLOCK{endif} %end of the recsys section

\BLOCK{ if dict['metrics'] is defined } %beginning of the eval model section
\section{Metrics}


\BLOCK{if dict['metrics']['Precision'] is defined} %beginning of the precision section
%\subsection{Precision}


In the field of information retrieval, the metric \textbf{Precision} is the fraction
of retrieved documents that are relevant to the query.


In ClayRS the Precision metric is calculated as such for the \textbf{single user}:

    \[
    Precision_u = \frac{tp_u}{tp_u + fp_u}
    \]

    Where:

    - $tp_u$ is the number of items which are in the recommendation list of the user and have a
      rating $\geq$ relevant\_threshold in its 'ground truth'

    - $fp_u$ is the number of items which are in the recommendation list of the user and have a
      rating $<$ relevant\_threshold in its 'ground truth'



    And it is calculated as such for the \textbf{entire system}, depending if 'macro' average or 'micro' average has been
    chosen:

    \[
    Precision_{sys} - micro = \frac{\sum_{u \in U} tp_u}{\sum_{u \in U} tp_u + \sum_{u \in U} fp_u}
    \]


    \[
    Precision_{sys} - macro = \frac{\sum_{u \in U} Precision_u}{|U|}
    \]
In ClayRS, Precision needs those parameters:

the \textbf{relevant\_threshold}, is a parameter needed to discern relevant items and non-relevant items for every user.
If not specified, the mean rating score of every user will be used, in this experiment it has been set to
\textbf{\VAR{dict['metrics']['Precision']['relevant_threshold']|safe_text}}.

\textbf{sys\_average}, a parameter that specifies how the system average must be computed the default value is 'macro',
in this experiment the value of the sys\_average is \textbf{\VAR{dict['metrics']['Precision']['sys_average']|safe_text}}.
%\begin{table}[ht]
%    \centering
%  \begin{tabular}{|c|c|}
%    \hline
%    \textbf{Parameter}& \textbf{Value} \\ \hline
%    relevant\_threshold  & \VAR{dict['metrics']['Precision']['relevant_threshold']|safe_text}\\ \hline
%    sys\_average  & \VAR{dict['metrics']['Precision']['sys_average']|safe_text}\\ \hline
    %\VAR precision  & \VAR{dict['metrics']['Precision']['precision']|safe_text}\\
%  \end{tabular}
%    \caption{Table of the precision configuration}
%\end{table}

\BLOCK{endif} %end of the precision section



\BLOCK{if dict['metrics']['PrecisionAtK'] is defined} %beginning of the precision at k section
%\subsection{Metrics: Precision at K}

\textbf{Precision at k} is the proportion of recommended items in the top-k set that are relevant.
 The Precision@K metric is calculated as such for the \textbf{single user}:

    \[
    Precision@K_u = \frac{tp@K_u}{tp@K_u + fp@K_u}
    \]

    Where:

    - $tp@K_u$ is the number of items which are in the recommendation list  of the user
      \textbf{cutoff to the first K items} and have a rating $\geq$ relevant\_threshold in its 'ground truth'

    - $tp@K_u$ is the number of items which are in the recommendation list  of the user
      \textbf{cutoff to the first K items} and have a rating $<$ relevant\_threshold in its 'ground truth'

    And it is calculated as such for the **entire system**, depending if 'macro' average or 'micro' average has been
    chosen:

    \[
    Precision@K_{sys} - micro = \frac{\sum_{u \in U} tp@K_u}{\sum_{u \in U} tp@K_u + \sum_{u \in U} fp@K_u}
    \]

    \[
    Precision@K_{sys} - macro = \frac{\sum_{u \in U} Precision@K_u}{|U|}
    \]



In this experiment the value \textbf{k is \VAR{dict['metrics']['PrecisionAtK']['k']|safe_text}},
the sys\_average is \textbf{\VAR{dict['metrics']['PrecisionAtK']['sys_average']|safe_text}}


%\begin{table}[ht]
%    \centering
%  \begin{tabular}{|c|c|}
%    \hline
%    \textbf{Parameter}& \textbf{Value} \\ \hline
%    k  & \VAR{dict['metrics']['PrecisionAtK']['k']|safe_text}\\ \hline
%    sys\_average  & \VAR{dict['metrics']['PrecisionAtK']['sys_average']|safe_text}\\ \hline
    %\VAR precision  & \VAR{dict['metrics']['PrecisionAtK']['precision']|safe_text}\\
%  \end{tabular}
%   \caption{Table of the precision at k configuration}
%\end{table}
\BLOCK{endif} %end of the precision at ksection

\BLOCK{if dict['metrics']['FMeasureAtK'] is defined} %beginning of the fmeasure at k section
%\subsection{Metrics: F - measure at K}

The F-measure of the system is defined as the weighted harmonic mean of its precision and recall

\begin{table}[ht]
    \centering
  \begin{tabular}{|c|c|}
    \hline
    \textbf{Parameter}& \textbf{Value} \\ \hline
    k  & \VAR{dict['metrics']['FMeasureAtK']['k']|safe_text}\\ \hline
    beta  & \VAR{dict['metrics']['FMeasureAtK']['beta']|safe_text}\\ \hline
    sys\_average  & \VAR{dict['metrics']['FMeasureAtK']['sys_average']|safe_text}\\ \hline
    \end{tabular}
    \caption{Table of the fmeasure at k configuration}
\end{table}
\BLOCK{endif} %end of the fmeasure at k section

\BLOCK{if dict['sys_results']['sys - fold1'] is defined} %beginning of sysfold 1 results
%\subsection{Sys Results fold1 :}

\begin{table}[!hbp]
    \centering
  \begin{tabular}{|c|c|}
    \hline
    \textbf{Metric}& \textbf{Value} \\ \hline
    Precision - macro & \VAR{dict['sys_results']['sys - fold1']['Precision - macro']|safe_text}\\ \hline
    Precision@2 - macro  & \VAR{dict['sys_results']['sys - fold1']['Precision@2 - macro']|safe_text}\\ \hline
    NDCG  & \VAR{dict['sys_results']['sys - fold1']['NDCG']|safe_text}\\ \hline
    MRR  & \VAR{dict['sys_results']['sys - fold1']['MRR']|safe_text}\\ \hline
    F1@1 - macro  & \VAR{dict['sys_results']['sys - fold1']['F1@1 - macro']|safe_text}\\ \hline
  \end{tabular}
  \caption{Table of the results}
\end{table}
\BLOCK{endif} % end of sysfold 1 results

\BLOCK{endif} %end of the recsys section


\end{document}