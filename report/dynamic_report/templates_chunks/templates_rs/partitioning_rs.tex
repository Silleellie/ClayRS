
###

% --------------- START SECTION OF PARTITIONING ------------------------------------

\subsection{Partitioning techinque used}\label{subsec:partitioning}
\BLOCK{if  my_dict['partitioning']['KFoldPartitioning'] is defined}
% KFOLD PARTITIONING TECNIQUE
K-fold cross-validation is a technique used in machine learning to assess
the performance of a predictive model. The basic idea is to divide the dataset
into K subsets, or folds. The model is then trained K times, each time using K-1
folds for training and the remaining fold for validation. This process is
repeated K times, with a different fold used as the validation set in each iteration
\hfill\break
\hfill\break
The KFoldPartitioning has been used with the following setting:
\hfill\break
\hfill\break
The train set size of this experiment is the \VAR{my_dict['partitioning']['KFoldPartitioning']['train_set_size'] * 100}\%
of the original dataset, while the test set is the remaining \VAR{(100 - (my_dict['partitioning']['KFoldPartitioning']['train_set_size'] * 100))}\%.
\hfill\break
\hfill\break
\BLOCK{if my_dict.get('partitioning', {}).get('KFoldPartitioning', {}).get('shuffle') == True}
The data has been shuffled before being split into batches.
The partitioning technique has been executed with the following settings:
\begin{itemize}
    \item number of splits: \VAR{my_dict['partitioning']['KFoldPartitioning']['n_splits']}
    \item shuffle: \VAR{my_dict['partitioning']['KFoldPartitioning']['shuffle']}
    \item random state: \VAR{my_dict['partitioning']['KFoldPartitioning']['random_state']|default('no random state applied')}
    \item skip user error: \VAR{my_dict['partitioning']['KFoldPartitioning']['skip_user_error']|default('no setted')}
\end{itemize}
\BLOCK{endif}
% KFOLD PARTITIONING TECNIQUE ended

\BLOCK{elif  my_dict['partitioning']['HoldOutPartitioning'] is defined}
%  HOLD-OUT PARTIONING TECNIQUE
The partitioning used is the Hold-Out Partitioning.
This approach splits the dataset in use into a ‘train’ set and a ‘test’ set.
The training set is what the model is trained on, and the test set is used to see how
well the model will perform on new, unseen data.
\hfill\break
\hfill\break
The train set size of this experiment is the \VAR{my_dict['partitioning']['HoldOutPartitioning']['train_set_size'] * 100}\%
of the original dataset, while the test set is the remaining \VAR{(100 - (my_dict['partitioning']['HoldOutPartitioning']['train_set_size'] * 100))}\%.
\hfill\break
\hfill\break
\BLOCK{ if my_dict.get('partitioning', {}).get('HoldOutPartitioning', {}).get('shuffle') == True }
The data has been shuffled before being split into batches.
%  HOLD-OUT PARTIONING TECNIQUE ended

\BLOCK{endif}

\BLOCK{elif}

\BLOCK{else}

\BLOCK{endif}


###