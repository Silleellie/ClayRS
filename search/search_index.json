{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Warning Docs are complete, but revision is still a Work in Progress. Sorry for any typos! Welcome to ClayRS's documentation! ClayRS is a python framework for (mainly) content-based recommender systems which allows you to perform several operations, starting from a raw representation of users and items to building and evaluating a recommender system. It also supports graph-based recommendation with feature selection algorithms and graph manipulation methods. The framework has three main modules, which you can also use individually: Given a raw source, the Content Analyzer : Creates and serializes contents, Using the chosen configuration The RecSys module allows to: Instantiate a recommender system Using items and users serialized by the Content Analyzer Make score prediction or recommend items for the active user(s) The EvalModel has the task of evaluating a recommender system, using several state-of-the-art metrics The various sections of this documentation will guide you in becoming a full expert of ClayRS !","title":"Home"},{"location":"#welcome-to-clayrss-documentation","text":"ClayRS is a python framework for (mainly) content-based recommender systems which allows you to perform several operations, starting from a raw representation of users and items to building and evaluating a recommender system. It also supports graph-based recommendation with feature selection algorithms and graph manipulation methods. The framework has three main modules, which you can also use individually: Given a raw source, the Content Analyzer : Creates and serializes contents, Using the chosen configuration The RecSys module allows to: Instantiate a recommender system Using items and users serialized by the Content Analyzer Make score prediction or recommend items for the active user(s) The EvalModel has the task of evaluating a recommender system, using several state-of-the-art metrics The various sections of this documentation will guide you in becoming a full expert of ClayRS !","title":"Welcome to ClayRS's documentation!"},{"location":"content_analyzer/config/","text":"Content Analyzer Config ContentAnalyzerConfig ( source , id , output_directory , field_dict = None , exogenous_representation_list = None , export_json = False ) Bases: ABC Abstract class that represents the configuration for the content analyzer. The configuration specifies how the Content Analyzer needs to complexly represent contents, i.e. how to preprocess them and how to represent them PARAMETER DESCRIPTION source Raw data source wrapper which contains original information about contents to process TYPE: RawInformationSource id Field of the raw source which represents each content uniquely. TYPE: Union [ str , List [ str ]] output_directory Where contents complexly represented will be serialized TYPE: str field_dict Dictionary object which contains, for each field of the raw source to process, a FieldConfig object (e.g. {'plot': FieldConfig(SkLearnTfIdf(), 'genres': FieldConfig(WhooshTfIdf()))} ) TYPE: Dict [ str , List [ FieldConfig ]] DEFAULT: None exogenous_representation_list List of ExogenousTechnique objects that will be used to expand each contents with data from external sources TYPE: Union [ ExogenousConfig , List [ ExogenousConfig ]] DEFAULT: None export_json If set to True, contents complexly represented will be serialized in a human readable JSON, other than in a proprietary format of the framework TYPE: bool DEFAULT: False Source code in clayrs/content_analyzer/config.py 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 def __init__ ( self , source : RawInformationSource , id : Union [ str , List [ str ]], output_directory : str , field_dict : Dict [ str , List [ FieldConfig ]] = None , exogenous_representation_list : Union [ ExogenousConfig , List [ ExogenousConfig ]] = None , export_json : bool = False ): if field_dict is None : field_dict = {} if exogenous_representation_list is None : exogenous_representation_list = [] self . __source = source self . __id = id self . __output_directory = output_directory self . __field_dict = field_dict self . __exogenous_representation_list = exogenous_representation_list self . __export_json = export_json if not isinstance ( self . __exogenous_representation_list , list ): self . __exogenous_representation_list = [ self . __exogenous_representation_list ] if not isinstance ( self . __id , list ): self . __id = [ self . __id ] add_multiple_config ( field_name , config_list ) Method which adds multiple complex representations for the field_name of the raw source Examples: Represent preprocessed field \"Plot\" of the raw source with a tf-idf technique using sklearn and a word embedding technique using Word2Vec. For the latter, no preprocessing operation will be applied >>> import clayrs.content_analyzer as ca >>> movies_ca_config . add_multiple_config ( \"Plot\" , >>> [ FieldConfig ( ca . SkLearnTfIdf (), >>> preprocessing = ca . NLTK ( stopwords_removal = True )), >>> >>> FieldConfig ( ca . WordEmbeddingTechnique ( ca . GensimWord2Vec ()))] PARAMETER DESCRIPTION field_name field name of the raw source which must be complexly represented TYPE: str config_list List of FieldConfig objects specifying how to represent the field of the raw source TYPE: List [ FieldConfig ] Source code in clayrs/content_analyzer/config.py 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 def add_multiple_config ( self , field_name : str , config_list : List [ FieldConfig ]): \"\"\" Method which adds multiple complex representations for the `field_name` of the raw source Examples: * Represent preprocessed field \"Plot\" of the raw source with a tf-idf technique using sklearn and a word embedding technique using Word2Vec. For the latter, no preprocessing operation will be applied >>> import clayrs.content_analyzer as ca >>> movies_ca_config.add_multiple_config(\"Plot\", >>> [FieldConfig(ca.SkLearnTfIdf(), >>> preprocessing=ca.NLTK(stopwords_removal=True)), >>> >>> FieldConfig(ca.WordEmbeddingTechnique(ca.GensimWord2Vec()))] Args: field_name: field name of the raw source which must be complexly represented config_list: List of `FieldConfig` objects specifying how to represent the field of the raw source \"\"\" # If the field_name is not in the field_dict keys it means there is no list to append the FieldConfig to, # so a new list is instantiated if self . __field_dict . get ( field_name ) is not None : self . __field_dict [ field_name ] . extend ( config_list ) else : self . __field_dict [ field_name ] = list () self . __field_dict [ field_name ] . extend ( config_list ) add_multiple_exogenous ( config_list ) Method which adds multiple exogenous representations which will be used to expand each content Examples: Expand each content by using DBPedia as external source and local dataset as external source >>> import clayrs.content_analyzer as ca >>> movies_ca_config . add_single_exogenous ( >>> [ >>> ca . ExogenousConfig ( >>> ca . DBPediaMappingTechnique ( 'dbo:Film' , 'Title' , 'EN' ) >>> ), >>> >>> ca . ExogenousConfig ( >>> ca . PropertiesFromDataset ( field_name_list = [ 'director' ]) >>> ), >>> ] >>> ) PARAMETER DESCRIPTION config_list List containing ExogenousConfig objects specifying how to expand each content TYPE: List [ ExogenousConfig ] Source code in clayrs/content_analyzer/config.py 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 def add_multiple_exogenous ( self , config_list : List [ ExogenousConfig ]): \"\"\" Method which adds multiple exogenous representations which will be used to expand each content Examples: * Expand each content by using DBPedia as external source and local dataset as external source >>> import clayrs.content_analyzer as ca >>> movies_ca_config.add_single_exogenous( >>> [ >>> ca.ExogenousConfig( >>> ca.DBPediaMappingTechnique('dbo:Film', 'Title', 'EN') >>> ), >>> >>> ca.ExogenousConfig( >>> ca.PropertiesFromDataset(field_name_list=['director']) >>> ), >>> ] >>> ) Args: config_list: List containing `ExogenousConfig` objects specifying how to expand each content \"\"\" self . __exogenous_representation_list . extend ( config_list ) add_single_config ( field_name , field_config ) Method which adds a single complex representation for the field_name of the raw source Examples: Represent field \"Plot\" of the raw source with a tf-idf technique using sklearn >>> import clayrs.content_analyzer as ca >>> movies_ca_config . add_single_config ( \"Plot\" , FieldConfig ( ca . SkLearnTfIdf ())) PARAMETER DESCRIPTION field_name field name of the raw source which must be complexly represented TYPE: str field_config FieldConfig specifying how to represent the field of the raw source TYPE: FieldConfig Source code in clayrs/content_analyzer/config.py 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 def add_single_config ( self , field_name : str , field_config : FieldConfig ): \"\"\" Method which adds a single complex representation for the `field_name` of the raw source Examples: * Represent field \"Plot\" of the raw source with a tf-idf technique using sklearn >>> import clayrs.content_analyzer as ca >>> movies_ca_config.add_single_config(\"Plot\", FieldConfig(ca.SkLearnTfIdf())) Args: field_name: field name of the raw source which must be complexly represented field_config: `FieldConfig` specifying how to represent the field of the raw source \"\"\" # If the field_name is not in the field_dict keys it means there is no list to append the FieldConfig to, # so a new list is instantiated if self . __field_dict . get ( field_name ) is not None : self . __field_dict [ field_name ] . append ( field_config ) else : self . __field_dict [ field_name ] = list () self . __field_dict [ field_name ] . append ( field_config ) add_single_exogenous ( exogenous_config ) Method which adds a single exogenous representation which will be used to expand each content Examples: Expand each content by using DBPedia as external source >>> import clayrs.content_analyzer as ca >>> movies_ca_config . add_single_exogenous ( >>> ca . ExogenousConfig ( >>> ca . DBPediaMappingTechnique ( 'dbo:Film' , 'Title' , 'EN' ) >>> ) >>> ) PARAMETER DESCRIPTION exogenous_config ExogenousConfig object specifying how to expand each content TYPE: ExogenousConfig Source code in clayrs/content_analyzer/config.py 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 def add_single_exogenous ( self , exogenous_config : ExogenousConfig ): \"\"\" Method which adds a single exogenous representation which will be used to expand each content Examples: * Expand each content by using DBPedia as external source >>> import clayrs.content_analyzer as ca >>> movies_ca_config.add_single_exogenous( >>> ca.ExogenousConfig( >>> ca.DBPediaMappingTechnique('dbo:Film', 'Title', 'EN') >>> ) >>> ) Args: exogenous_config: `ExogenousConfig` object specifying how to expand each content \"\"\" self . __exogenous_representation_list . append ( exogenous_config ) exogenous_representation_list () property Getter for the exogenous_representation_list Source code in clayrs/content_analyzer/config.py 270 271 272 273 274 275 @property def exogenous_representation_list ( self ) -> List [ ExogenousConfig ]: \"\"\" Getter for the exogenous_representation_list \"\"\" return self . __exogenous_representation_list export_json () property Getter for the export_json parameter Source code in clayrs/content_analyzer/config.py 277 278 279 280 281 282 @property def export_json ( self ) -> bool : \"\"\" Getter for the export_json parameter \"\"\" return self . __export_json get_configs_list ( field_name ) Method which returns the list of all FieldConfig objects specified for the input field_name parameter PARAMETER DESCRIPTION field_name Name of the field for which the list of field configs will be retrieved TYPE: str RETURNS DESCRIPTION List [ FieldConfig ] List containing all FieldConfig objects specified for the input field_name Source code in clayrs/content_analyzer/config.py 284 285 286 287 288 289 290 291 292 293 294 def get_configs_list ( self , field_name : str ) -> List [ FieldConfig ]: \"\"\" Method which returns the list of all `FieldConfig` objects specified for the input `field_name` parameter Args: field_name: Name of the field for which the list of field configs will be retrieved Returns: List containing all `FieldConfig` objects specified for the input `field_name` \"\"\" return [ config for config in self . __field_dict [ field_name ]] get_field_name_list () Method which returns a list containing all the fields of the raw source for which at least one FieldConfig object has been assigned (i.e. at least one complex representations is specified) RETURNS DESCRIPTION List [ str ] List of all the fields of the raw source that must be complexly represented Source code in clayrs/content_analyzer/config.py 296 297 298 299 300 301 302 303 304 def get_field_name_list ( self ) -> List [ str ]: \"\"\" Method which returns a list containing all the fields of the raw source for which at least one `FieldConfig` object has been assigned (i.e. at least one complex representations is specified) Returns: List of all the fields of the raw source that must be complexly represented \"\"\" return list ( self . __field_dict . keys ()) id () property Getter for the id that represents the ids of the produced contents Source code in clayrs/content_analyzer/config.py 256 257 258 259 260 261 @property def id ( self ) -> List [ str ]: \"\"\" Getter for the id that represents the ids of the produced contents \"\"\" return self . __id output_directory () property Getter for the output directory where the produced contents will be stored Source code in clayrs/content_analyzer/config.py 249 250 251 252 253 254 @property def output_directory ( self ): \"\"\" Getter for the output directory where the produced contents will be stored \"\"\" return self . __output_directory source () property Getter for the raw information source where the original contents are stored Source code in clayrs/content_analyzer/config.py 263 264 265 266 267 268 @property def source ( self ) -> RawInformationSource : \"\"\" Getter for the raw information source where the original contents are stored \"\"\" return self . __source ExogenousConfig ( exogenous_technique , id = None ) Class that represents the configuration for a single exogenous representation. The config allows the user to specify an ExogenousPropertiesRetrieval technique to use to expand each content. W.r.t FieldConfig objects, an ExogenousConfig does not refer to a particular field but to the whole content itself. You can use the id parameter to assign a custom id for the representation: by doing so the user can freely refer to it by using the custom id given, rather than positional integers (which are given automatically by the framework). This will create an exogenous representation for the content by expanding it using DBPedia, said representation will be named 'test' ExogenousConfig ( DBPediaMappingTechnique ( 'dbo:Film' , 'Title' , 'EN' ), id = 'test' ) Same as the example above, but since no custom id was assigned, the exogenous representation can be referred to only with an integer (0 if it's the first exogenous representation specified for the contents, 1 if it's the second, etc.) ExogenousConfig ( DBPediaMappingTechnique ( 'dbo:Film' , 'Title' , 'EN' )) PARAMETER DESCRIPTION exogenous_technique Technique which will be used to expand each content with data from external sources. An example would be the DBPediaMappingTechnique which allows to retrieve properties from DBPedia. TYPE: ExogenousPropertiesRetrieval id Custom id that can be used later by the user to easily refer to the representation generated by this config. IDs for a single field should be unique! And should only contain '_', '-' and alphanumeric characters TYPE: str DEFAULT: None Source code in clayrs/content_analyzer/config.py 174 175 176 177 178 179 def __init__ ( self , exogenous_technique : ExogenousPropertiesRetrieval , id : str = None ): if id is not None : self . _check_custom_id ( id ) self . __exogenous_technique = exogenous_technique self . __id = id exogenous_technique () property Getter for the exogenous properties retrieval technique Source code in clayrs/content_analyzer/config.py 181 182 183 184 185 186 @property def exogenous_technique ( self ): \"\"\" Getter for the exogenous properties retrieval technique \"\"\" return self . __exogenous_technique id () property Getter for the ExogenousConfig id Source code in clayrs/content_analyzer/config.py 188 189 190 191 192 193 @property def id ( self ): \"\"\" Getter for the ExogenousConfig id \"\"\" return self . __id FieldConfig ( content_technique = OriginalData (), preprocessing = None , memory_interface = None , id = None ) Class that represents the configuration for a single representation of a field. The configuration of a single representation is defined by a FieldContentProductionTechnique (e.g. an EmbeddingTechnique ) that will be applied to the pre-processed data of said field. To specify how to preprocess data, simply specify an InformationProcessor in the preprocessing parameter. Multiple InformationProcessor can be wrapped in a list: in this case, the field will be preprocessed by performing operations all objects inside the list. If preprocessing is not defined, no preprocessing operations will be done on the field data. You can use the id parameter to assign a custom id for the representation: by doing so the user can freely refer to it by using the custom id given, rather than positional integers (which are given automatically by the framework). There is also a memory_interface attribute which allows to define a data structure where the representation will be serialized (e.g. an Index). Various configurations are possible depending on how the user wants to represent a particular field: This will produce a field representation using the SkLearnTfIdf technique on the field data preprocessed by NLTK by performing stopwords removal, and the name of the produced representation will be 'field_example' FieldConfig ( SkLearnTfIdf (), NLTK ( stopwords_removal = True ), id = 'field_example' ) This will produce the same result as above but the id for the field representation defined by this config will be set by the ContentAnalyzer once it is being processed (0 integer if it's the first representation specified for the field, 1 if it's the second, etc.) FieldConfig ( SkLearnTfIdf (), NLTK ()) This will produce a field representation using the SkLearnTfIdf technique on the field data without applying any preprocessing operation, but it will not be directly stored in the content, instead it will be stored in a index FieldConfig ( SkLearnTfIdf (), memory_interface = SearchIndex ( / somedir )) In the following nothing will be done on the field data, it will be represented as is FieldConfig () PARAMETER DESCRIPTION content_technique Technique that will be applied to the field in order to produce a complex representation of said field TYPE: FieldContentProductionTechnique DEFAULT: OriginalData() preprocessing Single InformationProcessor object or a list of InformationProcessor objects that will be used preprocess field data before applying the content_technique TYPE: Union [ InformationProcessor , List [ InformationProcessor ]] DEFAULT: None memory_interface complex structure where the content representation can be serialized (an Index for example) TYPE: InformationInterface DEFAULT: None id Custom id that can be used later by the user to easily refer to the representation generated by this config. IDs for a single field should be unique! And should only contain '_', '-' and alphanumeric characters TYPE: str DEFAULT: None Source code in clayrs/content_analyzer/config.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def __init__ ( self , content_technique : FieldContentProductionTechnique = OriginalData (), preprocessing : Union [ InformationProcessor , List [ InformationProcessor ]] = None , memory_interface : InformationInterface = None , id : str = None ): if preprocessing is None : preprocessing = [] if id is not None : self . _check_custom_id ( id ) self . __content_technique = content_technique self . __preprocessing = preprocessing self . __memory_interface = memory_interface self . __id = id if not isinstance ( self . __preprocessing , list ): self . __preprocessing = [ self . __preprocessing ] content_technique () property Getter for the field content production technique of the field Source code in clayrs/content_analyzer/config.py 107 108 109 110 111 112 @property def content_technique ( self ): \"\"\" Getter for the field content production technique of the field \"\"\" return self . __content_technique id () property Getter for the id of the field config Source code in clayrs/content_analyzer/config.py 121 122 123 124 125 126 @property def id ( self ): \"\"\" Getter for the id of the field config \"\"\" return self . __id memory_interface () property Getter for the index associated to the field config Source code in clayrs/content_analyzer/config.py 100 101 102 103 104 105 @property def memory_interface ( self ): \"\"\" Getter for the index associated to the field config \"\"\" return self . __memory_interface preprocessing () property Getter for the list of preprocessor of the field config Source code in clayrs/content_analyzer/config.py 114 115 116 117 118 119 @property def preprocessing ( self ): \"\"\" Getter for the list of preprocessor of the field config \"\"\" return self . __preprocessing ItemAnalyzerConfig Bases: ContentAnalyzerConfig Class that represents the configuration for the content analyzer. The configuration specifies how the Content Analyzer needs to complexly represent contents, i.e. how to preprocess them and how to represent them In particular this class refers to items . Examples: >>> import clayrs.content_analyzer as ca >>> raw_source = ca . JSONFile ( json_path ) >>> movies_config = ca . ItemAnalyzerConfig ( raw_source , id = 'movie_id' , output_directory = 'movies_codified/' ) >>> # add single field config >>> movies_config . add_single_config ( 'occupation' , FieldConfig ( content_technique = ca . OriginalData ())) >>> # add single exogenous technique >>> movies_config . add_single_exogenous ( ca . ExogenousConfig ( ca . PropertiesFromDataset ( field_name_list = [ 'gender' ])) UserAnalyzerConfig Bases: ContentAnalyzerConfig Class that represents the configuration for the content analyzer. The configuration specifies how the Content Analyzer needs to complexly represent contents, i.e. how to preprocess them and how to represent them In particular this class refers to users . Examples: >>> import clayrs.content_analyzer as ca >>> raw_source = ca . JSONFile ( json_path ) >>> users_config = ca . UserAnalyzerConfig ( raw_source , id = 'user_id' , output_directory = 'users_codified/' ) >>> # add single field config >>> users_config . add_single_config ( 'occupation' , FieldConfig ( content_technique = ca . OriginalData ())) >>> # add single exogenous technique >>> users_config . add_single_exogenous ( ca . ExogenousConfig ( ca . PropertiesFromDataset ( field_name_list = [ 'gender' ])) Content Analyzer Class ContentAnalyzer ( config ) Class to whom the control of the content analysis phase is delegated. It uses the data stored in the configuration file to create and serialize the contents the user wants to produce. It also checks that the configurations the user wants to run on the raw contents have unique ids (otherwise it would be impossible to refer to a particular field representation or exogenous representation) PARAMETER DESCRIPTION config configuration for processing the item fields. This parameter provides the possibility of customizing the way in which the input data is processed. TYPE: ContentAnalyzerConfig Source code in clayrs/content_analyzer/content_analyzer_main.py 33 34 def __init__ ( self , config : ContentAnalyzerConfig ): self . _config : ContentAnalyzerConfig = config fit () Processes the creation of the contents and serializes the contents. This method starts the content production process and initializes everything that will be used to create said contents, their fields and their representations Source code in clayrs/content_analyzer/content_analyzer_main.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def fit ( self ): \"\"\" Processes the creation of the contents and serializes the contents. This method starts the content production process and initializes everything that will be used to create said contents, their fields and their representations \"\"\" # before starting the process, the content analyzer manin checks that there are no duplicate id cases # both in the field dictionary and in the exogenous representation list # this is done now and not recursively for each content during the creation process, in order to avoid starting # an operation that is going to fail try : self . __check_field_dict () self . __check_exogenous_representation_list () except ValueError as e : raise e # creates the directory where the data will be serialized and overwrites it if it already exists output_path = self . _config . output_directory if os . path . exists ( output_path ): shutil . rmtree ( output_path ) os . makedirs ( output_path ) contents_producer = ContentsProducer . get_instance () contents_producer . set_config ( self . _config ) created_contents = contents_producer . create_contents () if self . _config . export_json : json_path = os . path . join ( self . _config . output_directory , 'contents.json' ) with open ( json_path , \"w\" ) as data : json . dump ( created_contents , data , cls = ContentEncoder , indent = 4 ) with get_progbar ( created_contents ) as pbar : pbar . set_description ( \"Serializing contents\" ) for content in pbar : self . __serialize_content ( content )","title":"Content Analyzer config and class"},{"location":"content_analyzer/config/#content-analyzer-config","text":"","title":"Content Analyzer Config"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ContentAnalyzerConfig","text":"Bases: ABC Abstract class that represents the configuration for the content analyzer. The configuration specifies how the Content Analyzer needs to complexly represent contents, i.e. how to preprocess them and how to represent them PARAMETER DESCRIPTION source Raw data source wrapper which contains original information about contents to process TYPE: RawInformationSource id Field of the raw source which represents each content uniquely. TYPE: Union [ str , List [ str ]] output_directory Where contents complexly represented will be serialized TYPE: str field_dict Dictionary object which contains, for each field of the raw source to process, a FieldConfig object (e.g. {'plot': FieldConfig(SkLearnTfIdf(), 'genres': FieldConfig(WhooshTfIdf()))} ) TYPE: Dict [ str , List [ FieldConfig ]] DEFAULT: None exogenous_representation_list List of ExogenousTechnique objects that will be used to expand each contents with data from external sources TYPE: Union [ ExogenousConfig , List [ ExogenousConfig ]] DEFAULT: None export_json If set to True, contents complexly represented will be serialized in a human readable JSON, other than in a proprietary format of the framework TYPE: bool DEFAULT: False Source code in clayrs/content_analyzer/config.py 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 def __init__ ( self , source : RawInformationSource , id : Union [ str , List [ str ]], output_directory : str , field_dict : Dict [ str , List [ FieldConfig ]] = None , exogenous_representation_list : Union [ ExogenousConfig , List [ ExogenousConfig ]] = None , export_json : bool = False ): if field_dict is None : field_dict = {} if exogenous_representation_list is None : exogenous_representation_list = [] self . __source = source self . __id = id self . __output_directory = output_directory self . __field_dict = field_dict self . __exogenous_representation_list = exogenous_representation_list self . __export_json = export_json if not isinstance ( self . __exogenous_representation_list , list ): self . __exogenous_representation_list = [ self . __exogenous_representation_list ] if not isinstance ( self . __id , list ): self . __id = [ self . __id ]","title":"ContentAnalyzerConfig"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ContentAnalyzerConfig.add_multiple_config","text":"Method which adds multiple complex representations for the field_name of the raw source Examples: Represent preprocessed field \"Plot\" of the raw source with a tf-idf technique using sklearn and a word embedding technique using Word2Vec. For the latter, no preprocessing operation will be applied >>> import clayrs.content_analyzer as ca >>> movies_ca_config . add_multiple_config ( \"Plot\" , >>> [ FieldConfig ( ca . SkLearnTfIdf (), >>> preprocessing = ca . NLTK ( stopwords_removal = True )), >>> >>> FieldConfig ( ca . WordEmbeddingTechnique ( ca . GensimWord2Vec ()))] PARAMETER DESCRIPTION field_name field name of the raw source which must be complexly represented TYPE: str config_list List of FieldConfig objects specifying how to represent the field of the raw source TYPE: List [ FieldConfig ] Source code in clayrs/content_analyzer/config.py 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 def add_multiple_config ( self , field_name : str , config_list : List [ FieldConfig ]): \"\"\" Method which adds multiple complex representations for the `field_name` of the raw source Examples: * Represent preprocessed field \"Plot\" of the raw source with a tf-idf technique using sklearn and a word embedding technique using Word2Vec. For the latter, no preprocessing operation will be applied >>> import clayrs.content_analyzer as ca >>> movies_ca_config.add_multiple_config(\"Plot\", >>> [FieldConfig(ca.SkLearnTfIdf(), >>> preprocessing=ca.NLTK(stopwords_removal=True)), >>> >>> FieldConfig(ca.WordEmbeddingTechnique(ca.GensimWord2Vec()))] Args: field_name: field name of the raw source which must be complexly represented config_list: List of `FieldConfig` objects specifying how to represent the field of the raw source \"\"\" # If the field_name is not in the field_dict keys it means there is no list to append the FieldConfig to, # so a new list is instantiated if self . __field_dict . get ( field_name ) is not None : self . __field_dict [ field_name ] . extend ( config_list ) else : self . __field_dict [ field_name ] = list () self . __field_dict [ field_name ] . extend ( config_list )","title":"add_multiple_config()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ContentAnalyzerConfig.add_multiple_exogenous","text":"Method which adds multiple exogenous representations which will be used to expand each content Examples: Expand each content by using DBPedia as external source and local dataset as external source >>> import clayrs.content_analyzer as ca >>> movies_ca_config . add_single_exogenous ( >>> [ >>> ca . ExogenousConfig ( >>> ca . DBPediaMappingTechnique ( 'dbo:Film' , 'Title' , 'EN' ) >>> ), >>> >>> ca . ExogenousConfig ( >>> ca . PropertiesFromDataset ( field_name_list = [ 'director' ]) >>> ), >>> ] >>> ) PARAMETER DESCRIPTION config_list List containing ExogenousConfig objects specifying how to expand each content TYPE: List [ ExogenousConfig ] Source code in clayrs/content_analyzer/config.py 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 def add_multiple_exogenous ( self , config_list : List [ ExogenousConfig ]): \"\"\" Method which adds multiple exogenous representations which will be used to expand each content Examples: * Expand each content by using DBPedia as external source and local dataset as external source >>> import clayrs.content_analyzer as ca >>> movies_ca_config.add_single_exogenous( >>> [ >>> ca.ExogenousConfig( >>> ca.DBPediaMappingTechnique('dbo:Film', 'Title', 'EN') >>> ), >>> >>> ca.ExogenousConfig( >>> ca.PropertiesFromDataset(field_name_list=['director']) >>> ), >>> ] >>> ) Args: config_list: List containing `ExogenousConfig` objects specifying how to expand each content \"\"\" self . __exogenous_representation_list . extend ( config_list )","title":"add_multiple_exogenous()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ContentAnalyzerConfig.add_single_config","text":"Method which adds a single complex representation for the field_name of the raw source Examples: Represent field \"Plot\" of the raw source with a tf-idf technique using sklearn >>> import clayrs.content_analyzer as ca >>> movies_ca_config . add_single_config ( \"Plot\" , FieldConfig ( ca . SkLearnTfIdf ())) PARAMETER DESCRIPTION field_name field name of the raw source which must be complexly represented TYPE: str field_config FieldConfig specifying how to represent the field of the raw source TYPE: FieldConfig Source code in clayrs/content_analyzer/config.py 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 def add_single_config ( self , field_name : str , field_config : FieldConfig ): \"\"\" Method which adds a single complex representation for the `field_name` of the raw source Examples: * Represent field \"Plot\" of the raw source with a tf-idf technique using sklearn >>> import clayrs.content_analyzer as ca >>> movies_ca_config.add_single_config(\"Plot\", FieldConfig(ca.SkLearnTfIdf())) Args: field_name: field name of the raw source which must be complexly represented field_config: `FieldConfig` specifying how to represent the field of the raw source \"\"\" # If the field_name is not in the field_dict keys it means there is no list to append the FieldConfig to, # so a new list is instantiated if self . __field_dict . get ( field_name ) is not None : self . __field_dict [ field_name ] . append ( field_config ) else : self . __field_dict [ field_name ] = list () self . __field_dict [ field_name ] . append ( field_config )","title":"add_single_config()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ContentAnalyzerConfig.add_single_exogenous","text":"Method which adds a single exogenous representation which will be used to expand each content Examples: Expand each content by using DBPedia as external source >>> import clayrs.content_analyzer as ca >>> movies_ca_config . add_single_exogenous ( >>> ca . ExogenousConfig ( >>> ca . DBPediaMappingTechnique ( 'dbo:Film' , 'Title' , 'EN' ) >>> ) >>> ) PARAMETER DESCRIPTION exogenous_config ExogenousConfig object specifying how to expand each content TYPE: ExogenousConfig Source code in clayrs/content_analyzer/config.py 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 def add_single_exogenous ( self , exogenous_config : ExogenousConfig ): \"\"\" Method which adds a single exogenous representation which will be used to expand each content Examples: * Expand each content by using DBPedia as external source >>> import clayrs.content_analyzer as ca >>> movies_ca_config.add_single_exogenous( >>> ca.ExogenousConfig( >>> ca.DBPediaMappingTechnique('dbo:Film', 'Title', 'EN') >>> ) >>> ) Args: exogenous_config: `ExogenousConfig` object specifying how to expand each content \"\"\" self . __exogenous_representation_list . append ( exogenous_config )","title":"add_single_exogenous()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ContentAnalyzerConfig.exogenous_representation_list","text":"Getter for the exogenous_representation_list Source code in clayrs/content_analyzer/config.py 270 271 272 273 274 275 @property def exogenous_representation_list ( self ) -> List [ ExogenousConfig ]: \"\"\" Getter for the exogenous_representation_list \"\"\" return self . __exogenous_representation_list","title":"exogenous_representation_list()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ContentAnalyzerConfig.export_json","text":"Getter for the export_json parameter Source code in clayrs/content_analyzer/config.py 277 278 279 280 281 282 @property def export_json ( self ) -> bool : \"\"\" Getter for the export_json parameter \"\"\" return self . __export_json","title":"export_json()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ContentAnalyzerConfig.get_configs_list","text":"Method which returns the list of all FieldConfig objects specified for the input field_name parameter PARAMETER DESCRIPTION field_name Name of the field for which the list of field configs will be retrieved TYPE: str RETURNS DESCRIPTION List [ FieldConfig ] List containing all FieldConfig objects specified for the input field_name Source code in clayrs/content_analyzer/config.py 284 285 286 287 288 289 290 291 292 293 294 def get_configs_list ( self , field_name : str ) -> List [ FieldConfig ]: \"\"\" Method which returns the list of all `FieldConfig` objects specified for the input `field_name` parameter Args: field_name: Name of the field for which the list of field configs will be retrieved Returns: List containing all `FieldConfig` objects specified for the input `field_name` \"\"\" return [ config for config in self . __field_dict [ field_name ]]","title":"get_configs_list()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ContentAnalyzerConfig.get_field_name_list","text":"Method which returns a list containing all the fields of the raw source for which at least one FieldConfig object has been assigned (i.e. at least one complex representations is specified) RETURNS DESCRIPTION List [ str ] List of all the fields of the raw source that must be complexly represented Source code in clayrs/content_analyzer/config.py 296 297 298 299 300 301 302 303 304 def get_field_name_list ( self ) -> List [ str ]: \"\"\" Method which returns a list containing all the fields of the raw source for which at least one `FieldConfig` object has been assigned (i.e. at least one complex representations is specified) Returns: List of all the fields of the raw source that must be complexly represented \"\"\" return list ( self . __field_dict . keys ())","title":"get_field_name_list()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ContentAnalyzerConfig.id","text":"Getter for the id that represents the ids of the produced contents Source code in clayrs/content_analyzer/config.py 256 257 258 259 260 261 @property def id ( self ) -> List [ str ]: \"\"\" Getter for the id that represents the ids of the produced contents \"\"\" return self . __id","title":"id()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ContentAnalyzerConfig.output_directory","text":"Getter for the output directory where the produced contents will be stored Source code in clayrs/content_analyzer/config.py 249 250 251 252 253 254 @property def output_directory ( self ): \"\"\" Getter for the output directory where the produced contents will be stored \"\"\" return self . __output_directory","title":"output_directory()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ContentAnalyzerConfig.source","text":"Getter for the raw information source where the original contents are stored Source code in clayrs/content_analyzer/config.py 263 264 265 266 267 268 @property def source ( self ) -> RawInformationSource : \"\"\" Getter for the raw information source where the original contents are stored \"\"\" return self . __source","title":"source()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ExogenousConfig","text":"Class that represents the configuration for a single exogenous representation. The config allows the user to specify an ExogenousPropertiesRetrieval technique to use to expand each content. W.r.t FieldConfig objects, an ExogenousConfig does not refer to a particular field but to the whole content itself. You can use the id parameter to assign a custom id for the representation: by doing so the user can freely refer to it by using the custom id given, rather than positional integers (which are given automatically by the framework). This will create an exogenous representation for the content by expanding it using DBPedia, said representation will be named 'test' ExogenousConfig ( DBPediaMappingTechnique ( 'dbo:Film' , 'Title' , 'EN' ), id = 'test' ) Same as the example above, but since no custom id was assigned, the exogenous representation can be referred to only with an integer (0 if it's the first exogenous representation specified for the contents, 1 if it's the second, etc.) ExogenousConfig ( DBPediaMappingTechnique ( 'dbo:Film' , 'Title' , 'EN' )) PARAMETER DESCRIPTION exogenous_technique Technique which will be used to expand each content with data from external sources. An example would be the DBPediaMappingTechnique which allows to retrieve properties from DBPedia. TYPE: ExogenousPropertiesRetrieval id Custom id that can be used later by the user to easily refer to the representation generated by this config. IDs for a single field should be unique! And should only contain '_', '-' and alphanumeric characters TYPE: str DEFAULT: None Source code in clayrs/content_analyzer/config.py 174 175 176 177 178 179 def __init__ ( self , exogenous_technique : ExogenousPropertiesRetrieval , id : str = None ): if id is not None : self . _check_custom_id ( id ) self . __exogenous_technique = exogenous_technique self . __id = id","title":"ExogenousConfig"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ExogenousConfig.exogenous_technique","text":"Getter for the exogenous properties retrieval technique Source code in clayrs/content_analyzer/config.py 181 182 183 184 185 186 @property def exogenous_technique ( self ): \"\"\" Getter for the exogenous properties retrieval technique \"\"\" return self . __exogenous_technique","title":"exogenous_technique()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ExogenousConfig.id","text":"Getter for the ExogenousConfig id Source code in clayrs/content_analyzer/config.py 188 189 190 191 192 193 @property def id ( self ): \"\"\" Getter for the ExogenousConfig id \"\"\" return self . __id","title":"id()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.FieldConfig","text":"Class that represents the configuration for a single representation of a field. The configuration of a single representation is defined by a FieldContentProductionTechnique (e.g. an EmbeddingTechnique ) that will be applied to the pre-processed data of said field. To specify how to preprocess data, simply specify an InformationProcessor in the preprocessing parameter. Multiple InformationProcessor can be wrapped in a list: in this case, the field will be preprocessed by performing operations all objects inside the list. If preprocessing is not defined, no preprocessing operations will be done on the field data. You can use the id parameter to assign a custom id for the representation: by doing so the user can freely refer to it by using the custom id given, rather than positional integers (which are given automatically by the framework). There is also a memory_interface attribute which allows to define a data structure where the representation will be serialized (e.g. an Index). Various configurations are possible depending on how the user wants to represent a particular field: This will produce a field representation using the SkLearnTfIdf technique on the field data preprocessed by NLTK by performing stopwords removal, and the name of the produced representation will be 'field_example' FieldConfig ( SkLearnTfIdf (), NLTK ( stopwords_removal = True ), id = 'field_example' ) This will produce the same result as above but the id for the field representation defined by this config will be set by the ContentAnalyzer once it is being processed (0 integer if it's the first representation specified for the field, 1 if it's the second, etc.) FieldConfig ( SkLearnTfIdf (), NLTK ()) This will produce a field representation using the SkLearnTfIdf technique on the field data without applying any preprocessing operation, but it will not be directly stored in the content, instead it will be stored in a index FieldConfig ( SkLearnTfIdf (), memory_interface = SearchIndex ( / somedir )) In the following nothing will be done on the field data, it will be represented as is FieldConfig () PARAMETER DESCRIPTION content_technique Technique that will be applied to the field in order to produce a complex representation of said field TYPE: FieldContentProductionTechnique DEFAULT: OriginalData() preprocessing Single InformationProcessor object or a list of InformationProcessor objects that will be used preprocess field data before applying the content_technique TYPE: Union [ InformationProcessor , List [ InformationProcessor ]] DEFAULT: None memory_interface complex structure where the content representation can be serialized (an Index for example) TYPE: InformationInterface DEFAULT: None id Custom id that can be used later by the user to easily refer to the representation generated by this config. IDs for a single field should be unique! And should only contain '_', '-' and alphanumeric characters TYPE: str DEFAULT: None Source code in clayrs/content_analyzer/config.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 def __init__ ( self , content_technique : FieldContentProductionTechnique = OriginalData (), preprocessing : Union [ InformationProcessor , List [ InformationProcessor ]] = None , memory_interface : InformationInterface = None , id : str = None ): if preprocessing is None : preprocessing = [] if id is not None : self . _check_custom_id ( id ) self . __content_technique = content_technique self . __preprocessing = preprocessing self . __memory_interface = memory_interface self . __id = id if not isinstance ( self . __preprocessing , list ): self . __preprocessing = [ self . __preprocessing ]","title":"FieldConfig"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.FieldConfig.content_technique","text":"Getter for the field content production technique of the field Source code in clayrs/content_analyzer/config.py 107 108 109 110 111 112 @property def content_technique ( self ): \"\"\" Getter for the field content production technique of the field \"\"\" return self . __content_technique","title":"content_technique()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.FieldConfig.id","text":"Getter for the id of the field config Source code in clayrs/content_analyzer/config.py 121 122 123 124 125 126 @property def id ( self ): \"\"\" Getter for the id of the field config \"\"\" return self . __id","title":"id()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.FieldConfig.memory_interface","text":"Getter for the index associated to the field config Source code in clayrs/content_analyzer/config.py 100 101 102 103 104 105 @property def memory_interface ( self ): \"\"\" Getter for the index associated to the field config \"\"\" return self . __memory_interface","title":"memory_interface()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.FieldConfig.preprocessing","text":"Getter for the list of preprocessor of the field config Source code in clayrs/content_analyzer/config.py 114 115 116 117 118 119 @property def preprocessing ( self ): \"\"\" Getter for the list of preprocessor of the field config \"\"\" return self . __preprocessing","title":"preprocessing()"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.ItemAnalyzerConfig","text":"Bases: ContentAnalyzerConfig Class that represents the configuration for the content analyzer. The configuration specifies how the Content Analyzer needs to complexly represent contents, i.e. how to preprocess them and how to represent them In particular this class refers to items . Examples: >>> import clayrs.content_analyzer as ca >>> raw_source = ca . JSONFile ( json_path ) >>> movies_config = ca . ItemAnalyzerConfig ( raw_source , id = 'movie_id' , output_directory = 'movies_codified/' ) >>> # add single field config >>> movies_config . add_single_config ( 'occupation' , FieldConfig ( content_technique = ca . OriginalData ())) >>> # add single exogenous technique >>> movies_config . add_single_exogenous ( ca . ExogenousConfig ( ca . PropertiesFromDataset ( field_name_list = [ 'gender' ]))","title":"ItemAnalyzerConfig"},{"location":"content_analyzer/config/#clayrs.content_analyzer.config.UserAnalyzerConfig","text":"Bases: ContentAnalyzerConfig Class that represents the configuration for the content analyzer. The configuration specifies how the Content Analyzer needs to complexly represent contents, i.e. how to preprocess them and how to represent them In particular this class refers to users . Examples: >>> import clayrs.content_analyzer as ca >>> raw_source = ca . JSONFile ( json_path ) >>> users_config = ca . UserAnalyzerConfig ( raw_source , id = 'user_id' , output_directory = 'users_codified/' ) >>> # add single field config >>> users_config . add_single_config ( 'occupation' , FieldConfig ( content_technique = ca . OriginalData ())) >>> # add single exogenous technique >>> users_config . add_single_exogenous ( ca . ExogenousConfig ( ca . PropertiesFromDataset ( field_name_list = [ 'gender' ]))","title":"UserAnalyzerConfig"},{"location":"content_analyzer/config/#content-analyzer-class","text":"","title":"Content Analyzer Class"},{"location":"content_analyzer/config/#clayrs.content_analyzer.ContentAnalyzer","text":"Class to whom the control of the content analysis phase is delegated. It uses the data stored in the configuration file to create and serialize the contents the user wants to produce. It also checks that the configurations the user wants to run on the raw contents have unique ids (otherwise it would be impossible to refer to a particular field representation or exogenous representation) PARAMETER DESCRIPTION config configuration for processing the item fields. This parameter provides the possibility of customizing the way in which the input data is processed. TYPE: ContentAnalyzerConfig Source code in clayrs/content_analyzer/content_analyzer_main.py 33 34 def __init__ ( self , config : ContentAnalyzerConfig ): self . _config : ContentAnalyzerConfig = config","title":"ContentAnalyzer"},{"location":"content_analyzer/config/#clayrs.content_analyzer.content_analyzer_main.ContentAnalyzer.fit","text":"Processes the creation of the contents and serializes the contents. This method starts the content production process and initializes everything that will be used to create said contents, their fields and their representations Source code in clayrs/content_analyzer/content_analyzer_main.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def fit ( self ): \"\"\" Processes the creation of the contents and serializes the contents. This method starts the content production process and initializes everything that will be used to create said contents, their fields and their representations \"\"\" # before starting the process, the content analyzer manin checks that there are no duplicate id cases # both in the field dictionary and in the exogenous representation list # this is done now and not recursively for each content during the creation process, in order to avoid starting # an operation that is going to fail try : self . __check_field_dict () self . __check_exogenous_representation_list () except ValueError as e : raise e # creates the directory where the data will be serialized and overwrites it if it already exists output_path = self . _config . output_directory if os . path . exists ( output_path ): shutil . rmtree ( output_path ) os . makedirs ( output_path ) contents_producer = ContentsProducer . get_instance () contents_producer . set_config ( self . _config ) created_contents = contents_producer . create_contents () if self . _config . export_json : json_path = os . path . join ( self . _config . output_directory , 'contents.json' ) with open ( json_path , \"w\" ) as data : json . dump ( created_contents , data , cls = ContentEncoder , indent = 4 ) with get_progbar ( created_contents ) as pbar : pbar . set_description ( \"Serializing contents\" ) for content in pbar : self . __serialize_content ( content )","title":"fit()"},{"location":"content_analyzer/index_interface/","text":"Index interface IndexInterface ( directory ) Bases: TextInterface Abstract class that takes care of serializing and deserializing text in an indexed structure using the Whoosh library PARAMETER DESCRIPTION directory Path of the directory where the content will be serialized TYPE: str Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 26 27 28 29 30 31 def __init__ ( self , directory : str ): super () . __init__ ( directory ) self . __doc = None # document that is currently being created and will be added to the index self . __writer = None # index writer self . __doc_index = 0 # current position the document will have in the index once it is serialized self . __schema_changed = False # true if the schema has been changed, false otherwise get_field ( field_name , content_id ) Uses a search index to retrieve the content corresponding to the content_id (if it is a string) or in the corresponding position (if it is an integer), and returns the data in the field corresponding to the field_name PARAMETER DESCRIPTION field_name name of the field from which the data will be retrieved TYPE: str content_id either the position or Id of the content that contains the specified field TYPE: Union [ str , int ] RETURNS DESCRIPTION str Data contained in the field of the content Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def get_field ( self , field_name : str , content_id : Union [ str , int ]) -> str : \"\"\" Uses a search index to retrieve the content corresponding to the content_id (if it is a string) or in the corresponding position (if it is an integer), and returns the data in the field corresponding to the field_name Args: field_name (str): name of the field from which the data will be retrieved content_id (Union[str, int]): either the position or Id of the content that contains the specified field Returns: Data contained in the field of the content \"\"\" ix = open_dir ( self . directory ) with ix . searcher () as searcher : if isinstance ( content_id , str ): query = Term ( \"content_id\" , content_id ) result = searcher . search ( query ) result = result [ 0 ][ field_name ] elif isinstance ( content_id , int ): result = searcher . reader () . stored_fields ( content_id )[ field_name ] return result get_tf_idf ( field_name , content_id ) Calculates the tf-idf for the words contained in the field of the content whose id is content_id (if it is a string) or in the given position (if it is an integer). The tf-idf computation formula is: \\[ tf \\mbox{-} idf = (1 + log10(tf)) * log10(idf) \\] PARAMETER DESCRIPTION field_name Name of the field containing the words for which calculate the tf-idf TYPE: str content_id either the position or Id of the content that contains the specified field TYPE: Union [ str , int ] RETURNS DESCRIPTION words_bag Dictionary whose keys are the words contained in the field, and the corresponding values are the tf-idf values TYPE: Dict [ str , float ] Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def get_tf_idf ( self , field_name : str , content_id : Union [ str , int ]) -> Dict [ str , float ]: r \"\"\" Calculates the tf-idf for the words contained in the field of the content whose id is content_id (if it is a string) or in the given position (if it is an integer). The tf-idf computation formula is: $$ tf \\mbox{-} idf = (1 + log10(tf)) * log10(idf) $$ Args: field_name: Name of the field containing the words for which calculate the tf-idf content_id: either the position or Id of the content that contains the specified field Returns: words_bag: Dictionary whose keys are the words contained in the field, and the corresponding values are the tf-idf values \"\"\" ix = open_dir ( self . directory ) words_bag = {} with ix . searcher () as searcher : if isinstance ( content_id , str ): query = Term ( \"content_id\" , content_id ) doc_num = searcher . search ( query ) . docnum ( 0 ) elif isinstance ( content_id , int ): doc_num = content_id # if the document has the field == \"\" (length == 0) then the bag of word is empty if len ( searcher . ixreader . stored_fields ( doc_num )[ field_name ]) > 0 : # retrieves the frequency vector (used for tf) list_with_freq = [ term_with_freq for term_with_freq in searcher . vector ( doc_num , field_name ) . items_as ( \"frequency\" )] for term , freq in list_with_freq : tf = 1 + math . log10 ( freq ) idf = math . log10 ( searcher . doc_count () / searcher . doc_frequency ( field_name , term )) words_bag [ term ] = tf * idf return words_bag init_writing ( delete_old = False ) Creates the index locally (in the directory passed in the constructor) and initializes the index writer. If an index already exists in the directory, what happens depend on the attribute delete_old passed as argument PARAMETER DESCRIPTION delete_old if True, the index that was in the same directory is destroyed and replaced; if False, the index is simply opened TYPE: bool DEFAULT: False Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def init_writing ( self , delete_old : bool = False ): \"\"\" Creates the index locally (in the directory passed in the constructor) and initializes the index writer. If an index already exists in the directory, what happens depend on the attribute delete_old passed as argument Args: delete_old (bool): if True, the index that was in the same directory is destroyed and replaced; if False, the index is simply opened \"\"\" if os . path . exists ( self . directory ): if delete_old : self . delete () os . mkdir ( self . directory ) ix = create_in ( self . directory , Schema ()) self . __writer = ix . writer () else : ix = open_dir ( self . directory ) self . __writer = ix . writer () self . __doc_index = self . __writer . reader () . doc_count () else : os . mkdir ( self . directory ) ix = create_in ( self . directory , Schema ()) self . __writer = ix . writer () new_content () The new content is a document that will be indexed. In this case the document is a dictionary with the name of the field as key and the data inside the field as value Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 67 68 69 70 71 72 def new_content ( self ): \"\"\" The new content is a document that will be indexed. In this case the document is a dictionary with the name of the field as key and the data inside the field as value \"\"\" self . __doc = {} new_field ( field_name , field_data ) Adds a new field to the document that is being created. Since the index Schema is generated dynamically, if the field name is not in the Schema already it is added to it PARAMETER DESCRIPTION field_name Name of the new field TYPE: str field_data Data to put into the field TYPE: object Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 74 75 76 77 78 79 80 81 82 83 84 85 86 def new_field ( self , field_name : str , field_data : object ): \"\"\" Adds a new field to the document that is being created. Since the index Schema is generated dynamically, if the field name is not in the Schema already it is added to it Args: field_name (str): Name of the new field field_data (object): Data to put into the field \"\"\" if field_name not in open_dir ( self . directory ) . schema . names (): self . __writer . add_field ( field_name , self . schema_type ) self . __schema_changed = True self . __doc [ field_name ] = field_data query ( string_query , results_number , mask_list = None , candidate_list = None , classic_similarity = True ) Uses a search index to query the index in order to retrieve specific contents using a query expressed in string form PARAMETER DESCRIPTION string_query query expressed as a string TYPE: str results_number number of results the searcher will return for the query TYPE: int mask_list list of content_ids of items to ignore in the search process TYPE: list DEFAULT: None candidate_list list of content_ids of items to consider in the search process, if it is not None only items in the list will be considered TYPE: list DEFAULT: None classic_similarity if True, classic tf idf is used for scoring, otherwise BM25F is used TYPE: bool DEFAULT: True RETURNS DESCRIPTION results the final results dictionary containing the results found from the search index for the query. The dictionary will be in the following form: {content_id: {\"item\": item_dictionary, \"score\": item_score}, ...} content_id is the content_id for the corresponding item item_dictionary is the dictionary of the item containing the fields as keys and the contents as values. So it will be in the following form: {\"Plot\": \"this is the plot\", \"Genre\": \"this is the Genre\"} The item_dictionary will not contain the content_id since it is already defined and used as key of the external dictionary items_score is the score given to the item for the query by the index searcher TYPE: dict Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 def query ( self , string_query : str , results_number : int , mask_list : list = None , candidate_list : list = None , classic_similarity : bool = True ) -> dict : \"\"\" Uses a search index to query the index in order to retrieve specific contents using a query expressed in string form Args: string_query: query expressed as a string results_number: number of results the searcher will return for the query mask_list: list of content_ids of items to ignore in the search process candidate_list: list of content_ids of items to consider in the search process, if it is not None only items in the list will be considered classic_similarity: if True, classic tf idf is used for scoring, otherwise BM25F is used Returns: results: the final results dictionary containing the results found from the search index for the query. The dictionary will be in the following form: {content_id: {\"item\": item_dictionary, \"score\": item_score}, ...} content_id is the content_id for the corresponding item item_dictionary is the dictionary of the item containing the fields as keys and the contents as values. So it will be in the following form: {\"Plot\": \"this is the plot\", \"Genre\": \"this is the Genre\"} The item_dictionary will not contain the content_id since it is already defined and used as key of the external dictionary items_score is the score given to the item for the query by the index searcher \"\"\" ix = open_dir ( self . directory ) with ix . searcher ( weighting = TF_IDF if classic_similarity else BM25F ) as searcher : candidate_query_list = None mask_query_list = None # the mask list contains the content_id for the items to ignore in the searching process # from the mask list a mask query is created and it will be used by the searcher if mask_list is not None : mask_query_list = [] for document in mask_list : mask_query_list . append ( Term ( \"content_id\" , document )) mask_query_list = Or ( mask_query_list ) # the candidate list contains the content_id for the items to consider in the searching process # from the candidate list a candidate query is created and it will be used by the searcher if candidate_list is not None : candidate_query_list = [] for candidate in candidate_list : candidate_query_list . append ( Term ( \"content_id\" , candidate )) candidate_query_list = Or ( candidate_query_list ) schema = ix . schema parser = QueryParser ( \"content_id\" , schema = schema , group = OrGroup ) # regular expression to match the possible field styles # examples: \"content_id\" or \"Genre#2\" or \"Genre#2#custom_id\" parser . add_plugin ( FieldsPlugin ( r '(?P<text>[\\w-]+(\\#[\\w-]+(\\#[\\w-]+)?)?|[*]):' )) query = parser . parse ( string_query ) score_docs = \\ searcher . search ( query , limit = results_number , filter = candidate_query_list , mask = mask_query_list ) # creation of the results dictionary, This phase is necessary because the Hit objects returned by the # searcher as results need the reader inside the search index in order to return information # so it would be impossible to access a field or the score of the item from outside this method # because of that this dictionary containing the most important infos is created results = {} for hit in score_docs : hit_dict = dict ( hit ) content_id = hit_dict . pop ( \"content_id\" ) results [ content_id ] = {} results [ content_id ][ \"item\" ] = hit_dict results [ content_id ][ \"score\" ] = hit . score return results schema_type () abstractmethod property Whoosh uses a Schema that defines, for each field of the content, how to store the data. In the case of this project, every field will have the same structure and will share the same field type. This method returns said field type. Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 33 34 35 36 37 38 39 40 41 @property @abc . abstractmethod def schema_type ( self ): \"\"\" Whoosh uses a Schema that defines, for each field of the content, how to store the data. In the case of this project, every field will have the same structure and will share the same field type. This method returns said field type. \"\"\" raise NotImplementedError serialize_content () Serializes the content in the index. If the schema changed, the writer will commit the changes to the schema before adding the document to the index. Once the document is indexed, it can be deleted from the IndexInterface and the document position in the index is returned Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 def serialize_content ( self ) -> int : \"\"\" Serializes the content in the index. If the schema changed, the writer will commit the changes to the schema before adding the document to the index. Once the document is indexed, it can be deleted from the IndexInterface and the document position in the index is returned \"\"\" if self . __schema_changed : self . __writer . commit () self . __writer = open_dir ( self . directory ) . writer () self . __schema_changed = False self . __writer . add_document ( ** self . __doc ) del self . __doc self . __doc_index += 1 return self . __doc_index - 1 stop_writing () Stops the index writer and commits the operations Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 103 104 105 106 107 108 def stop_writing ( self ): \"\"\" Stops the index writer and commits the operations \"\"\" self . __writer . commit () del self . __writer KeywordIndex ( directory ) Bases: IndexInterface This class implements the schema_type method: KeyWord. This is useful for splitting the indexed text in a list of tokens. The Frequency vector is also added so that the tf calculation is possible. Commas is true in case of a \"content_id\" field data containing white spaces Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 260 261 def __init__ ( self , directory : str ): super () . __init__ ( directory ) SearchIndex ( directory ) Bases: IndexInterface This class implements the schema_type method: Text. By using a SimpleAnalyzer for the field, the data is kept as much as the original as possible Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 280 281 def __init__ ( self , directory : str ): super () . __init__ ( directory )","title":"Index Interface"},{"location":"content_analyzer/index_interface/#index-interface","text":"","title":"Index interface"},{"location":"content_analyzer/index_interface/#clayrs.content_analyzer.memory_interfaces.text_interface.IndexInterface","text":"Bases: TextInterface Abstract class that takes care of serializing and deserializing text in an indexed structure using the Whoosh library PARAMETER DESCRIPTION directory Path of the directory where the content will be serialized TYPE: str Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 26 27 28 29 30 31 def __init__ ( self , directory : str ): super () . __init__ ( directory ) self . __doc = None # document that is currently being created and will be added to the index self . __writer = None # index writer self . __doc_index = 0 # current position the document will have in the index once it is serialized self . __schema_changed = False # true if the schema has been changed, false otherwise","title":"IndexInterface"},{"location":"content_analyzer/index_interface/#clayrs.content_analyzer.memory_interfaces.text_interface.IndexInterface.get_field","text":"Uses a search index to retrieve the content corresponding to the content_id (if it is a string) or in the corresponding position (if it is an integer), and returns the data in the field corresponding to the field_name PARAMETER DESCRIPTION field_name name of the field from which the data will be retrieved TYPE: str content_id either the position or Id of the content that contains the specified field TYPE: Union [ str , int ] RETURNS DESCRIPTION str Data contained in the field of the content Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def get_field ( self , field_name : str , content_id : Union [ str , int ]) -> str : \"\"\" Uses a search index to retrieve the content corresponding to the content_id (if it is a string) or in the corresponding position (if it is an integer), and returns the data in the field corresponding to the field_name Args: field_name (str): name of the field from which the data will be retrieved content_id (Union[str, int]): either the position or Id of the content that contains the specified field Returns: Data contained in the field of the content \"\"\" ix = open_dir ( self . directory ) with ix . searcher () as searcher : if isinstance ( content_id , str ): query = Term ( \"content_id\" , content_id ) result = searcher . search ( query ) result = result [ 0 ][ field_name ] elif isinstance ( content_id , int ): result = searcher . reader () . stored_fields ( content_id )[ field_name ] return result","title":"get_field()"},{"location":"content_analyzer/index_interface/#clayrs.content_analyzer.memory_interfaces.text_interface.IndexInterface.get_tf_idf","text":"Calculates the tf-idf for the words contained in the field of the content whose id is content_id (if it is a string) or in the given position (if it is an integer). The tf-idf computation formula is: \\[ tf \\mbox{-} idf = (1 + log10(tf)) * log10(idf) \\] PARAMETER DESCRIPTION field_name Name of the field containing the words for which calculate the tf-idf TYPE: str content_id either the position or Id of the content that contains the specified field TYPE: Union [ str , int ] RETURNS DESCRIPTION words_bag Dictionary whose keys are the words contained in the field, and the corresponding values are the tf-idf values TYPE: Dict [ str , float ] Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 def get_tf_idf ( self , field_name : str , content_id : Union [ str , int ]) -> Dict [ str , float ]: r \"\"\" Calculates the tf-idf for the words contained in the field of the content whose id is content_id (if it is a string) or in the given position (if it is an integer). The tf-idf computation formula is: $$ tf \\mbox{-} idf = (1 + log10(tf)) * log10(idf) $$ Args: field_name: Name of the field containing the words for which calculate the tf-idf content_id: either the position or Id of the content that contains the specified field Returns: words_bag: Dictionary whose keys are the words contained in the field, and the corresponding values are the tf-idf values \"\"\" ix = open_dir ( self . directory ) words_bag = {} with ix . searcher () as searcher : if isinstance ( content_id , str ): query = Term ( \"content_id\" , content_id ) doc_num = searcher . search ( query ) . docnum ( 0 ) elif isinstance ( content_id , int ): doc_num = content_id # if the document has the field == \"\" (length == 0) then the bag of word is empty if len ( searcher . ixreader . stored_fields ( doc_num )[ field_name ]) > 0 : # retrieves the frequency vector (used for tf) list_with_freq = [ term_with_freq for term_with_freq in searcher . vector ( doc_num , field_name ) . items_as ( \"frequency\" )] for term , freq in list_with_freq : tf = 1 + math . log10 ( freq ) idf = math . log10 ( searcher . doc_count () / searcher . doc_frequency ( field_name , term )) words_bag [ term ] = tf * idf return words_bag","title":"get_tf_idf()"},{"location":"content_analyzer/index_interface/#clayrs.content_analyzer.memory_interfaces.text_interface.IndexInterface.init_writing","text":"Creates the index locally (in the directory passed in the constructor) and initializes the index writer. If an index already exists in the directory, what happens depend on the attribute delete_old passed as argument PARAMETER DESCRIPTION delete_old if True, the index that was in the same directory is destroyed and replaced; if False, the index is simply opened TYPE: bool DEFAULT: False Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def init_writing ( self , delete_old : bool = False ): \"\"\" Creates the index locally (in the directory passed in the constructor) and initializes the index writer. If an index already exists in the directory, what happens depend on the attribute delete_old passed as argument Args: delete_old (bool): if True, the index that was in the same directory is destroyed and replaced; if False, the index is simply opened \"\"\" if os . path . exists ( self . directory ): if delete_old : self . delete () os . mkdir ( self . directory ) ix = create_in ( self . directory , Schema ()) self . __writer = ix . writer () else : ix = open_dir ( self . directory ) self . __writer = ix . writer () self . __doc_index = self . __writer . reader () . doc_count () else : os . mkdir ( self . directory ) ix = create_in ( self . directory , Schema ()) self . __writer = ix . writer ()","title":"init_writing()"},{"location":"content_analyzer/index_interface/#clayrs.content_analyzer.memory_interfaces.text_interface.IndexInterface.new_content","text":"The new content is a document that will be indexed. In this case the document is a dictionary with the name of the field as key and the data inside the field as value Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 67 68 69 70 71 72 def new_content ( self ): \"\"\" The new content is a document that will be indexed. In this case the document is a dictionary with the name of the field as key and the data inside the field as value \"\"\" self . __doc = {}","title":"new_content()"},{"location":"content_analyzer/index_interface/#clayrs.content_analyzer.memory_interfaces.text_interface.IndexInterface.new_field","text":"Adds a new field to the document that is being created. Since the index Schema is generated dynamically, if the field name is not in the Schema already it is added to it PARAMETER DESCRIPTION field_name Name of the new field TYPE: str field_data Data to put into the field TYPE: object Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 74 75 76 77 78 79 80 81 82 83 84 85 86 def new_field ( self , field_name : str , field_data : object ): \"\"\" Adds a new field to the document that is being created. Since the index Schema is generated dynamically, if the field name is not in the Schema already it is added to it Args: field_name (str): Name of the new field field_data (object): Data to put into the field \"\"\" if field_name not in open_dir ( self . directory ) . schema . names (): self . __writer . add_field ( field_name , self . schema_type ) self . __schema_changed = True self . __doc [ field_name ] = field_data","title":"new_field()"},{"location":"content_analyzer/index_interface/#clayrs.content_analyzer.memory_interfaces.text_interface.IndexInterface.query","text":"Uses a search index to query the index in order to retrieve specific contents using a query expressed in string form PARAMETER DESCRIPTION string_query query expressed as a string TYPE: str results_number number of results the searcher will return for the query TYPE: int mask_list list of content_ids of items to ignore in the search process TYPE: list DEFAULT: None candidate_list list of content_ids of items to consider in the search process, if it is not None only items in the list will be considered TYPE: list DEFAULT: None classic_similarity if True, classic tf idf is used for scoring, otherwise BM25F is used TYPE: bool DEFAULT: True RETURNS DESCRIPTION results the final results dictionary containing the results found from the search index for the query. The dictionary will be in the following form: {content_id: {\"item\": item_dictionary, \"score\": item_score}, ...} content_id is the content_id for the corresponding item item_dictionary is the dictionary of the item containing the fields as keys and the contents as values. So it will be in the following form: {\"Plot\": \"this is the plot\", \"Genre\": \"this is the Genre\"} The item_dictionary will not contain the content_id since it is already defined and used as key of the external dictionary items_score is the score given to the item for the query by the index searcher TYPE: dict Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 def query ( self , string_query : str , results_number : int , mask_list : list = None , candidate_list : list = None , classic_similarity : bool = True ) -> dict : \"\"\" Uses a search index to query the index in order to retrieve specific contents using a query expressed in string form Args: string_query: query expressed as a string results_number: number of results the searcher will return for the query mask_list: list of content_ids of items to ignore in the search process candidate_list: list of content_ids of items to consider in the search process, if it is not None only items in the list will be considered classic_similarity: if True, classic tf idf is used for scoring, otherwise BM25F is used Returns: results: the final results dictionary containing the results found from the search index for the query. The dictionary will be in the following form: {content_id: {\"item\": item_dictionary, \"score\": item_score}, ...} content_id is the content_id for the corresponding item item_dictionary is the dictionary of the item containing the fields as keys and the contents as values. So it will be in the following form: {\"Plot\": \"this is the plot\", \"Genre\": \"this is the Genre\"} The item_dictionary will not contain the content_id since it is already defined and used as key of the external dictionary items_score is the score given to the item for the query by the index searcher \"\"\" ix = open_dir ( self . directory ) with ix . searcher ( weighting = TF_IDF if classic_similarity else BM25F ) as searcher : candidate_query_list = None mask_query_list = None # the mask list contains the content_id for the items to ignore in the searching process # from the mask list a mask query is created and it will be used by the searcher if mask_list is not None : mask_query_list = [] for document in mask_list : mask_query_list . append ( Term ( \"content_id\" , document )) mask_query_list = Or ( mask_query_list ) # the candidate list contains the content_id for the items to consider in the searching process # from the candidate list a candidate query is created and it will be used by the searcher if candidate_list is not None : candidate_query_list = [] for candidate in candidate_list : candidate_query_list . append ( Term ( \"content_id\" , candidate )) candidate_query_list = Or ( candidate_query_list ) schema = ix . schema parser = QueryParser ( \"content_id\" , schema = schema , group = OrGroup ) # regular expression to match the possible field styles # examples: \"content_id\" or \"Genre#2\" or \"Genre#2#custom_id\" parser . add_plugin ( FieldsPlugin ( r '(?P<text>[\\w-]+(\\#[\\w-]+(\\#[\\w-]+)?)?|[*]):' )) query = parser . parse ( string_query ) score_docs = \\ searcher . search ( query , limit = results_number , filter = candidate_query_list , mask = mask_query_list ) # creation of the results dictionary, This phase is necessary because the Hit objects returned by the # searcher as results need the reader inside the search index in order to return information # so it would be impossible to access a field or the score of the item from outside this method # because of that this dictionary containing the most important infos is created results = {} for hit in score_docs : hit_dict = dict ( hit ) content_id = hit_dict . pop ( \"content_id\" ) results [ content_id ] = {} results [ content_id ][ \"item\" ] = hit_dict results [ content_id ][ \"score\" ] = hit . score return results","title":"query()"},{"location":"content_analyzer/index_interface/#clayrs.content_analyzer.memory_interfaces.text_interface.IndexInterface.schema_type","text":"Whoosh uses a Schema that defines, for each field of the content, how to store the data. In the case of this project, every field will have the same structure and will share the same field type. This method returns said field type. Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 33 34 35 36 37 38 39 40 41 @property @abc . abstractmethod def schema_type ( self ): \"\"\" Whoosh uses a Schema that defines, for each field of the content, how to store the data. In the case of this project, every field will have the same structure and will share the same field type. This method returns said field type. \"\"\" raise NotImplementedError","title":"schema_type()"},{"location":"content_analyzer/index_interface/#clayrs.content_analyzer.memory_interfaces.text_interface.IndexInterface.serialize_content","text":"Serializes the content in the index. If the schema changed, the writer will commit the changes to the schema before adding the document to the index. Once the document is indexed, it can be deleted from the IndexInterface and the document position in the index is returned Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 88 89 90 91 92 93 94 95 96 97 98 99 100 101 def serialize_content ( self ) -> int : \"\"\" Serializes the content in the index. If the schema changed, the writer will commit the changes to the schema before adding the document to the index. Once the document is indexed, it can be deleted from the IndexInterface and the document position in the index is returned \"\"\" if self . __schema_changed : self . __writer . commit () self . __writer = open_dir ( self . directory ) . writer () self . __schema_changed = False self . __writer . add_document ( ** self . __doc ) del self . __doc self . __doc_index += 1 return self . __doc_index - 1","title":"serialize_content()"},{"location":"content_analyzer/index_interface/#clayrs.content_analyzer.memory_interfaces.text_interface.IndexInterface.stop_writing","text":"Stops the index writer and commits the operations Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 103 104 105 106 107 108 def stop_writing ( self ): \"\"\" Stops the index writer and commits the operations \"\"\" self . __writer . commit () del self . __writer","title":"stop_writing()"},{"location":"content_analyzer/index_interface/#clayrs.content_analyzer.memory_interfaces.text_interface.KeywordIndex","text":"Bases: IndexInterface This class implements the schema_type method: KeyWord. This is useful for splitting the indexed text in a list of tokens. The Frequency vector is also added so that the tf calculation is possible. Commas is true in case of a \"content_id\" field data containing white spaces Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 260 261 def __init__ ( self , directory : str ): super () . __init__ ( directory )","title":"KeywordIndex"},{"location":"content_analyzer/index_interface/#clayrs.content_analyzer.memory_interfaces.text_interface.SearchIndex","text":"Bases: IndexInterface This class implements the schema_type method: Text. By using a SimpleAnalyzer for the field, the data is kept as much as the original as possible Source code in clayrs/content_analyzer/memory_interfaces/text_interface.py 280 281 def __init__ ( self , directory : str ): super () . __init__ ( directory )","title":"SearchIndex"},{"location":"content_analyzer/introduction/","text":"Warning Docs are complete, but revision is still a Work in Progress. Sorry for any typos! Introduction The Content Analyzer module has the task to build a complex representation for chosen contents, starting from their raw representation The following will introduce you to the standard usage pipeline for this module, showing you all the various operations that can be performed Item Config Suppose the following JSON file which contains information about movies: It will act as raw source for items . JSON items raw source [ { \"movielens_id\": \"1\", \"title\": \"Toy Story\", \"plot\": \"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy\" \"genres\": \"Animation, Adventure, Comedy, Family, Fantasy\", \"year\": \"1995\", \"rating\": \"8.3\", \"directors\": \"John Lasseter\", \"dbpedia_uri\": \"http://dbpedia.org/resource/Toy_Story\", \"dbpedia_label\": \"Toy Story\" } ] In order to define the item representation , the ItemAnalyzerConfig class must be instantiated and the following parameters should be defined: source : the path of the file containing items info id : the field that uniquely identifies an item output_directory : the path where serialized representations are saved Info In the following suppose that the raw source is a JSON file, but ClayRS is able to read from different sources, as CSVFile, DATFile, and more. Refer to the Raw source wrappers section for more from clayrs import content_analyzer as ca json_source = ca . JSONFile ( 'items_info.json' ) # Configuration of item representation movies_ca_config = ca . ItemAnalyzerConfig ( source = json_source , id = 'movielens_id' , output_directory = 'movies_codified/' , ) Once we have initialized our items configuration, we are ready to complexly represent one or more fields of the specified raw source Complex representation Every field of the raw source can be represented using several techniques, such as 'tfidf' , 'embeddings' , etc. It is possible to process the content of each field using a Natural Language Processing (NLP) pipeline . The preprocessing will be done before assigning a complex representation to said field. It is also possible to assign a custom id for each generated representation, in order to allow a simpler reference in the recommendation phase. Both NLP pipeline and custom id are optional parameters If a list of NLP preprocessors is passed to the preprocessing parameter, then all operations specified will be performed in order So, for example, we could represent the 'plot' field by performing lemmatization and stopwords removal , and represent it using tfidf : movies_ca_config . add_single_config ( 'plot' , ca . FieldConfig ( ca . SkLearnTfIdf (), preprocessing = ca . NLTK ( stopwords_removal = True , lemmatization = True ), id = 'tfidf' ) # Custom id ) But we could also specify for the same field multiple complex representations at once with the add_multiple_config() method: In this case each representation can be preceded by different preprocessing operations! So, for example, we could represent the 'genres' field by: Removing punctuation and representing it using the pre-trained glove-twitter-50 model from Gensim ; Performing lemmatization and representing it by using the Word2Vec model which will be trained from scratch on our corpus movies_ca_config . add_multiple_config ( 'genres' , [ # first representation ca . FieldConfig ( ca . WordEmbeddingTechnique ( ca . Gensim ( 'glove-twitter-50' )), preprocessing = ca . NLTK ( remove_punctuation = True ), id = 'glove' ), # second representation ca . FieldConfig ( ca . WordEmbeddingTechnique ( ca . GensimWord2Vec ()), preprocessing = ca . Spacy ( lemmatization = True ), id = 'word2vec' ) ] ) Exogenous representation We could expand each item by using Exogenous techniques : they are very useful if you plan to use a graph based recommender system later in the experiment. In order to do that, we call the add_single_exogenous() method (or add_multiple_exogenous() in case of multiple exogenous techniques) and pass the instantiated ExogenousTechnique object. Info Exogenous properties are those extracted from an external source, more info here In this case we expand each content with properties extracted from the DBPedia ontology : The first parameter of the DBPediaMappingTechnique object is the entity type of every content ( dbo:Film in this case). Multiple prefixes such as rdf , rdfs , foaf , dbo are imported by default, but if you need another type of entity you can pass its uri directly 'dbo:Film' <-EQUIVALENT-> '<http://dbpedia.org/ontology/Film>' The second parameter instead is the field in the raw source which must exactly match the string representation of the rdfs:label of the content on DBPedia movies_ca_config . add_single_exogenous ( ca . ExogenousConfig ( ca . DBPediaMappingTechnique ( 'dbo:Film' , 'dbpedia_label' ), id = 'dbpedia' ) ) Store in an index You could also store in a complex data structure certain representation codified for the contents. In the following we are exporting the textual data \"as is\" and preprocessed with stopwords_removal and stemming in a Whoosh index Info Textual representations stored in an index can be exploited later in the RecSys phase by the IndexQuery algorithm movies_ca_config . add_multiple_config ( 'genres' , [ # first representation - no preprocessing ca . FieldConfig ( ca . OriginalData (), memory_interfaces = ca . SearchIndex ( 'index_folder' ), id = 'index_original' ), # first representation - with preprocessing ca . FieldConfig ( ca . OriginalData (), preprocessing = ca . NLTK ( stopwords_removal = True , stemming = True ), memory_interfaces = ca . SearchIndex ( 'index_folder' ), id = 'index_original' ), ] ) User Config Suppose the following JSON file which contains information about movies: It will act as raw source for users . CSV users raw source user_id,age,gender,occupation,zip_code 1,24,M,technician,85711 2,53,F,other,94043 In order to define the user representation , the UserAnalyzerConfig class must be instantiated and the following parameters should be defined: source : the path of the file containing users info id : the field that uniquely identifies an user output_directory : the path where serialized representations are saved # Configuration of user representation users_ca_config = ca . UserAnalyzerConfig ( ca . CSVFile ( 'users_info.csv' ), id = 'user_id' , output_directory = 'users_codified/' , ) The operations you could perform for users are exactly the same you could perform on items! So please refer to the above section For example, we could just expand each user with exogenous properties extracted from local dataset: PropertiesFromDataset() exogenous technique allows specifying which fields to use in order to expand every user info If no field is specified, all fields from the raw source will be used In this case, we expand every user with gender and occupation users_ca_config . add_single_exogenous ( ca . ExogenousConfig ( ca . PropertiesFromDataset ( field_name_list = [ 'gender' , 'occupation' ]) ) ) Serializing Content At the end of the configuration step, we provide the configuration (regardless if it's for items or users ) to the ContentAnalyzer class and call the fit() method: The Content Analyzer will represent and serialize every item. # complexly represent items ca . ContentAnalyzer ( config = movies_ca_config ) . fit () # complexly represent users ca . ContentAnalyzer ( config = users_ca_config ) . fit () Exporting to JSON file There is also the optional parameter export_json in the ItemAnalyzerConfig or UserAnalyzerConfig : If set to True, contents complexly represented will also be serialized in a human readable JSON # Configuration of item representation movies_ca_config = ca . ItemAnalyzerConfig ( source = ca . JSONFile ( 'items_info.json' ), id = 'movielens_id' , output_directory = 'movies_codified/' , export_json = True ) After specifying a fitting representation for items and calling the fit() method of the ContentAnalyzer , the output folder will have the following structure: \ud83d\udcc1 movies_codified/ \u2514\u2500\u2500 \ud83d\udcc4 contents.json \u2514\u2500\u2500 \ud83d\udcc4 1.xz \u2514\u2500\u2500 \ud83d\udcc4 2.xz \u2514\u2500\u2500 \ud83d\udcc4 ...","title":"Introduction"},{"location":"content_analyzer/introduction/#introduction","text":"The Content Analyzer module has the task to build a complex representation for chosen contents, starting from their raw representation The following will introduce you to the standard usage pipeline for this module, showing you all the various operations that can be performed","title":"Introduction"},{"location":"content_analyzer/introduction/#item-config","text":"Suppose the following JSON file which contains information about movies: It will act as raw source for items . JSON items raw source [ { \"movielens_id\": \"1\", \"title\": \"Toy Story\", \"plot\": \"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy\" \"genres\": \"Animation, Adventure, Comedy, Family, Fantasy\", \"year\": \"1995\", \"rating\": \"8.3\", \"directors\": \"John Lasseter\", \"dbpedia_uri\": \"http://dbpedia.org/resource/Toy_Story\", \"dbpedia_label\": \"Toy Story\" } ] In order to define the item representation , the ItemAnalyzerConfig class must be instantiated and the following parameters should be defined: source : the path of the file containing items info id : the field that uniquely identifies an item output_directory : the path where serialized representations are saved Info In the following suppose that the raw source is a JSON file, but ClayRS is able to read from different sources, as CSVFile, DATFile, and more. Refer to the Raw source wrappers section for more from clayrs import content_analyzer as ca json_source = ca . JSONFile ( 'items_info.json' ) # Configuration of item representation movies_ca_config = ca . ItemAnalyzerConfig ( source = json_source , id = 'movielens_id' , output_directory = 'movies_codified/' , ) Once we have initialized our items configuration, we are ready to complexly represent one or more fields of the specified raw source","title":"Item Config"},{"location":"content_analyzer/introduction/#complex-representation","text":"Every field of the raw source can be represented using several techniques, such as 'tfidf' , 'embeddings' , etc. It is possible to process the content of each field using a Natural Language Processing (NLP) pipeline . The preprocessing will be done before assigning a complex representation to said field. It is also possible to assign a custom id for each generated representation, in order to allow a simpler reference in the recommendation phase. Both NLP pipeline and custom id are optional parameters If a list of NLP preprocessors is passed to the preprocessing parameter, then all operations specified will be performed in order So, for example, we could represent the 'plot' field by performing lemmatization and stopwords removal , and represent it using tfidf : movies_ca_config . add_single_config ( 'plot' , ca . FieldConfig ( ca . SkLearnTfIdf (), preprocessing = ca . NLTK ( stopwords_removal = True , lemmatization = True ), id = 'tfidf' ) # Custom id ) But we could also specify for the same field multiple complex representations at once with the add_multiple_config() method: In this case each representation can be preceded by different preprocessing operations! So, for example, we could represent the 'genres' field by: Removing punctuation and representing it using the pre-trained glove-twitter-50 model from Gensim ; Performing lemmatization and representing it by using the Word2Vec model which will be trained from scratch on our corpus movies_ca_config . add_multiple_config ( 'genres' , [ # first representation ca . FieldConfig ( ca . WordEmbeddingTechnique ( ca . Gensim ( 'glove-twitter-50' )), preprocessing = ca . NLTK ( remove_punctuation = True ), id = 'glove' ), # second representation ca . FieldConfig ( ca . WordEmbeddingTechnique ( ca . GensimWord2Vec ()), preprocessing = ca . Spacy ( lemmatization = True ), id = 'word2vec' ) ] )","title":"Complex representation"},{"location":"content_analyzer/introduction/#exogenous-representation","text":"We could expand each item by using Exogenous techniques : they are very useful if you plan to use a graph based recommender system later in the experiment. In order to do that, we call the add_single_exogenous() method (or add_multiple_exogenous() in case of multiple exogenous techniques) and pass the instantiated ExogenousTechnique object. Info Exogenous properties are those extracted from an external source, more info here In this case we expand each content with properties extracted from the DBPedia ontology : The first parameter of the DBPediaMappingTechnique object is the entity type of every content ( dbo:Film in this case). Multiple prefixes such as rdf , rdfs , foaf , dbo are imported by default, but if you need another type of entity you can pass its uri directly 'dbo:Film' <-EQUIVALENT-> '<http://dbpedia.org/ontology/Film>' The second parameter instead is the field in the raw source which must exactly match the string representation of the rdfs:label of the content on DBPedia movies_ca_config . add_single_exogenous ( ca . ExogenousConfig ( ca . DBPediaMappingTechnique ( 'dbo:Film' , 'dbpedia_label' ), id = 'dbpedia' ) )","title":"Exogenous representation"},{"location":"content_analyzer/introduction/#store-in-an-index","text":"You could also store in a complex data structure certain representation codified for the contents. In the following we are exporting the textual data \"as is\" and preprocessed with stopwords_removal and stemming in a Whoosh index Info Textual representations stored in an index can be exploited later in the RecSys phase by the IndexQuery algorithm movies_ca_config . add_multiple_config ( 'genres' , [ # first representation - no preprocessing ca . FieldConfig ( ca . OriginalData (), memory_interfaces = ca . SearchIndex ( 'index_folder' ), id = 'index_original' ), # first representation - with preprocessing ca . FieldConfig ( ca . OriginalData (), preprocessing = ca . NLTK ( stopwords_removal = True , stemming = True ), memory_interfaces = ca . SearchIndex ( 'index_folder' ), id = 'index_original' ), ] )","title":"Store in an index"},{"location":"content_analyzer/introduction/#user-config","text":"Suppose the following JSON file which contains information about movies: It will act as raw source for users . CSV users raw source user_id,age,gender,occupation,zip_code 1,24,M,technician,85711 2,53,F,other,94043 In order to define the user representation , the UserAnalyzerConfig class must be instantiated and the following parameters should be defined: source : the path of the file containing users info id : the field that uniquely identifies an user output_directory : the path where serialized representations are saved # Configuration of user representation users_ca_config = ca . UserAnalyzerConfig ( ca . CSVFile ( 'users_info.csv' ), id = 'user_id' , output_directory = 'users_codified/' , ) The operations you could perform for users are exactly the same you could perform on items! So please refer to the above section For example, we could just expand each user with exogenous properties extracted from local dataset: PropertiesFromDataset() exogenous technique allows specifying which fields to use in order to expand every user info If no field is specified, all fields from the raw source will be used In this case, we expand every user with gender and occupation users_ca_config . add_single_exogenous ( ca . ExogenousConfig ( ca . PropertiesFromDataset ( field_name_list = [ 'gender' , 'occupation' ]) ) )","title":"User Config"},{"location":"content_analyzer/introduction/#serializing-content","text":"At the end of the configuration step, we provide the configuration (regardless if it's for items or users ) to the ContentAnalyzer class and call the fit() method: The Content Analyzer will represent and serialize every item. # complexly represent items ca . ContentAnalyzer ( config = movies_ca_config ) . fit () # complexly represent users ca . ContentAnalyzer ( config = users_ca_config ) . fit ()","title":"Serializing Content"},{"location":"content_analyzer/introduction/#exporting-to-json-file","text":"There is also the optional parameter export_json in the ItemAnalyzerConfig or UserAnalyzerConfig : If set to True, contents complexly represented will also be serialized in a human readable JSON # Configuration of item representation movies_ca_config = ca . ItemAnalyzerConfig ( source = ca . JSONFile ( 'items_info.json' ), id = 'movielens_id' , output_directory = 'movies_codified/' , export_json = True ) After specifying a fitting representation for items and calling the fit() method of the ContentAnalyzer , the output folder will have the following structure: \ud83d\udcc1 movies_codified/ \u2514\u2500\u2500 \ud83d\udcc4 contents.json \u2514\u2500\u2500 \ud83d\udcc4 1.xz \u2514\u2500\u2500 \ud83d\udcc4 2.xz \u2514\u2500\u2500 \ud83d\udcc4 ...","title":"Exporting to JSON file"},{"location":"content_analyzer/raw_sources/","text":"Raw Source Wrappers CSVFile ( file_path , separator = ',' , has_header = True , encoding = 'utf-8-sig' ) Bases: RawInformationSource Wrapper for a CSV file. This class is able to read from a CSV file where each entry is separated by the a certain separator ( , by default). So by using this class you can also read TSV file for examples, by specifying separator='\\t' . A CSV File most typically has a header: in this case, each entry can be referenced with its column header. In case the CSV File hasn't a header, simply specify has_header=False : in this case, each entry can be referenced with a string representing its positional index (e.g. '0' for entry in the first position, '1' for the entry in the second position, etc.) You can iterate over the whole content of the raw source with a simple for loop: each row will be returned as a dictionary where keys are strings representing the positional indices, values are the entries Examples: Consider the following CSV file with header movie_id,movie_title,release_year 1,Jumanji,1995 2,Toy Story,1995 >>> file = CSVFile ( csv_path ) >>> print ( list ( file )) [{'movie_id': '1', 'movie_title': 'Jumanji', 'release_year': '1995'}, {'movie_id': '2', 'movie_title': 'Toy Story', 'release_year': '1995'}] Consider the following TSV file with no header 1 Jumanji 1995 2 Toy Story 1995 >>> file = CSVFile ( tsv_path , separator = ' \\t ' , has_header = False ) >>> print ( list ( file )) [{'0': '1', '1': 'Jumanji', '2': '1995'}, {'0': '2', '1': 'Toy Story', '2': '1995'}] PARAMETER DESCRIPTION file_path Path of the dat file TYPE: str separator Character which separates each entry. By default is a comma ( , ), but in case you need to read from a TSV file simply change this parameter to \\t TYPE: str DEFAULT: ',' has_header Boolean value which specifies if the file has an header or not. Default is True TYPE: bool DEFAULT: True encoding Define the type of encoding of data stored in the source (example: \"utf-8\") TYPE: str DEFAULT: 'utf-8-sig' Source code in clayrs/content_analyzer/raw_information_source.py 229 230 231 232 233 def __init__ ( self , file_path : str , separator : str = ',' , has_header : bool = True , encoding : str = \"utf-8-sig\" ): super () . __init__ ( encoding ) self . __file_path = file_path self . __has_header = has_header self . __separator = separator representative_name () property Method which returns a meaningful name for the raw source. In this case it's simply the file name + its extension RETURNS DESCRIPTION str The representative name for the raw source Source code in clayrs/content_analyzer/raw_information_source.py 235 236 237 238 239 240 241 242 243 244 245 246 247 248 @property def representative_name ( self ) -> str : \"\"\" Method which returns a meaningful name for the raw source. In this case it's simply the file name + its extension Returns: The representative name for the raw source \"\"\" # file name with extension file_name = os . path . basename ( self . __file_path ) return file_name DATFile ( file_path , encoding = 'utf-8' ) Bases: RawInformationSource Wrapper for a DAT file. This class is able to read from a DAT file where each entry is separated by the :: string. Since a DAT file has no header, each entry can be referenced with a string representing its positional index (e.g. '0' for entry in the first position, '1' for the entry in the second position, etc.) You can iterate over the whole content of the raw source with a simple for loop: each row will be returned as a dictionary where keys are strings representing the positional indices, values are the entries Examples: Consider the following DAT file 10::worker::75011 11::without occupation::76112 >>> file = DATFile ( dat_path ) >>> print ( list ( file )) [{'0': '10', '1': 'worker', '2': '75011'}, {'0': '11', '1': 'without occupation', '2': '76112'}] PARAMETER DESCRIPTION file_path path of the dat file TYPE: str encoding define the type of encoding of data stored in the source (example: \"utf-8\") TYPE: str DEFAULT: 'utf-8' Source code in clayrs/content_analyzer/raw_information_source.py 78 79 80 def __init__ ( self , file_path : str , encoding : str = \"utf-8\" ): super () . __init__ ( encoding ) self . __file_path = file_path representative_name () property Method which returns a meaningful name for the raw source. In this case it's simply the file name + its extension RETURNS DESCRIPTION str The representative name for the raw source Source code in clayrs/content_analyzer/raw_information_source.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 @property def representative_name ( self ) -> str : \"\"\" Method which returns a meaningful name for the raw source. In this case it's simply the file name + its extension Returns: The representative name for the raw source \"\"\" # file name with extension file_name = os . path . basename ( self . __file_path ) return file_name JSONFile ( file_path , encoding = 'utf-8' ) Bases: RawInformationSource Wrapper for a JSON file. This class is able to read from a JSON file where each \"row\" is a dictionary-like object inside a list You can iterate over the whole content of the raw source with a simple for loop: each row will be returned as a dictionary Examples: Consider the following JSON file [{\"Title\":\"Jumanji\",\"Year\":\"1995\"}, {\"Title\":\"Toy Story\",\"Year\":\"1995\"}] >>> file = JSONFile ( json_path ) >>> print ( list ( file )) [{'Title': 'Jumanji', 'Year': '1995'}, {'Title': 'Toy Story', 'Year': '1995'}] PARAMETER DESCRIPTION file_path path of the dat file TYPE: str encoding define the type of encoding of data stored in the source (example: \"utf-8\") TYPE: str DEFAULT: 'utf-8' Source code in clayrs/content_analyzer/raw_information_source.py 146 147 148 def __init__ ( self , file_path : str , encoding : str = \"utf-8\" ): super () . __init__ ( encoding ) self . __file_path = file_path representative_name () property Method which returns a meaningful name for the raw source. In this case it's simply the file name + its extension RETURNS DESCRIPTION str The representative name for the raw source Source code in clayrs/content_analyzer/raw_information_source.py 150 151 152 153 154 155 156 157 158 159 160 161 162 163 @property def representative_name ( self ) -> str : \"\"\" Method which returns a meaningful name for the raw source. In this case it's simply the file name + its extension Returns: The representative name for the raw source \"\"\" # file name with extension file_name = os . path . basename ( self . __file_path ) return file_name SQLDatabase ( host , username , password , database_name , table_name , encoding = 'utf-8' ) Bases: RawInformationSource Wrapper for a SQL database. You can iterate over the whole content of the raw source with a simple for loop: each row will be returned as a dictionary where keys are strings representing the positional indices, values are the entries Examples: Consider the following SQL table for the databaase 'movies' in localhost +----------+-------------+--------------+ | Movie ID | Movie Title | Release Year | +----------+-------------+--------------+ | 1 | Jumanji | 1995 | | 2 | Toy Story | 1995 | +----------+-------------+--------------+ >>> file = SQLDatabase ( host = '127.0.0.1' , username = 'root' , password = 'root' , >>> database_name = 'movies' , table_name = 'movies_table' ) >>> print ( list ( file )) [{'Movie ID': '1', 'Movie Title': 'Jumanji', 'Release Year': '1995'}, {'Movie ID': '2', 'Movie Title': 'Toy Story', 'Release Year': '1995'}] PARAMETER DESCRIPTION host host ip of the sql server TYPE: str username username for the access TYPE: str password password for the access TYPE: str database_name name of database TYPE: str table_name name of the database table where data is stored TYPE: str encoding Define the type of encoding of data stored in the source (example: \"utf-8\") TYPE: str DEFAULT: 'utf-8' Source code in clayrs/content_analyzer/raw_information_source.py 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def __init__ ( self , host : str , username : str , password : str , database_name : str , table_name : str , encoding : str = \"utf-8\" ): super () . __init__ ( encoding ) self . __host : str = host self . __username : str = username self . __password : str = password self . __database_name : str = database_name self . __table_name : str = table_name conn = mysql . connector . connect ( host = self . __host , user = self . __username , password = self . __password , charset = self . encoding ) cursor = conn . cursor () query = \"\"\"USE \"\"\" + self . __database_name + \"\"\";\"\"\" cursor . execute ( query ) conn . commit () self . __conn = conn representative_name () property Method which returns a meaningful name for the raw source. In this case it's the host name followed by the table name RETURNS DESCRIPTION str The representative name for the raw source Source code in clayrs/content_analyzer/raw_information_source.py 382 383 384 385 386 387 388 389 390 391 392 @property def representative_name ( self ) -> str : \"\"\" Method which returns a meaningful name for the raw source. In this case it's the host name followed by the table name Returns: The representative name for the raw source \"\"\" return f \" { self . host } / { self . table_name } \"","title":"Raw source wrappers"},{"location":"content_analyzer/raw_sources/#raw-source-wrappers","text":"","title":"Raw Source Wrappers"},{"location":"content_analyzer/raw_sources/#clayrs.content_analyzer.raw_information_source.CSVFile","text":"Bases: RawInformationSource Wrapper for a CSV file. This class is able to read from a CSV file where each entry is separated by the a certain separator ( , by default). So by using this class you can also read TSV file for examples, by specifying separator='\\t' . A CSV File most typically has a header: in this case, each entry can be referenced with its column header. In case the CSV File hasn't a header, simply specify has_header=False : in this case, each entry can be referenced with a string representing its positional index (e.g. '0' for entry in the first position, '1' for the entry in the second position, etc.) You can iterate over the whole content of the raw source with a simple for loop: each row will be returned as a dictionary where keys are strings representing the positional indices, values are the entries Examples: Consider the following CSV file with header movie_id,movie_title,release_year 1,Jumanji,1995 2,Toy Story,1995 >>> file = CSVFile ( csv_path ) >>> print ( list ( file )) [{'movie_id': '1', 'movie_title': 'Jumanji', 'release_year': '1995'}, {'movie_id': '2', 'movie_title': 'Toy Story', 'release_year': '1995'}] Consider the following TSV file with no header 1 Jumanji 1995 2 Toy Story 1995 >>> file = CSVFile ( tsv_path , separator = ' \\t ' , has_header = False ) >>> print ( list ( file )) [{'0': '1', '1': 'Jumanji', '2': '1995'}, {'0': '2', '1': 'Toy Story', '2': '1995'}] PARAMETER DESCRIPTION file_path Path of the dat file TYPE: str separator Character which separates each entry. By default is a comma ( , ), but in case you need to read from a TSV file simply change this parameter to \\t TYPE: str DEFAULT: ',' has_header Boolean value which specifies if the file has an header or not. Default is True TYPE: bool DEFAULT: True encoding Define the type of encoding of data stored in the source (example: \"utf-8\") TYPE: str DEFAULT: 'utf-8-sig' Source code in clayrs/content_analyzer/raw_information_source.py 229 230 231 232 233 def __init__ ( self , file_path : str , separator : str = ',' , has_header : bool = True , encoding : str = \"utf-8-sig\" ): super () . __init__ ( encoding ) self . __file_path = file_path self . __has_header = has_header self . __separator = separator","title":"CSVFile"},{"location":"content_analyzer/raw_sources/#clayrs.content_analyzer.raw_information_source.CSVFile.representative_name","text":"Method which returns a meaningful name for the raw source. In this case it's simply the file name + its extension RETURNS DESCRIPTION str The representative name for the raw source Source code in clayrs/content_analyzer/raw_information_source.py 235 236 237 238 239 240 241 242 243 244 245 246 247 248 @property def representative_name ( self ) -> str : \"\"\" Method which returns a meaningful name for the raw source. In this case it's simply the file name + its extension Returns: The representative name for the raw source \"\"\" # file name with extension file_name = os . path . basename ( self . __file_path ) return file_name","title":"representative_name()"},{"location":"content_analyzer/raw_sources/#clayrs.content_analyzer.raw_information_source.DATFile","text":"Bases: RawInformationSource Wrapper for a DAT file. This class is able to read from a DAT file where each entry is separated by the :: string. Since a DAT file has no header, each entry can be referenced with a string representing its positional index (e.g. '0' for entry in the first position, '1' for the entry in the second position, etc.) You can iterate over the whole content of the raw source with a simple for loop: each row will be returned as a dictionary where keys are strings representing the positional indices, values are the entries Examples: Consider the following DAT file 10::worker::75011 11::without occupation::76112 >>> file = DATFile ( dat_path ) >>> print ( list ( file )) [{'0': '10', '1': 'worker', '2': '75011'}, {'0': '11', '1': 'without occupation', '2': '76112'}] PARAMETER DESCRIPTION file_path path of the dat file TYPE: str encoding define the type of encoding of data stored in the source (example: \"utf-8\") TYPE: str DEFAULT: 'utf-8' Source code in clayrs/content_analyzer/raw_information_source.py 78 79 80 def __init__ ( self , file_path : str , encoding : str = \"utf-8\" ): super () . __init__ ( encoding ) self . __file_path = file_path","title":"DATFile"},{"location":"content_analyzer/raw_sources/#clayrs.content_analyzer.raw_information_source.DATFile.representative_name","text":"Method which returns a meaningful name for the raw source. In this case it's simply the file name + its extension RETURNS DESCRIPTION str The representative name for the raw source Source code in clayrs/content_analyzer/raw_information_source.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 @property def representative_name ( self ) -> str : \"\"\" Method which returns a meaningful name for the raw source. In this case it's simply the file name + its extension Returns: The representative name for the raw source \"\"\" # file name with extension file_name = os . path . basename ( self . __file_path ) return file_name","title":"representative_name()"},{"location":"content_analyzer/raw_sources/#clayrs.content_analyzer.raw_information_source.JSONFile","text":"Bases: RawInformationSource Wrapper for a JSON file. This class is able to read from a JSON file where each \"row\" is a dictionary-like object inside a list You can iterate over the whole content of the raw source with a simple for loop: each row will be returned as a dictionary Examples: Consider the following JSON file [{\"Title\":\"Jumanji\",\"Year\":\"1995\"}, {\"Title\":\"Toy Story\",\"Year\":\"1995\"}] >>> file = JSONFile ( json_path ) >>> print ( list ( file )) [{'Title': 'Jumanji', 'Year': '1995'}, {'Title': 'Toy Story', 'Year': '1995'}] PARAMETER DESCRIPTION file_path path of the dat file TYPE: str encoding define the type of encoding of data stored in the source (example: \"utf-8\") TYPE: str DEFAULT: 'utf-8' Source code in clayrs/content_analyzer/raw_information_source.py 146 147 148 def __init__ ( self , file_path : str , encoding : str = \"utf-8\" ): super () . __init__ ( encoding ) self . __file_path = file_path","title":"JSONFile"},{"location":"content_analyzer/raw_sources/#clayrs.content_analyzer.raw_information_source.JSONFile.representative_name","text":"Method which returns a meaningful name for the raw source. In this case it's simply the file name + its extension RETURNS DESCRIPTION str The representative name for the raw source Source code in clayrs/content_analyzer/raw_information_source.py 150 151 152 153 154 155 156 157 158 159 160 161 162 163 @property def representative_name ( self ) -> str : \"\"\" Method which returns a meaningful name for the raw source. In this case it's simply the file name + its extension Returns: The representative name for the raw source \"\"\" # file name with extension file_name = os . path . basename ( self . __file_path ) return file_name","title":"representative_name()"},{"location":"content_analyzer/raw_sources/#clayrs.content_analyzer.raw_information_source.SQLDatabase","text":"Bases: RawInformationSource Wrapper for a SQL database. You can iterate over the whole content of the raw source with a simple for loop: each row will be returned as a dictionary where keys are strings representing the positional indices, values are the entries Examples: Consider the following SQL table for the databaase 'movies' in localhost +----------+-------------+--------------+ | Movie ID | Movie Title | Release Year | +----------+-------------+--------------+ | 1 | Jumanji | 1995 | | 2 | Toy Story | 1995 | +----------+-------------+--------------+ >>> file = SQLDatabase ( host = '127.0.0.1' , username = 'root' , password = 'root' , >>> database_name = 'movies' , table_name = 'movies_table' ) >>> print ( list ( file )) [{'Movie ID': '1', 'Movie Title': 'Jumanji', 'Release Year': '1995'}, {'Movie ID': '2', 'Movie Title': 'Toy Story', 'Release Year': '1995'}] PARAMETER DESCRIPTION host host ip of the sql server TYPE: str username username for the access TYPE: str password password for the access TYPE: str database_name name of database TYPE: str table_name name of the database table where data is stored TYPE: str encoding Define the type of encoding of data stored in the source (example: \"utf-8\") TYPE: str DEFAULT: 'utf-8' Source code in clayrs/content_analyzer/raw_information_source.py 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def __init__ ( self , host : str , username : str , password : str , database_name : str , table_name : str , encoding : str = \"utf-8\" ): super () . __init__ ( encoding ) self . __host : str = host self . __username : str = username self . __password : str = password self . __database_name : str = database_name self . __table_name : str = table_name conn = mysql . connector . connect ( host = self . __host , user = self . __username , password = self . __password , charset = self . encoding ) cursor = conn . cursor () query = \"\"\"USE \"\"\" + self . __database_name + \"\"\";\"\"\" cursor . execute ( query ) conn . commit () self . __conn = conn","title":"SQLDatabase"},{"location":"content_analyzer/raw_sources/#clayrs.content_analyzer.raw_information_source.SQLDatabase.representative_name","text":"Method which returns a meaningful name for the raw source. In this case it's the host name followed by the table name RETURNS DESCRIPTION str The representative name for the raw source Source code in clayrs/content_analyzer/raw_information_source.py 382 383 384 385 386 387 388 389 390 391 392 @property def representative_name ( self ) -> str : \"\"\" Method which returns a meaningful name for the raw source. In this case it's the host name followed by the table name Returns: The representative name for the raw source \"\"\" return f \" { self . host } / { self . table_name } \"","title":"representative_name()"},{"location":"content_analyzer/content_techniques/original_data/","text":"Content Analyzer Config OriginalData ( dtype = str ) Bases: FieldContentProductionTechnique Technique used to retrieve the original data within the content's raw source without applying any processing operation. Note that if specified, preprocessing operations will still be applied! This technique is particularly useful if the user wants to keep the original data of the contents PARAMETER DESCRIPTION dtype If specified, data will be casted to the chosen dtype TYPE: Callable DEFAULT: str Source code in clayrs/content_analyzer/field_content_production_techniques/field_content_production_technique.py 224 225 226 def __init__ ( self , dtype : Callable = str ): super () . __init__ () self . __dtype = dtype","title":"Original Data"},{"location":"content_analyzer/content_techniques/original_data/#content-analyzer-config","text":"","title":"Content Analyzer Config"},{"location":"content_analyzer/content_techniques/original_data/#clayrs.content_analyzer.OriginalData","text":"Bases: FieldContentProductionTechnique Technique used to retrieve the original data within the content's raw source without applying any processing operation. Note that if specified, preprocessing operations will still be applied! This technique is particularly useful if the user wants to keep the original data of the contents PARAMETER DESCRIPTION dtype If specified, data will be casted to the chosen dtype TYPE: Callable DEFAULT: str Source code in clayrs/content_analyzer/field_content_production_techniques/field_content_production_technique.py 224 225 226 def __init__ ( self , dtype : Callable = str ): super () . __init__ () self . __dtype = dtype","title":"OriginalData"},{"location":"content_analyzer/content_techniques/synset_df_frequency/","text":"Content Analyzer Config PyWSDSynsetDocumentFrequency () Bases: SynsetDocumentFrequency Class that produces a sparse vector for each content representing the document frequency of each synset found inside the document. The synsets are computed thanks to PyWSD library. Consider this textual representation: content1: \"After being trapped in a jungle board game for 26 years\" content2: \"After considering jungle County, it was trapped in a jungle\" This technique will produce the following sparse vectors: # vocabulary of the features vocabulary = {'trap.v.04': 4, 'jungle.n.03': 2, 'board.n.09': 0, 'plot.n.01': 3, 'twenty-six.s.01': 5, 'year.n.03': 7, 'view.v.02': 6, 'county.n.02': 1} content1: (0, 4) 1 (0, 2) 1 (0, 0) 1 (0, 3) 1 (0, 5) 1 (0, 7) 1 content2: (0, 4) 1 (0, 2) 2 (0, 6) 1 (0, 1) 1 Source code in clayrs/content_analyzer/field_content_production_techniques/synset_document_frequency.py 51 52 53 54 55 56 57 def __init__ ( self ): # The import is here since pywsd has a long warm up phase that should affect the computation # only when effectively instantiated from pywsd import disambiguate self . disambiguate = disambiguate super () . __init__ ()","title":"Synset Document Frequency"},{"location":"content_analyzer/content_techniques/synset_df_frequency/#content-analyzer-config","text":"","title":"Content Analyzer Config"},{"location":"content_analyzer/content_techniques/synset_df_frequency/#clayrs.content_analyzer.PyWSDSynsetDocumentFrequency","text":"Bases: SynsetDocumentFrequency Class that produces a sparse vector for each content representing the document frequency of each synset found inside the document. The synsets are computed thanks to PyWSD library. Consider this textual representation: content1: \"After being trapped in a jungle board game for 26 years\" content2: \"After considering jungle County, it was trapped in a jungle\" This technique will produce the following sparse vectors: # vocabulary of the features vocabulary = {'trap.v.04': 4, 'jungle.n.03': 2, 'board.n.09': 0, 'plot.n.01': 3, 'twenty-six.s.01': 5, 'year.n.03': 7, 'view.v.02': 6, 'county.n.02': 1} content1: (0, 4) 1 (0, 2) 1 (0, 0) 1 (0, 3) 1 (0, 5) 1 (0, 7) 1 content2: (0, 4) 1 (0, 2) 2 (0, 6) 1 (0, 1) 1 Source code in clayrs/content_analyzer/field_content_production_techniques/synset_document_frequency.py 51 52 53 54 55 56 57 def __init__ ( self ): # The import is here since pywsd has a long warm up phase that should affect the computation # only when effectively instantiated from pywsd import disambiguate self . disambiguate = disambiguate super () . __init__ ()","title":"PyWSDSynsetDocumentFrequency"},{"location":"content_analyzer/content_techniques/tfidf/","text":"Content Analyzer Config SkLearnTfIdf ( max_df = 1.0 , min_df = 1 , max_features = None , vocabulary = None , binary = False , dtype = np . float64 , norm = 'l2' , use_idf = True , smooth_idf = True , sublinear_tf = False ) Bases: TfIdfTechnique Class that produces a sparse vector for each content representing the tf-idf scores of its terms using SkLearn. Please refer to its documentation for more information about how it's computed PARAMETER DESCRIPTION max_df When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float in range [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None. TYPE: Union [ float , int ] DEFAULT: 1.0 min_df When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float in range of [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None. TYPE: Union [ float , int ] DEFAULT: 1 max_features If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus. This parameter is ignored if vocabulary is not None. TYPE: int DEFAULT: None vocabulary Either a Mapping (e.g., a dict) where keys are terms and values are indices in the feature matrix, or an iterable over terms. If not given, a vocabulary is determined from the input documents. TYPE: Union [ Mapping , Iterable ] DEFAULT: None binary If True, all non-zero term counts are set to 1. This does not mean outputs will have only 0/1 values, only that the tf term in tf-idf is binary. (Set idf and normalization to False to get 0/1 outputs). TYPE: bool DEFAULT: False dtype Precision of the tf-idf scores TYPE: Callable DEFAULT: np.float64 norm Each output row will have unit norm, either: 'l2': Sum of squares of vector elements is 1. The cosine similarity between two vectors is their dot product when l2 norm has been applied. 'l1': Sum of absolute values of vector elements is 1. See :func: preprocessing.normalize . TYPE: str DEFAULT: 'l2' use_idf Enable inverse-document-frequency reweighting. If False, idf(t) = 1. TYPE: bool DEFAULT: True smooth_idf Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions. TYPE: bool DEFAULT: True sublinear_tf Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf). TYPE: bool DEFAULT: False Source code in clayrs/content_analyzer/field_content_production_techniques/tf_idf.py 81 82 83 84 85 86 87 88 89 def __init__ ( self , max_df : Union [ float , int ] = 1.0 , min_df : Union [ float , int ] = 1 , max_features : int = None , vocabulary : Union [ Mapping , Iterable ] = None , binary : bool = False , dtype : Callable = np . float64 , norm : str = 'l2' , use_idf : bool = True , smooth_idf : bool = True , sublinear_tf : bool = False ): super () . __init__ () self . _sk_vectorizer = TfidfVectorizer ( max_df = max_df , min_df = min_df , max_features = max_features , vocabulary = vocabulary , binary = binary , dtype = dtype , norm = norm , use_idf = use_idf , smooth_idf = smooth_idf , sublinear_tf = sublinear_tf ) WhooshTfIdf () Bases: TfIdfTechnique Class that produces a sparse vector for each content representing the tf-idf scores of its terms using Whoosh The tf-idf computation formula is: \\[ tf \\mbox{-} idf = (1 + log10(tf)) * log10(idf) \\] Source code in clayrs/content_analyzer/field_content_production_techniques/tf_idf.py 133 134 def __init__ ( self ): super () . __init__ ()","title":"TfIdf"},{"location":"content_analyzer/content_techniques/tfidf/#content-analyzer-config","text":"","title":"Content Analyzer Config"},{"location":"content_analyzer/content_techniques/tfidf/#clayrs.content_analyzer.SkLearnTfIdf","text":"Bases: TfIdfTechnique Class that produces a sparse vector for each content representing the tf-idf scores of its terms using SkLearn. Please refer to its documentation for more information about how it's computed PARAMETER DESCRIPTION max_df When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float in range [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None. TYPE: Union [ float , int ] DEFAULT: 1.0 min_df When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float in range of [0.0, 1.0], the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None. TYPE: Union [ float , int ] DEFAULT: 1 max_features If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus. This parameter is ignored if vocabulary is not None. TYPE: int DEFAULT: None vocabulary Either a Mapping (e.g., a dict) where keys are terms and values are indices in the feature matrix, or an iterable over terms. If not given, a vocabulary is determined from the input documents. TYPE: Union [ Mapping , Iterable ] DEFAULT: None binary If True, all non-zero term counts are set to 1. This does not mean outputs will have only 0/1 values, only that the tf term in tf-idf is binary. (Set idf and normalization to False to get 0/1 outputs). TYPE: bool DEFAULT: False dtype Precision of the tf-idf scores TYPE: Callable DEFAULT: np.float64 norm Each output row will have unit norm, either: 'l2': Sum of squares of vector elements is 1. The cosine similarity between two vectors is their dot product when l2 norm has been applied. 'l1': Sum of absolute values of vector elements is 1. See :func: preprocessing.normalize . TYPE: str DEFAULT: 'l2' use_idf Enable inverse-document-frequency reweighting. If False, idf(t) = 1. TYPE: bool DEFAULT: True smooth_idf Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions. TYPE: bool DEFAULT: True sublinear_tf Apply sublinear tf scaling, i.e. replace tf with 1 + log(tf). TYPE: bool DEFAULT: False Source code in clayrs/content_analyzer/field_content_production_techniques/tf_idf.py 81 82 83 84 85 86 87 88 89 def __init__ ( self , max_df : Union [ float , int ] = 1.0 , min_df : Union [ float , int ] = 1 , max_features : int = None , vocabulary : Union [ Mapping , Iterable ] = None , binary : bool = False , dtype : Callable = np . float64 , norm : str = 'l2' , use_idf : bool = True , smooth_idf : bool = True , sublinear_tf : bool = False ): super () . __init__ () self . _sk_vectorizer = TfidfVectorizer ( max_df = max_df , min_df = min_df , max_features = max_features , vocabulary = vocabulary , binary = binary , dtype = dtype , norm = norm , use_idf = use_idf , smooth_idf = smooth_idf , sublinear_tf = sublinear_tf )","title":"SkLearnTfIdf"},{"location":"content_analyzer/content_techniques/tfidf/#clayrs.content_analyzer.WhooshTfIdf","text":"Bases: TfIdfTechnique Class that produces a sparse vector for each content representing the tf-idf scores of its terms using Whoosh The tf-idf computation formula is: \\[ tf \\mbox{-} idf = (1 + log10(tf)) * log10(idf) \\] Source code in clayrs/content_analyzer/field_content_production_techniques/tf_idf.py 133 134 def __init__ ( self ): super () . __init__ ()","title":"WhooshTfIdf"},{"location":"content_analyzer/content_techniques/embedding_techniques/combining_embeddings/","text":"Combine Embeddings Via the following, you can obtain embeddings of coarser granularity from models which return embeddings of finer granularity (e.g. obtain sentence embeddings from a model which returns word embeddings) from clayrs import content_analyzer as ca # obtain sentence embeddings combining token embeddings with a # centroid technique ca . Word2SentenceEmbedding ( embedding_source = ca . Gensim ( 'glove-twitter-50' ), combining_technique = ca . Centroid ()) Word2SentenceEmbedding ( embedding_source , combining_technique ) Bases: CombiningSentenceEmbeddingTechnique Class that makes use of a word granularity embedding source to produce sentence embeddings PARAMETER DESCRIPTION embedding_source Any WordEmbedding model TYPE: Union [ WordEmbeddingLoader , WordEmbeddingLearner , str ] combining_technique Technique used to combine embeddings of finer granularity (word-level) to obtain embeddings of coarser granularity (sentence-level) TYPE: CombiningTechnique Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 320 321 322 323 324 def __init__ ( self , embedding_source : Union [ WordEmbeddingLoader , WordEmbeddingLearner , str ], combining_technique : CombiningTechnique ): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, WordEmbeddingLoader) super () . __init__ ( embedding_source , combining_technique ) Word2DocEmbedding ( embedding_source , combining_technique ) Bases: CombiningDocumentEmbeddingTechnique Class that makes use of a word granularity embedding source to produce embeddings of document granularity PARAMETER DESCRIPTION embedding_source Any WordEmbedding model TYPE: Union [ WordEmbeddingLoader , WordEmbeddingLearner , str ] combining_technique Technique used to combine embeddings of finer granularity (word-level) to obtain embeddings of coarser granularity (doc-level) TYPE: CombiningTechnique Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 372 373 374 375 376 def __init__ ( self , embedding_source : Union [ WordEmbeddingLoader , WordEmbeddingLearner , str ], combining_technique : CombiningTechnique ): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, WordEmbeddingLoader) super () . __init__ ( embedding_source , combining_technique ) Sentence2DocEmbedding ( embedding_source , combining_technique ) Bases: CombiningDocumentEmbeddingTechnique Class that makes use of a sentence granularity embedding source to produce embeddings of document granularity PARAMETER DESCRIPTION embedding_source Any SentenceEmbedding model TYPE: Union [ SentenceEmbeddingLoader , SentenceEmbeddingLearner , str ] combining_technique Technique used to combine embeddings of finer granularity (sentence-level) to obtain embeddings of coarser granularity (doc-level) TYPE: CombiningTechnique Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 400 401 402 403 404 def __init__ ( self , embedding_source : Union [ SentenceEmbeddingLoader , SentenceEmbeddingLearner , str ], combining_technique : CombiningTechnique ): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, SentenceEmbeddingLoader) super () . __init__ ( embedding_source , combining_technique ) Combining Techniques Centroid Bases: CombiningTechnique This class computes the centroid vector of a matrix. combine ( embedding_matrix ) Calculates the centroid of the input matrix PARAMETER DESCRIPTION embedding_matrix np bi-dimensional array where rows are words columns are hidden dimension whose centroid will be calculated TYPE: np . ndarray RETURNS DESCRIPTION np . ndarray Centroid vector of the input matrix Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/combining_technique.py 34 35 36 37 38 39 40 41 42 43 44 45 def combine ( self , embedding_matrix : np . ndarray ) -> np . ndarray : \"\"\" Calculates the centroid of the input matrix Args: embedding_matrix: np bi-dimensional array where rows are words columns are hidden dimension whose centroid will be calculated Returns: Centroid vector of the input matrix \"\"\" return np . nanmean ( embedding_matrix , axis = 0 ) Sum Bases: CombiningTechnique This class computes the sum vector of a matrix. combine ( embedding_matrix ) Calculates the sum vector of the input matrix PARAMETER DESCRIPTION embedding_matrix np bi-dimensional array where rows are words columns are hidden dimension whose sum vector will be calculated TYPE: np . ndarray RETURNS DESCRIPTION np . ndarray Sum vector of the input matrix Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/combining_technique.py 58 59 60 61 62 63 64 65 66 67 68 69 def combine ( self , embedding_matrix : np . ndarray ) -> np . ndarray : \"\"\" Calculates the sum vector of the input matrix Args: embedding_matrix: np bi-dimensional array where rows are words columns are hidden dimension whose sum vector will be calculated Returns: Sum vector of the input matrix \"\"\" return np . sum ( embedding_matrix , axis = 0 ) SingleToken ( token_index ) Bases: CombiningTechnique Class which takes a specific row as representative of the whole matrix PARAMETER DESCRIPTION token_index index of the row of the matrix to take TYPE: int Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/combining_technique.py 85 86 87 def __init__ ( self , token_index : int ): self . token_index = token_index super () . __init__ () combine ( embedding_matrix ) Takes the row with index token_index (set in the constructor) from the input embedding_matrix PARAMETER DESCRIPTION embedding_matrix np bi-dimensional array where rows are words columns are hidden dimension from where the single token will be extracted TYPE: np . ndarray RETURNS DESCRIPTION np . ndarray Single row as representative of the whole matrix RAISES DESCRIPTION IndexError Exception raised when token_index (set in the constructor) is out of bounds for the input matrix Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/combining_technique.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def combine ( self , embedding_matrix : np . ndarray ) -> np . ndarray : \"\"\" Takes the row with index `token_index` (set in the constructor) from the input `embedding_matrix` Args: embedding_matrix: np bi-dimensional array where rows are words columns are hidden dimension from where the single token will be extracted Returns: Single row as representative of the whole matrix Raises: IndexError: Exception raised when `token_index` (set in the constructor) is out of bounds for the input matrix \"\"\" try : sentence_embedding = embedding_matrix [ self . token_index ] except IndexError : raise IndexError ( f 'The embedding matrix has { embedding_matrix . shape [ 1 ] } ' f 'embeddings but you tried to take the { self . token_index + 1 } th' ) return sentence_embedding","title":"Combining Embeddings"},{"location":"content_analyzer/content_techniques/embedding_techniques/combining_embeddings/#combine-embeddings","text":"Via the following, you can obtain embeddings of coarser granularity from models which return embeddings of finer granularity (e.g. obtain sentence embeddings from a model which returns word embeddings) from clayrs import content_analyzer as ca # obtain sentence embeddings combining token embeddings with a # centroid technique ca . Word2SentenceEmbedding ( embedding_source = ca . Gensim ( 'glove-twitter-50' ), combining_technique = ca . Centroid ())","title":"Combine Embeddings"},{"location":"content_analyzer/content_techniques/embedding_techniques/combining_embeddings/#clayrs.content_analyzer.Word2SentenceEmbedding","text":"Bases: CombiningSentenceEmbeddingTechnique Class that makes use of a word granularity embedding source to produce sentence embeddings PARAMETER DESCRIPTION embedding_source Any WordEmbedding model TYPE: Union [ WordEmbeddingLoader , WordEmbeddingLearner , str ] combining_technique Technique used to combine embeddings of finer granularity (word-level) to obtain embeddings of coarser granularity (sentence-level) TYPE: CombiningTechnique Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 320 321 322 323 324 def __init__ ( self , embedding_source : Union [ WordEmbeddingLoader , WordEmbeddingLearner , str ], combining_technique : CombiningTechnique ): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, WordEmbeddingLoader) super () . __init__ ( embedding_source , combining_technique )","title":"Word2SentenceEmbedding"},{"location":"content_analyzer/content_techniques/embedding_techniques/combining_embeddings/#clayrs.content_analyzer.Word2DocEmbedding","text":"Bases: CombiningDocumentEmbeddingTechnique Class that makes use of a word granularity embedding source to produce embeddings of document granularity PARAMETER DESCRIPTION embedding_source Any WordEmbedding model TYPE: Union [ WordEmbeddingLoader , WordEmbeddingLearner , str ] combining_technique Technique used to combine embeddings of finer granularity (word-level) to obtain embeddings of coarser granularity (doc-level) TYPE: CombiningTechnique Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 372 373 374 375 376 def __init__ ( self , embedding_source : Union [ WordEmbeddingLoader , WordEmbeddingLearner , str ], combining_technique : CombiningTechnique ): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, WordEmbeddingLoader) super () . __init__ ( embedding_source , combining_technique )","title":"Word2DocEmbedding"},{"location":"content_analyzer/content_techniques/embedding_techniques/combining_embeddings/#clayrs.content_analyzer.Sentence2DocEmbedding","text":"Bases: CombiningDocumentEmbeddingTechnique Class that makes use of a sentence granularity embedding source to produce embeddings of document granularity PARAMETER DESCRIPTION embedding_source Any SentenceEmbedding model TYPE: Union [ SentenceEmbeddingLoader , SentenceEmbeddingLearner , str ] combining_technique Technique used to combine embeddings of finer granularity (sentence-level) to obtain embeddings of coarser granularity (doc-level) TYPE: CombiningTechnique Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 400 401 402 403 404 def __init__ ( self , embedding_source : Union [ SentenceEmbeddingLoader , SentenceEmbeddingLearner , str ], combining_technique : CombiningTechnique ): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, SentenceEmbeddingLoader) super () . __init__ ( embedding_source , combining_technique )","title":"Sentence2DocEmbedding"},{"location":"content_analyzer/content_techniques/embedding_techniques/combining_embeddings/#combining-techniques","text":"","title":"Combining Techniques"},{"location":"content_analyzer/content_techniques/embedding_techniques/combining_embeddings/#clayrs.content_analyzer.Centroid","text":"Bases: CombiningTechnique This class computes the centroid vector of a matrix.","title":"Centroid"},{"location":"content_analyzer/content_techniques/embedding_techniques/combining_embeddings/#clayrs.content_analyzer.field_content_production_techniques.embedding_technique.combining_technique.Centroid.combine","text":"Calculates the centroid of the input matrix PARAMETER DESCRIPTION embedding_matrix np bi-dimensional array where rows are words columns are hidden dimension whose centroid will be calculated TYPE: np . ndarray RETURNS DESCRIPTION np . ndarray Centroid vector of the input matrix Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/combining_technique.py 34 35 36 37 38 39 40 41 42 43 44 45 def combine ( self , embedding_matrix : np . ndarray ) -> np . ndarray : \"\"\" Calculates the centroid of the input matrix Args: embedding_matrix: np bi-dimensional array where rows are words columns are hidden dimension whose centroid will be calculated Returns: Centroid vector of the input matrix \"\"\" return np . nanmean ( embedding_matrix , axis = 0 )","title":"combine()"},{"location":"content_analyzer/content_techniques/embedding_techniques/combining_embeddings/#clayrs.content_analyzer.Sum","text":"Bases: CombiningTechnique This class computes the sum vector of a matrix.","title":"Sum"},{"location":"content_analyzer/content_techniques/embedding_techniques/combining_embeddings/#clayrs.content_analyzer.field_content_production_techniques.embedding_technique.combining_technique.Sum.combine","text":"Calculates the sum vector of the input matrix PARAMETER DESCRIPTION embedding_matrix np bi-dimensional array where rows are words columns are hidden dimension whose sum vector will be calculated TYPE: np . ndarray RETURNS DESCRIPTION np . ndarray Sum vector of the input matrix Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/combining_technique.py 58 59 60 61 62 63 64 65 66 67 68 69 def combine ( self , embedding_matrix : np . ndarray ) -> np . ndarray : \"\"\" Calculates the sum vector of the input matrix Args: embedding_matrix: np bi-dimensional array where rows are words columns are hidden dimension whose sum vector will be calculated Returns: Sum vector of the input matrix \"\"\" return np . sum ( embedding_matrix , axis = 0 )","title":"combine()"},{"location":"content_analyzer/content_techniques/embedding_techniques/combining_embeddings/#clayrs.content_analyzer.SingleToken","text":"Bases: CombiningTechnique Class which takes a specific row as representative of the whole matrix PARAMETER DESCRIPTION token_index index of the row of the matrix to take TYPE: int Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/combining_technique.py 85 86 87 def __init__ ( self , token_index : int ): self . token_index = token_index super () . __init__ ()","title":"SingleToken"},{"location":"content_analyzer/content_techniques/embedding_techniques/combining_embeddings/#clayrs.content_analyzer.field_content_production_techniques.embedding_technique.combining_technique.SingleToken.combine","text":"Takes the row with index token_index (set in the constructor) from the input embedding_matrix PARAMETER DESCRIPTION embedding_matrix np bi-dimensional array where rows are words columns are hidden dimension from where the single token will be extracted TYPE: np . ndarray RETURNS DESCRIPTION np . ndarray Single row as representative of the whole matrix RAISES DESCRIPTION IndexError Exception raised when token_index (set in the constructor) is out of bounds for the input matrix Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/combining_technique.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def combine ( self , embedding_matrix : np . ndarray ) -> np . ndarray : \"\"\" Takes the row with index `token_index` (set in the constructor) from the input `embedding_matrix` Args: embedding_matrix: np bi-dimensional array where rows are words columns are hidden dimension from where the single token will be extracted Returns: Single row as representative of the whole matrix Raises: IndexError: Exception raised when `token_index` (set in the constructor) is out of bounds for the input matrix \"\"\" try : sentence_embedding = embedding_matrix [ self . token_index ] except IndexError : raise IndexError ( f 'The embedding matrix has { embedding_matrix . shape [ 1 ] } ' f 'embeddings but you tried to take the { self . token_index + 1 } th' ) return sentence_embedding","title":"combine()"},{"location":"content_analyzer/content_techniques/embedding_techniques/contextualized_embeddings/","text":"Contextualized Embeddings Via the following, you can obtain embeddings of finer granularity from models which are able to return also embeddings of coarser granularity (e.g. obtain word embeddings from a model which is also able to return sentence embeddings). For now only models working at sentence and token level are implemented from clayrs import content_analyzer as ca # obtain sentence embeddings combining token embeddings with a # centroid technique ca . Sentence2WordEmbedding ( embedding_source = ca . BertTransformers ( 'bert-base-uncased' )) Sentence2WordEmbedding ( embedding_source ) Bases: DecombiningInWordsEmbeddingTechnique Class that makes use of a sentence granularity embedding source to produce an embedding matrix with word granularity Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 466 467 468 469 def __init__ ( self , embedding_source : Union [ SentenceEmbeddingLoader , SentenceEmbeddingLearner ]): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, SentenceEmbeddingLoader) super () . __init__ ( embedding_source ) produce_single_repr ( field_data ) Produces a single matrix where each row is the embedding representation of each token of the sentence, while the columns are the hidden dimension of the chosen model PARAMETER DESCRIPTION field_data textual data to complexly represent TYPE: Union [ List [ str ], str ] RETURNS DESCRIPTION EmbeddingField Embedding for each token of the sentence Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 def produce_single_repr ( self , field_data : Union [ List [ str ], str ]) -> EmbeddingField : \"\"\" Produces a single matrix where each row is the embedding representation of each token of the sentence, while the columns are the hidden dimension of the chosen model Args: field_data: textual data to complexly represent Returns: Embedding for each token of the sentence \"\"\" field_data = check_not_tokenized ( field_data ) embedding_source : Union [ SentenceEmbeddingLoader , SentenceEmbeddingLearner ] = self . embedding_source words_embeddings = embedding_source . get_embedding_token ( field_data ) return EmbeddingField ( words_embeddings ) Model able to return sentence and token embeddings BertTransformers ( model_name = 'bert-base-uncased' , vec_strategy = CatStrategy ( 1 ), pooling_strategy = Centroid ()) Bases: Transformers Class that produces sentences/token embeddings using any Bert model from hugging face. PARAMETER DESCRIPTION model_name Name of the embeddings model to download or path where the model is stored locally TYPE: str DEFAULT: 'bert-base-uncased' vec_strategy Strategy which will be used to combine each output layer to obtain a single one TYPE: VectorStrategy DEFAULT: CatStrategy(1) pooling_strategy Strategy which will be used to combine the embedding representation of each token into a single one, representing the embedding of the whole sentence TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/content_analyzer/embeddings/embedding_loader/transformer.py 83 84 85 86 def __init__ ( self , model_name : str = 'bert-base-uncased' , vec_strategy : VectorStrategy = CatStrategy ( 1 ), pooling_strategy : CombiningTechnique = Centroid ()): super () . __init__ ( model_name , vec_strategy , pooling_strategy ) T5Transformers ( model_name = 't5-small' , vec_strategy = CatStrategy ( 1 ), pooling_strategy = Centroid ()) Bases: Transformers Class that produces sentences/token embeddings using sbert. PARAMETER DESCRIPTION model_name Name of the embeddings model to download or path where the model is stored locally TYPE: str DEFAULT: 't5-small' vec_strategy Strategy which will be used to combine each output layer to obtain a single one TYPE: VectorStrategy DEFAULT: CatStrategy(1) pooling_strategy Strategy which will be used to combine the embedding representation of each token into a single one, representing the embedding of the whole sentence TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/content_analyzer/embeddings/embedding_loader/transformer.py 122 123 124 125 def __init__ ( self , model_name : str = 't5-small' , vec_strategy : VectorStrategy = CatStrategy ( 1 ), pooling_strategy : CombiningTechnique = Centroid ()): super () . __init__ ( model_name , vec_strategy , pooling_strategy )","title":"Contextualized Embeddings"},{"location":"content_analyzer/content_techniques/embedding_techniques/contextualized_embeddings/#contextualized-embeddings","text":"Via the following, you can obtain embeddings of finer granularity from models which are able to return also embeddings of coarser granularity (e.g. obtain word embeddings from a model which is also able to return sentence embeddings). For now only models working at sentence and token level are implemented from clayrs import content_analyzer as ca # obtain sentence embeddings combining token embeddings with a # centroid technique ca . Sentence2WordEmbedding ( embedding_source = ca . BertTransformers ( 'bert-base-uncased' ))","title":"Contextualized Embeddings"},{"location":"content_analyzer/content_techniques/embedding_techniques/contextualized_embeddings/#clayrs.content_analyzer.Sentence2WordEmbedding","text":"Bases: DecombiningInWordsEmbeddingTechnique Class that makes use of a sentence granularity embedding source to produce an embedding matrix with word granularity Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 466 467 468 469 def __init__ ( self , embedding_source : Union [ SentenceEmbeddingLoader , SentenceEmbeddingLearner ]): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, SentenceEmbeddingLoader) super () . __init__ ( embedding_source )","title":"Sentence2WordEmbedding"},{"location":"content_analyzer/content_techniques/embedding_techniques/contextualized_embeddings/#clayrs.content_analyzer.field_content_production_techniques.embedding_technique.embedding_technique.Sentence2WordEmbedding.produce_single_repr","text":"Produces a single matrix where each row is the embedding representation of each token of the sentence, while the columns are the hidden dimension of the chosen model PARAMETER DESCRIPTION field_data textual data to complexly represent TYPE: Union [ List [ str ], str ] RETURNS DESCRIPTION EmbeddingField Embedding for each token of the sentence Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 def produce_single_repr ( self , field_data : Union [ List [ str ], str ]) -> EmbeddingField : \"\"\" Produces a single matrix where each row is the embedding representation of each token of the sentence, while the columns are the hidden dimension of the chosen model Args: field_data: textual data to complexly represent Returns: Embedding for each token of the sentence \"\"\" field_data = check_not_tokenized ( field_data ) embedding_source : Union [ SentenceEmbeddingLoader , SentenceEmbeddingLearner ] = self . embedding_source words_embeddings = embedding_source . get_embedding_token ( field_data ) return EmbeddingField ( words_embeddings )","title":"produce_single_repr()"},{"location":"content_analyzer/content_techniques/embedding_techniques/contextualized_embeddings/#model-able-to-return-sentence-and-token-embeddings","text":"","title":"Model able to return sentence and token embeddings"},{"location":"content_analyzer/content_techniques/embedding_techniques/contextualized_embeddings/#clayrs.content_analyzer.BertTransformers","text":"Bases: Transformers Class that produces sentences/token embeddings using any Bert model from hugging face. PARAMETER DESCRIPTION model_name Name of the embeddings model to download or path where the model is stored locally TYPE: str DEFAULT: 'bert-base-uncased' vec_strategy Strategy which will be used to combine each output layer to obtain a single one TYPE: VectorStrategy DEFAULT: CatStrategy(1) pooling_strategy Strategy which will be used to combine the embedding representation of each token into a single one, representing the embedding of the whole sentence TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/content_analyzer/embeddings/embedding_loader/transformer.py 83 84 85 86 def __init__ ( self , model_name : str = 'bert-base-uncased' , vec_strategy : VectorStrategy = CatStrategy ( 1 ), pooling_strategy : CombiningTechnique = Centroid ()): super () . __init__ ( model_name , vec_strategy , pooling_strategy )","title":"BertTransformers"},{"location":"content_analyzer/content_techniques/embedding_techniques/contextualized_embeddings/#clayrs.content_analyzer.T5Transformers","text":"Bases: Transformers Class that produces sentences/token embeddings using sbert. PARAMETER DESCRIPTION model_name Name of the embeddings model to download or path where the model is stored locally TYPE: str DEFAULT: 't5-small' vec_strategy Strategy which will be used to combine each output layer to obtain a single one TYPE: VectorStrategy DEFAULT: CatStrategy(1) pooling_strategy Strategy which will be used to combine the embedding representation of each token into a single one, representing the embedding of the whole sentence TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/content_analyzer/embeddings/embedding_loader/transformer.py 122 123 124 125 def __init__ ( self , model_name : str = 't5-small' , vec_strategy : VectorStrategy = CatStrategy ( 1 ), pooling_strategy : CombiningTechnique = Centroid ()): super () . __init__ ( model_name , vec_strategy , pooling_strategy )","title":"T5Transformers"},{"location":"content_analyzer/content_techniques/embedding_techniques/document_embeddings/","text":"Document Embeddings Via the following, you can obtain embeddings of document granularity from clayrs import content_analyzer as ca # obtain document embeddings by training LDA model # on corpus of contents to complexly represent ca . DocumentEmbeddingTechnique ( embedding_source = ca . GensimLDA ()) DocumentEmbeddingTechnique ( embedding_source ) Bases: StandardEmbeddingTechnique Class that makes use of a document granularity embedding source to produce document embeddings PARAMETER DESCRIPTION embedding_source Any DocumentEmbedding model TYPE: Union [ DocumentEmbeddingLoader , DocumentEmbeddingLearner , str ] Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 223 224 225 226 def __init__ ( self , embedding_source : Union [ DocumentEmbeddingLoader , DocumentEmbeddingLearner , str ]): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, DocumentEmbeddingLoader) super () . __init__ ( embedding_source ) Document Embedding models GensimLatentSemanticAnalysis ( reference = None , auto_save = True , ** kwargs ) Bases: GensimDocumentEmbeddingLearner Class that implements Latent Semantic Analysis (A.K.A. Latent Semantic Indexing) (LSI) thanks to the Gensim library. If a pre-trained local Word2Vec model must be loaded, put its path in the reference parameter. Otherwise, a Word2Vec model will be trained from scratch based on the preprocessed corpus of the contents to complexly represent If you'd like to save the model once trained, set the path in the reference parameter and set auto_save=True . If reference is None, trained model won't be saved after training and will only be used to produce contents in the current run Additional parameters regarding the model itself could be passed, check gensim documentation to see what else can be customized PARAMETER DESCRIPTION reference Path of the model to load/where the model trained will be saved if auto_save=True . If None the trained model won't be saved after training and will only be used to produce contents in the current run TYPE: str DEFAULT: None auto_save If True, the model will be saved in the path specified in reference parameter TYPE: bool DEFAULT: True Source code in clayrs/content_analyzer/embeddings/embedding_learner/latent_semantic_analysis.py 33 34 def __init__ ( self , reference : str = None , auto_save : bool = True , ** kwargs ): super () . __init__ ( reference , auto_save , \".model\" , ** kwargs ) GensimLDA ( reference = None , auto_save = True , ** kwargs ) Bases: GensimDocumentEmbeddingLearner Class that implements Latent Dirichlet Allocation (LDA) thanks to the Gensim library. If a pre-trained local Word2Vec model must be loaded, put its path in the reference parameter. Otherwise, a Word2Vec model will be trained from scratch based on the preprocessed corpus of the contents to complexly represent If you'd like to save the model once trained, set the path in the reference parameter and set auto_save=True . If reference is None, trained model won't be saved after training and will only be used to produce contents in the current run Additional parameters regarding the model itself could be passed, check gensim documentation to see what else can be customized PARAMETER DESCRIPTION reference Path of the model to load/where the model trained will be saved if auto_save=True . If None the trained model won't be saved after training and will only be used to produce contents in the current run TYPE: str DEFAULT: None auto_save If True, the model will be saved in the path specified in reference parameter TYPE: bool DEFAULT: True Source code in clayrs/content_analyzer/embeddings/embedding_learner/lda.py 33 34 def __init__ ( self , reference : str = None , auto_save : bool = True , ** kwargs ): super () . __init__ ( reference , auto_save , \".model\" , ** kwargs )","title":"Document Embeddings"},{"location":"content_analyzer/content_techniques/embedding_techniques/document_embeddings/#document-embeddings","text":"Via the following, you can obtain embeddings of document granularity from clayrs import content_analyzer as ca # obtain document embeddings by training LDA model # on corpus of contents to complexly represent ca . DocumentEmbeddingTechnique ( embedding_source = ca . GensimLDA ())","title":"Document Embeddings"},{"location":"content_analyzer/content_techniques/embedding_techniques/document_embeddings/#clayrs.content_analyzer.DocumentEmbeddingTechnique","text":"Bases: StandardEmbeddingTechnique Class that makes use of a document granularity embedding source to produce document embeddings PARAMETER DESCRIPTION embedding_source Any DocumentEmbedding model TYPE: Union [ DocumentEmbeddingLoader , DocumentEmbeddingLearner , str ] Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 223 224 225 226 def __init__ ( self , embedding_source : Union [ DocumentEmbeddingLoader , DocumentEmbeddingLearner , str ]): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, DocumentEmbeddingLoader) super () . __init__ ( embedding_source )","title":"DocumentEmbeddingTechnique"},{"location":"content_analyzer/content_techniques/embedding_techniques/document_embeddings/#document-embedding-models","text":"","title":"Document Embedding models"},{"location":"content_analyzer/content_techniques/embedding_techniques/document_embeddings/#clayrs.content_analyzer.GensimLatentSemanticAnalysis","text":"Bases: GensimDocumentEmbeddingLearner Class that implements Latent Semantic Analysis (A.K.A. Latent Semantic Indexing) (LSI) thanks to the Gensim library. If a pre-trained local Word2Vec model must be loaded, put its path in the reference parameter. Otherwise, a Word2Vec model will be trained from scratch based on the preprocessed corpus of the contents to complexly represent If you'd like to save the model once trained, set the path in the reference parameter and set auto_save=True . If reference is None, trained model won't be saved after training and will only be used to produce contents in the current run Additional parameters regarding the model itself could be passed, check gensim documentation to see what else can be customized PARAMETER DESCRIPTION reference Path of the model to load/where the model trained will be saved if auto_save=True . If None the trained model won't be saved after training and will only be used to produce contents in the current run TYPE: str DEFAULT: None auto_save If True, the model will be saved in the path specified in reference parameter TYPE: bool DEFAULT: True Source code in clayrs/content_analyzer/embeddings/embedding_learner/latent_semantic_analysis.py 33 34 def __init__ ( self , reference : str = None , auto_save : bool = True , ** kwargs ): super () . __init__ ( reference , auto_save , \".model\" , ** kwargs )","title":"GensimLatentSemanticAnalysis"},{"location":"content_analyzer/content_techniques/embedding_techniques/document_embeddings/#clayrs.content_analyzer.GensimLDA","text":"Bases: GensimDocumentEmbeddingLearner Class that implements Latent Dirichlet Allocation (LDA) thanks to the Gensim library. If a pre-trained local Word2Vec model must be loaded, put its path in the reference parameter. Otherwise, a Word2Vec model will be trained from scratch based on the preprocessed corpus of the contents to complexly represent If you'd like to save the model once trained, set the path in the reference parameter and set auto_save=True . If reference is None, trained model won't be saved after training and will only be used to produce contents in the current run Additional parameters regarding the model itself could be passed, check gensim documentation to see what else can be customized PARAMETER DESCRIPTION reference Path of the model to load/where the model trained will be saved if auto_save=True . If None the trained model won't be saved after training and will only be used to produce contents in the current run TYPE: str DEFAULT: None auto_save If True, the model will be saved in the path specified in reference parameter TYPE: bool DEFAULT: True Source code in clayrs/content_analyzer/embeddings/embedding_learner/lda.py 33 34 def __init__ ( self , reference : str = None , auto_save : bool = True , ** kwargs ): super () . __init__ ( reference , auto_save , \".model\" , ** kwargs )","title":"GensimLDA"},{"location":"content_analyzer/content_techniques/embedding_techniques/sentence_embeddings/","text":"Sentence Embeddings Via the following, you can obtain embeddings of sentence granularity from clayrs import content_analyzer as ca # obtain sentence embeddings using pre-trained model 'glove-twitter-50' # from SBERT library ca . SentenceEmbeddingTechnique ( embedding_source = ca . Sbert ( 'paraphrase-distilroberta-base-v1' )) SentenceEmbeddingTechnique ( embedding_source ) Bases: StandardEmbeddingTechnique Class that makes use of a sentence granularity embedding source to produce sentence embeddings PARAMETER DESCRIPTION embedding_source Any SentenceEmbedding model TYPE: Union [ SentenceEmbeddingLoader , SentenceEmbeddingLearner , str ] Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 200 201 202 203 def __init__ ( self , embedding_source : Union [ SentenceEmbeddingLoader , SentenceEmbeddingLearner , str ]): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, SentenceEmbeddingLoader) super () . __init__ ( embedding_source ) Sentence Embedding models BertTransformers ( model_name = 'bert-base-uncased' , vec_strategy = CatStrategy ( 1 ), pooling_strategy = Centroid ()) Bases: Transformers Class that produces sentences/token embeddings using any Bert model from hugging face. PARAMETER DESCRIPTION model_name Name of the embeddings model to download or path where the model is stored locally TYPE: str DEFAULT: 'bert-base-uncased' vec_strategy Strategy which will be used to combine each output layer to obtain a single one TYPE: VectorStrategy DEFAULT: CatStrategy(1) pooling_strategy Strategy which will be used to combine the embedding representation of each token into a single one, representing the embedding of the whole sentence TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/content_analyzer/embeddings/embedding_loader/transformer.py 83 84 85 86 def __init__ ( self , model_name : str = 'bert-base-uncased' , vec_strategy : VectorStrategy = CatStrategy ( 1 ), pooling_strategy : CombiningTechnique = Centroid ()): super () . __init__ ( model_name , vec_strategy , pooling_strategy ) Sbert ( model_name_or_file_path = 'paraphrase-distilroberta-base-v1' ) Bases: SentenceEmbeddingLoader Class that produces sentences embeddings using sbert. The model will be automatically downloaded if not present locally. PARAMETER DESCRIPTION model_name_or_file_path name of the model to download or path where the model is stored locally TYPE: str DEFAULT: 'paraphrase-distilroberta-base-v1' Source code in clayrs/content_analyzer/embeddings/embedding_loader/sbert.py 18 19 def __init__ ( self , model_name_or_file_path : str = 'paraphrase-distilroberta-base-v1' ): super () . __init__ ( model_name_or_file_path ) T5Transformers ( model_name = 't5-small' , vec_strategy = CatStrategy ( 1 ), pooling_strategy = Centroid ()) Bases: Transformers Class that produces sentences/token embeddings using sbert. PARAMETER DESCRIPTION model_name Name of the embeddings model to download or path where the model is stored locally TYPE: str DEFAULT: 't5-small' vec_strategy Strategy which will be used to combine each output layer to obtain a single one TYPE: VectorStrategy DEFAULT: CatStrategy(1) pooling_strategy Strategy which will be used to combine the embedding representation of each token into a single one, representing the embedding of the whole sentence TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/content_analyzer/embeddings/embedding_loader/transformer.py 122 123 124 125 def __init__ ( self , model_name : str = 't5-small' , vec_strategy : VectorStrategy = CatStrategy ( 1 ), pooling_strategy : CombiningTechnique = Centroid ()): super () . __init__ ( model_name , vec_strategy , pooling_strategy )","title":"Sentence Embeddings"},{"location":"content_analyzer/content_techniques/embedding_techniques/sentence_embeddings/#sentence-embeddings","text":"Via the following, you can obtain embeddings of sentence granularity from clayrs import content_analyzer as ca # obtain sentence embeddings using pre-trained model 'glove-twitter-50' # from SBERT library ca . SentenceEmbeddingTechnique ( embedding_source = ca . Sbert ( 'paraphrase-distilroberta-base-v1' ))","title":"Sentence Embeddings"},{"location":"content_analyzer/content_techniques/embedding_techniques/sentence_embeddings/#clayrs.content_analyzer.SentenceEmbeddingTechnique","text":"Bases: StandardEmbeddingTechnique Class that makes use of a sentence granularity embedding source to produce sentence embeddings PARAMETER DESCRIPTION embedding_source Any SentenceEmbedding model TYPE: Union [ SentenceEmbeddingLoader , SentenceEmbeddingLearner , str ] Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 200 201 202 203 def __init__ ( self , embedding_source : Union [ SentenceEmbeddingLoader , SentenceEmbeddingLearner , str ]): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, SentenceEmbeddingLoader) super () . __init__ ( embedding_source )","title":"SentenceEmbeddingTechnique"},{"location":"content_analyzer/content_techniques/embedding_techniques/sentence_embeddings/#sentence-embedding-models","text":"","title":"Sentence Embedding models"},{"location":"content_analyzer/content_techniques/embedding_techniques/sentence_embeddings/#clayrs.content_analyzer.BertTransformers","text":"Bases: Transformers Class that produces sentences/token embeddings using any Bert model from hugging face. PARAMETER DESCRIPTION model_name Name of the embeddings model to download or path where the model is stored locally TYPE: str DEFAULT: 'bert-base-uncased' vec_strategy Strategy which will be used to combine each output layer to obtain a single one TYPE: VectorStrategy DEFAULT: CatStrategy(1) pooling_strategy Strategy which will be used to combine the embedding representation of each token into a single one, representing the embedding of the whole sentence TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/content_analyzer/embeddings/embedding_loader/transformer.py 83 84 85 86 def __init__ ( self , model_name : str = 'bert-base-uncased' , vec_strategy : VectorStrategy = CatStrategy ( 1 ), pooling_strategy : CombiningTechnique = Centroid ()): super () . __init__ ( model_name , vec_strategy , pooling_strategy )","title":"BertTransformers"},{"location":"content_analyzer/content_techniques/embedding_techniques/sentence_embeddings/#clayrs.content_analyzer.Sbert","text":"Bases: SentenceEmbeddingLoader Class that produces sentences embeddings using sbert. The model will be automatically downloaded if not present locally. PARAMETER DESCRIPTION model_name_or_file_path name of the model to download or path where the model is stored locally TYPE: str DEFAULT: 'paraphrase-distilroberta-base-v1' Source code in clayrs/content_analyzer/embeddings/embedding_loader/sbert.py 18 19 def __init__ ( self , model_name_or_file_path : str = 'paraphrase-distilroberta-base-v1' ): super () . __init__ ( model_name_or_file_path )","title":"Sbert"},{"location":"content_analyzer/content_techniques/embedding_techniques/sentence_embeddings/#clayrs.content_analyzer.T5Transformers","text":"Bases: Transformers Class that produces sentences/token embeddings using sbert. PARAMETER DESCRIPTION model_name Name of the embeddings model to download or path where the model is stored locally TYPE: str DEFAULT: 't5-small' vec_strategy Strategy which will be used to combine each output layer to obtain a single one TYPE: VectorStrategy DEFAULT: CatStrategy(1) pooling_strategy Strategy which will be used to combine the embedding representation of each token into a single one, representing the embedding of the whole sentence TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/content_analyzer/embeddings/embedding_loader/transformer.py 122 123 124 125 def __init__ ( self , model_name : str = 't5-small' , vec_strategy : VectorStrategy = CatStrategy ( 1 ), pooling_strategy : CombiningTechnique = Centroid ()): super () . __init__ ( model_name , vec_strategy , pooling_strategy )","title":"T5Transformers"},{"location":"content_analyzer/content_techniques/embedding_techniques/word_embeddings/","text":"Word Embeddings Via the following, you can obtain embeddings of word granularity from clayrs import content_analyzer as ca # obtain word embeddings using pre-trained model 'glove-twitter-50' # from Gensim library ca . WordEmbeddingTechnique ( embedding_source = ca . Gensim ( 'glove-twitter-50' )) WordEmbeddingTechnique ( embedding_source ) Bases: StandardEmbeddingTechnique Class that makes use of a word granularity embedding source to produce word embeddings PARAMETER DESCRIPTION embedding_source Any WordEmbedding model TYPE: Union [ WordEmbeddingLoader , WordEmbeddingLearner , str ] Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 177 178 179 180 def __init__ ( self , embedding_source : Union [ WordEmbeddingLoader , WordEmbeddingLearner , str ]): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, WordEmbeddingLoader) super () . __init__ ( embedding_source ) Word Embedding models Gensim ( model_name = 'glove-twitter-25' ) Bases: WordEmbeddingLoader Class that produces word embeddings using gensim pre-trained models. The model will be automatically downloaded using the gensim downloader api if not present locally. PARAMETER DESCRIPTION model_name Name of the model to load/download TYPE: str DEFAULT: 'glove-twitter-25' Source code in clayrs/content_analyzer/embeddings/embedding_loader/gensim.py 18 19 def __init__ ( self , model_name : str = 'glove-twitter-25' ): super () . __init__ ( model_name ) GensimDoc2Vec ( reference = None , auto_save = True , ** kwargs ) Bases: GensimWordEmbeddingLearner Class that implements Doc2Vec model thanks to the Gensim library. If a pre-trained local Word2Vec model must be loaded, put its path in the reference parameter. Otherwise, a Word2Vec model will be trained from scratch based on the preprocessed corpus of the contents to complexly represent If you'd like to save the model once trained, set the path in the reference parameter and set auto_save=True . If reference is None, trained model won't be saved after training and will only be used to produce contents in the current run Additional parameters regarding the model itself could be passed, check gensim documentation to see what else can be customized PARAMETER DESCRIPTION reference Path of the model to load/where the model trained will be saved if auto_save=True . If None the trained model won't be saved after training and will only be used to produce contents in the current run TYPE: str DEFAULT: None auto_save If True, the model will be saved in the path specified in reference parameter TYPE: bool DEFAULT: True Source code in clayrs/content_analyzer/embeddings/embedding_learner/doc2vec.py 29 30 def __init__ ( self , reference : str = None , auto_save : bool = True , ** kwargs ): super () . __init__ ( reference , auto_save , \".kv\" , ** kwargs ) GensimFastText ( reference = None , auto_save = True , ** kwargs ) Bases: GensimWordEmbeddingLearner Class that implements FastText model thanks to the Gensim library. If a pre-trained local Word2Vec model must be loaded, put its path in the reference parameter. Otherwise, a Word2Vec model will be trained from scratch based on the preprocessed corpus of the contents to complexly represent If you'd like to save the model once trained, set the path in the reference parameter and set auto_save=True . If reference is None, trained model won't be saved after training and will only be used to produce contents in the current run Additional parameters regarding the model itself could be passed, check gensim documentation to see what else can be customized PARAMETER DESCRIPTION reference Path of the model to load/where the model trained will be saved if auto_save=True . If None the trained model won't be saved after training and will only be used to produce contents in the current run TYPE: str DEFAULT: None auto_save If True, the model will be saved in the path specified in reference parameter TYPE: bool DEFAULT: True Source code in clayrs/content_analyzer/embeddings/embedding_learner/fasttext.py 29 30 def __init__ ( self , reference : str = None , auto_save : bool = True , ** kwargs ): super () . __init__ ( reference , auto_save , \".kv\" , ** kwargs ) GensimRandomIndexing ( reference = None , auto_save = True , ** kwargs ) Bases: GensimDocumentEmbeddingLearner Class that implements RandomIndexing model thanks to the Gensim library. If a pre-trained local Word2Vec model must be loaded, put its path in the reference parameter. Otherwise, a Word2Vec model will be trained from scratch based on the preprocessed corpus of the contents to complexly represent If you'd like to save the model once trained, set the path in the reference parameter and set auto_save=True . If reference is None, trained model won't be saved after training and will only be used to produce contents in the current run Additional parameters regarding the model itself could be passed, check gensim documentation to see what else can be customized PARAMETER DESCRIPTION reference Path of the model to load/where the model trained will be saved if auto_save=True . If None the trained model won't be saved after training and will only be used to produce contents in the current run TYPE: str DEFAULT: None auto_save If True, the model will be saved in the path specified in reference parameter TYPE: bool DEFAULT: True Source code in clayrs/content_analyzer/embeddings/embedding_learner/random_indexing.py 33 34 def __init__ ( self , reference : str = None , auto_save : bool = True , ** kwargs ): super () . __init__ ( reference , auto_save , \".model\" , ** kwargs ) GensimWord2Vec ( reference = None , auto_save = True , ** kwargs ) Bases: GensimWordEmbeddingLearner Class that implements Word2Vec model thanks to the Gensim library. If a pre-trained local Word2Vec model must be loaded, put its path in the reference parameter. Otherwise, a Word2Vec model will be trained from scratch based on the preprocessed corpus of the contents to complexly represent If you'd like to save the model once trained, set the path in the reference parameter and set auto_save=True . If reference is None, trained model won't be saved after training and will only be used to produce contents in the current run Additional parameters regarding the model itself could be passed, check gensim documentation to see what else can be customized PARAMETER DESCRIPTION reference Path of the model to load/where the model trained will be saved if auto_save=True . If None the trained model won't be saved after training and will only be used to produce contents in the current run TYPE: str DEFAULT: None auto_save If True, the model will be saved in the path specified in reference parameter TYPE: bool DEFAULT: True Source code in clayrs/content_analyzer/embeddings/embedding_learner/word2vec.py 29 30 def __init__ ( self , reference : str = None , auto_save : bool = True , ** kwargs ): super () . __init__ ( reference , auto_save , \".kv\" , ** kwargs )","title":"Word Embeddings"},{"location":"content_analyzer/content_techniques/embedding_techniques/word_embeddings/#word-embeddings","text":"Via the following, you can obtain embeddings of word granularity from clayrs import content_analyzer as ca # obtain word embeddings using pre-trained model 'glove-twitter-50' # from Gensim library ca . WordEmbeddingTechnique ( embedding_source = ca . Gensim ( 'glove-twitter-50' ))","title":"Word Embeddings"},{"location":"content_analyzer/content_techniques/embedding_techniques/word_embeddings/#clayrs.content_analyzer.WordEmbeddingTechnique","text":"Bases: StandardEmbeddingTechnique Class that makes use of a word granularity embedding source to produce word embeddings PARAMETER DESCRIPTION embedding_source Any WordEmbedding model TYPE: Union [ WordEmbeddingLoader , WordEmbeddingLearner , str ] Source code in clayrs/content_analyzer/field_content_production_techniques/embedding_technique/embedding_technique.py 177 178 179 180 def __init__ ( self , embedding_source : Union [ WordEmbeddingLoader , WordEmbeddingLearner , str ]): # if isinstance(embedding_source, str): # embedding_source = self.from_str_to_embedding_source(embedding_source, WordEmbeddingLoader) super () . __init__ ( embedding_source )","title":"WordEmbeddingTechnique"},{"location":"content_analyzer/content_techniques/embedding_techniques/word_embeddings/#word-embedding-models","text":"","title":"Word Embedding models"},{"location":"content_analyzer/content_techniques/embedding_techniques/word_embeddings/#clayrs.content_analyzer.Gensim","text":"Bases: WordEmbeddingLoader Class that produces word embeddings using gensim pre-trained models. The model will be automatically downloaded using the gensim downloader api if not present locally. PARAMETER DESCRIPTION model_name Name of the model to load/download TYPE: str DEFAULT: 'glove-twitter-25' Source code in clayrs/content_analyzer/embeddings/embedding_loader/gensim.py 18 19 def __init__ ( self , model_name : str = 'glove-twitter-25' ): super () . __init__ ( model_name )","title":"Gensim"},{"location":"content_analyzer/content_techniques/embedding_techniques/word_embeddings/#clayrs.content_analyzer.GensimDoc2Vec","text":"Bases: GensimWordEmbeddingLearner Class that implements Doc2Vec model thanks to the Gensim library. If a pre-trained local Word2Vec model must be loaded, put its path in the reference parameter. Otherwise, a Word2Vec model will be trained from scratch based on the preprocessed corpus of the contents to complexly represent If you'd like to save the model once trained, set the path in the reference parameter and set auto_save=True . If reference is None, trained model won't be saved after training and will only be used to produce contents in the current run Additional parameters regarding the model itself could be passed, check gensim documentation to see what else can be customized PARAMETER DESCRIPTION reference Path of the model to load/where the model trained will be saved if auto_save=True . If None the trained model won't be saved after training and will only be used to produce contents in the current run TYPE: str DEFAULT: None auto_save If True, the model will be saved in the path specified in reference parameter TYPE: bool DEFAULT: True Source code in clayrs/content_analyzer/embeddings/embedding_learner/doc2vec.py 29 30 def __init__ ( self , reference : str = None , auto_save : bool = True , ** kwargs ): super () . __init__ ( reference , auto_save , \".kv\" , ** kwargs )","title":"GensimDoc2Vec"},{"location":"content_analyzer/content_techniques/embedding_techniques/word_embeddings/#clayrs.content_analyzer.GensimFastText","text":"Bases: GensimWordEmbeddingLearner Class that implements FastText model thanks to the Gensim library. If a pre-trained local Word2Vec model must be loaded, put its path in the reference parameter. Otherwise, a Word2Vec model will be trained from scratch based on the preprocessed corpus of the contents to complexly represent If you'd like to save the model once trained, set the path in the reference parameter and set auto_save=True . If reference is None, trained model won't be saved after training and will only be used to produce contents in the current run Additional parameters regarding the model itself could be passed, check gensim documentation to see what else can be customized PARAMETER DESCRIPTION reference Path of the model to load/where the model trained will be saved if auto_save=True . If None the trained model won't be saved after training and will only be used to produce contents in the current run TYPE: str DEFAULT: None auto_save If True, the model will be saved in the path specified in reference parameter TYPE: bool DEFAULT: True Source code in clayrs/content_analyzer/embeddings/embedding_learner/fasttext.py 29 30 def __init__ ( self , reference : str = None , auto_save : bool = True , ** kwargs ): super () . __init__ ( reference , auto_save , \".kv\" , ** kwargs )","title":"GensimFastText"},{"location":"content_analyzer/content_techniques/embedding_techniques/word_embeddings/#clayrs.content_analyzer.GensimRandomIndexing","text":"Bases: GensimDocumentEmbeddingLearner Class that implements RandomIndexing model thanks to the Gensim library. If a pre-trained local Word2Vec model must be loaded, put its path in the reference parameter. Otherwise, a Word2Vec model will be trained from scratch based on the preprocessed corpus of the contents to complexly represent If you'd like to save the model once trained, set the path in the reference parameter and set auto_save=True . If reference is None, trained model won't be saved after training and will only be used to produce contents in the current run Additional parameters regarding the model itself could be passed, check gensim documentation to see what else can be customized PARAMETER DESCRIPTION reference Path of the model to load/where the model trained will be saved if auto_save=True . If None the trained model won't be saved after training and will only be used to produce contents in the current run TYPE: str DEFAULT: None auto_save If True, the model will be saved in the path specified in reference parameter TYPE: bool DEFAULT: True Source code in clayrs/content_analyzer/embeddings/embedding_learner/random_indexing.py 33 34 def __init__ ( self , reference : str = None , auto_save : bool = True , ** kwargs ): super () . __init__ ( reference , auto_save , \".model\" , ** kwargs )","title":"GensimRandomIndexing"},{"location":"content_analyzer/content_techniques/embedding_techniques/word_embeddings/#clayrs.content_analyzer.GensimWord2Vec","text":"Bases: GensimWordEmbeddingLearner Class that implements Word2Vec model thanks to the Gensim library. If a pre-trained local Word2Vec model must be loaded, put its path in the reference parameter. Otherwise, a Word2Vec model will be trained from scratch based on the preprocessed corpus of the contents to complexly represent If you'd like to save the model once trained, set the path in the reference parameter and set auto_save=True . If reference is None, trained model won't be saved after training and will only be used to produce contents in the current run Additional parameters regarding the model itself could be passed, check gensim documentation to see what else can be customized PARAMETER DESCRIPTION reference Path of the model to load/where the model trained will be saved if auto_save=True . If None the trained model won't be saved after training and will only be used to produce contents in the current run TYPE: str DEFAULT: None auto_save If True, the model will be saved in the path specified in reference parameter TYPE: bool DEFAULT: True Source code in clayrs/content_analyzer/embeddings/embedding_learner/word2vec.py 29 30 def __init__ ( self , reference : str = None , auto_save : bool = True , ** kwargs ): super () . __init__ ( reference , auto_save , \".kv\" , ** kwargs )","title":"GensimWord2Vec"},{"location":"content_analyzer/exogenous_techniques/babelfy/","text":"Properties from DBPedia ontology BabelPyEntityLinking ( field_to_link , api_key = None , lang = 'EN' ) Bases: EntityLinking Exogenous technique which expands each content by using as external source the the BabelFy library. Each content will be expanded with the following babelfy properties (if available): 'babelSynsetID', 'DBPediaURL', 'BabelNetURL', 'score', 'coherenceScore', 'globalScore', 'source' PARAMETER DESCRIPTION field_to_link Field of the raw source which will be used to search for the content properties in BabelFy TYPE: str api_key String obtained by registering to babelfy website. If None only few queries can be executed TYPE: str DEFAULT: None lang Language of the properties to retrieve TYPE: str DEFAULT: 'EN' Source code in clayrs/content_analyzer/exogenous_properties_retrieval.py 625 626 627 628 629 630 def __init__ ( self , field_to_link : str , api_key : str = None , lang : str = \"EN\" ): super () . __init__ ( \"all_retrieved\" ) # fixed mode since it doesn't make sense for babelfy self . __field_to_link = field_to_link self . __api_key = api_key self . __lang = lang self . __babel_client = BabelfyClient ( self . __api_key , { \"lang\" : lang })","title":"BabelFy Entity Linking"},{"location":"content_analyzer/exogenous_techniques/babelfy/#properties-from-dbpedia-ontology","text":"","title":"Properties from DBPedia ontology"},{"location":"content_analyzer/exogenous_techniques/babelfy/#clayrs.content_analyzer.BabelPyEntityLinking","text":"Bases: EntityLinking Exogenous technique which expands each content by using as external source the the BabelFy library. Each content will be expanded with the following babelfy properties (if available): 'babelSynsetID', 'DBPediaURL', 'BabelNetURL', 'score', 'coherenceScore', 'globalScore', 'source' PARAMETER DESCRIPTION field_to_link Field of the raw source which will be used to search for the content properties in BabelFy TYPE: str api_key String obtained by registering to babelfy website. If None only few queries can be executed TYPE: str DEFAULT: None lang Language of the properties to retrieve TYPE: str DEFAULT: 'EN' Source code in clayrs/content_analyzer/exogenous_properties_retrieval.py 625 626 627 628 629 630 def __init__ ( self , field_to_link : str , api_key : str = None , lang : str = \"EN\" ): super () . __init__ ( \"all_retrieved\" ) # fixed mode since it doesn't make sense for babelfy self . __field_to_link = field_to_link self . __api_key = api_key self . __lang = lang self . __babel_client = BabelfyClient ( self . __api_key , { \"lang\" : lang })","title":"BabelPyEntityLinking"},{"location":"content_analyzer/exogenous_techniques/dbpedia/","text":"Properties from DBPedia ontology DBPediaMappingTechnique ( entity_type , label_field , lang = 'EN' , mode = 'only_retrieved_evaluated' , return_prop_as_uri = False , max_timeout = 5 ) Bases: ExogenousPropertiesRetrieval Exogenous technique which expands each content by using as external source the DBPedia ontology It needs the entity of the contents for which a mapping is required (e.g. entity_type= dbo:Film ) and the field of the raw source that will be used for the actual mapping: Different modalities are available: If mode='only_retrieved_evaluated' , all properties from DBPedia will be retrieved but discarding the ones with a blank value (i.e. '') If mode='all' , all properties in DBPedia + all properties in local raw source will be retrieved. Local properties will be overwritten by dbpedia values if there's a conflict (same property in dbpedia and in local dataset) If mode='all_retrieved' , all properties in DBPedia only will be retrieved If mode='original_retrieved' , all local properties with their DBPedia value will be retrieved PARAMETER DESCRIPTION entity_type Domain of the contents you want to process (e.g. 'dbo:Film') TYPE: str label_field Field of the raw source that will be used to map each content, DBPedia node with property rdfs:label equal to specified field value will be retrieved TYPE: str lang Language of the rdfs:label that should match with label_field in the raw source TYPE: str DEFAULT: 'EN' mode Parameter which specifies which properties should be retrieved. Possible values are ['only_retrieved_evaluated', 'all', 'all_retrieved', 'original_retrieved']: 1. 'only retrieved evaluated' will retrieve properties which have a value, discarding ones with a blank value (i.e. '') 2. 'all' will retrieve all properties from DBPedia + local source, regardless if they have a value or not 3. 'all_retrieved' will retrieve all properties from DBPedia only 4. 'original_retrieved' will retrieve all local properties with their DBPedia value TYPE: str DEFAULT: 'only_retrieved_evaluated' return_prop_as_uri If set to True, properties will be returned in their full uri form rather than in their rdfs:label form (e.g. \"http://dbpedia.org/ontology/director\" rather than \"film director\") TYPE: bool DEFAULT: False max_timeout Sometimes when mapping content to dbpedia, a batch of query may take longer than the max time allowed by the server due to internet issues: the framework will re-try the exact query max_timeout times before raising a TimeoutError TYPE: int DEFAULT: 5 Source code in clayrs/content_analyzer/exogenous_properties_retrieval.py 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 def __init__ ( self , entity_type : str , label_field : str , lang : str = 'EN' , mode : str = 'only_retrieved_evaluated' , return_prop_as_uri : bool = False , max_timeout : int = 5 ): super () . __init__ ( mode ) self . _entity_type = entity_type self . _label_field = label_field self . _prop_as_uri = return_prop_as_uri self . _lang = lang self . _max_timeout = max_timeout self . _sparql = SPARQLWrapper ( \"https://dbpedia.org/sparql\" ) self . _sparql . setReturnFormat ( JSON ) self . _class_properties = self . _get_properties_class ()","title":"DBPedia Mapping"},{"location":"content_analyzer/exogenous_techniques/dbpedia/#properties-from-dbpedia-ontology","text":"","title":"Properties from DBPedia ontology"},{"location":"content_analyzer/exogenous_techniques/dbpedia/#clayrs.content_analyzer.DBPediaMappingTechnique","text":"Bases: ExogenousPropertiesRetrieval Exogenous technique which expands each content by using as external source the DBPedia ontology It needs the entity of the contents for which a mapping is required (e.g. entity_type= dbo:Film ) and the field of the raw source that will be used for the actual mapping: Different modalities are available: If mode='only_retrieved_evaluated' , all properties from DBPedia will be retrieved but discarding the ones with a blank value (i.e. '') If mode='all' , all properties in DBPedia + all properties in local raw source will be retrieved. Local properties will be overwritten by dbpedia values if there's a conflict (same property in dbpedia and in local dataset) If mode='all_retrieved' , all properties in DBPedia only will be retrieved If mode='original_retrieved' , all local properties with their DBPedia value will be retrieved PARAMETER DESCRIPTION entity_type Domain of the contents you want to process (e.g. 'dbo:Film') TYPE: str label_field Field of the raw source that will be used to map each content, DBPedia node with property rdfs:label equal to specified field value will be retrieved TYPE: str lang Language of the rdfs:label that should match with label_field in the raw source TYPE: str DEFAULT: 'EN' mode Parameter which specifies which properties should be retrieved. Possible values are ['only_retrieved_evaluated', 'all', 'all_retrieved', 'original_retrieved']: 1. 'only retrieved evaluated' will retrieve properties which have a value, discarding ones with a blank value (i.e. '') 2. 'all' will retrieve all properties from DBPedia + local source, regardless if they have a value or not 3. 'all_retrieved' will retrieve all properties from DBPedia only 4. 'original_retrieved' will retrieve all local properties with their DBPedia value TYPE: str DEFAULT: 'only_retrieved_evaluated' return_prop_as_uri If set to True, properties will be returned in their full uri form rather than in their rdfs:label form (e.g. \"http://dbpedia.org/ontology/director\" rather than \"film director\") TYPE: bool DEFAULT: False max_timeout Sometimes when mapping content to dbpedia, a batch of query may take longer than the max time allowed by the server due to internet issues: the framework will re-try the exact query max_timeout times before raising a TimeoutError TYPE: int DEFAULT: 5 Source code in clayrs/content_analyzer/exogenous_properties_retrieval.py 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 def __init__ ( self , entity_type : str , label_field : str , lang : str = 'EN' , mode : str = 'only_retrieved_evaluated' , return_prop_as_uri : bool = False , max_timeout : int = 5 ): super () . __init__ ( mode ) self . _entity_type = entity_type self . _label_field = label_field self . _prop_as_uri = return_prop_as_uri self . _lang = lang self . _max_timeout = max_timeout self . _sparql = SPARQLWrapper ( \"https://dbpedia.org/sparql\" ) self . _sparql . setReturnFormat ( JSON ) self . _class_properties = self . _get_properties_class ()","title":"DBPediaMappingTechnique"},{"location":"content_analyzer/exogenous_techniques/properties_from_dataset/","text":"Properties from local dataset PropertiesFromDataset ( mode = 'only_retrieved_evaluated' , field_name_list = None ) Bases: ExogenousPropertiesRetrieval Exogenous technique which expands each content by using as external source the raw source itself Different modalities are available: If mode='only_retrieved_evaluated' all fields for the content will be retrieved from raw source but discarding the ones with a blank value (i.e. '') JSON raw source [{'Title': 'Jumanji', 'Year': 1995}, {'Title': 'Toy Story', 'Year': ''}] json_file = JSONFile ( json_path ) PropertiesFromDataset ( mode = 'only_retrieved_evaluated' ) . get_properties ( json_file ) # output is a list of PropertiesDict object with the following values: # [{'Title': 'Jumanji', 'Year': 1995}, # {'Title': 'Toy Story'}] If mode='all' all fields for the content will be retrieved from raw source including the ones with a blank value JSON raw source [{'Title': 'Jumanji', 'Year': 1995}, {'Title': 'Toy Story', 'Year': ''}] json_file = JSONFile ( json_path ) PropertiesFromDataset ( mode = 'only_retrieved_evaluated' ) . get_properties ( json_file ) # output is a list of PropertiesDict object with the following values: # [{'Title': 'Jumanji', 'Year': 1995}, # {'Title': 'Toy Story', 'Year': ''}] You could also choose exactly which fields to use to expand each content with the field_name_list parameter JSON raw source [{'Title': 'Jumanji', 'Year': 1995}, {'Title': 'Toy Story', 'Year': ''}] json_file = JSONFile ( json_path ) PropertiesFromDataset ( mode = 'only_retrieved_evaluated' , field_name_list = [ 'Title' ]) . get_properties ( json_file ) # output is a list of PropertiesDict object with the following values: # [{'Title': 'Jumanji'}, # {'Title': 'Toy Story'}] PARAMETER DESCRIPTION mode Parameter which specifies which properties should be retrieved. Possible values are ['only_retrieved_evaluated', 'all']: 1. 'only retrieved evaluated' will retrieve properties which have a value, discarding ones with a blank value (i.e. '') 2. 'all' will retrieve all properties, regardless if they have a value or not TYPE: str DEFAULT: 'only_retrieved_evaluated' field_name_list List of fields from the raw source that will be retrieved. Useful if you want to expand each content with only a subset of available properties from the local dataset TYPE: List [ str ] DEFAULT: None Source code in clayrs/content_analyzer/exogenous_properties_retrieval.py 139 140 141 def __init__ ( self , mode : str = 'only_retrieved_evaluated' , field_name_list : List [ str ] = None ): super () . __init__ ( mode ) self . __field_name_list : List [ str ] = field_name_list","title":"Properties From Dataset"},{"location":"content_analyzer/exogenous_techniques/properties_from_dataset/#properties-from-local-dataset","text":"","title":"Properties from local dataset"},{"location":"content_analyzer/exogenous_techniques/properties_from_dataset/#clayrs.content_analyzer.PropertiesFromDataset","text":"Bases: ExogenousPropertiesRetrieval Exogenous technique which expands each content by using as external source the raw source itself Different modalities are available: If mode='only_retrieved_evaluated' all fields for the content will be retrieved from raw source but discarding the ones with a blank value (i.e. '') JSON raw source [{'Title': 'Jumanji', 'Year': 1995}, {'Title': 'Toy Story', 'Year': ''}] json_file = JSONFile ( json_path ) PropertiesFromDataset ( mode = 'only_retrieved_evaluated' ) . get_properties ( json_file ) # output is a list of PropertiesDict object with the following values: # [{'Title': 'Jumanji', 'Year': 1995}, # {'Title': 'Toy Story'}] If mode='all' all fields for the content will be retrieved from raw source including the ones with a blank value JSON raw source [{'Title': 'Jumanji', 'Year': 1995}, {'Title': 'Toy Story', 'Year': ''}] json_file = JSONFile ( json_path ) PropertiesFromDataset ( mode = 'only_retrieved_evaluated' ) . get_properties ( json_file ) # output is a list of PropertiesDict object with the following values: # [{'Title': 'Jumanji', 'Year': 1995}, # {'Title': 'Toy Story', 'Year': ''}] You could also choose exactly which fields to use to expand each content with the field_name_list parameter JSON raw source [{'Title': 'Jumanji', 'Year': 1995}, {'Title': 'Toy Story', 'Year': ''}] json_file = JSONFile ( json_path ) PropertiesFromDataset ( mode = 'only_retrieved_evaluated' , field_name_list = [ 'Title' ]) . get_properties ( json_file ) # output is a list of PropertiesDict object with the following values: # [{'Title': 'Jumanji'}, # {'Title': 'Toy Story'}] PARAMETER DESCRIPTION mode Parameter which specifies which properties should be retrieved. Possible values are ['only_retrieved_evaluated', 'all']: 1. 'only retrieved evaluated' will retrieve properties which have a value, discarding ones with a blank value (i.e. '') 2. 'all' will retrieve all properties, regardless if they have a value or not TYPE: str DEFAULT: 'only_retrieved_evaluated' field_name_list List of fields from the raw source that will be retrieved. Useful if you want to expand each content with only a subset of available properties from the local dataset TYPE: List [ str ] DEFAULT: None Source code in clayrs/content_analyzer/exogenous_properties_retrieval.py 139 140 141 def __init__ ( self , mode : str = 'only_retrieved_evaluated' , field_name_list : List [ str ] = None ): super () . __init__ ( mode ) self . __field_name_list : List [ str ] = field_name_list","title":"PropertiesFromDataset"},{"location":"content_analyzer/information_preprocessors/ekphrasis/","text":"Ekphrasis Preprocessor Ekphrasis ( * , omit = None , normalize = None , unpack_contractions = False , unpack_hashtags = False , annotate = None , corrector = None , tokenizer = social_tokenizer_ekphrasis , segmenter = None , all_caps_tag = None , spell_correction = False , segmentation = False , dicts = None , spell_correct_elong = False ) Bases: NLP Interface to the Ekphrasis library for natural language processing features Examples: Normalize email and percentage tokens but omit email ones: >>> ek = Ekphrasis ( omit = [ 'email' ], normalize = [ 'email' , 'percent' ]) >>> ek . process ( \"this is an email: alias@mail.com and this is a percent 23%\" ) ['this', 'is', 'an', 'email', ':', 'and', 'this', 'is', 'a', 'percent', '<percent>'] Unpack contractions on running text: >>> ek = Ekphrasis ( unpack_contractions = True ) >>> ek . process ( \"I can't do this because I won't and I shouldn't\" ) ['i', 'can', 'not', 'do', 'this', 'because', 'i', 'will', 'not', 'and', 'i', 'should', 'not'] Unpack hashtag using statistics from 'twitter' corpus: >>> ek = Ekphrasis ( unpack_hashtags = True , segmenter = 'twitter' ) >>> ek . process ( \"#next #gamedev #retrogaming #coolphoto no unpack\" ) ['next', 'game', 'dev', 'retro', 'gaming', 'cool', 'photo', 'no', 'unpack'] Annotate words in CAPS and repeated tokens with single tag for CAPS words: >>> ek = Ekphrasis ( annotate = [ 'allcaps' , 'repeated' ], all_caps_tag = 'single' ) >>> ek . process ( \"this is good !!! text and a SHOUTED one\" ) ['this', 'is', 'good', '!', '<repeated>', 'text', 'and', 'a', 'shouted', '<allcaps>', 'one'] Perform segmentation using statistics from 'twitter' corpus: >>> ek = Ekphrasis ( segmentation = True , segmenter = 'twitter' ) >>> ek . process ( \"thewatercooler exponentialbackoff no segmentation\" ) ['the', 'watercooler', 'exponential', 'back', 'off', 'no', 'segmentation'] Substitute words with custom tokens: >>> ek = Ekphrasis ( dicts = [{ ':)' : '<happy>' , ':(' : '<sad>' }]) >>> ek . process ( \"Hello :) how are you? :(\" ) ['Hello', '<happy>', 'how', 'are', 'you', '?', '<sad>'] Perform spell correction on text and on elongated words by using statistics from default 'english' corpus: >>> Ekphrasis ( spell_correction = True , spell_correct_elong = True ) >>> ek . process ( \"This is huuuuge. The korrect way of doing tihngs is not the followingt\" ) [\"this\", 'is', 'huge', '.', 'the', 'correct', \"way\", \"of\", \"doing\", \"things\", \"is\", 'not', 'the', 'following'] PARAMETER DESCRIPTION omit Choose what tokens that you want to omit from the text. Possible values: ['email', 'percent', 'money', 'phone', 'user','time', 'url', 'date', 'hashtag'] Important Notes: 1 - the token in this list must be present in the `normalize` list to have any effect! 2 - put url at front, if you plan to use it. Messes with the regexes! 3 - if you use hashtag then unpack_hashtags will automatically be set to False TYPE: List DEFAULT: None normalize Choose what tokens that you want to normalize from the text. Possible values: ['email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'hashtag'] For example: myaddress@mysite.com -> <email> Important Notes: 1 - put url at front, if you plan to use it. Messes with the regexes! 2 - if you use hashtag then unpack_hashtags will automatically be set to False TYPE: List DEFAULT: None unpack_contractions Replace English contractions in running text with their unshortened forms for example: can't -> can not, wouldn't -> would not, and so on... TYPE: bool DEFAULT: False unpack_hashtags split a hashtag to its constituent words. for example: #ilikedogs -> i like dogs TYPE: bool DEFAULT: False annotate add special tags to special tokens. Possible values: ['hashtag', 'allcaps', 'elongated', 'repeated'] for example: myaddress@mysite.com -> myaddress@mysite.com TYPE: List DEFAULT: None corrector define the statistics of what corpus you would like to use [english, twitter]. Be sure to set spell_correction to True if you want to perform spell correction on the running text TYPE: str DEFAULT: None tokenizer callable function that accepts a string and returns a list of strings. If no tokenizer is provided then the text will be tokenized on whitespace TYPE: Callable DEFAULT: social_tokenizer_ekphrasis segmenter define the statistics of what corpus you would like to use [english, twitter]. Be sure to set segmentation to True if you want to perform segmentation on the running text TYPE: str DEFAULT: None all_caps_tag how to wrap the capitalized words Note: applicable only when allcaps is included in the annotate list Possible values [single, wrap, every] : - single: add a tag after the last capitalized word for example: \"SHOUTED TEXT\" -> \"shouted text <allcaps>\" - wrap: wrap all words with opening and closing tags for example: \"SHOUTED TEXT\" -> \"<allcaps> shouted text </allcaps>\" - every: add a tag after each word for example: \"SHOUTED TEXT\" -> \"shouted <allcaps> text <allcaps>\" TYPE: str DEFAULT: None spell_correction If set to True, running text will be spell corrected using statistics of corpus set in corrector parameter TYPE: bool DEFAULT: False segmentation If set to True, running text will be segmented using statistics of corpus set in corrector parameter for example: exponentialbackoff -> exponential back off TYPE: bool DEFAULT: False spell_correct_elong choose if you want to perform spell correction after the normalization of elongated words. significantly affects performance (speed) TYPE: bool DEFAULT: False spell_correction choose if you want to perform spell correction to the text. significantly affects performance (speed) TYPE: bool DEFAULT: False Source code in clayrs/content_analyzer/information_processor/ekphrasis.py 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def __init__ ( self , * , omit : List = None , normalize : List = None , unpack_contractions : bool = False , unpack_hashtags : bool = False , annotate : List = None , corrector : str = None , tokenizer : Callable = social_tokenizer_ekphrasis , segmenter : str = None , all_caps_tag : str = None , spell_correction : bool = False , segmentation : bool = False , dicts : List [ Dict ] = None , spell_correct_elong : bool = False ): # ekphrasis has default values for arguments not passed. So if they are not evaluated in our class, # we simply don't pass them to ekphrasis kwargs_to_pass = { argument : arg_value for argument , arg_value in zip ( locals () . keys (), locals () . values ()) if argument != 'self' and arg_value is not None } self . text_processor = TextPreProcessor ( ** kwargs_to_pass ) self . spell_correct_elong = spell_correct_elong self . sc = None if spell_correction is True : if corrector is not None : self . sc = SpellCorrector ( corpus = corrector ) else : self . sc = SpellCorrector () self . segmentation = segmentation self . ws = None if segmentation is True : if segmenter is not None : self . ws = Segmenter ( corpus = segmenter ) else : self . ws = Segmenter () self . _repr_string = autorepr ( self , inspect . currentframe ()) process ( field_data ) PARAMETER DESCRIPTION field_data Running text to be processed TYPE: str RETURNS DESCRIPTION field_data List of str representing running text preprocessed TYPE: List [ str ] Source code in clayrs/content_analyzer/information_processor/ekphrasis.py 216 217 218 219 220 221 222 223 224 225 226 227 228 def process ( self , field_data : str ) -> List [ str ]: \"\"\" Args: field_data: Running text to be processed Returns: field_data: List of str representing running text preprocessed \"\"\" field_data = self . text_processor . pre_process_doc ( field_data ) if self . sc is not None : field_data = self . __spell_check ( field_data ) if self . ws is not None : field_data = self . __word_segmenter ( field_data ) return field_data","title":"Ekphrasis"},{"location":"content_analyzer/information_preprocessors/ekphrasis/#ekphrasis-preprocessor","text":"","title":"Ekphrasis Preprocessor"},{"location":"content_analyzer/information_preprocessors/ekphrasis/#clayrs.content_analyzer.Ekphrasis","text":"Bases: NLP Interface to the Ekphrasis library for natural language processing features Examples: Normalize email and percentage tokens but omit email ones: >>> ek = Ekphrasis ( omit = [ 'email' ], normalize = [ 'email' , 'percent' ]) >>> ek . process ( \"this is an email: alias@mail.com and this is a percent 23%\" ) ['this', 'is', 'an', 'email', ':', 'and', 'this', 'is', 'a', 'percent', '<percent>'] Unpack contractions on running text: >>> ek = Ekphrasis ( unpack_contractions = True ) >>> ek . process ( \"I can't do this because I won't and I shouldn't\" ) ['i', 'can', 'not', 'do', 'this', 'because', 'i', 'will', 'not', 'and', 'i', 'should', 'not'] Unpack hashtag using statistics from 'twitter' corpus: >>> ek = Ekphrasis ( unpack_hashtags = True , segmenter = 'twitter' ) >>> ek . process ( \"#next #gamedev #retrogaming #coolphoto no unpack\" ) ['next', 'game', 'dev', 'retro', 'gaming', 'cool', 'photo', 'no', 'unpack'] Annotate words in CAPS and repeated tokens with single tag for CAPS words: >>> ek = Ekphrasis ( annotate = [ 'allcaps' , 'repeated' ], all_caps_tag = 'single' ) >>> ek . process ( \"this is good !!! text and a SHOUTED one\" ) ['this', 'is', 'good', '!', '<repeated>', 'text', 'and', 'a', 'shouted', '<allcaps>', 'one'] Perform segmentation using statistics from 'twitter' corpus: >>> ek = Ekphrasis ( segmentation = True , segmenter = 'twitter' ) >>> ek . process ( \"thewatercooler exponentialbackoff no segmentation\" ) ['the', 'watercooler', 'exponential', 'back', 'off', 'no', 'segmentation'] Substitute words with custom tokens: >>> ek = Ekphrasis ( dicts = [{ ':)' : '<happy>' , ':(' : '<sad>' }]) >>> ek . process ( \"Hello :) how are you? :(\" ) ['Hello', '<happy>', 'how', 'are', 'you', '?', '<sad>'] Perform spell correction on text and on elongated words by using statistics from default 'english' corpus: >>> Ekphrasis ( spell_correction = True , spell_correct_elong = True ) >>> ek . process ( \"This is huuuuge. The korrect way of doing tihngs is not the followingt\" ) [\"this\", 'is', 'huge', '.', 'the', 'correct', \"way\", \"of\", \"doing\", \"things\", \"is\", 'not', 'the', 'following'] PARAMETER DESCRIPTION omit Choose what tokens that you want to omit from the text. Possible values: ['email', 'percent', 'money', 'phone', 'user','time', 'url', 'date', 'hashtag'] Important Notes: 1 - the token in this list must be present in the `normalize` list to have any effect! 2 - put url at front, if you plan to use it. Messes with the regexes! 3 - if you use hashtag then unpack_hashtags will automatically be set to False TYPE: List DEFAULT: None normalize Choose what tokens that you want to normalize from the text. Possible values: ['email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'hashtag'] For example: myaddress@mysite.com -> <email> Important Notes: 1 - put url at front, if you plan to use it. Messes with the regexes! 2 - if you use hashtag then unpack_hashtags will automatically be set to False TYPE: List DEFAULT: None unpack_contractions Replace English contractions in running text with their unshortened forms for example: can't -> can not, wouldn't -> would not, and so on... TYPE: bool DEFAULT: False unpack_hashtags split a hashtag to its constituent words. for example: #ilikedogs -> i like dogs TYPE: bool DEFAULT: False annotate add special tags to special tokens. Possible values: ['hashtag', 'allcaps', 'elongated', 'repeated'] for example: myaddress@mysite.com -> myaddress@mysite.com TYPE: List DEFAULT: None corrector define the statistics of what corpus you would like to use [english, twitter]. Be sure to set spell_correction to True if you want to perform spell correction on the running text TYPE: str DEFAULT: None tokenizer callable function that accepts a string and returns a list of strings. If no tokenizer is provided then the text will be tokenized on whitespace TYPE: Callable DEFAULT: social_tokenizer_ekphrasis segmenter define the statistics of what corpus you would like to use [english, twitter]. Be sure to set segmentation to True if you want to perform segmentation on the running text TYPE: str DEFAULT: None all_caps_tag how to wrap the capitalized words Note: applicable only when allcaps is included in the annotate list Possible values [single, wrap, every] : - single: add a tag after the last capitalized word for example: \"SHOUTED TEXT\" -> \"shouted text <allcaps>\" - wrap: wrap all words with opening and closing tags for example: \"SHOUTED TEXT\" -> \"<allcaps> shouted text </allcaps>\" - every: add a tag after each word for example: \"SHOUTED TEXT\" -> \"shouted <allcaps> text <allcaps>\" TYPE: str DEFAULT: None spell_correction If set to True, running text will be spell corrected using statistics of corpus set in corrector parameter TYPE: bool DEFAULT: False segmentation If set to True, running text will be segmented using statistics of corpus set in corrector parameter for example: exponentialbackoff -> exponential back off TYPE: bool DEFAULT: False spell_correct_elong choose if you want to perform spell correction after the normalization of elongated words. significantly affects performance (speed) TYPE: bool DEFAULT: False spell_correction choose if you want to perform spell correction to the text. significantly affects performance (speed) TYPE: bool DEFAULT: False Source code in clayrs/content_analyzer/information_processor/ekphrasis.py 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def __init__ ( self , * , omit : List = None , normalize : List = None , unpack_contractions : bool = False , unpack_hashtags : bool = False , annotate : List = None , corrector : str = None , tokenizer : Callable = social_tokenizer_ekphrasis , segmenter : str = None , all_caps_tag : str = None , spell_correction : bool = False , segmentation : bool = False , dicts : List [ Dict ] = None , spell_correct_elong : bool = False ): # ekphrasis has default values for arguments not passed. So if they are not evaluated in our class, # we simply don't pass them to ekphrasis kwargs_to_pass = { argument : arg_value for argument , arg_value in zip ( locals () . keys (), locals () . values ()) if argument != 'self' and arg_value is not None } self . text_processor = TextPreProcessor ( ** kwargs_to_pass ) self . spell_correct_elong = spell_correct_elong self . sc = None if spell_correction is True : if corrector is not None : self . sc = SpellCorrector ( corpus = corrector ) else : self . sc = SpellCorrector () self . segmentation = segmentation self . ws = None if segmentation is True : if segmenter is not None : self . ws = Segmenter ( corpus = segmenter ) else : self . ws = Segmenter () self . _repr_string = autorepr ( self , inspect . currentframe ())","title":"Ekphrasis"},{"location":"content_analyzer/information_preprocessors/ekphrasis/#clayrs.content_analyzer.information_processor.ekphrasis.Ekphrasis.process","text":"PARAMETER DESCRIPTION field_data Running text to be processed TYPE: str RETURNS DESCRIPTION field_data List of str representing running text preprocessed TYPE: List [ str ] Source code in clayrs/content_analyzer/information_processor/ekphrasis.py 216 217 218 219 220 221 222 223 224 225 226 227 228 def process ( self , field_data : str ) -> List [ str ]: \"\"\" Args: field_data: Running text to be processed Returns: field_data: List of str representing running text preprocessed \"\"\" field_data = self . text_processor . pre_process_doc ( field_data ) if self . sc is not None : field_data = self . __spell_check ( field_data ) if self . ws is not None : field_data = self . __word_segmenter ( field_data ) return field_data","title":"process()"},{"location":"content_analyzer/information_preprocessors/nltk/","text":"NLTK Preprocessor NLTK ( * , strip_multiple_whitespaces = True , remove_punctuation = False , stopwords_removal = False , url_tagging = False , lemmatization = False , stemming = False , pos_tag = False , lang = 'english' ) Bases: NLP Interface to the NLTK library for natural language processing features. Examples: Strip multiple whitespaces from running text >>> nltk_obj = NLTK ( strip_multiple_whitespaces = True ) >>> nltk_obj . process ( 'This has a lot of spaces' ) ['This', 'has', 'a', 'lot', 'of', 'spaces'] Remove punctuation from running text >>> nltk_obj = NLTK ( remove_punctuation = True ) >>> nltk_obj . process ( \"Hello there. How are you? I'm fine, thanks.\" ) [\"Hello\", \"there\", \"How\", \"are\", \"you\", \"I\", \"m\", \"fine\", \"thanks\"] Remove stopwords using from running text >>> nltk_obj = NLTK ( stopwords_removal = True ) >>> nltk_obj . process ( \"The striped bats are hanging on their feet for the best\" ) [\"striped\", \"bats\", \"hanging\", \"feet\", \"best\"] Replace URL with a normalized token <URL> >>> nltk_obj = NLTK ( url_tagging = True ) >>> nltk_obj . process ( \"This is facebook http://facebook.com and github https://github.com\" ) ['This', 'is', 'facebook', '<URL>', 'and', 'github', '<URL>'] Perform lemmatization on running text >>> nltk_obj = NLTK ( lemmatization = True ) >>> nltk_obj . process ( \"The striped bats are hanging on their feet for best\" ) [\"The\", \"strip\", \"bat\", \"be\", \"hang\", \"on\", \"their\", \"foot\", \"for\", \"best\"] Perform stemming on running text >>> nltk_obj = NLTK ( stemming = True ) >>> nltk_obj . process ( \"These unbelievable abnormous objects\" ) ['these', 'unbeliev', 'abnorm', 'object'] Label each token in the running text with its POS tag >>> nltk_obj = NLTK ( pos_tag = True ) >>> nltk_obj . process ( \"Facebook was fined by Hewlett Packard for spending 100\u20ac\" ) ['Facebook_NNP', 'was_VBD', 'fined_VBN', 'by_IN', 'Hewlett_NNP', 'Packard_NNP', 'for_IN', 'spending_VBG', '100\u20ac_CD'] PARAMETER DESCRIPTION strip_multiple_whitespaces If set to True, all multiple whitespaces will be reduced to only one white space TYPE: bool DEFAULT: True remove_punctuation If set to True, all punctuation from the running text will be removed TYPE: bool DEFAULT: False stopwords_removal If set to True, all stowpwords from the running text will be removed TYPE: bool DEFAULT: False url_tagging If set to True, all urls in the running text will be replaced with the <URL> token TYPE: bool DEFAULT: False lemmatization If set to True, each token in the running text will be brought to its lemma TYPE: bool DEFAULT: False stemming If set to True, each token in the running text will be brought to its stem TYPE: bool DEFAULT: False pos_tag If set to True, each token in the running text will be labeled with its POS tag in the form token_TAG TYPE: bool DEFAULT: False lang Language of the running text TYPE: str DEFAULT: 'english' Source code in clayrs/content_analyzer/information_processor/nltk.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 def __init__ ( self , * , strip_multiple_whitespaces : bool = True , remove_punctuation : bool = False , stopwords_removal : bool = False , url_tagging : bool = False , lemmatization : bool = False , stemming : bool = False , pos_tag : bool = False , lang : str = 'english' ): if not NLTK . _corpus_downloaded : self . __download_corpus () NLTK . _corpus_downloaded = True self . stopwords_removal = stopwords_removal self . stemming = stemming self . stemmer = SnowballStemmer ( language = lang ) self . lemmatization = lemmatization self . lemmatizer = WordNetLemmatizer () self . strip_multiple_whitespaces = strip_multiple_whitespaces self . url_tagging = url_tagging self . remove_punctuation = remove_punctuation self . pos_tag = pos_tag self . __full_lang_code = lang","title":"NLTK"},{"location":"content_analyzer/information_preprocessors/nltk/#nltk-preprocessor","text":"","title":"NLTK Preprocessor"},{"location":"content_analyzer/information_preprocessors/nltk/#clayrs.content_analyzer.NLTK","text":"Bases: NLP Interface to the NLTK library for natural language processing features. Examples: Strip multiple whitespaces from running text >>> nltk_obj = NLTK ( strip_multiple_whitespaces = True ) >>> nltk_obj . process ( 'This has a lot of spaces' ) ['This', 'has', 'a', 'lot', 'of', 'spaces'] Remove punctuation from running text >>> nltk_obj = NLTK ( remove_punctuation = True ) >>> nltk_obj . process ( \"Hello there. How are you? I'm fine, thanks.\" ) [\"Hello\", \"there\", \"How\", \"are\", \"you\", \"I\", \"m\", \"fine\", \"thanks\"] Remove stopwords using from running text >>> nltk_obj = NLTK ( stopwords_removal = True ) >>> nltk_obj . process ( \"The striped bats are hanging on their feet for the best\" ) [\"striped\", \"bats\", \"hanging\", \"feet\", \"best\"] Replace URL with a normalized token <URL> >>> nltk_obj = NLTK ( url_tagging = True ) >>> nltk_obj . process ( \"This is facebook http://facebook.com and github https://github.com\" ) ['This', 'is', 'facebook', '<URL>', 'and', 'github', '<URL>'] Perform lemmatization on running text >>> nltk_obj = NLTK ( lemmatization = True ) >>> nltk_obj . process ( \"The striped bats are hanging on their feet for best\" ) [\"The\", \"strip\", \"bat\", \"be\", \"hang\", \"on\", \"their\", \"foot\", \"for\", \"best\"] Perform stemming on running text >>> nltk_obj = NLTK ( stemming = True ) >>> nltk_obj . process ( \"These unbelievable abnormous objects\" ) ['these', 'unbeliev', 'abnorm', 'object'] Label each token in the running text with its POS tag >>> nltk_obj = NLTK ( pos_tag = True ) >>> nltk_obj . process ( \"Facebook was fined by Hewlett Packard for spending 100\u20ac\" ) ['Facebook_NNP', 'was_VBD', 'fined_VBN', 'by_IN', 'Hewlett_NNP', 'Packard_NNP', 'for_IN', 'spending_VBG', '100\u20ac_CD'] PARAMETER DESCRIPTION strip_multiple_whitespaces If set to True, all multiple whitespaces will be reduced to only one white space TYPE: bool DEFAULT: True remove_punctuation If set to True, all punctuation from the running text will be removed TYPE: bool DEFAULT: False stopwords_removal If set to True, all stowpwords from the running text will be removed TYPE: bool DEFAULT: False url_tagging If set to True, all urls in the running text will be replaced with the <URL> token TYPE: bool DEFAULT: False lemmatization If set to True, each token in the running text will be brought to its lemma TYPE: bool DEFAULT: False stemming If set to True, each token in the running text will be brought to its stem TYPE: bool DEFAULT: False pos_tag If set to True, each token in the running text will be labeled with its POS tag in the form token_TAG TYPE: bool DEFAULT: False lang Language of the running text TYPE: str DEFAULT: 'english' Source code in clayrs/content_analyzer/information_processor/nltk.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 def __init__ ( self , * , strip_multiple_whitespaces : bool = True , remove_punctuation : bool = False , stopwords_removal : bool = False , url_tagging : bool = False , lemmatization : bool = False , stemming : bool = False , pos_tag : bool = False , lang : str = 'english' ): if not NLTK . _corpus_downloaded : self . __download_corpus () NLTK . _corpus_downloaded = True self . stopwords_removal = stopwords_removal self . stemming = stemming self . stemmer = SnowballStemmer ( language = lang ) self . lemmatization = lemmatization self . lemmatizer = WordNetLemmatizer () self . strip_multiple_whitespaces = strip_multiple_whitespaces self . url_tagging = url_tagging self . remove_punctuation = remove_punctuation self . pos_tag = pos_tag self . __full_lang_code = lang","title":"NLTK"},{"location":"content_analyzer/information_preprocessors/spacy/","text":"Spacy preprocessor Spacy ( model = 'en_core_web_sm' , * , strip_multiple_whitespaces = True , remove_punctuation = False , stopwords_removal = False , new_stopwords = None , not_stopwords = None , lemmatization = False , url_tagging = False , named_entity_recognition = False ) Bases: NLP Interface to the Spacy library for natural language processing features Examples: Strip multiple whitespaces from running text >>> spacy_obj = Spacy ( strip_multiple_whitespaces = True ) >>> spacy_obj . process ( 'This has a lot of spaces' ) ['This', 'has', 'a', 'lot', 'of', 'spaces'] Remove punctuation from running text >>> spacy_obj = Spacy ( remove_punctuation = True ) >>> spacy_obj . process ( \"Hello there. How are you? I'm fine, thanks.\" ) [\"Hello\", \"there\", \"How\", \"are\", \"you\", \"I\", \"'m\", \"fine\", \"thanks\"] Remove stopwords using default stopwords corpus of spacy from running text >>> spacy_obj = Spacy ( stopwords_removal = True ) >>> spacy_obj . process ( \"The striped bats are hanging on their feet for the best\" ) [\"striped\", \"bats\", \"hanging\", \"feet\", \"best\"] Remove stopwords using default stopwords corpus of spacy + new_stopwords list from running text >>> spacy_obj = Spacy ( stopwords_removal = True , new_stopwords = [ 'bats' , 'best' ]) >>> spacy_obj . process ( \"The striped bats are hanging on their feet for the best\" ) [\"striped\", \"hanging\", \"feet\"] Remove stopwords using default stopwords corpus of spacy - not_stopwords list from running text >>> spacy_obj = Spacy ( stopwords_removal = True , not_stopwords = [ 'The' , 'the' , 'on' ]) >>> spacy_obj . process ( \"The striped bats are hanging on their feet for the best\" ) [\"The\", \"striped\", \"bats\", \"hanging\", \"on\", \"feet\", \"the\", \"best\"] Replace URL with a normalized token <URL> >>> spacy_obj = Spacy ( url_tagging = True ) >>> spacy_obj . process ( \"This is facebook http://facebook.com and github https://github.com\" ) ['This', 'is', 'facebook', '<URL>', 'and', 'github', '<URL>'] Perform lemmatization on running text >>> spacy_obj = Spacy ( lemmatization = True ) >>> spacy_obj . process ( \"The striped bats are hanging on their feet for best\" ) [\"The\", \"strip\", \"bat\", \"be\", \"hang\", \"on\", \"their\", \"foot\", \"for\", \"best\"] Perform NER on running text (NEs will be tagged with BIO tagging) >>> spacy_obj = Spacy ( named_entity_recognition = True ) >>> spacy_obj . process ( \"Facebook was fined by Hewlett Packard for spending 100\u20ac\" ) [\"Facebook\", \"was\", \"fined\", \"by\", \"<Hewlett_ORG_B>\", \"<Packard_ORG_I>\", \"for\", \"spending\", \"<100_MONEY_B>\", \"<\u20ac_MONEY_I>\"] PARAMETER DESCRIPTION model Spacy model that will be used to perform nlp operations. It will be downloaded if not present locally TYPE: str DEFAULT: 'en_core_web_sm' strip_multiple_whitespaces If set to True, all multiple whitespaces will be reduced to only one white space TYPE: bool DEFAULT: True remove_punctuation If set to True, all punctuation from the running text will be removed TYPE: bool DEFAULT: False stopwords_removal If set to True, all stowpwords from the running text will be removed TYPE: bool DEFAULT: False new_stopwords List which contains custom defined stopwords that will be removed if stopwords_removal=True TYPE: List [ str ] DEFAULT: None not_stopwords List which contains custom defined stopwords that will not be considered as such, therefore won't be removed if stopwords_removal=True TYPE: List [ str ] DEFAULT: None url_tagging If set to True, all urls in the running text will be replaced with the <URL> token TYPE: bool DEFAULT: False lemmatization If set to True, each token in the running text will be brought to its lemma TYPE: bool DEFAULT: False named_entity_recognition If set to True, named entities recognized will be labeled in the form <token_B_TAG> or <token_I_TAG> , according to BIO tagging strategy TYPE: bool DEFAULT: False Source code in clayrs/content_analyzer/information_processor/spacy.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 def __init__ ( self , model : str = 'en_core_web_sm' , * , strip_multiple_whitespaces : bool = True , remove_punctuation : bool = False , stopwords_removal : bool = False , new_stopwords : List [ str ] = None , not_stopwords : List [ str ] = None , lemmatization : bool = False , url_tagging : bool = False , named_entity_recognition : bool = False ): self . model = model self . stopwords_removal = stopwords_removal self . lemmatization = lemmatization self . strip_multiple_whitespaces = strip_multiple_whitespaces self . url_tagging = url_tagging self . remove_punctuation = remove_punctuation self . named_entity_recognition = named_entity_recognition # download the model if not present. In any case load it if model not in spacy . cli . info ()[ 'pipelines' ]: spacy . cli . download ( model ) self . _nlp = spacy . load ( model ) # Adding custom rule of preserving '<URL>' token and in general token # wrapped by '<...>' prefixes = list ( self . _nlp . Defaults . prefixes ) prefixes . remove ( '<' ) prefix_regex = spacy . util . compile_prefix_regex ( prefixes ) self . _nlp . tokenizer . prefix_search = prefix_regex . search suffixes = list ( self . _nlp . Defaults . suffixes ) suffixes . remove ( '>' ) suffix_regex = spacy . util . compile_suffix_regex ( suffixes ) self . _nlp . tokenizer . suffix_search = suffix_regex . search self . not_stopwords_list = not_stopwords if not_stopwords is not None : for stopword in not_stopwords : self . _nlp . vocab [ stopword ] . is_stop = False self . new_stopwords_list = new_stopwords if new_stopwords is not None : for stopword in new_stopwords : self . _nlp . vocab [ stopword ] . is_stop = True process ( field_data ) PARAMETER DESCRIPTION field_data content to be processed TYPE: str RETURNS DESCRIPTION field_data list of str or dict in case of named entity recognition TYPE: List [ str ] Source code in clayrs/content_analyzer/information_processor/spacy.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def process ( self , field_data : str ) -> List [ str ]: \"\"\" Args: field_data: content to be processed Returns: field_data: list of str or dict in case of named entity recognition \"\"\" field_data = check_not_tokenized ( field_data ) if self . strip_multiple_whitespaces : field_data = self . __strip_multiple_whitespaces_operation ( field_data ) field_data = self . __tokenization_operation ( field_data ) if self . named_entity_recognition : field_data = self . __named_entity_recognition_operation ( field_data ) if self . remove_punctuation : field_data = self . __remove_punctuation ( field_data ) if self . stopwords_removal : field_data = self . __stopwords_removal_operation ( field_data ) if self . lemmatization : field_data = self . __lemmatization_operation ( field_data ) if self . url_tagging : field_data = self . __url_tagging_operation ( field_data ) return self . __token_to_string ( field_data )","title":"Spacy"},{"location":"content_analyzer/information_preprocessors/spacy/#spacy-preprocessor","text":"","title":"Spacy preprocessor"},{"location":"content_analyzer/information_preprocessors/spacy/#clayrs.content_analyzer.Spacy","text":"Bases: NLP Interface to the Spacy library for natural language processing features Examples: Strip multiple whitespaces from running text >>> spacy_obj = Spacy ( strip_multiple_whitespaces = True ) >>> spacy_obj . process ( 'This has a lot of spaces' ) ['This', 'has', 'a', 'lot', 'of', 'spaces'] Remove punctuation from running text >>> spacy_obj = Spacy ( remove_punctuation = True ) >>> spacy_obj . process ( \"Hello there. How are you? I'm fine, thanks.\" ) [\"Hello\", \"there\", \"How\", \"are\", \"you\", \"I\", \"'m\", \"fine\", \"thanks\"] Remove stopwords using default stopwords corpus of spacy from running text >>> spacy_obj = Spacy ( stopwords_removal = True ) >>> spacy_obj . process ( \"The striped bats are hanging on their feet for the best\" ) [\"striped\", \"bats\", \"hanging\", \"feet\", \"best\"] Remove stopwords using default stopwords corpus of spacy + new_stopwords list from running text >>> spacy_obj = Spacy ( stopwords_removal = True , new_stopwords = [ 'bats' , 'best' ]) >>> spacy_obj . process ( \"The striped bats are hanging on their feet for the best\" ) [\"striped\", \"hanging\", \"feet\"] Remove stopwords using default stopwords corpus of spacy - not_stopwords list from running text >>> spacy_obj = Spacy ( stopwords_removal = True , not_stopwords = [ 'The' , 'the' , 'on' ]) >>> spacy_obj . process ( \"The striped bats are hanging on their feet for the best\" ) [\"The\", \"striped\", \"bats\", \"hanging\", \"on\", \"feet\", \"the\", \"best\"] Replace URL with a normalized token <URL> >>> spacy_obj = Spacy ( url_tagging = True ) >>> spacy_obj . process ( \"This is facebook http://facebook.com and github https://github.com\" ) ['This', 'is', 'facebook', '<URL>', 'and', 'github', '<URL>'] Perform lemmatization on running text >>> spacy_obj = Spacy ( lemmatization = True ) >>> spacy_obj . process ( \"The striped bats are hanging on their feet for best\" ) [\"The\", \"strip\", \"bat\", \"be\", \"hang\", \"on\", \"their\", \"foot\", \"for\", \"best\"] Perform NER on running text (NEs will be tagged with BIO tagging) >>> spacy_obj = Spacy ( named_entity_recognition = True ) >>> spacy_obj . process ( \"Facebook was fined by Hewlett Packard for spending 100\u20ac\" ) [\"Facebook\", \"was\", \"fined\", \"by\", \"<Hewlett_ORG_B>\", \"<Packard_ORG_I>\", \"for\", \"spending\", \"<100_MONEY_B>\", \"<\u20ac_MONEY_I>\"] PARAMETER DESCRIPTION model Spacy model that will be used to perform nlp operations. It will be downloaded if not present locally TYPE: str DEFAULT: 'en_core_web_sm' strip_multiple_whitespaces If set to True, all multiple whitespaces will be reduced to only one white space TYPE: bool DEFAULT: True remove_punctuation If set to True, all punctuation from the running text will be removed TYPE: bool DEFAULT: False stopwords_removal If set to True, all stowpwords from the running text will be removed TYPE: bool DEFAULT: False new_stopwords List which contains custom defined stopwords that will be removed if stopwords_removal=True TYPE: List [ str ] DEFAULT: None not_stopwords List which contains custom defined stopwords that will not be considered as such, therefore won't be removed if stopwords_removal=True TYPE: List [ str ] DEFAULT: None url_tagging If set to True, all urls in the running text will be replaced with the <URL> token TYPE: bool DEFAULT: False lemmatization If set to True, each token in the running text will be brought to its lemma TYPE: bool DEFAULT: False named_entity_recognition If set to True, named entities recognized will be labeled in the form <token_B_TAG> or <token_I_TAG> , according to BIO tagging strategy TYPE: bool DEFAULT: False Source code in clayrs/content_analyzer/information_processor/spacy.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 def __init__ ( self , model : str = 'en_core_web_sm' , * , strip_multiple_whitespaces : bool = True , remove_punctuation : bool = False , stopwords_removal : bool = False , new_stopwords : List [ str ] = None , not_stopwords : List [ str ] = None , lemmatization : bool = False , url_tagging : bool = False , named_entity_recognition : bool = False ): self . model = model self . stopwords_removal = stopwords_removal self . lemmatization = lemmatization self . strip_multiple_whitespaces = strip_multiple_whitespaces self . url_tagging = url_tagging self . remove_punctuation = remove_punctuation self . named_entity_recognition = named_entity_recognition # download the model if not present. In any case load it if model not in spacy . cli . info ()[ 'pipelines' ]: spacy . cli . download ( model ) self . _nlp = spacy . load ( model ) # Adding custom rule of preserving '<URL>' token and in general token # wrapped by '<...>' prefixes = list ( self . _nlp . Defaults . prefixes ) prefixes . remove ( '<' ) prefix_regex = spacy . util . compile_prefix_regex ( prefixes ) self . _nlp . tokenizer . prefix_search = prefix_regex . search suffixes = list ( self . _nlp . Defaults . suffixes ) suffixes . remove ( '>' ) suffix_regex = spacy . util . compile_suffix_regex ( suffixes ) self . _nlp . tokenizer . suffix_search = suffix_regex . search self . not_stopwords_list = not_stopwords if not_stopwords is not None : for stopword in not_stopwords : self . _nlp . vocab [ stopword ] . is_stop = False self . new_stopwords_list = new_stopwords if new_stopwords is not None : for stopword in new_stopwords : self . _nlp . vocab [ stopword ] . is_stop = True","title":"Spacy"},{"location":"content_analyzer/information_preprocessors/spacy/#clayrs.content_analyzer.information_processor.spacy.Spacy.process","text":"PARAMETER DESCRIPTION field_data content to be processed TYPE: str RETURNS DESCRIPTION field_data list of str or dict in case of named entity recognition TYPE: List [ str ] Source code in clayrs/content_analyzer/information_processor/spacy.py 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 def process ( self , field_data : str ) -> List [ str ]: \"\"\" Args: field_data: content to be processed Returns: field_data: list of str or dict in case of named entity recognition \"\"\" field_data = check_not_tokenized ( field_data ) if self . strip_multiple_whitespaces : field_data = self . __strip_multiple_whitespaces_operation ( field_data ) field_data = self . __tokenization_operation ( field_data ) if self . named_entity_recognition : field_data = self . __named_entity_recognition_operation ( field_data ) if self . remove_punctuation : field_data = self . __remove_punctuation ( field_data ) if self . stopwords_removal : field_data = self . __stopwords_removal_operation ( field_data ) if self . lemmatization : field_data = self . __lemmatization_operation ( field_data ) if self . url_tagging : field_data = self . __url_tagging_operation ( field_data ) return self . __token_to_string ( field_data )","title":"process()"},{"location":"content_analyzer/ratings/ratings/","text":"Ratings class The Ratings class is the main responsible for importing a dataset containing interactions between users and items Ratings ( source , user_id_column = 0 , item_id_column = 1 , score_column = 2 , timestamp_column = None , score_processor = None ) Class responsible of importing an interaction frame into the framework If the source file contains users, items and ratings in this order, no additional parameters are needed, otherwise the mapping must be explicitly specified using: 'user_id' column, 'item_id' column, 'score' column The score column can also be processed: in case you would like to consider as score the sentiment of a textual review, or maybe normalizing all scores in \\([0, 1]\\) range. Check the example below for more Examples: CSV raw source user_id,item_id,rating,timestamp,review u1,i1,4,00112,good movie u2,i1,3,00113,an average movie u2,i32,2,00114,a bad movie As you can see the user id column, item id column and score column are the first three column and are already in sequential order, so no additional parameter is required to the Ratings class: >>> import clayrs.content_analyzer as ca >>> ratings_raw_source = ca . CSVFile ( 'ratings.csv' ) >>> # add timestamp='timestamp' to the following if >>> # you want to load also the timestamp >>> ratings = ca . Ratings ( ratings_raw_source ) In case columns in the raw source are not in the above order you must specify an appropriate mapping via positional index (useful in case your raw source doesn't have a header) or via column ids: >>> # (mapping by index) EQUIVALENT: >>> ratings = ca . Ratings ( >>> ca . CSVFile ( 'ratings.csv' ), >>> user_id_column = 0 , # (1) >>> item_id_column = 1 , # (2) >>> score_column = 2 # (3) >>> ) First column of raw source is the column containing all user ids Second column of raw source is the column containing all item ids Third column of raw source is the column containing all the scores >>> # (mapping by column name) EQUIVALENT: >>> ratings = ca . Ratings ( >>> ca . CSVFile ( 'ratings.csv' ), >>> user_id_column = 'user_id' , # (1) >>> item_id_column = 'item_id' , # (2) >>> score_column = 'rating' # (3) >>> ) The column with id 'user_id' of raw source is the column containing all user ids The column with id 'item_id' of raw source is the column containing all item ids The column with id 'rating' of raw source is the column containing all the scores In case you would like to use the sentiment of the review column of the above raw source as score column, simply specify the appropriate ScoreProcessor object >>> ratings_raw_source = ca . CSVFile ( 'ratings.csv' ) >>> ratings = ca . Ratings ( ratings_raw_source , >>> score_column = 'review' , >>> score_processor = ca . TextBlobSentimentAnalysis ()) PARAMETER DESCRIPTION source Source containing the raw interaction frame TYPE: RawInformationSource user_id_column Name or positional index of the field of the raw source representing users column TYPE: Union [ str , int ] DEFAULT: 0 item_id_column Name or positional index of the field of the raw source representing items column TYPE: Union [ str , int ] DEFAULT: 1 score_column Name or positional index of the field of the raw source representing score column TYPE: Union [ str , int ] DEFAULT: 2 timestamp_column Name or positional index of the field of the raw source representing timesamp column TYPE: Union [ str , int ] DEFAULT: None score_processor ScoreProcessor object which will process the score_column accordingly. Useful if you want to perform sentiment analysis on a textual column or you want to normalize all scores in \\([0, 1]\\) range TYPE: ScoreProcessor DEFAULT: None Source code in clayrs/content_analyzer/ratings_manager/ratings.py 173 174 175 176 177 178 179 180 181 def __init__ ( self , source : RawInformationSource , user_id_column : Union [ str , int ] = 0 , item_id_column : Union [ str , int ] = 1 , score_column : Union [ str , int ] = 2 , timestamp_column : Union [ str , int ] = None , score_processor : ScoreProcessor = None ): self . _ratings_dict = self . _import_ratings ( source , user_id_column , item_id_column , score_column , timestamp_column , score_processor ) __iter__ () The Ratings object can be iterated over and each iteration will return an Interaction object Examples: Rating object to iterate +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u2 | i5 | 1 | +---------+---------+-------+ >>> # for simplicity we stop after the first iteration >>> for interaction in ratings : >>> first_interaction = interaction >>> break >>> first_interaction Interaction('u1', 'i1', 4) Source code in clayrs/content_analyzer/ratings_manager/ratings.py 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 def __iter__ ( self ): \"\"\" The `Ratings` object can be iterated over and each iteration will return an `Interaction` object Examples: ```title=\"Rating object to iterate\" +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u2 | i5 | 1 | +---------+---------+-------+ ``` >>> # for simplicity we stop after the first iteration >>> for interaction in ratings: >>> first_interaction = interaction >>> break >>> first_interaction Interaction('u1', 'i1', 4) \"\"\" yield from itertools . chain . from_iterable ( self . _ratings_dict . values ()) filter_ratings ( user_list ) Method which will filter the rating frame by keeping only interactions of users appearing in the user_list . This method will return a new Ratings object without changing the original Examples: Starting Rating object +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | | u2 | i5 | 1 | +---------+---------+-------+ >>> rating_frame . filter_ratings ([ 'u1' ]) Returned Rating object +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | +---------+---------+-------+ PARAMETER DESCRIPTION user_list List of user ids that will be present in the filtered Ratings object TYPE: Iterable [ str ] Returns The filtered Ratings object which contains only interactions of selected users Source code in clayrs/content_analyzer/ratings_manager/ratings.py 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 def filter_ratings ( self , user_list : Iterable [ str ]) -> Ratings : \"\"\" Method which will filter the rating frame by keeping only interactions of users appearing in the `user_list`. This method will return a new `Ratings` object without changing the original Examples: ```title=\"Starting Rating object\" +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | | u2 | i5 | 1 | +---------+---------+-------+ ``` >>> rating_frame.filter_ratings(['u1']) ```title=\"Returned Rating object\" +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | +---------+---------+-------+ ``` Args: user_list: List of user ids that will be present in the filtered `Ratings` object Returns The filtered Ratings object which contains only interactions of selected users \"\"\" filtered_ratings_generator = (( user , self . _ratings_dict [ user ]) for user in user_list ) return self . from_dict ( filtered_ratings_generator ) from_dataframe ( interaction_frame , user_column = 0 , item_column = 1 , score_column = 2 , timestamp_column = None ) classmethod Class method which allows to instantiate a Ratings object by using an existing pandas DataFrame If the pandas DataFrame contains users, items and ratings in this order, no additional parameters are needed, otherwise the mapping must be explicitly specified using: 'user_id' column, 'item_id' column, 'score' column Check documentation of the Ratings class for examples on mapping columns explicitly, the functioning is the same Examples: >>> ratings_df = pd . DataFrame ({ 'user_id' : [ 'u1' , 'u1' , 'u1' ], >>> 'item_id' : [ 'i1' , 'i2' , 'i3' ], >>> 'score' : [ 4 , 3 , 3 ]) >>> Ratings . from_dataframe ( ratings_df ) PARAMETER DESCRIPTION interaction_frame pandas DataFrame which represents the original interactions frame TYPE: pd . DataFrame user_column Name or positional index of the field of the DataFrame representing users column TYPE: Union [ str , int ] DEFAULT: 0 item_column Name or positional index of the field of the DataFrame representing items column TYPE: Union [ str , int ] DEFAULT: 1 score_column Name or positional index of the field of the DataFrame representing score column TYPE: Union [ str , int ] DEFAULT: 2 timestamp_column Name or positional index of the field of the raw source representing timesamp column TYPE: Union [ str , int ] DEFAULT: None RETURNS DESCRIPTION Ratings Ratings object instantiated thanks to an existing Pandas DataFrame Source code in clayrs/content_analyzer/ratings_manager/ratings.py 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 @classmethod def from_dataframe ( cls , interaction_frame : pd . DataFrame , user_column : Union [ str , int ] = 0 , item_column : Union [ str , int ] = 1 , score_column : Union [ str , int ] = 2 , timestamp_column : Union [ str , int ] = None ) -> Ratings : \"\"\" Class method which allows to instantiate a `Ratings` object by using an existing pandas DataFrame **If** the pandas DataFrame contains users, items and ratings in this order, no additional parameters are needed, **otherwise** the mapping must be explicitly specified using: * **'user_id'** column, * **'item_id'** column, * **'score'** column Check documentation of the `Ratings` class for examples on mapping columns explicitly, the functioning is the same Examples: >>> ratings_df = pd.DataFrame({'user_id': ['u1', 'u1', 'u1'], >>> 'item_id': ['i1', 'i2', 'i3'], >>> 'score': [4, 3, 3]) >>> Ratings.from_dataframe(ratings_df) Args: interaction_frame: pandas DataFrame which represents the original interactions frame user_column: Name or positional index of the field of the DataFrame representing *users* column item_column: Name or positional index of the field of the DataFrame representing *items* column score_column: Name or positional index of the field of the DataFrame representing *score* column timestamp_column: Name or positional index of the field of the raw source representing *timesamp* column Returns: `Ratings` object instantiated thanks to an existing Pandas DataFrame \"\"\" def get_value_row_df ( row , column , dtype ): try : if isinstance ( column , str ): value = row [ column ] else : # it's an int, so we get the column id and then we get the corresponding value in the row key_dict = interaction_frame . columns [ column ] value = row [ key_dict ] except ( KeyError , IndexError ) as e : if isinstance ( e , KeyError ): raise KeyError ( f \"Column { column } not found in interaction frame!\" ) else : raise IndexError ( f \"Column { column } not found in interaction frame!\" ) return dtype ( value ) if value is not None else None obj = cls . __new__ ( cls ) # Does not call __init__ super ( Ratings , obj ) . __init__ () # Don't forget to call any polymorphic base class initializers ratings_dict = defaultdict ( list ) if not interaction_frame . empty : for row in interaction_frame . to_dict ( orient = 'records' ): user_id = get_value_row_df ( row , user_column , str ) item_id = get_value_row_df ( row , item_column , str ) score = get_value_row_df ( row , score_column , float ) timestamp = get_value_row_df ( row , timestamp_column , str ) if timestamp_column is not None else None ratings_dict [ user_id ] . append ( Interaction ( user_id , item_id , score , timestamp )) obj . _ratings_dict = dict ( ratings_dict ) return obj from_dict ( interaction_dict ) classmethod Class method which allows to instantiate a Ratings object by using an existing dictionary containing user_id as keys and lists of Interaction objects as value Examples: >>> interactions_dict = { 'u1' : [ Interaction ( 'u1' , 'i2' , 4 ), Interaction ( 'u1' , 'i3' , 3 )], >>> 'u2' : [ Interaction ( 'u2' , 'i2' , 5 )]} >>> Ratings . from_dict ( interactions_dict ) PARAMETER DESCRIPTION interaction_dict Dictionary containing user_id as keys and lists of Interaction objets as values or its generator TYPE: Union [ Dict [ str , List [ Interaction ]], Iterator ] RETURNS DESCRIPTION Ratings Ratings object instantiated thanks to an existing dictionary Source code in clayrs/content_analyzer/ratings_manager/ratings.py 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 @classmethod def from_dict ( cls , interaction_dict : Union [ Dict [ str , List [ Interaction ]], Iterator ]) -> Ratings : \"\"\" Class method which allows to instantiate a `Ratings` object by using an existing dictionary containing user_id as keys and lists of `Interaction` objects as value Examples: >>> interactions_dict = {'u1': [Interaction('u1', 'i2', 4), Interaction('u1', 'i3', 3)], >>> 'u2': [Interaction('u2', 'i2', 5)]} >>> Ratings.from_dict(interactions_dict) Args: interaction_dict: Dictionary containing user_id as keys and lists of `Interaction` objets as values or its generator Returns: `Ratings` object instantiated thanks to an existing dictionary \"\"\" obj = cls . __new__ ( cls ) # Does not call __init__ super ( Ratings , obj ) . __init__ () # Don't forget to call any polymorphic base class initializers obj . _ratings_dict = dict ( interaction_dict ) return obj from_list ( interaction_list ) classmethod Class method which allows to instantiate a Ratings object by using an existing list containing Interaction objects or its generator Examples: >>> interactions_list = [ Interaction ( 'u1' , 'i1' , 5 ), Interaction ( 'u2' , 'i1' , 4 )] >>> Ratings . from_list ( interactions_list ) PARAMETER DESCRIPTION interaction_list List containing Interaction objects or its generator TYPE: Union [ List [ Interaction ], Iterator ] RETURNS DESCRIPTION Ratings Ratings object instantiated thanks to an existing interaction list Source code in clayrs/content_analyzer/ratings_manager/ratings.py 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 @classmethod def from_list ( cls , interaction_list : Union [ List [ Interaction ], Iterator ]) -> Ratings : \"\"\" Class method which allows to instantiate a `Ratings` object by using an existing list containing `Interaction` objects or its generator Examples: >>> interactions_list = [Interaction('u1', 'i1', 5), Interaction('u2', 'i1', 4)] >>> Ratings.from_list(interactions_list) Args: interaction_list: List containing `Interaction` objects or its generator Returns: `Ratings` object instantiated thanks to an existing interaction list \"\"\" obj = cls . __new__ ( cls ) # Does not call __init__ super ( Ratings , obj ) . __init__ () # Don't forget to call any polymorphic base class initializers ratings_dict = defaultdict ( list ) for interaction in interaction_list : ratings_dict [ interaction . user_id ] . append ( interaction ) obj . _ratings_dict = dict ( ratings_dict ) return obj get_user_interactions ( user_id , head = None ) Method which returns a list of Interaction objects for a single user, one for each interaction of the user. Then you can easily iterate and extract useful information using list comprehension Examples: So if the rating frame is the following: +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | | u2 | i5 | 1 | +---------+---------+-------+ >>> rating_frame . get_user_interactions ( 'u1' ) [Interaction(user_id='u1', item_id='i1', score=4), Interaction(user_id='u1', item_id='i2', score=3)] So you could easily extract all the ratings that a user has given for example: >>> [ interaction . score for interaction in rating_frame . get_user_interactions ( 'u1' )] [4, 3] If you only want the first \\(k\\) interactions of the user, set head=k . The interactions returned are the first \\(k\\) according to their order of appearance in the rating frame: >>> rating_frame . get_user_interactions ( 'u1' , head = 1 ) [Interaction(user_id='u1', item_id='i1', score=4)] PARAMETER DESCRIPTION user_id User for which interactions must be extracted TYPE: str head Integer which will cut the list of interactions of the user returned. The interactions returned are the first \\(k\\) according to their order of appearance TYPE: int DEFAULT: None RETURNS DESCRIPTION List [ Interaction ] List of Interaction objects of a single user Source code in clayrs/content_analyzer/ratings_manager/ratings.py 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 def get_user_interactions ( self , user_id : str , head : int = None ) -> List [ Interaction ]: \"\"\" Method which returns a list of `Interaction` objects for a single user, one for each interaction of the user. Then you can easily iterate and extract useful information using list comprehension Examples: So if the rating frame is the following: ``` +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | | u2 | i5 | 1 | +---------+---------+-------+ ``` >>> rating_frame.get_user_interactions('u1') [Interaction(user_id='u1', item_id='i1', score=4), Interaction(user_id='u1', item_id='i2', score=3)] So you could easily extract all the ratings that a user has given for example: >>> [interaction.score for interaction in rating_frame.get_user_interactions('u1')] [4, 3] If you only want the first $k$ interactions of the user, set `head=k`. The interactions returned are the first $k$ according to their order of appearance in the rating frame: >>> rating_frame.get_user_interactions('u1', head=1) [Interaction(user_id='u1', item_id='i1', score=4)] Args: user_id: User for which interactions must be extracted head: Integer which will cut the list of interactions of the user returned. The interactions returned are the first $k$ according to their order of appearance Returns: List of Interaction objects of a single user \"\"\" return self . _ratings_dict [ user_id ][: head ] item_id_column () property cached Getter for the user id column. This will return the item column \"as is\", so it will contain duplicate items. Use set(item_id_column) to get all unique users RETURNS DESCRIPTION list Items column with duplicates Source code in clayrs/content_analyzer/ratings_manager/ratings.py 196 197 198 199 200 201 202 203 204 205 206 @property @functools . lru_cache ( maxsize = 128 ) def item_id_column ( self ) -> list : \"\"\" Getter for the user id column. This will return the item column \"as is\", so it will contain duplicate items. Use set(item_id_column) to get all unique users Returns: Items column with duplicates \"\"\" return [ interaction . item_id for interaction in self ] score_column () property cached Getter for the score column. This will return the score column \"as is\". RETURNS DESCRIPTION list Score column Source code in clayrs/content_analyzer/ratings_manager/ratings.py 208 209 210 211 212 213 214 215 216 217 @property @functools . lru_cache ( maxsize = 128 ) def score_column ( self ) -> list : \"\"\" Getter for the score column. This will return the score column \"as is\". Returns: Score column \"\"\" return [ interaction . score for interaction in self ] take_head_all ( head ) Method which will retain only \\(k\\) interactions for each user. The \\(k\\) interactions retained are the first which appears in the rating frame. This method will return a new Ratings object without changing the original Examples: Starting Rating object +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | | u2 | i5 | 1 | | u2 | i6 | 2 | +---------+---------+-------+ >>> rating_frame . take_head_all ( head = 1 ) Returned Rating object +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u2 | i5 | 1 | +---------+---------+-------+ PARAMETER DESCRIPTION head The number of interactions to retain for each user TYPE: int RETURNS DESCRIPTION Ratings The filtered Ratings object which contains only first \\(k\\) interactions for each user Source code in clayrs/content_analyzer/ratings_manager/ratings.py 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 def take_head_all ( self , head : int ) -> Ratings : \"\"\" Method which will retain only $k$ interactions for each user. The $k$ interactions retained are the first which appears in the rating frame. This method will return a new `Ratings` object without changing the original Examples: ```title=\"Starting Rating object\" +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | | u2 | i5 | 1 | | u2 | i6 | 2 | +---------+---------+-------+ ``` >>> rating_frame.take_head_all(head=1) ```title=\"Returned Rating object\" +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u2 | i5 | 1 | +---------+---------+-------+ ``` Args: head: The number of interactions to retain for each user Returns: The filtered Ratings object which contains only first $k$ interactions for each user \"\"\" ratings_cut_generator = (( user_id , user_ratings [: head ]) for user_id , user_ratings in zip ( self . _ratings_dict . keys (), self . _ratings_dict . values ())) return self . from_dict ( ratings_cut_generator ) timestamp_column () property cached Getter for the timestamp column. This will return the score column \"as is\". If no timestamp is present then an empty list is returned RETURNS DESCRIPTION list Timestamp column or empty list if no timestamp is present Source code in clayrs/content_analyzer/ratings_manager/ratings.py 219 220 221 222 223 224 225 226 227 228 229 @property @functools . lru_cache ( maxsize = 128 ) def timestamp_column ( self ) -> list : \"\"\" Getter for the timestamp column. This will return the score column \"as is\". If no timestamp is present then an empty list is returned Returns: Timestamp column or empty list if no timestamp is present \"\"\" return [ interaction . timestamp for interaction in self if interaction . timestamp is not None ] to_csv ( output_directory = '.' , file_name = 'ratings_frame' , overwrite = False ) Method which will save the Ratings object to a csv file PARAMETER DESCRIPTION output_directory directory which will contain the csv file TYPE: str DEFAULT: '.' file_name Name of the csv_file TYPE: str DEFAULT: 'ratings_frame' overwrite If set to True and a csv file exists in the same output directory with the same file name, it will be overwritten TYPE: bool DEFAULT: False Source code in clayrs/content_analyzer/ratings_manager/ratings.py 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 def to_csv ( self , output_directory : str = '.' , file_name : str = 'ratings_frame' , overwrite : bool = False ): \"\"\" Method which will save the `Ratings` object to a `csv` file Args: output_directory: directory which will contain the csv file file_name: Name of the csv_file overwrite: If set to True and a csv file exists in the same output directory with the same file name, it will be overwritten \"\"\" Path ( output_directory ) . mkdir ( parents = True , exist_ok = True ) file_name = get_valid_filename ( output_directory , file_name , 'csv' , overwrite ) frame = self . to_dataframe () frame . to_csv ( os . path . join ( output_directory , file_name ), index = False , header = True ) to_dataframe () Method which will convert the Rating object to a pandas DataFrame object . The returned DataFrame object will contain the 'user_id', 'item_id' and 'score' column and optionally the 'timestamp' column, if at least one interaction has a timestamp. RETURNS DESCRIPTION pd . DataFrame The rating frame converted to a pandas DataFrame with 'user_id', 'item_id', 'score' column and optionally pd . DataFrame the 'timestamp' column Source code in clayrs/content_analyzer/ratings_manager/ratings.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 def to_dataframe ( self ) -> pd . DataFrame : \"\"\" Method which will convert the `Rating` object to a `pandas DataFrame object`. The returned DataFrame object will contain the 'user_id', 'item_id' and 'score' column and optionally the 'timestamp' column, if at least one interaction has a timestamp. Returns: The rating frame converted to a pandas DataFrame with 'user_id', 'item_id', 'score' column and optionally the 'timestamp' column \"\"\" will_be_frame = { 'user_id' : self . user_id_column , 'item_id' : self . item_id_column , 'score' : self . score_column } if len ( self . timestamp_column ) != 0 : will_be_frame [ 'timestamp' ] = self . timestamp_column return pd . DataFrame ( will_be_frame ) user_id_column () property cached Getter for the user id column. This will return the user column \"as is\", so it will contain duplicate users. Use set(user_id_column) to get all unique users RETURNS DESCRIPTION list Users column with duplicates Source code in clayrs/content_analyzer/ratings_manager/ratings.py 183 184 185 186 187 188 189 190 191 192 193 194 @property @functools . lru_cache ( maxsize = 128 ) def user_id_column ( self ) -> list : \"\"\" Getter for the user id column. This will return the user column \"as is\", so it will contain duplicate users. Use set(user_id_column) to get all unique users Returns: Users column with duplicates \"\"\" return [ interaction . user_id for interaction in self ]","title":"Ratings class"},{"location":"content_analyzer/ratings/ratings/#ratings-class","text":"The Ratings class is the main responsible for importing a dataset containing interactions between users and items","title":"Ratings class"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.Ratings","text":"Class responsible of importing an interaction frame into the framework If the source file contains users, items and ratings in this order, no additional parameters are needed, otherwise the mapping must be explicitly specified using: 'user_id' column, 'item_id' column, 'score' column The score column can also be processed: in case you would like to consider as score the sentiment of a textual review, or maybe normalizing all scores in \\([0, 1]\\) range. Check the example below for more Examples: CSV raw source user_id,item_id,rating,timestamp,review u1,i1,4,00112,good movie u2,i1,3,00113,an average movie u2,i32,2,00114,a bad movie As you can see the user id column, item id column and score column are the first three column and are already in sequential order, so no additional parameter is required to the Ratings class: >>> import clayrs.content_analyzer as ca >>> ratings_raw_source = ca . CSVFile ( 'ratings.csv' ) >>> # add timestamp='timestamp' to the following if >>> # you want to load also the timestamp >>> ratings = ca . Ratings ( ratings_raw_source ) In case columns in the raw source are not in the above order you must specify an appropriate mapping via positional index (useful in case your raw source doesn't have a header) or via column ids: >>> # (mapping by index) EQUIVALENT: >>> ratings = ca . Ratings ( >>> ca . CSVFile ( 'ratings.csv' ), >>> user_id_column = 0 , # (1) >>> item_id_column = 1 , # (2) >>> score_column = 2 # (3) >>> ) First column of raw source is the column containing all user ids Second column of raw source is the column containing all item ids Third column of raw source is the column containing all the scores >>> # (mapping by column name) EQUIVALENT: >>> ratings = ca . Ratings ( >>> ca . CSVFile ( 'ratings.csv' ), >>> user_id_column = 'user_id' , # (1) >>> item_id_column = 'item_id' , # (2) >>> score_column = 'rating' # (3) >>> ) The column with id 'user_id' of raw source is the column containing all user ids The column with id 'item_id' of raw source is the column containing all item ids The column with id 'rating' of raw source is the column containing all the scores In case you would like to use the sentiment of the review column of the above raw source as score column, simply specify the appropriate ScoreProcessor object >>> ratings_raw_source = ca . CSVFile ( 'ratings.csv' ) >>> ratings = ca . Ratings ( ratings_raw_source , >>> score_column = 'review' , >>> score_processor = ca . TextBlobSentimentAnalysis ()) PARAMETER DESCRIPTION source Source containing the raw interaction frame TYPE: RawInformationSource user_id_column Name or positional index of the field of the raw source representing users column TYPE: Union [ str , int ] DEFAULT: 0 item_id_column Name or positional index of the field of the raw source representing items column TYPE: Union [ str , int ] DEFAULT: 1 score_column Name or positional index of the field of the raw source representing score column TYPE: Union [ str , int ] DEFAULT: 2 timestamp_column Name or positional index of the field of the raw source representing timesamp column TYPE: Union [ str , int ] DEFAULT: None score_processor ScoreProcessor object which will process the score_column accordingly. Useful if you want to perform sentiment analysis on a textual column or you want to normalize all scores in \\([0, 1]\\) range TYPE: ScoreProcessor DEFAULT: None Source code in clayrs/content_analyzer/ratings_manager/ratings.py 173 174 175 176 177 178 179 180 181 def __init__ ( self , source : RawInformationSource , user_id_column : Union [ str , int ] = 0 , item_id_column : Union [ str , int ] = 1 , score_column : Union [ str , int ] = 2 , timestamp_column : Union [ str , int ] = None , score_processor : ScoreProcessor = None ): self . _ratings_dict = self . _import_ratings ( source , user_id_column , item_id_column , score_column , timestamp_column , score_processor )","title":"Ratings"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.ratings.Ratings.__iter__","text":"The Ratings object can be iterated over and each iteration will return an Interaction object Examples: Rating object to iterate +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u2 | i5 | 1 | +---------+---------+-------+ >>> # for simplicity we stop after the first iteration >>> for interaction in ratings : >>> first_interaction = interaction >>> break >>> first_interaction Interaction('u1', 'i1', 4) Source code in clayrs/content_analyzer/ratings_manager/ratings.py 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 def __iter__ ( self ): \"\"\" The `Ratings` object can be iterated over and each iteration will return an `Interaction` object Examples: ```title=\"Rating object to iterate\" +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u2 | i5 | 1 | +---------+---------+-------+ ``` >>> # for simplicity we stop after the first iteration >>> for interaction in ratings: >>> first_interaction = interaction >>> break >>> first_interaction Interaction('u1', 'i1', 4) \"\"\" yield from itertools . chain . from_iterable ( self . _ratings_dict . values ())","title":"__iter__()"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.ratings.Ratings.filter_ratings","text":"Method which will filter the rating frame by keeping only interactions of users appearing in the user_list . This method will return a new Ratings object without changing the original Examples: Starting Rating object +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | | u2 | i5 | 1 | +---------+---------+-------+ >>> rating_frame . filter_ratings ([ 'u1' ]) Returned Rating object +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | +---------+---------+-------+ PARAMETER DESCRIPTION user_list List of user ids that will be present in the filtered Ratings object TYPE: Iterable [ str ] Returns The filtered Ratings object which contains only interactions of selected users Source code in clayrs/content_analyzer/ratings_manager/ratings.py 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 def filter_ratings ( self , user_list : Iterable [ str ]) -> Ratings : \"\"\" Method which will filter the rating frame by keeping only interactions of users appearing in the `user_list`. This method will return a new `Ratings` object without changing the original Examples: ```title=\"Starting Rating object\" +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | | u2 | i5 | 1 | +---------+---------+-------+ ``` >>> rating_frame.filter_ratings(['u1']) ```title=\"Returned Rating object\" +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | +---------+---------+-------+ ``` Args: user_list: List of user ids that will be present in the filtered `Ratings` object Returns The filtered Ratings object which contains only interactions of selected users \"\"\" filtered_ratings_generator = (( user , self . _ratings_dict [ user ]) for user in user_list ) return self . from_dict ( filtered_ratings_generator )","title":"filter_ratings()"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.ratings.Ratings.from_dataframe","text":"Class method which allows to instantiate a Ratings object by using an existing pandas DataFrame If the pandas DataFrame contains users, items and ratings in this order, no additional parameters are needed, otherwise the mapping must be explicitly specified using: 'user_id' column, 'item_id' column, 'score' column Check documentation of the Ratings class for examples on mapping columns explicitly, the functioning is the same Examples: >>> ratings_df = pd . DataFrame ({ 'user_id' : [ 'u1' , 'u1' , 'u1' ], >>> 'item_id' : [ 'i1' , 'i2' , 'i3' ], >>> 'score' : [ 4 , 3 , 3 ]) >>> Ratings . from_dataframe ( ratings_df ) PARAMETER DESCRIPTION interaction_frame pandas DataFrame which represents the original interactions frame TYPE: pd . DataFrame user_column Name or positional index of the field of the DataFrame representing users column TYPE: Union [ str , int ] DEFAULT: 0 item_column Name or positional index of the field of the DataFrame representing items column TYPE: Union [ str , int ] DEFAULT: 1 score_column Name or positional index of the field of the DataFrame representing score column TYPE: Union [ str , int ] DEFAULT: 2 timestamp_column Name or positional index of the field of the raw source representing timesamp column TYPE: Union [ str , int ] DEFAULT: None RETURNS DESCRIPTION Ratings Ratings object instantiated thanks to an existing Pandas DataFrame Source code in clayrs/content_analyzer/ratings_manager/ratings.py 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 @classmethod def from_dataframe ( cls , interaction_frame : pd . DataFrame , user_column : Union [ str , int ] = 0 , item_column : Union [ str , int ] = 1 , score_column : Union [ str , int ] = 2 , timestamp_column : Union [ str , int ] = None ) -> Ratings : \"\"\" Class method which allows to instantiate a `Ratings` object by using an existing pandas DataFrame **If** the pandas DataFrame contains users, items and ratings in this order, no additional parameters are needed, **otherwise** the mapping must be explicitly specified using: * **'user_id'** column, * **'item_id'** column, * **'score'** column Check documentation of the `Ratings` class for examples on mapping columns explicitly, the functioning is the same Examples: >>> ratings_df = pd.DataFrame({'user_id': ['u1', 'u1', 'u1'], >>> 'item_id': ['i1', 'i2', 'i3'], >>> 'score': [4, 3, 3]) >>> Ratings.from_dataframe(ratings_df) Args: interaction_frame: pandas DataFrame which represents the original interactions frame user_column: Name or positional index of the field of the DataFrame representing *users* column item_column: Name or positional index of the field of the DataFrame representing *items* column score_column: Name or positional index of the field of the DataFrame representing *score* column timestamp_column: Name or positional index of the field of the raw source representing *timesamp* column Returns: `Ratings` object instantiated thanks to an existing Pandas DataFrame \"\"\" def get_value_row_df ( row , column , dtype ): try : if isinstance ( column , str ): value = row [ column ] else : # it's an int, so we get the column id and then we get the corresponding value in the row key_dict = interaction_frame . columns [ column ] value = row [ key_dict ] except ( KeyError , IndexError ) as e : if isinstance ( e , KeyError ): raise KeyError ( f \"Column { column } not found in interaction frame!\" ) else : raise IndexError ( f \"Column { column } not found in interaction frame!\" ) return dtype ( value ) if value is not None else None obj = cls . __new__ ( cls ) # Does not call __init__ super ( Ratings , obj ) . __init__ () # Don't forget to call any polymorphic base class initializers ratings_dict = defaultdict ( list ) if not interaction_frame . empty : for row in interaction_frame . to_dict ( orient = 'records' ): user_id = get_value_row_df ( row , user_column , str ) item_id = get_value_row_df ( row , item_column , str ) score = get_value_row_df ( row , score_column , float ) timestamp = get_value_row_df ( row , timestamp_column , str ) if timestamp_column is not None else None ratings_dict [ user_id ] . append ( Interaction ( user_id , item_id , score , timestamp )) obj . _ratings_dict = dict ( ratings_dict ) return obj","title":"from_dataframe()"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.ratings.Ratings.from_dict","text":"Class method which allows to instantiate a Ratings object by using an existing dictionary containing user_id as keys and lists of Interaction objects as value Examples: >>> interactions_dict = { 'u1' : [ Interaction ( 'u1' , 'i2' , 4 ), Interaction ( 'u1' , 'i3' , 3 )], >>> 'u2' : [ Interaction ( 'u2' , 'i2' , 5 )]} >>> Ratings . from_dict ( interactions_dict ) PARAMETER DESCRIPTION interaction_dict Dictionary containing user_id as keys and lists of Interaction objets as values or its generator TYPE: Union [ Dict [ str , List [ Interaction ]], Iterator ] RETURNS DESCRIPTION Ratings Ratings object instantiated thanks to an existing dictionary Source code in clayrs/content_analyzer/ratings_manager/ratings.py 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 @classmethod def from_dict ( cls , interaction_dict : Union [ Dict [ str , List [ Interaction ]], Iterator ]) -> Ratings : \"\"\" Class method which allows to instantiate a `Ratings` object by using an existing dictionary containing user_id as keys and lists of `Interaction` objects as value Examples: >>> interactions_dict = {'u1': [Interaction('u1', 'i2', 4), Interaction('u1', 'i3', 3)], >>> 'u2': [Interaction('u2', 'i2', 5)]} >>> Ratings.from_dict(interactions_dict) Args: interaction_dict: Dictionary containing user_id as keys and lists of `Interaction` objets as values or its generator Returns: `Ratings` object instantiated thanks to an existing dictionary \"\"\" obj = cls . __new__ ( cls ) # Does not call __init__ super ( Ratings , obj ) . __init__ () # Don't forget to call any polymorphic base class initializers obj . _ratings_dict = dict ( interaction_dict ) return obj","title":"from_dict()"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.ratings.Ratings.from_list","text":"Class method which allows to instantiate a Ratings object by using an existing list containing Interaction objects or its generator Examples: >>> interactions_list = [ Interaction ( 'u1' , 'i1' , 5 ), Interaction ( 'u2' , 'i1' , 4 )] >>> Ratings . from_list ( interactions_list ) PARAMETER DESCRIPTION interaction_list List containing Interaction objects or its generator TYPE: Union [ List [ Interaction ], Iterator ] RETURNS DESCRIPTION Ratings Ratings object instantiated thanks to an existing interaction list Source code in clayrs/content_analyzer/ratings_manager/ratings.py 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 @classmethod def from_list ( cls , interaction_list : Union [ List [ Interaction ], Iterator ]) -> Ratings : \"\"\" Class method which allows to instantiate a `Ratings` object by using an existing list containing `Interaction` objects or its generator Examples: >>> interactions_list = [Interaction('u1', 'i1', 5), Interaction('u2', 'i1', 4)] >>> Ratings.from_list(interactions_list) Args: interaction_list: List containing `Interaction` objects or its generator Returns: `Ratings` object instantiated thanks to an existing interaction list \"\"\" obj = cls . __new__ ( cls ) # Does not call __init__ super ( Ratings , obj ) . __init__ () # Don't forget to call any polymorphic base class initializers ratings_dict = defaultdict ( list ) for interaction in interaction_list : ratings_dict [ interaction . user_id ] . append ( interaction ) obj . _ratings_dict = dict ( ratings_dict ) return obj","title":"from_list()"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.ratings.Ratings.get_user_interactions","text":"Method which returns a list of Interaction objects for a single user, one for each interaction of the user. Then you can easily iterate and extract useful information using list comprehension Examples: So if the rating frame is the following: +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | | u2 | i5 | 1 | +---------+---------+-------+ >>> rating_frame . get_user_interactions ( 'u1' ) [Interaction(user_id='u1', item_id='i1', score=4), Interaction(user_id='u1', item_id='i2', score=3)] So you could easily extract all the ratings that a user has given for example: >>> [ interaction . score for interaction in rating_frame . get_user_interactions ( 'u1' )] [4, 3] If you only want the first \\(k\\) interactions of the user, set head=k . The interactions returned are the first \\(k\\) according to their order of appearance in the rating frame: >>> rating_frame . get_user_interactions ( 'u1' , head = 1 ) [Interaction(user_id='u1', item_id='i1', score=4)] PARAMETER DESCRIPTION user_id User for which interactions must be extracted TYPE: str head Integer which will cut the list of interactions of the user returned. The interactions returned are the first \\(k\\) according to their order of appearance TYPE: int DEFAULT: None RETURNS DESCRIPTION List [ Interaction ] List of Interaction objects of a single user Source code in clayrs/content_analyzer/ratings_manager/ratings.py 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 def get_user_interactions ( self , user_id : str , head : int = None ) -> List [ Interaction ]: \"\"\" Method which returns a list of `Interaction` objects for a single user, one for each interaction of the user. Then you can easily iterate and extract useful information using list comprehension Examples: So if the rating frame is the following: ``` +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | | u2 | i5 | 1 | +---------+---------+-------+ ``` >>> rating_frame.get_user_interactions('u1') [Interaction(user_id='u1', item_id='i1', score=4), Interaction(user_id='u1', item_id='i2', score=3)] So you could easily extract all the ratings that a user has given for example: >>> [interaction.score for interaction in rating_frame.get_user_interactions('u1')] [4, 3] If you only want the first $k$ interactions of the user, set `head=k`. The interactions returned are the first $k$ according to their order of appearance in the rating frame: >>> rating_frame.get_user_interactions('u1', head=1) [Interaction(user_id='u1', item_id='i1', score=4)] Args: user_id: User for which interactions must be extracted head: Integer which will cut the list of interactions of the user returned. The interactions returned are the first $k$ according to their order of appearance Returns: List of Interaction objects of a single user \"\"\" return self . _ratings_dict [ user_id ][: head ]","title":"get_user_interactions()"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.ratings.Ratings.item_id_column","text":"Getter for the user id column. This will return the item column \"as is\", so it will contain duplicate items. Use set(item_id_column) to get all unique users RETURNS DESCRIPTION list Items column with duplicates Source code in clayrs/content_analyzer/ratings_manager/ratings.py 196 197 198 199 200 201 202 203 204 205 206 @property @functools . lru_cache ( maxsize = 128 ) def item_id_column ( self ) -> list : \"\"\" Getter for the user id column. This will return the item column \"as is\", so it will contain duplicate items. Use set(item_id_column) to get all unique users Returns: Items column with duplicates \"\"\" return [ interaction . item_id for interaction in self ]","title":"item_id_column()"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.ratings.Ratings.score_column","text":"Getter for the score column. This will return the score column \"as is\". RETURNS DESCRIPTION list Score column Source code in clayrs/content_analyzer/ratings_manager/ratings.py 208 209 210 211 212 213 214 215 216 217 @property @functools . lru_cache ( maxsize = 128 ) def score_column ( self ) -> list : \"\"\" Getter for the score column. This will return the score column \"as is\". Returns: Score column \"\"\" return [ interaction . score for interaction in self ]","title":"score_column()"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.ratings.Ratings.take_head_all","text":"Method which will retain only \\(k\\) interactions for each user. The \\(k\\) interactions retained are the first which appears in the rating frame. This method will return a new Ratings object without changing the original Examples: Starting Rating object +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | | u2 | i5 | 1 | | u2 | i6 | 2 | +---------+---------+-------+ >>> rating_frame . take_head_all ( head = 1 ) Returned Rating object +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u2 | i5 | 1 | +---------+---------+-------+ PARAMETER DESCRIPTION head The number of interactions to retain for each user TYPE: int RETURNS DESCRIPTION Ratings The filtered Ratings object which contains only first \\(k\\) interactions for each user Source code in clayrs/content_analyzer/ratings_manager/ratings.py 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 def take_head_all ( self , head : int ) -> Ratings : \"\"\" Method which will retain only $k$ interactions for each user. The $k$ interactions retained are the first which appears in the rating frame. This method will return a new `Ratings` object without changing the original Examples: ```title=\"Starting Rating object\" +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u1 | i2 | 3 | | u2 | i5 | 1 | | u2 | i6 | 2 | +---------+---------+-------+ ``` >>> rating_frame.take_head_all(head=1) ```title=\"Returned Rating object\" +---------+---------+-------+ | user_id | item_id | score | +---------+---------+-------+ | u1 | i1 | 4 | | u2 | i5 | 1 | +---------+---------+-------+ ``` Args: head: The number of interactions to retain for each user Returns: The filtered Ratings object which contains only first $k$ interactions for each user \"\"\" ratings_cut_generator = (( user_id , user_ratings [: head ]) for user_id , user_ratings in zip ( self . _ratings_dict . keys (), self . _ratings_dict . values ())) return self . from_dict ( ratings_cut_generator )","title":"take_head_all()"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.ratings.Ratings.timestamp_column","text":"Getter for the timestamp column. This will return the score column \"as is\". If no timestamp is present then an empty list is returned RETURNS DESCRIPTION list Timestamp column or empty list if no timestamp is present Source code in clayrs/content_analyzer/ratings_manager/ratings.py 219 220 221 222 223 224 225 226 227 228 229 @property @functools . lru_cache ( maxsize = 128 ) def timestamp_column ( self ) -> list : \"\"\" Getter for the timestamp column. This will return the score column \"as is\". If no timestamp is present then an empty list is returned Returns: Timestamp column or empty list if no timestamp is present \"\"\" return [ interaction . timestamp for interaction in self if interaction . timestamp is not None ]","title":"timestamp_column()"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.ratings.Ratings.to_csv","text":"Method which will save the Ratings object to a csv file PARAMETER DESCRIPTION output_directory directory which will contain the csv file TYPE: str DEFAULT: '.' file_name Name of the csv_file TYPE: str DEFAULT: 'ratings_frame' overwrite If set to True and a csv file exists in the same output directory with the same file name, it will be overwritten TYPE: bool DEFAULT: False Source code in clayrs/content_analyzer/ratings_manager/ratings.py 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 def to_csv ( self , output_directory : str = '.' , file_name : str = 'ratings_frame' , overwrite : bool = False ): \"\"\" Method which will save the `Ratings` object to a `csv` file Args: output_directory: directory which will contain the csv file file_name: Name of the csv_file overwrite: If set to True and a csv file exists in the same output directory with the same file name, it will be overwritten \"\"\" Path ( output_directory ) . mkdir ( parents = True , exist_ok = True ) file_name = get_valid_filename ( output_directory , file_name , 'csv' , overwrite ) frame = self . to_dataframe () frame . to_csv ( os . path . join ( output_directory , file_name ), index = False , header = True )","title":"to_csv()"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.ratings.Ratings.to_dataframe","text":"Method which will convert the Rating object to a pandas DataFrame object . The returned DataFrame object will contain the 'user_id', 'item_id' and 'score' column and optionally the 'timestamp' column, if at least one interaction has a timestamp. RETURNS DESCRIPTION pd . DataFrame The rating frame converted to a pandas DataFrame with 'user_id', 'item_id', 'score' column and optionally pd . DataFrame the 'timestamp' column Source code in clayrs/content_analyzer/ratings_manager/ratings.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 def to_dataframe ( self ) -> pd . DataFrame : \"\"\" Method which will convert the `Rating` object to a `pandas DataFrame object`. The returned DataFrame object will contain the 'user_id', 'item_id' and 'score' column and optionally the 'timestamp' column, if at least one interaction has a timestamp. Returns: The rating frame converted to a pandas DataFrame with 'user_id', 'item_id', 'score' column and optionally the 'timestamp' column \"\"\" will_be_frame = { 'user_id' : self . user_id_column , 'item_id' : self . item_id_column , 'score' : self . score_column } if len ( self . timestamp_column ) != 0 : will_be_frame [ 'timestamp' ] = self . timestamp_column return pd . DataFrame ( will_be_frame )","title":"to_dataframe()"},{"location":"content_analyzer/ratings/ratings/#clayrs.content_analyzer.ratings_manager.ratings.Ratings.user_id_column","text":"Getter for the user id column. This will return the user column \"as is\", so it will contain duplicate users. Use set(user_id_column) to get all unique users RETURNS DESCRIPTION list Users column with duplicates Source code in clayrs/content_analyzer/ratings_manager/ratings.py 183 184 185 186 187 188 189 190 191 192 193 194 @property @functools . lru_cache ( maxsize = 128 ) def user_id_column ( self ) -> list : \"\"\" Getter for the user id column. This will return the user column \"as is\", so it will contain duplicate users. Use set(user_id_column) to get all unique users Returns: Users column with duplicates \"\"\" return [ interaction . user_id for interaction in self ]","title":"user_id_column()"},{"location":"content_analyzer/ratings/score_processors/","text":"Score Processors NumberNormalizer ( scale , decimal_rounding = None ) Bases: ScoreProcessor Class that normalizes numeric scores to a scale in the range \\([-1.0, 1.0]\\) PARAMETER DESCRIPTION scale Tuple where the first value is the minimum of the actual scale, second value is the maximum of the actual scale (e.g. (1, 5) represents an actual scale of scores from 1 (included) to 5 (included)) TYPE: Tuple [ float , float ] decimal_rounding If set, the normalized score will be rounded to the chosen decimal digit TYPE: int DEFAULT: None Source code in clayrs/content_analyzer/ratings_manager/score_processor.py 48 49 50 51 52 53 54 55 56 def __init__ ( self , scale : Tuple [ float , float ], decimal_rounding : int = None ): super () . __init__ ( decimal_rounding ) if len ( scale ) != 2 : raise ValueError ( \"The voting scale should be a tuple containing exactly two values,\" \"the minimum of the scale and the maximum!\" ) self . _old_min = scale [ 0 ] self . _old_max = scale [ 1 ] fit ( score_data ) Method which will normalize the given score PARAMETER DESCRIPTION score_data score that will be normalized TYPE: float RETURNS DESCRIPTION float score normalized in the interval \\([-1, 1]\\) Source code in clayrs/content_analyzer/ratings_manager/score_processor.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def fit ( self , score_data : float ) -> float : \"\"\" Method which will normalize the given score Args: score_data: score that will be normalized Returns: score normalized in the interval $[-1, 1]$ \"\"\" def convert_into_range ( value : float , old_min : float , old_max : float , new_min : int = - 1 , new_max : int = 1 ): new_value = (( value - old_min ) / ( old_max - old_min )) * ( new_max - new_min ) + new_min if self . decimal_rounding : new_value = np . round ( new_value , self . decimal_rounding ) return new_value return convert_into_range ( float ( score_data ), self . _old_min , self . _old_max ) TextBlobSentimentAnalysis ( decimal_rounding = None ) Bases: SentimentAnalysis Class that compute sentiment polarity on a textual field using TextBlob library. The given score will be in the \\([-1.0, 1.0]\\) range Source code in clayrs/content_analyzer/ratings_manager/sentiment_analysis.py 12 13 def __init__ ( self , decimal_rounding : int = None ): super () . __init__ ( decimal_rounding ) fit ( score_data ) This method calculates the sentiment polarity score on textual reviews PARAMETER DESCRIPTION score_data text for which sentiment polarity must be computed and considered as score TYPE: str RETURNS DESCRIPTION float The sentiment polarity of the textual data in range \\([-1.0, 1.0]\\) Source code in clayrs/content_analyzer/ratings_manager/sentiment_analysis.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 def fit ( self , score_data : str ) -> float : \"\"\" This method calculates the sentiment polarity score on textual reviews Args: score_data: text for which sentiment polarity must be computed and considered as score Returns: The sentiment polarity of the textual data in range $[-1.0, 1.0]$ \"\"\" polarity_score = TextBlob ( score_data ) . sentiment . polarity if self . decimal_rounding : polarity_score = round ( polarity_score , self . decimal_rounding ) return polarity_score","title":"Score processors"},{"location":"content_analyzer/ratings/score_processors/#score-processors","text":"","title":"Score Processors"},{"location":"content_analyzer/ratings/score_processors/#clayrs.content_analyzer.ratings_manager.NumberNormalizer","text":"Bases: ScoreProcessor Class that normalizes numeric scores to a scale in the range \\([-1.0, 1.0]\\) PARAMETER DESCRIPTION scale Tuple where the first value is the minimum of the actual scale, second value is the maximum of the actual scale (e.g. (1, 5) represents an actual scale of scores from 1 (included) to 5 (included)) TYPE: Tuple [ float , float ] decimal_rounding If set, the normalized score will be rounded to the chosen decimal digit TYPE: int DEFAULT: None Source code in clayrs/content_analyzer/ratings_manager/score_processor.py 48 49 50 51 52 53 54 55 56 def __init__ ( self , scale : Tuple [ float , float ], decimal_rounding : int = None ): super () . __init__ ( decimal_rounding ) if len ( scale ) != 2 : raise ValueError ( \"The voting scale should be a tuple containing exactly two values,\" \"the minimum of the scale and the maximum!\" ) self . _old_min = scale [ 0 ] self . _old_max = scale [ 1 ]","title":"NumberNormalizer"},{"location":"content_analyzer/ratings/score_processors/#clayrs.content_analyzer.ratings_manager.score_processor.NumberNormalizer.fit","text":"Method which will normalize the given score PARAMETER DESCRIPTION score_data score that will be normalized TYPE: float RETURNS DESCRIPTION float score normalized in the interval \\([-1, 1]\\) Source code in clayrs/content_analyzer/ratings_manager/score_processor.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 def fit ( self , score_data : float ) -> float : \"\"\" Method which will normalize the given score Args: score_data: score that will be normalized Returns: score normalized in the interval $[-1, 1]$ \"\"\" def convert_into_range ( value : float , old_min : float , old_max : float , new_min : int = - 1 , new_max : int = 1 ): new_value = (( value - old_min ) / ( old_max - old_min )) * ( new_max - new_min ) + new_min if self . decimal_rounding : new_value = np . round ( new_value , self . decimal_rounding ) return new_value return convert_into_range ( float ( score_data ), self . _old_min , self . _old_max )","title":"fit()"},{"location":"content_analyzer/ratings/score_processors/#clayrs.content_analyzer.ratings_manager.TextBlobSentimentAnalysis","text":"Bases: SentimentAnalysis Class that compute sentiment polarity on a textual field using TextBlob library. The given score will be in the \\([-1.0, 1.0]\\) range Source code in clayrs/content_analyzer/ratings_manager/sentiment_analysis.py 12 13 def __init__ ( self , decimal_rounding : int = None ): super () . __init__ ( decimal_rounding )","title":"TextBlobSentimentAnalysis"},{"location":"content_analyzer/ratings/score_processors/#clayrs.content_analyzer.ratings_manager.sentiment_analysis.TextBlobSentimentAnalysis.fit","text":"This method calculates the sentiment polarity score on textual reviews PARAMETER DESCRIPTION score_data text for which sentiment polarity must be computed and considered as score TYPE: str RETURNS DESCRIPTION float The sentiment polarity of the textual data in range \\([-1.0, 1.0]\\) Source code in clayrs/content_analyzer/ratings_manager/sentiment_analysis.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 def fit ( self , score_data : str ) -> float : \"\"\" This method calculates the sentiment polarity score on textual reviews Args: score_data: text for which sentiment polarity must be computed and considered as score Returns: The sentiment polarity of the textual data in range $[-1.0, 1.0]$ \"\"\" polarity_score = TextBlob ( score_data ) . sentiment . polarity if self . decimal_rounding : polarity_score = round ( polarity_score , self . decimal_rounding ) return polarity_score","title":"fit()"},{"location":"evaluation/eval_model/","text":"Eval Model class EvalModel ( pred_list , truth_list , metric_list ) Class for evaluating a recommender system. The Evaluation module needs the following parameters: A list of computed rank/predictions (in case multiple splits must be evaluated) A list of truths (in case multiple splits must be evaluated) List of metrics to compute Obviously the list of computed rank/predictions and list of truths must have the same length, and the rank/prediction in position \\(i\\) will be compared with the truth at position \\(i\\) Examples: >>> import clayrs.evaluation as eva >>> >>> em = eva . EvalModel ( >>> pred_list = rank_list , >>> truth_list = truth_list , >>> metric_list = [ >>> eva . NDCG (), >>> eva . Precision () >>> eva . RecallAtK ( k = 5 , sys_average = 'micro' ) >>> ] >>> ) Then call the fit() method of the instantiated EvalModel to perform the actual evaluation PARAMETER DESCRIPTION pred_list Recommendations list to evaluate. It's a list in case multiple splits must be evaluated. Both Rank objects (where items are ordered and the score is not relevant) or Prediction objects (where the score predicted is the predicted rating for the user regarding a certain item) can be evaluated TYPE: Union [ List [ Prediction ], List [ Rank ]] truth_list Ground truths list used to compare recommendations. It's a list in case multiple splits must be evaluated. TYPE: List [ Ratings ] metric_list List of metrics that will be used to evaluate recommendation list specified TYPE: List [ Metric ] RAISES DESCRIPTION ValueError ValueError is raised in case the pred_list and truth_list are empty or have different length Source code in clayrs/evaluation/eval_model.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , pred_list : Union [ List [ Prediction ], List [ Rank ]], truth_list : List [ Ratings ], metric_list : List [ Metric ]): if len ( pred_list ) == 0 and len ( truth_list ) == 0 : raise ValueError ( \"List containing predictions and list containing ground truths are empty!\" ) elif len ( pred_list ) != len ( truth_list ): raise ValueError ( \"List containing predictions and list containing ground truths must have the same length!\" ) self . _pred_list = pred_list self . _truth_list = truth_list self . _metric_list = metric_list self . _yaml_report_result = None append_metric ( metric ) Append a metric to the metric list that will be used to evaluate recommendation lists PARAMETER DESCRIPTION metric Metric to append to the metric list TYPE: Metric Source code in clayrs/evaluation/eval_model.py 100 101 102 103 104 105 106 107 def append_metric ( self , metric : Metric ): \"\"\" Append a metric to the metric list that will be used to evaluate recommendation lists Args: metric: Metric to append to the metric list \"\"\" self . _metric_list . append ( metric ) fit ( user_id_list = None ) This method performs the actual evaluation of the recommendation frames passed as input in the constructor of the class In case you want to perform evaluation for selected users, specify their ids parameter of this method. Otherwise, all users in the recommendation frames will be considered in the evaluation process Examples: >>> import clayrs.evaluation as eva >>> selected_users = [ 'u1' , 'u22' , 'u3' ] # (1) >>> em = eva . EvalModel ( >>> pred_list , >>> truth_list , >>> metric_list = [ eva . Precision (), eva . Recall ()] >>> ) >>> em . fit ( selected_users ) The method returns two pandas DataFrame: one containing system results for every metric in the metric list, one containing users results for every metric eligible RETURNS DESCRIPTION pd . DataFrame The first DataFrame contains the system result for every metric inside the metric_list pd . DataFrame The second DataFrame contains every user results for every metric eligible inside the metric_list Source code in clayrs/evaluation/eval_model.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 def fit ( self , user_id_list : list = None ) -> Tuple [ pd . DataFrame , pd . DataFrame ]: \"\"\" This method performs the actual evaluation of the recommendation frames passed as input in the constructor of the class In case you want to perform evaluation for selected users, specify their ids parameter of this method. Otherwise, all users in the recommendation frames will be considered in the evaluation process Examples: >>> import clayrs.evaluation as eva >>> selected_users = ['u1', 'u22', 'u3'] # (1) >>> em = eva.EvalModel( >>> pred_list, >>> truth_list, >>> metric_list=[eva.Precision(), eva.Recall()] >>> ) >>> em.fit(selected_users) The method returns two pandas DataFrame: one containing ***system results*** for every metric in the metric list, one containing ***users results*** for every metric eligible Returns: The first DataFrame contains the **system result** for every metric inside the metric_list The second DataFrame contains every **user results** for every metric eligible inside the metric_list \"\"\" logger . info ( 'Performing evaluation on metrics chosen' ) pred_list = self . _pred_list truth_list = self . _truth_list if user_id_list is not None : user_id_list_set = set ([ str ( user_id ) for user_id in user_id_list ]) pred_list = [ pred . filter_ratings ( user_id_list_set ) for pred in self . _pred_list ] truth_list = [ truth . filter_ratings ( user_id_list_set ) for truth in self . _truth_list ] sys_result , users_result = MetricEvaluator ( pred_list , truth_list ) . eval_metrics ( self . metric_list ) # we save the sys result for report yaml self . _yaml_report_result = sys_result . to_dict ( orient = 'index' ) return sys_result , users_result metric_list () property List of metrics used to evaluate recommendation lists RETURNS DESCRIPTION List [ Metric ] The list containing all metrics Source code in clayrs/evaluation/eval_model.py 90 91 92 93 94 95 96 97 98 @property def metric_list ( self ) -> List [ Metric ]: \"\"\" List of metrics used to evaluate recommendation lists Returns: The list containing all metrics \"\"\" return self . _metric_list pred_list () property List containing recommendations frame RETURNS DESCRIPTION Union [ List [ Prediction ], List [ Rank ]] The list containing recommendations frame Source code in clayrs/evaluation/eval_model.py 70 71 72 73 74 75 76 77 78 @property def pred_list ( self ) -> Union [ List [ Prediction ], List [ Rank ]]: \"\"\" List containing recommendations frame Returns: The list containing recommendations frame \"\"\" return self . _pred_list truth_list () property List containing ground truths RETURNS DESCRIPTION List [ Ratings ] The list containing ground truths Source code in clayrs/evaluation/eval_model.py 80 81 82 83 84 85 86 87 88 @property def truth_list ( self ) -> List [ Ratings ]: \"\"\" List containing ground truths Returns: The list containing ground truths \"\"\" return self . _truth_list","title":"EvalModel class"},{"location":"evaluation/eval_model/#eval-model-class","text":"","title":"Eval Model class"},{"location":"evaluation/eval_model/#clayrs.evaluation.eval_model.EvalModel","text":"Class for evaluating a recommender system. The Evaluation module needs the following parameters: A list of computed rank/predictions (in case multiple splits must be evaluated) A list of truths (in case multiple splits must be evaluated) List of metrics to compute Obviously the list of computed rank/predictions and list of truths must have the same length, and the rank/prediction in position \\(i\\) will be compared with the truth at position \\(i\\) Examples: >>> import clayrs.evaluation as eva >>> >>> em = eva . EvalModel ( >>> pred_list = rank_list , >>> truth_list = truth_list , >>> metric_list = [ >>> eva . NDCG (), >>> eva . Precision () >>> eva . RecallAtK ( k = 5 , sys_average = 'micro' ) >>> ] >>> ) Then call the fit() method of the instantiated EvalModel to perform the actual evaluation PARAMETER DESCRIPTION pred_list Recommendations list to evaluate. It's a list in case multiple splits must be evaluated. Both Rank objects (where items are ordered and the score is not relevant) or Prediction objects (where the score predicted is the predicted rating for the user regarding a certain item) can be evaluated TYPE: Union [ List [ Prediction ], List [ Rank ]] truth_list Ground truths list used to compare recommendations. It's a list in case multiple splits must be evaluated. TYPE: List [ Ratings ] metric_list List of metrics that will be used to evaluate recommendation list specified TYPE: List [ Metric ] RAISES DESCRIPTION ValueError ValueError is raised in case the pred_list and truth_list are empty or have different length Source code in clayrs/evaluation/eval_model.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def __init__ ( self , pred_list : Union [ List [ Prediction ], List [ Rank ]], truth_list : List [ Ratings ], metric_list : List [ Metric ]): if len ( pred_list ) == 0 and len ( truth_list ) == 0 : raise ValueError ( \"List containing predictions and list containing ground truths are empty!\" ) elif len ( pred_list ) != len ( truth_list ): raise ValueError ( \"List containing predictions and list containing ground truths must have the same length!\" ) self . _pred_list = pred_list self . _truth_list = truth_list self . _metric_list = metric_list self . _yaml_report_result = None","title":"EvalModel"},{"location":"evaluation/eval_model/#clayrs.evaluation.eval_model.EvalModel.append_metric","text":"Append a metric to the metric list that will be used to evaluate recommendation lists PARAMETER DESCRIPTION metric Metric to append to the metric list TYPE: Metric Source code in clayrs/evaluation/eval_model.py 100 101 102 103 104 105 106 107 def append_metric ( self , metric : Metric ): \"\"\" Append a metric to the metric list that will be used to evaluate recommendation lists Args: metric: Metric to append to the metric list \"\"\" self . _metric_list . append ( metric )","title":"append_metric()"},{"location":"evaluation/eval_model/#clayrs.evaluation.eval_model.EvalModel.fit","text":"This method performs the actual evaluation of the recommendation frames passed as input in the constructor of the class In case you want to perform evaluation for selected users, specify their ids parameter of this method. Otherwise, all users in the recommendation frames will be considered in the evaluation process Examples: >>> import clayrs.evaluation as eva >>> selected_users = [ 'u1' , 'u22' , 'u3' ] # (1) >>> em = eva . EvalModel ( >>> pred_list , >>> truth_list , >>> metric_list = [ eva . Precision (), eva . Recall ()] >>> ) >>> em . fit ( selected_users ) The method returns two pandas DataFrame: one containing system results for every metric in the metric list, one containing users results for every metric eligible RETURNS DESCRIPTION pd . DataFrame The first DataFrame contains the system result for every metric inside the metric_list pd . DataFrame The second DataFrame contains every user results for every metric eligible inside the metric_list Source code in clayrs/evaluation/eval_model.py 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 def fit ( self , user_id_list : list = None ) -> Tuple [ pd . DataFrame , pd . DataFrame ]: \"\"\" This method performs the actual evaluation of the recommendation frames passed as input in the constructor of the class In case you want to perform evaluation for selected users, specify their ids parameter of this method. Otherwise, all users in the recommendation frames will be considered in the evaluation process Examples: >>> import clayrs.evaluation as eva >>> selected_users = ['u1', 'u22', 'u3'] # (1) >>> em = eva.EvalModel( >>> pred_list, >>> truth_list, >>> metric_list=[eva.Precision(), eva.Recall()] >>> ) >>> em.fit(selected_users) The method returns two pandas DataFrame: one containing ***system results*** for every metric in the metric list, one containing ***users results*** for every metric eligible Returns: The first DataFrame contains the **system result** for every metric inside the metric_list The second DataFrame contains every **user results** for every metric eligible inside the metric_list \"\"\" logger . info ( 'Performing evaluation on metrics chosen' ) pred_list = self . _pred_list truth_list = self . _truth_list if user_id_list is not None : user_id_list_set = set ([ str ( user_id ) for user_id in user_id_list ]) pred_list = [ pred . filter_ratings ( user_id_list_set ) for pred in self . _pred_list ] truth_list = [ truth . filter_ratings ( user_id_list_set ) for truth in self . _truth_list ] sys_result , users_result = MetricEvaluator ( pred_list , truth_list ) . eval_metrics ( self . metric_list ) # we save the sys result for report yaml self . _yaml_report_result = sys_result . to_dict ( orient = 'index' ) return sys_result , users_result","title":"fit()"},{"location":"evaluation/eval_model/#clayrs.evaluation.eval_model.EvalModel.metric_list","text":"List of metrics used to evaluate recommendation lists RETURNS DESCRIPTION List [ Metric ] The list containing all metrics Source code in clayrs/evaluation/eval_model.py 90 91 92 93 94 95 96 97 98 @property def metric_list ( self ) -> List [ Metric ]: \"\"\" List of metrics used to evaluate recommendation lists Returns: The list containing all metrics \"\"\" return self . _metric_list","title":"metric_list()"},{"location":"evaluation/eval_model/#clayrs.evaluation.eval_model.EvalModel.pred_list","text":"List containing recommendations frame RETURNS DESCRIPTION Union [ List [ Prediction ], List [ Rank ]] The list containing recommendations frame Source code in clayrs/evaluation/eval_model.py 70 71 72 73 74 75 76 77 78 @property def pred_list ( self ) -> Union [ List [ Prediction ], List [ Rank ]]: \"\"\" List containing recommendations frame Returns: The list containing recommendations frame \"\"\" return self . _pred_list","title":"pred_list()"},{"location":"evaluation/eval_model/#clayrs.evaluation.eval_model.EvalModel.truth_list","text":"List containing ground truths RETURNS DESCRIPTION List [ Ratings ] The list containing ground truths Source code in clayrs/evaluation/eval_model.py 80 81 82 83 84 85 86 87 88 @property def truth_list ( self ) -> List [ Ratings ]: \"\"\" List containing ground truths Returns: The list containing ground truths \"\"\" return self . _truth_list","title":"truth_list()"},{"location":"evaluation/introduction/","text":"Warning Docs are complete, but revision is still a Work in Progress. Sorry for any typos! Introduction The Evaluation module has the task of evaluating a recommender system, using several state-of-the-art metrics The usage pipeline it's pretty simple, all the work is done by the EvalModel class class. Suppose you want to evaluate recommendation lists using NDCG , macro Precision , micro Recall@5 , you need to instantiate the EvalModel class with the following parameters: A list of computed rank/predictions (in case multiple splits must be evaluated) A list of truths (in case multiple splits must be evaluated) List of metrics to compute Obviously the list of computed rank/predictions and list of truths must have the same length, and the rank/prediction in position \\(i\\) will be compared with the truth at position \\(i\\) Usage example In this case rank_list and truth_list are results obtained from the RecSys module of the framework import clayrs.evaluation as eva em = eva . EvalModel ( pred_list = rank_list , truth_list = truth_list , metric_list = [ eva . NDCG (), eva . Precision (), # (1) eva . RecallAtK ( k = 5 , sys_average = 'micro' ) ] ) If not specified, by default system average is computed as macro Info Precision , Recall , and in general all classification metrics require a threshold which separates relevant items from non-relevant. If a threshold is specified, then it is fixed for all users If no threshold is specified, the mean rating score of each user will be used Check documentation of each metric for more Then simply call the fit () method of the instantiated object It will return two pandas DataFrame: the first one contains the metrics aggregated for the system, while the second contains the metrics computed for each user (where possible) sys_result , users_result = em . fit () Evaluating external recommendation lists The evaluation module is completely independent from the Recsys and Content Analyzer module: that means that we can easily evaluate recommendation lists computed by other frameworks/tools! Let's suppose we have recommendations (and related truths) generated via other tools in a csv format. We first import them into the framework and then pass them to the EvalModel class import clayrs.content_analyzer as ca csv_rank_1 = ca . CSVFile ( 'rank_split_1.csv' ) csv_truth_1 = ca . CSVFile ( 'truth_split_1.csv' ) csv_rank_2 = ca . CSVFile ( 'rank_split_2.csv' ) csv_truth_2 = ca . CSVFile ( 'truth_split_2.csv' ) # Importing split 1 (1) rank_1 = ca . Rank ( csv_rank_1 ) truth_1 = ca . Ratings ( csv_truth_1 ) # Importing split 2 (2) rank_2 = ca . Rank ( csv_rank_2 ) truth_2 = ca . Ratings ( csv_truth_2 ) # since multiple splits, we wrap ranks and truths in lists imported_ranks = [ rank_1 , rank_2 ] imported_truths = [ truth_1 , truth_2 ] Remember that this instantiation to the Rank/Ratings class assumes a certain order of the columns of your raw source. Otherwise, you need to manually map columns. Check related documentation for more Remember that this instantiation to the Rank/Ratings class assumes a certain order of the columns of your raw source. Otherwise, you need to manually map columns. Check related documentation for more Then simply evaluate them exactly in the same way as shown before! import clayrs.evaluation as eva em = eva . EvalModel ( pred_list = imported_ranks , truth_list = imported_truths , metric_list = [ # ... Choose your own metrics ] ) sys_results_df , users_results_df = em . fit () Perform a statistical test ClayRS lets you also compare different learning schemas by performing statistical tests: Simply instantiate the desired test and call its perform () method. The parameter it expects is the list of user_results dataframe obtained in the evaluation step, one for each learning schema to compare. ttest = eva . Ttest () all_comb_df = ttest . perform ([ user_result1 , user_result2 , user_result3 ]) Info In this case since the Ttest it's a paired test, the final result is a pandas DataFrame which contains learning schemas compared in pair: (system1, system2) (system1, system3) (system2, system3)","title":"Introduction"},{"location":"evaluation/introduction/#introduction","text":"The Evaluation module has the task of evaluating a recommender system, using several state-of-the-art metrics The usage pipeline it's pretty simple, all the work is done by the EvalModel class class. Suppose you want to evaluate recommendation lists using NDCG , macro Precision , micro Recall@5 , you need to instantiate the EvalModel class with the following parameters: A list of computed rank/predictions (in case multiple splits must be evaluated) A list of truths (in case multiple splits must be evaluated) List of metrics to compute Obviously the list of computed rank/predictions and list of truths must have the same length, and the rank/prediction in position \\(i\\) will be compared with the truth at position \\(i\\)","title":"Introduction"},{"location":"evaluation/introduction/#usage-example","text":"In this case rank_list and truth_list are results obtained from the RecSys module of the framework import clayrs.evaluation as eva em = eva . EvalModel ( pred_list = rank_list , truth_list = truth_list , metric_list = [ eva . NDCG (), eva . Precision (), # (1) eva . RecallAtK ( k = 5 , sys_average = 'micro' ) ] ) If not specified, by default system average is computed as macro Info Precision , Recall , and in general all classification metrics require a threshold which separates relevant items from non-relevant. If a threshold is specified, then it is fixed for all users If no threshold is specified, the mean rating score of each user will be used Check documentation of each metric for more Then simply call the fit () method of the instantiated object It will return two pandas DataFrame: the first one contains the metrics aggregated for the system, while the second contains the metrics computed for each user (where possible) sys_result , users_result = em . fit ()","title":"Usage example"},{"location":"evaluation/introduction/#evaluating-external-recommendation-lists","text":"The evaluation module is completely independent from the Recsys and Content Analyzer module: that means that we can easily evaluate recommendation lists computed by other frameworks/tools! Let's suppose we have recommendations (and related truths) generated via other tools in a csv format. We first import them into the framework and then pass them to the EvalModel class import clayrs.content_analyzer as ca csv_rank_1 = ca . CSVFile ( 'rank_split_1.csv' ) csv_truth_1 = ca . CSVFile ( 'truth_split_1.csv' ) csv_rank_2 = ca . CSVFile ( 'rank_split_2.csv' ) csv_truth_2 = ca . CSVFile ( 'truth_split_2.csv' ) # Importing split 1 (1) rank_1 = ca . Rank ( csv_rank_1 ) truth_1 = ca . Ratings ( csv_truth_1 ) # Importing split 2 (2) rank_2 = ca . Rank ( csv_rank_2 ) truth_2 = ca . Ratings ( csv_truth_2 ) # since multiple splits, we wrap ranks and truths in lists imported_ranks = [ rank_1 , rank_2 ] imported_truths = [ truth_1 , truth_2 ] Remember that this instantiation to the Rank/Ratings class assumes a certain order of the columns of your raw source. Otherwise, you need to manually map columns. Check related documentation for more Remember that this instantiation to the Rank/Ratings class assumes a certain order of the columns of your raw source. Otherwise, you need to manually map columns. Check related documentation for more Then simply evaluate them exactly in the same way as shown before! import clayrs.evaluation as eva em = eva . EvalModel ( pred_list = imported_ranks , truth_list = imported_truths , metric_list = [ # ... Choose your own metrics ] ) sys_results_df , users_results_df = em . fit ()","title":"Evaluating external recommendation lists"},{"location":"evaluation/introduction/#perform-a-statistical-test","text":"ClayRS lets you also compare different learning schemas by performing statistical tests: Simply instantiate the desired test and call its perform () method. The parameter it expects is the list of user_results dataframe obtained in the evaluation step, one for each learning schema to compare. ttest = eva . Ttest () all_comb_df = ttest . perform ([ user_result1 , user_result2 , user_result3 ]) Info In this case since the Ttest it's a paired test, the final result is a pandas DataFrame which contains learning schemas compared in pair: (system1, system2) (system1, system3) (system2, system3)","title":"Perform a statistical test"},{"location":"evaluation/metrics/classification_metrics/","text":"Classification metrics A classification metric uses confusion matrix terminology (true positive, false positive, true negative, false negative) to classify each item predicted, and in general it needs a way to discern relevant items from non-relevant items for users FMeasure ( beta = 1 , relevant_threshold = None , sys_average = 'macro' , precision = np . float64 ) Bases: ClassificationMetric The FMeasure metric combines Precision and Recall into a single metric. It is calculated as such for the single user : \\[ FMeasure_u = (1 + \\beta^2) \\cdot \\frac{P_u \\cdot R_u}{(\\beta^2 \\cdot P_u) + R_u} \\] Where: \\(P_u\\) is the Precision calculated for the user u \\(R_u\\) is the Recall calculated for the user u \\(\\beta\\) is a real factor which could weight differently Recall or Precision based on its value: \\(\\beta = 1\\) : Equally weight Precision and Recall \\(\\beta > 1\\) : Weight Recall more \\(\\beta < 1\\) : Weight Precision more A famous FMeasure is the F1 Metric, where \\(\\beta = 1\\) , which basically is the harmonic mean of recall and precision: \\[ F1_u = \\frac{2 \\cdot P_u \\cdot R_u}{P_u + R_u} \\] The FMeasure metric is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ FMeasure_{sys} - micro = (1 + \\beta^2) \\cdot \\frac{P_u \\cdot R_u}{(\\beta^2 \\cdot P_u) + R_u} \\] \\[ FMeasure_{sys} - macro = \\frac{\\sum_{u \\in U} FMeasure_u}{|U|} \\] PARAMETER DESCRIPTION beta real factor which could weight differently Recall or Precision based on its value. Default is 1 TYPE: float DEFAULT: 1 relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 463 464 465 466 def __init__ ( self , beta : float = 1 , relevant_threshold : float = None , sys_average : str = 'macro' , precision : [ Callable ] = np . float64 ): super () . __init__ ( relevant_threshold , sys_average , precision ) self . __beta = beta FMeasureAtK ( k , beta = 1 , relevant_threshold = None , sys_average = 'macro' ) Bases: FMeasure The FMeasure@K metric combines Precision@K and Recall@K into a single metric. It is calculated as such for the single user : \\[ FMeasure@K_u = (1 + \\beta^2) \\cdot \\frac{P@K_u \\cdot R@K_u}{(\\beta^2 \\cdot P@K_u) + R@K_u} \\] Where: \\(P@K_u\\) is the Precision at K calculated for the user u \\(R@K_u\\) is the Recall at K calculated for the user u \\(\\beta\\) is a real factor which could weight differently Recall or Precision based on its value: \\(\\beta = 1\\) : Equally weight Precision and Recall \\(\\beta > 1\\) : Weight Recall more \\(\\beta < 1\\) : Weight Precision more A famous FMeasure@K is the F1@K Metric, where :math: \\beta = 1 , which basically is the harmonic mean of recall and precision: \\[ F1@K_u = \\frac{2 \\cdot P@K_u \\cdot R@K_u}{P@K_u + R@K_u} \\] The FMeasure@K metric is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ FMeasure@K_{sys} - micro = (1 + \\beta^2) \\cdot \\frac{P@K_u \\cdot R@K_u}{(\\beta^2 \\cdot P@K_u) + R@K_u} \\] \\[ FMeasure@K_{sys} - macro = \\frac{\\sum_{u \\in U} FMeasure@K_u}{|U|} \\] PARAMETER DESCRIPTION k cutoff parameter. Will be used for the computation of Precision@K and Recall@K TYPE: int beta real factor which could weight differently Recall or Precision based on its value. Default is 1 TYPE: float DEFAULT: 1 relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 549 550 551 552 553 def __init__ ( self , k : int , beta : int = 1 , relevant_threshold : float = None , sys_average : str = 'macro' ): super () . __init__ ( beta , relevant_threshold , sys_average ) if k < 1 : raise ValueError ( 'k= {} not valid! k must be >= 1!' . format ( k )) self . __k = k Precision ( relevant_threshold = None , sys_average = 'macro' , precision = np . float64 ) Bases: ClassificationMetric The Precision metric is calculated as such for the single user : \\[ Precision_u = \\frac{tp_u}{tp_u + fp_u} \\] Where: \\(tp_u\\) is the number of items which are in the recommendation list of the user and have a rating >= relevant_threshold in its 'ground truth' \\(fp_u\\) is the number of items which are in the recommendation list of the user and have a rating < relevant_threshold in its 'ground truth' And it is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ Precision_{sys} - micro = \\frac{\\sum_{u \\in U} tp_u}{\\sum_{u \\in U} tp_u + \\sum_{u \\in U} fp_u} \\] \\[ Precision_{sys} - macro = \\frac{\\sum_{u \\in U} Precision_u}{|U|} \\] PARAMETER DESCRIPTION relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 147 148 149 def __init__ ( self , relevant_threshold : float = None , sys_average : str = 'macro' , precision : [ Callable ] = np . float64 ): super ( Precision , self ) . __init__ ( relevant_threshold , sys_average , precision ) PrecisionAtK ( k , relevant_threshold = None , sys_average = 'macro' , precision = np . float64 ) Bases: Precision The Precision@K metric is calculated as such for the single user : \\[ Precision@K_u = \\frac{tp@K_u}{tp@K_u + fp@K_u} \\] Where: \\(tp@K_u\\) is the number of items which are in the recommendation list of the user cutoff to the first K items and have a rating >= relevant_threshold in its 'ground truth' \\(tp@K_u\\) is the number of items which are in the recommendation list of the user cutoff to the first K items and have a rating < relevant_threshold in its 'ground truth' And it is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ Precision@K_{sys} - micro = \\frac{\\sum_{u \\in U} tp@K_u}{\\sum_{u \\in U} tp@K_u + \\sum_{u \\in U} fp@K_u} \\] \\[ Precision@K_{sys} - macro = \\frac{\\sum_{u \\in U} Precision@K_u}{|U|} \\] PARAMETER DESCRIPTION k cutoff parameter. Only the first k items of the recommendation list will be considered TYPE: int relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 208 209 210 211 212 213 def __init__ ( self , k : int , relevant_threshold : float = None , sys_average : str = 'macro' , precision : [ Callable ] = np . float64 ): super () . __init__ ( relevant_threshold , sys_average , precision ) if k < 1 : raise ValueError ( 'k= {} not valid! k must be >= 1!' . format ( k )) self . __k = k RPrecision ( relevant_threshold = None , sys_average = 'macro' , precision = np . float64 ) Bases: Precision The R-Precision metric is calculated as such for the single user : \\[ R-Precision_u = \\frac{tp@R_u}{tp@R_u + fp@R_u} \\] Where: \\(R\\) it's the number of relevant items for the user u \\(tp@R_u\\) is the number of items which are in the recommendation list of the user cutoff to the first R items and have a rating >= relevant_threshold in its 'ground truth' \\(tp@R_u\\) is the number of items which are in the recommendation list of the user cutoff to the first R items and have a rating < relevant_threshold in its 'ground truth' And it is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ Precision@R_{sys} - micro = \\frac{\\sum_{u \\in U} tp@R_u}{\\sum_{u \\in U} tp@R_u + \\sum_{u \\in U} fp@R_u} \\] \\[ Precision@R_{sys} - macro = \\frac{\\sum_{u \\in U} R-Precision_u}{|U|} \\] PARAMETER DESCRIPTION relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 271 272 273 def __init__ ( self , relevant_threshold : float = None , sys_average : str = 'macro' , precision : [ Callable ] = np . float64 ): super () . __init__ ( relevant_threshold , sys_average , precision ) Recall ( relevant_threshold = None , sys_average = 'macro' , precision = np . float64 ) Bases: ClassificationMetric The Recall metric is calculated as such for the single user : \\[ Recall_u = \\frac{tp_u}{tp_u + fn_u} \\] Where: \\(tp_u\\) is the number of items which are in the recommendation list of the user and have a rating >= relevant_threshold in its 'ground truth' \\(fn_u\\) is the number of items which are NOT in the recommendation list of the user and have a rating >= relevant_threshold in its 'ground truth' And it is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ Recall_{sys} - micro = \\frac{\\sum_{u \\in U} tp_u}{\\sum_{u \\in U} tp_u + \\sum_{u \\in U} fn_u} \\] \\[ Recall_{sys} - macro = \\frac{\\sum_{u \\in U} Recall_u}{|U|} \\] PARAMETER DESCRIPTION relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 328 329 330 def __init__ ( self , relevant_threshold : float = None , sys_average : str = 'macro' , precision : [ Callable ] = np . float64 ): super () . __init__ ( relevant_threshold , sys_average , precision ) RecallAtK ( k , relevant_threshold = None , sys_average = 'macro' , precision = np . float64 ) Bases: Recall The Recall@K metric is calculated as such for the single user : \\[ Recall@K_u = \\frac{tp@K_u}{tp@K_u + fn@K_u} \\] Where: \\(tp@K_u\\) is the number of items which are in the recommendation list of the user cutoff to the first K items and have a rating >= relevant_threshold in its 'ground truth' \\(tp@K_u\\) is the number of items which are NOT in the recommendation list of the user cutoff to the first K items and have a rating >= relevant_threshold in its 'ground truth' And it is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ Recall@K_{sys} - micro = \\frac{\\sum_{u \\in U} tp@K_u}{\\sum_{u \\in U} tp@K_u + \\sum_{u \\in U} fn@K_u} \\] \\[ Recall@K_{sys} - macro = \\frac{\\sum_{u \\in U} Recall@K_u}{|U|} \\] PARAMETER DESCRIPTION k cutoff parameter. Only the first k items of the recommendation list will be considered TYPE: int relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 388 389 390 391 392 393 def __init__ ( self , k : int , relevant_threshold : float = None , sys_average : str = 'macro' , precision : [ Callable ] = np . float64 ): super () . __init__ ( relevant_threshold , sys_average , precision ) if k < 1 : raise ValueError ( 'k= {} not valid! k must be >= 1!' . format ( k )) self . __k = k","title":"Classification metrics"},{"location":"evaluation/metrics/classification_metrics/#classification-metrics","text":"A classification metric uses confusion matrix terminology (true positive, false positive, true negative, false negative) to classify each item predicted, and in general it needs a way to discern relevant items from non-relevant items for users","title":"Classification metrics"},{"location":"evaluation/metrics/classification_metrics/#clayrs.evaluation.metrics.classification_metrics.FMeasure","text":"Bases: ClassificationMetric The FMeasure metric combines Precision and Recall into a single metric. It is calculated as such for the single user : \\[ FMeasure_u = (1 + \\beta^2) \\cdot \\frac{P_u \\cdot R_u}{(\\beta^2 \\cdot P_u) + R_u} \\] Where: \\(P_u\\) is the Precision calculated for the user u \\(R_u\\) is the Recall calculated for the user u \\(\\beta\\) is a real factor which could weight differently Recall or Precision based on its value: \\(\\beta = 1\\) : Equally weight Precision and Recall \\(\\beta > 1\\) : Weight Recall more \\(\\beta < 1\\) : Weight Precision more A famous FMeasure is the F1 Metric, where \\(\\beta = 1\\) , which basically is the harmonic mean of recall and precision: \\[ F1_u = \\frac{2 \\cdot P_u \\cdot R_u}{P_u + R_u} \\] The FMeasure metric is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ FMeasure_{sys} - micro = (1 + \\beta^2) \\cdot \\frac{P_u \\cdot R_u}{(\\beta^2 \\cdot P_u) + R_u} \\] \\[ FMeasure_{sys} - macro = \\frac{\\sum_{u \\in U} FMeasure_u}{|U|} \\] PARAMETER DESCRIPTION beta real factor which could weight differently Recall or Precision based on its value. Default is 1 TYPE: float DEFAULT: 1 relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 463 464 465 466 def __init__ ( self , beta : float = 1 , relevant_threshold : float = None , sys_average : str = 'macro' , precision : [ Callable ] = np . float64 ): super () . __init__ ( relevant_threshold , sys_average , precision ) self . __beta = beta","title":"FMeasure"},{"location":"evaluation/metrics/classification_metrics/#clayrs.evaluation.metrics.classification_metrics.FMeasureAtK","text":"Bases: FMeasure The FMeasure@K metric combines Precision@K and Recall@K into a single metric. It is calculated as such for the single user : \\[ FMeasure@K_u = (1 + \\beta^2) \\cdot \\frac{P@K_u \\cdot R@K_u}{(\\beta^2 \\cdot P@K_u) + R@K_u} \\] Where: \\(P@K_u\\) is the Precision at K calculated for the user u \\(R@K_u\\) is the Recall at K calculated for the user u \\(\\beta\\) is a real factor which could weight differently Recall or Precision based on its value: \\(\\beta = 1\\) : Equally weight Precision and Recall \\(\\beta > 1\\) : Weight Recall more \\(\\beta < 1\\) : Weight Precision more A famous FMeasure@K is the F1@K Metric, where :math: \\beta = 1 , which basically is the harmonic mean of recall and precision: \\[ F1@K_u = \\frac{2 \\cdot P@K_u \\cdot R@K_u}{P@K_u + R@K_u} \\] The FMeasure@K metric is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ FMeasure@K_{sys} - micro = (1 + \\beta^2) \\cdot \\frac{P@K_u \\cdot R@K_u}{(\\beta^2 \\cdot P@K_u) + R@K_u} \\] \\[ FMeasure@K_{sys} - macro = \\frac{\\sum_{u \\in U} FMeasure@K_u}{|U|} \\] PARAMETER DESCRIPTION k cutoff parameter. Will be used for the computation of Precision@K and Recall@K TYPE: int beta real factor which could weight differently Recall or Precision based on its value. Default is 1 TYPE: float DEFAULT: 1 relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 549 550 551 552 553 def __init__ ( self , k : int , beta : int = 1 , relevant_threshold : float = None , sys_average : str = 'macro' ): super () . __init__ ( beta , relevant_threshold , sys_average ) if k < 1 : raise ValueError ( 'k= {} not valid! k must be >= 1!' . format ( k )) self . __k = k","title":"FMeasureAtK"},{"location":"evaluation/metrics/classification_metrics/#clayrs.evaluation.metrics.classification_metrics.Precision","text":"Bases: ClassificationMetric The Precision metric is calculated as such for the single user : \\[ Precision_u = \\frac{tp_u}{tp_u + fp_u} \\] Where: \\(tp_u\\) is the number of items which are in the recommendation list of the user and have a rating >= relevant_threshold in its 'ground truth' \\(fp_u\\) is the number of items which are in the recommendation list of the user and have a rating < relevant_threshold in its 'ground truth' And it is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ Precision_{sys} - micro = \\frac{\\sum_{u \\in U} tp_u}{\\sum_{u \\in U} tp_u + \\sum_{u \\in U} fp_u} \\] \\[ Precision_{sys} - macro = \\frac{\\sum_{u \\in U} Precision_u}{|U|} \\] PARAMETER DESCRIPTION relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 147 148 149 def __init__ ( self , relevant_threshold : float = None , sys_average : str = 'macro' , precision : [ Callable ] = np . float64 ): super ( Precision , self ) . __init__ ( relevant_threshold , sys_average , precision )","title":"Precision"},{"location":"evaluation/metrics/classification_metrics/#clayrs.evaluation.metrics.classification_metrics.PrecisionAtK","text":"Bases: Precision The Precision@K metric is calculated as such for the single user : \\[ Precision@K_u = \\frac{tp@K_u}{tp@K_u + fp@K_u} \\] Where: \\(tp@K_u\\) is the number of items which are in the recommendation list of the user cutoff to the first K items and have a rating >= relevant_threshold in its 'ground truth' \\(tp@K_u\\) is the number of items which are in the recommendation list of the user cutoff to the first K items and have a rating < relevant_threshold in its 'ground truth' And it is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ Precision@K_{sys} - micro = \\frac{\\sum_{u \\in U} tp@K_u}{\\sum_{u \\in U} tp@K_u + \\sum_{u \\in U} fp@K_u} \\] \\[ Precision@K_{sys} - macro = \\frac{\\sum_{u \\in U} Precision@K_u}{|U|} \\] PARAMETER DESCRIPTION k cutoff parameter. Only the first k items of the recommendation list will be considered TYPE: int relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 208 209 210 211 212 213 def __init__ ( self , k : int , relevant_threshold : float = None , sys_average : str = 'macro' , precision : [ Callable ] = np . float64 ): super () . __init__ ( relevant_threshold , sys_average , precision ) if k < 1 : raise ValueError ( 'k= {} not valid! k must be >= 1!' . format ( k )) self . __k = k","title":"PrecisionAtK"},{"location":"evaluation/metrics/classification_metrics/#clayrs.evaluation.metrics.classification_metrics.RPrecision","text":"Bases: Precision The R-Precision metric is calculated as such for the single user : \\[ R-Precision_u = \\frac{tp@R_u}{tp@R_u + fp@R_u} \\] Where: \\(R\\) it's the number of relevant items for the user u \\(tp@R_u\\) is the number of items which are in the recommendation list of the user cutoff to the first R items and have a rating >= relevant_threshold in its 'ground truth' \\(tp@R_u\\) is the number of items which are in the recommendation list of the user cutoff to the first R items and have a rating < relevant_threshold in its 'ground truth' And it is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ Precision@R_{sys} - micro = \\frac{\\sum_{u \\in U} tp@R_u}{\\sum_{u \\in U} tp@R_u + \\sum_{u \\in U} fp@R_u} \\] \\[ Precision@R_{sys} - macro = \\frac{\\sum_{u \\in U} R-Precision_u}{|U|} \\] PARAMETER DESCRIPTION relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 271 272 273 def __init__ ( self , relevant_threshold : float = None , sys_average : str = 'macro' , precision : [ Callable ] = np . float64 ): super () . __init__ ( relevant_threshold , sys_average , precision )","title":"RPrecision"},{"location":"evaluation/metrics/classification_metrics/#clayrs.evaluation.metrics.classification_metrics.Recall","text":"Bases: ClassificationMetric The Recall metric is calculated as such for the single user : \\[ Recall_u = \\frac{tp_u}{tp_u + fn_u} \\] Where: \\(tp_u\\) is the number of items which are in the recommendation list of the user and have a rating >= relevant_threshold in its 'ground truth' \\(fn_u\\) is the number of items which are NOT in the recommendation list of the user and have a rating >= relevant_threshold in its 'ground truth' And it is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ Recall_{sys} - micro = \\frac{\\sum_{u \\in U} tp_u}{\\sum_{u \\in U} tp_u + \\sum_{u \\in U} fn_u} \\] \\[ Recall_{sys} - macro = \\frac{\\sum_{u \\in U} Recall_u}{|U|} \\] PARAMETER DESCRIPTION relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 328 329 330 def __init__ ( self , relevant_threshold : float = None , sys_average : str = 'macro' , precision : [ Callable ] = np . float64 ): super () . __init__ ( relevant_threshold , sys_average , precision )","title":"Recall"},{"location":"evaluation/metrics/classification_metrics/#clayrs.evaluation.metrics.classification_metrics.RecallAtK","text":"Bases: Recall The Recall@K metric is calculated as such for the single user : \\[ Recall@K_u = \\frac{tp@K_u}{tp@K_u + fn@K_u} \\] Where: \\(tp@K_u\\) is the number of items which are in the recommendation list of the user cutoff to the first K items and have a rating >= relevant_threshold in its 'ground truth' \\(tp@K_u\\) is the number of items which are NOT in the recommendation list of the user cutoff to the first K items and have a rating >= relevant_threshold in its 'ground truth' And it is calculated as such for the entire system , depending if 'macro' average or 'micro' average has been chosen: \\[ Recall@K_{sys} - micro = \\frac{\\sum_{u \\in U} tp@K_u}{\\sum_{u \\in U} tp@K_u + \\sum_{u \\in U} fn@K_u} \\] \\[ Recall@K_{sys} - macro = \\frac{\\sum_{u \\in U} Recall@K_u}{|U|} \\] PARAMETER DESCRIPTION k cutoff parameter. Only the first k items of the recommendation list will be considered TYPE: int relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None sys_average specify how the system average must be computed. Default is 'macro' TYPE: str DEFAULT: 'macro' Source code in clayrs/evaluation/metrics/classification_metrics.py 388 389 390 391 392 393 def __init__ ( self , k : int , relevant_threshold : float = None , sys_average : str = 'macro' , precision : [ Callable ] = np . float64 ): super () . __init__ ( relevant_threshold , sys_average , precision ) if k < 1 : raise ValueError ( 'k= {} not valid! k must be >= 1!' . format ( k )) self . __k = k","title":"RecallAtK"},{"location":"evaluation/metrics/error_metrics/","text":"Error metrics Error metrics evaluate 'how wrong' the recommender system was in predicting a rating MAE Bases: ErrorMetric The MAE (Mean Absolute Error) metric is calculated as such for the single user : \\[ MAE_u = \\sum_{i \\in T_u} \\frac{|r_{u,i} - \\hat{r}_{u,i}|}{|T_u|} \\] Where: \\(T_u\\) is the test set of the user \\(u\\) \\(r_{u, i}\\) is the actual score give by user \\(u\\) to item \\(i\\) \\(\\hat{r}_{u, i}\\) is the predicted score give by user \\(u\\) to item \\(i\\) And it is calculated as such for the entire system : \\[ MAE_{sys} = \\sum_{u \\in T} \\frac{MAE_u}{|T|} \\] Where: \\(T\\) is the test set \\(MAE_u\\) is the MAE calculated for user \\(u\\) There may be cases in which some items of the test set of the user could not be predicted (eg. A CBRS was chosen and items were not present locally, a methodology different than TestRatings was chosen). In those cases the \\(MAE_u\\) formula becomes \\[ MAE_u = \\sum_{i \\in T_u} \\frac{|r_{u,i} - \\hat{r}_{u,i}|}{|T_u| - unk} \\] Where: \\(unk\\) ( unknown ) is the number of items of the user test set that could not be predicted If no items of the user test set has been predicted ( \\(|T_u| - unk = 0\\) ), then: \\[ MAE_u = NaN \\] MSE Bases: ErrorMetric The MSE (Mean Squared Error) metric is calculated as such for the single user : \\[ MSE_u = \\sum_{i \\in T_u} \\frac{(r_{u,i} - \\hat{r}_{u,i})^2}{|T_u|} \\] Where: \\(T_u\\) is the test set of the user \\(u\\) \\(r_{u, i}\\) is the actual score give by user \\(u\\) to item \\(i\\) \\(\\hat{r}_{u, i}\\) is the predicted score give by user \\(u\\) to item \\(i\\) And it is calculated as such for the entire system : $$ MSE_{sys} = \\sum_{u \\in T} \\frac{MSE_u}{|T|} $$ Where: \\(T\\) is the test set \\(MSE_u\\) is the MSE calculated for user \\(u\\) There may be cases in which some items of the test set of the user could not be predicted (eg. A CBRS was chosen and items were not present locally) In those cases the \\(MSE_u\\) formula becomes \\[ MSE_u = \\sum_{i \\in T_u} \\frac{(r_{u,i} - \\hat{r}_{u,i})^2}{|T_u| - unk} \\] Where: \\(unk\\) ( unknown ) is the number of items of the user test set that could not be predicted If no items of the user test set has been predicted ( \\(|T_u| - unk = 0\\) ), then: \\[ MSE_u = NaN \\] RMSE Bases: ErrorMetric The RMSE (Root Mean Squared Error) metric is calculated as such for the single user : \\[ RMSE_u = \\sqrt{\\sum_{i \\in T_u} \\frac{(r_{u,i} - \\hat{r}_{u,i})^2}{|T_u|}} \\] Where: \\(T_u\\) is the test set of the user \\(u\\) \\(r_{u, i}\\) is the actual score give by user \\(u\\) to item \\(i\\) \\(\\hat{r}_{u, i}\\) is the predicted score give by user \\(u\\) to item \\(i\\) And it is calculated as such for the entire system : \\[ RMSE_{sys} = \\sum_{u \\in T} \\frac{RMSE_u}{|T|} \\] Where: \\(T\\) is the test set \\(RMSE_u\\) is the RMSE calculated for user \\(u\\) There may be cases in which some items of the test set of the user could not be predicted (eg. A CBRS was chosen and items were not present locally, a methodology different than TestRatings was chosen). In those cases the \\(RMSE_u\\) formula becomes \\[ RMSE_u = \\sqrt{\\sum_{i \\in T_u} \\frac{(r_{u,i} - \\hat{r}_{u,i})^2}{|T_u| - unk}} \\] Where: \\(unk\\) ( unknown ) is the number of items of the user test set that could not be predicted If no items of the user test set has been predicted ( \\(|T_u| - unk = 0\\) ), then: \\[ RMSE_u = NaN \\]","title":"Error metrics"},{"location":"evaluation/metrics/error_metrics/#error-metrics","text":"Error metrics evaluate 'how wrong' the recommender system was in predicting a rating","title":"Error metrics"},{"location":"evaluation/metrics/error_metrics/#clayrs.evaluation.metrics.error_metrics.MAE","text":"Bases: ErrorMetric The MAE (Mean Absolute Error) metric is calculated as such for the single user : \\[ MAE_u = \\sum_{i \\in T_u} \\frac{|r_{u,i} - \\hat{r}_{u,i}|}{|T_u|} \\] Where: \\(T_u\\) is the test set of the user \\(u\\) \\(r_{u, i}\\) is the actual score give by user \\(u\\) to item \\(i\\) \\(\\hat{r}_{u, i}\\) is the predicted score give by user \\(u\\) to item \\(i\\) And it is calculated as such for the entire system : \\[ MAE_{sys} = \\sum_{u \\in T} \\frac{MAE_u}{|T|} \\] Where: \\(T\\) is the test set \\(MAE_u\\) is the MAE calculated for user \\(u\\) There may be cases in which some items of the test set of the user could not be predicted (eg. A CBRS was chosen and items were not present locally, a methodology different than TestRatings was chosen). In those cases the \\(MAE_u\\) formula becomes \\[ MAE_u = \\sum_{i \\in T_u} \\frac{|r_{u,i} - \\hat{r}_{u,i}|}{|T_u| - unk} \\] Where: \\(unk\\) ( unknown ) is the number of items of the user test set that could not be predicted If no items of the user test set has been predicted ( \\(|T_u| - unk = 0\\) ), then: \\[ MAE_u = NaN \\]","title":"MAE"},{"location":"evaluation/metrics/error_metrics/#clayrs.evaluation.metrics.error_metrics.MSE","text":"Bases: ErrorMetric The MSE (Mean Squared Error) metric is calculated as such for the single user : \\[ MSE_u = \\sum_{i \\in T_u} \\frac{(r_{u,i} - \\hat{r}_{u,i})^2}{|T_u|} \\] Where: \\(T_u\\) is the test set of the user \\(u\\) \\(r_{u, i}\\) is the actual score give by user \\(u\\) to item \\(i\\) \\(\\hat{r}_{u, i}\\) is the predicted score give by user \\(u\\) to item \\(i\\) And it is calculated as such for the entire system : $$ MSE_{sys} = \\sum_{u \\in T} \\frac{MSE_u}{|T|} $$ Where: \\(T\\) is the test set \\(MSE_u\\) is the MSE calculated for user \\(u\\) There may be cases in which some items of the test set of the user could not be predicted (eg. A CBRS was chosen and items were not present locally) In those cases the \\(MSE_u\\) formula becomes \\[ MSE_u = \\sum_{i \\in T_u} \\frac{(r_{u,i} - \\hat{r}_{u,i})^2}{|T_u| - unk} \\] Where: \\(unk\\) ( unknown ) is the number of items of the user test set that could not be predicted If no items of the user test set has been predicted ( \\(|T_u| - unk = 0\\) ), then: \\[ MSE_u = NaN \\]","title":"MSE"},{"location":"evaluation/metrics/error_metrics/#clayrs.evaluation.metrics.error_metrics.RMSE","text":"Bases: ErrorMetric The RMSE (Root Mean Squared Error) metric is calculated as such for the single user : \\[ RMSE_u = \\sqrt{\\sum_{i \\in T_u} \\frac{(r_{u,i} - \\hat{r}_{u,i})^2}{|T_u|}} \\] Where: \\(T_u\\) is the test set of the user \\(u\\) \\(r_{u, i}\\) is the actual score give by user \\(u\\) to item \\(i\\) \\(\\hat{r}_{u, i}\\) is the predicted score give by user \\(u\\) to item \\(i\\) And it is calculated as such for the entire system : \\[ RMSE_{sys} = \\sum_{u \\in T} \\frac{RMSE_u}{|T|} \\] Where: \\(T\\) is the test set \\(RMSE_u\\) is the RMSE calculated for user \\(u\\) There may be cases in which some items of the test set of the user could not be predicted (eg. A CBRS was chosen and items were not present locally, a methodology different than TestRatings was chosen). In those cases the \\(RMSE_u\\) formula becomes \\[ RMSE_u = \\sqrt{\\sum_{i \\in T_u} \\frac{(r_{u,i} - \\hat{r}_{u,i})^2}{|T_u| - unk}} \\] Where: \\(unk\\) ( unknown ) is the number of items of the user test set that could not be predicted If no items of the user test set has been predicted ( \\(|T_u| - unk = 0\\) ), then: \\[ RMSE_u = NaN \\]","title":"RMSE"},{"location":"evaluation/metrics/fairness_metrics/","text":"Fairness metrics Fairness metrics evaluate how unbiased the recommendation lists are (e.g. unbiased towards popularity of the items) CatalogCoverage ( catalog , top_n = None , k = None ) Bases: PredictionCoverage The Catalog Coverage metric measures in percentage how many distinct items are being recommended in relation to all available items. It's a system wide metric, so only its result it will be returned and not those of every user. It differs from the Prediction Coverage since it allows for different parameters to come into play. If no parameter is passed then it's a simple Prediction Coverage. The metric is calculated as such: \\[ Catalog Coverage_{sys} = (\\frac{|\\bigcup_{j=1...N}reclist(u_j)|}{|I|})\\cdot100 \\] Where: \\(N\\) is the total number of users \\(reclist(u_j)\\) is the set of items contained in the recommendation list of user \\(j\\) \\(I\\) is the set of all available items The \\(I\\) must be specified through the 'catalog' parameter The recommendation list of every user ( \\(reclist(u_j)\\) ) can be reduced to the first n parameter with the top-n parameter, so that catalog coverage is measured considering only the most highest ranked items. With the 'k' parameter one could specify the number of users that will be used to calculate catalog coverage: k users will be randomly sampled and their recommendation lists will be used. The formula above becomes: \\[ Catalog Coverage_{sys} = (\\frac{|\\bigcup_{j=1...k}reclist(u_j)|}{|I|})\\cdot100 \\] Where: \\(k\\) is the parameter specified Obviously 'k' < N, else simply recommendation lists of all users will be used Check the 'Beyond Accuracy: Evaluating Recommender Systems by Coverage and Serendipity' paper and page 13 of the 'Comparison of group recommendation algorithms' paper for more PARAMETER DESCRIPTION catalog set of item id of the catalog on which the prediction coverage must be computed TYPE: Set [ str ] top_n it's a cutoff parameter, if specified the Catalog Coverage will be calculated considering only the first 'n' items of every recommendation list of all users. Default is None TYPE: int DEFAULT: None k number of users randomly sampled. If specified, k users will be randomly sampled across all users and only their recommendation lists will be used to compute the CatalogCoverage TYPE: int DEFAULT: None Source code in clayrs/evaluation/metrics/fairness_metrics.py 347 348 349 350 def __init__ ( self , catalog : Set [ str ], top_n : int = None , k : int = None ): super () . __init__ ( catalog ) self . __top_n = top_n self . __k = k DeltaGap ( user_groups , user_profiles , original_ratings , top_n = None , pop_percentage = 0.2 ) Bases: GroupFairnessMetric The Delta GAP (Group Average popularity) metric lets you compare the average popularity \"requested\" by one or multiple groups of users and the average popularity \"obtained\" with the recommendation given by the recsys. It's a system wide metric and results of every group will be returned. It is calculated as such: \\[ \\Delta GAP = \\frac{recs_GAP - profile_GAP}{profile_GAP} \\] Users are split into groups based on the user_groups parameter, which contains names of the groups as keys, and percentage of how many user must contain a group as values. For example: user_groups = {'popular_users': 0.3, 'medium_popular_users': 0.2, 'low_popular_users': 0.5} Every user will be inserted in a group based on how many popular items the user has rated (in relation to the percentage of users we specified as value in the dictionary): users with many popular items will be inserted into the first group users with niche items rated will be inserted into one of the last groups. In general users are grouped by \\(Popularity\\_ratio\\) in a descending order. \\(Popularity\\_ratio\\) for a single user \\(u\\) is defined as: \\[ Popularity\\_ratio_u = n\\_most\\_popular\\_items\\_rated_u / n\\_items\\_rated_u \\] The most popular items are the first pop_percentage % items of all items ordered in a descending order by popularity. The popularity of an item is defined as the number of times it is rated in the original_ratings parameter divided by the total number of users in the original_ratings . It can happen that for a particular user of a group no recommendation are available: in that case it will be skipped and it won't be considered in the \\(\\Delta GAP\\) computation of its group. In case no user of a group has recs available, a warning will be printed and the whole group won't be considered. If the 'top_n' parameter is specified, then the \\(\\Delta GAP\\) will be calculated considering only the first n items of every recommendation list of all users PARAMETER DESCRIPTION user_groups Dict containing group names as keys and percentage of users as value, used to split users in groups. Users with more popular items rated are grouped into the first group, users with slightly less popular items rated are grouped into the second one, etc. TYPE: Dict [ str , float ] user_profiles one or more Ratings objects containing interactions of the profile of each user (e.g. the train set ). It should be one for each split to evaluate! TYPE: Union [ list , Ratings ] original_ratings Ratings object containing original interactions of the dataset that will be used to compute the popularity of each item (i.e. the number of times it is rated divided by the total number of users) TYPE: Ratings top_n it's a cutoff parameter, if specified the Gini index will be calculated considering only their first 'n' items of every recommendation list of all users. Default is None TYPE: int DEFAULT: None pop_percentage How many (in percentage) most popular items must be considered. Default is 0.2 TYPE: float DEFAULT: 0.2 Source code in clayrs/evaluation/metrics/fairness_metrics.py 449 450 451 452 453 454 455 456 457 458 459 460 461 def __init__ ( self , user_groups : Dict [ str , float ], user_profiles : Union [ list , Ratings ], original_ratings : Ratings , top_n : int = None , pop_percentage : float = 0.2 ): if not 0 < pop_percentage <= 1 : raise ValueError ( 'Incorrect percentage! Valid percentage range: 0 < percentage <= 1' ) super () . __init__ ( user_groups ) self . _pop_by_item = get_item_popularity ( original_ratings ) if not isinstance ( user_profiles , list ): user_profiles = [ user_profiles ] self . _user_profiles = user_profiles self . __top_n = top_n self . _pop_percentage = pop_percentage calculate_delta_gap ( recs_gap , profile_gap ) staticmethod Compute the ratio between the recommendation gap and the user profiles gap PARAMETER DESCRIPTION recs_gap recommendation gap TYPE: float profile_gap user profiles gap TYPE: float RETURNS DESCRIPTION score delta gap measure TYPE: float Source code in clayrs/evaluation/metrics/fairness_metrics.py 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 @staticmethod def calculate_delta_gap ( recs_gap : float , profile_gap : float ) -> float : \"\"\" Compute the ratio between the recommendation gap and the user profiles gap Args: recs_gap: recommendation gap profile_gap: user profiles gap Returns: score: delta gap measure \"\"\" result = 0 if profile_gap != 0.0 : result = ( recs_gap - profile_gap ) / profile_gap return result calculate_gap ( group , avg_pop_by_users ) staticmethod Compute the GAP (Group Average Popularity) formula \\[ GAP = \\frac{\\sum_{u \\in U}\\cdot \\frac{\\sum_{i \\in i_u} pop_i}{|i_u|}}{|G|} \\] Where: \\(G\\) is the set of users \\(i_u\\) is the set of items rated/recommended by/to user \\(u\\) \\(pop_i\\) is the popularity of item i PARAMETER DESCRIPTION group the set of users (user_id) TYPE: Set [ str ] avg_pop_by_users average popularity by user TYPE: Dict [ str , object ] RETURNS DESCRIPTION score gap score TYPE: float Source code in clayrs/evaluation/metrics/fairness_metrics.py 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 @staticmethod def calculate_gap ( group : Set [ str ], avg_pop_by_users : Dict [ str , object ]) -> float : r \"\"\" Compute the GAP (Group Average Popularity) formula $$ GAP = \\frac{\\sum_{u \\in U}\\cdot \\frac{\\sum_{i \\in i_u} pop_i}{|i_u|}}{|G|} $$ Where: - $G$ is the set of users - $i_u$ is the set of items rated/recommended by/to user $u$ - $pop_i$ is the popularity of item i Args: group: the set of users (user_id) avg_pop_by_users: average popularity by user Returns: score (float): gap score \"\"\" total_pop = 0 for user in group : if avg_pop_by_users . get ( user ): total_pop += avg_pop_by_users [ user ] return total_pop / len ( group ) GiniIndex ( top_n = None ) Bases: FairnessMetric The Gini Index metric measures inequality in recommendation lists. It's a system wide metric, so only its result it will be returned and not those of every user. The metric is calculated as such: \\[ Gini_{sys} = \\frac{\\sum_i(2i - n - 1)x_i}{n\\cdot\\sum_i x_i} \\] Where: \\(n\\) is the total number of distinct items that are being recommended \\(x_i\\) is the number of times that the item \\(i\\) has been recommended A perfectly equal recommender system should recommend every item the same number of times, in which case the Gini index would be equal to 0. The more the recsys is \"disegual\", the more the Gini Index is closer to 1 If the 'top_n' parameter is specified, then the Gini index will measure inequality considering only the first n items of every recommendation list of all users PARAMETER DESCRIPTION top_n it's a cutoff parameter, if specified the Gini index will be calculated considering only the first 'n' items of every recommendation list of all users. Default is None TYPE: int DEFAULT: None Source code in clayrs/evaluation/metrics/fairness_metrics.py 184 185 def __init__ ( self , top_n : int = None ): self . __top_n = top_n GroupFairnessMetric ( user_groups ) Bases: FairnessMetric Abstract class for fairness metrics based on user groups It has some concrete methods useful for group divisions, since every subclass needs to split users into groups. PARAMETER DESCRIPTION user_groups Dict containing group names as keys and percentage of users as value, used to split users in groups. Users with more popular items rated are grouped into the first group, users with slightly less popular items rated are grouped into the second one, etc. TYPE: Dict [ str , float ] Source code in clayrs/evaluation/metrics/fairness_metrics.py 43 44 def __init__ ( self , user_groups : Dict [ str , float ]): self . __user_groups = user_groups get_avg_pop_by_users ( data , pop_by_items , group = None ) staticmethod Get the average popularity for each user in the data parameter. Average popularity of a single user \\(u\\) is defined as: \\[ avg\\_pop_u = \\frac{\\sum_{i \\in i_u} pop_i}{|i_u|} \\] PARAMETER DESCRIPTION data The Ratings object that will be used to compute average popularity of each user TYPE: Ratings pop_by_items popularity for each label ('label', 'popularity') TYPE: Dict group (optional) the set of users (user_id) TYPE: Set [ str ] DEFAULT: None RETURNS DESCRIPTION Dict [ str , float ] Python dictionary containing as keys each user id and as values the average popularity of each user Source code in clayrs/evaluation/metrics/fairness_metrics.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 @staticmethod def get_avg_pop_by_users ( data : Ratings , pop_by_items : Dict , group : Set [ str ] = None ) -> Dict [ str , float ]: r \"\"\" Get the average popularity for each user in the `data` parameter. Average popularity of a single user $u$ is defined as: $$ avg\\_pop_u = \\frac{\\sum_{i \\in i_u} pop_i}{|i_u|} $$ Args: data: The `Ratings` object that will be used to compute average popularity of each user pop_by_items: popularity for each label ('label', 'popularity') group: (optional) the set of users (user_id) Returns: Python dictionary containing as keys each user id and as values the average popularity of each user \"\"\" if group is None : group = set ( data . user_id_column ) list_by_user = { user : [ interaction . item_id for interaction in data . get_user_interactions ( user )] for user in group } avg_pop_by_users = { user : get_avg_pop ( list_by_user [ user ], pop_by_items ) for user in group } return avg_pop_by_users split_user_in_groups ( score_frame , groups , pop_items ) staticmethod Users are split into groups based on the groups parameter, which contains names of the groups as keys, and percentage of how many user must contain a group as values. For example: groups = {'popular_users': 0.3, 'medium_popular_users': 0.2, 'low_popular_users': 0.5} Every user will be inserted in a group based on how many popular items the user has rated (in relation to the percentage of users we specified as value in the dictionary): users with many popular items will be inserted into the first group users with niche items rated will be inserted into one of the last groups. In general users are grouped by \\(Popularity\\_ratio\\) in a descending order. \\(Popularity\\_ratio\\) for a single user \\(u\\) is defined as: \\[ Popularity\\_ratio_u = n\\_most\\_popular\\_items\\_rated_u / n\\_items\\_rated_u \\] The most popular items are the first pop_percentage % items of all items ordered in a descending order by popularity. The popularity of an item is defined as the number of times it is rated in the original_ratings parameter divided by the total number of users in the original_ratings . PARAMETER DESCRIPTION score_frame the Ratings object TYPE: Ratings groups each key contains the name of the group and each value contains the percentage of the specified group. If the groups don't cover the entire user collection, the rest of the users are considered in a 'default_diverse' group TYPE: Dict [ str , float ] pop_items set of most popular item_id labels TYPE: Set [ str ] RETURNS DESCRIPTION Dict [ str , Set [ str ]] A python dictionary containing as keys each group name and as values the set of user_id belonging to the particular group. Source code in clayrs/evaluation/metrics/fairness_metrics.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 @staticmethod def split_user_in_groups ( score_frame : Ratings , groups : Dict [ str , float ], pop_items : Set [ str ]) -> Dict [ str , Set [ str ]]: r \"\"\" Users are split into groups based on the *groups* parameter, which contains names of the groups as keys, and percentage of how many user must contain a group as values. For example: groups = {'popular_users': 0.3, 'medium_popular_users': 0.2, 'low_popular_users': 0.5} Every user will be inserted in a group based on how many popular items the user has rated (in relation to the percentage of users we specified as value in the dictionary): * users with many popular items will be inserted into the first group * users with niche items rated will be inserted into one of the last groups. In general users are grouped by $Popularity\\_ratio$ in a descending order. $Popularity\\_ratio$ for a single user $u$ is defined as: $$ Popularity\\_ratio_u = n\\_most\\_popular\\_items\\_rated_u / n\\_items\\_rated_u $$ The *most popular items* are the first `pop_percentage`% items of all items ordered in a descending order by popularity. The popularity of an item is defined as the number of times it is rated in the `original_ratings` parameter divided by the total number of users in the `original_ratings`. Args: score_frame: the Ratings object groups: each key contains the name of the group and each value contains the percentage of the specified group. If the groups don't cover the entire user collection, the rest of the users are considered in a 'default_diverse' group pop_items: set of most popular *item_id* labels Returns: A python dictionary containing as keys each group name and as values the set of *user_id* belonging to the particular group. \"\"\" num_of_users = len ( set ( score_frame . user_id_column )) if num_of_users < len ( groups ): raise NotEnoughUsers ( \"You can't split in {} groups {} users! \" \"Try reducing number of groups\" . format ( len ( groups ), num_of_users )) for percentage_chosen in groups . values (): if not 0 < percentage_chosen <= 1 : raise ValueError ( 'Incorrect percentage! Valid percentage range: 0 < percentage <= 1' ) total = sum ( groups . values ()) if total > 1 : raise ValueError ( \"Incorrect percentage! Sum of percentage is > than 1\" ) elif total < 1 : raise ValueError ( \"Sum of percentage is < than 1! Please add another group or redistribute percentages \" \"among already defined group to reach a total of 1!\" ) pop_ratio_by_users = pop_ratio_by_user ( score_frame , most_pop_items = pop_items ) pop_ratio_by_users = sorted ( pop_ratio_by_users , key = pop_ratio_by_users . get , reverse = True ) groups_dict : Dict [ str , Set [ str ]] = {} last_index = 0 percentage = 0.0 for group_name in groups : percentage += groups [ group_name ] group_index = round ( num_of_users * percentage ) if group_index == 0 : logger . warning ( 'Not enough rows for group {} ! It will be discarded' . format ( group_name )) else : groups_dict [ group_name ] = set ( pop_ratio_by_users [ last_index : group_index ]) last_index = group_index return groups_dict PredictionCoverage ( catalog ) Bases: FairnessMetric The Prediction Coverage metric measures in percentage how many distinct items are being recommended in relation to all available items. It's a system wide metric, so only its result it will be returned and not those of every user. The metric is calculated as such: \\[ Prediction Coverage_{sys} = (\\frac{|I_p|}{|I|})\\cdot100 \\] Where: \\(I\\) is the set of all available items \\(I_p\\) is the set of recommended items The \\(I\\) must be specified through the 'catalog' parameter Check the 'Beyond Accuracy: Evaluating Recommender Systems by Coverage and Serendipity' paper for more PARAMETER DESCRIPTION catalog set of item id of the catalog on which the prediction coverage must be computed TYPE: Set [ str ] Source code in clayrs/evaluation/metrics/fairness_metrics.py 255 256 def __init__ ( self , catalog : Set [ str ]): self . __catalog = set ( str ( item_id ) for item_id in catalog )","title":"Fairness metrics"},{"location":"evaluation/metrics/fairness_metrics/#fairness-metrics","text":"Fairness metrics evaluate how unbiased the recommendation lists are (e.g. unbiased towards popularity of the items)","title":"Fairness metrics"},{"location":"evaluation/metrics/fairness_metrics/#clayrs.evaluation.metrics.fairness_metrics.CatalogCoverage","text":"Bases: PredictionCoverage The Catalog Coverage metric measures in percentage how many distinct items are being recommended in relation to all available items. It's a system wide metric, so only its result it will be returned and not those of every user. It differs from the Prediction Coverage since it allows for different parameters to come into play. If no parameter is passed then it's a simple Prediction Coverage. The metric is calculated as such: \\[ Catalog Coverage_{sys} = (\\frac{|\\bigcup_{j=1...N}reclist(u_j)|}{|I|})\\cdot100 \\] Where: \\(N\\) is the total number of users \\(reclist(u_j)\\) is the set of items contained in the recommendation list of user \\(j\\) \\(I\\) is the set of all available items The \\(I\\) must be specified through the 'catalog' parameter The recommendation list of every user ( \\(reclist(u_j)\\) ) can be reduced to the first n parameter with the top-n parameter, so that catalog coverage is measured considering only the most highest ranked items. With the 'k' parameter one could specify the number of users that will be used to calculate catalog coverage: k users will be randomly sampled and their recommendation lists will be used. The formula above becomes: \\[ Catalog Coverage_{sys} = (\\frac{|\\bigcup_{j=1...k}reclist(u_j)|}{|I|})\\cdot100 \\] Where: \\(k\\) is the parameter specified Obviously 'k' < N, else simply recommendation lists of all users will be used Check the 'Beyond Accuracy: Evaluating Recommender Systems by Coverage and Serendipity' paper and page 13 of the 'Comparison of group recommendation algorithms' paper for more PARAMETER DESCRIPTION catalog set of item id of the catalog on which the prediction coverage must be computed TYPE: Set [ str ] top_n it's a cutoff parameter, if specified the Catalog Coverage will be calculated considering only the first 'n' items of every recommendation list of all users. Default is None TYPE: int DEFAULT: None k number of users randomly sampled. If specified, k users will be randomly sampled across all users and only their recommendation lists will be used to compute the CatalogCoverage TYPE: int DEFAULT: None Source code in clayrs/evaluation/metrics/fairness_metrics.py 347 348 349 350 def __init__ ( self , catalog : Set [ str ], top_n : int = None , k : int = None ): super () . __init__ ( catalog ) self . __top_n = top_n self . __k = k","title":"CatalogCoverage"},{"location":"evaluation/metrics/fairness_metrics/#clayrs.evaluation.metrics.fairness_metrics.DeltaGap","text":"Bases: GroupFairnessMetric The Delta GAP (Group Average popularity) metric lets you compare the average popularity \"requested\" by one or multiple groups of users and the average popularity \"obtained\" with the recommendation given by the recsys. It's a system wide metric and results of every group will be returned. It is calculated as such: \\[ \\Delta GAP = \\frac{recs_GAP - profile_GAP}{profile_GAP} \\] Users are split into groups based on the user_groups parameter, which contains names of the groups as keys, and percentage of how many user must contain a group as values. For example: user_groups = {'popular_users': 0.3, 'medium_popular_users': 0.2, 'low_popular_users': 0.5} Every user will be inserted in a group based on how many popular items the user has rated (in relation to the percentage of users we specified as value in the dictionary): users with many popular items will be inserted into the first group users with niche items rated will be inserted into one of the last groups. In general users are grouped by \\(Popularity\\_ratio\\) in a descending order. \\(Popularity\\_ratio\\) for a single user \\(u\\) is defined as: \\[ Popularity\\_ratio_u = n\\_most\\_popular\\_items\\_rated_u / n\\_items\\_rated_u \\] The most popular items are the first pop_percentage % items of all items ordered in a descending order by popularity. The popularity of an item is defined as the number of times it is rated in the original_ratings parameter divided by the total number of users in the original_ratings . It can happen that for a particular user of a group no recommendation are available: in that case it will be skipped and it won't be considered in the \\(\\Delta GAP\\) computation of its group. In case no user of a group has recs available, a warning will be printed and the whole group won't be considered. If the 'top_n' parameter is specified, then the \\(\\Delta GAP\\) will be calculated considering only the first n items of every recommendation list of all users PARAMETER DESCRIPTION user_groups Dict containing group names as keys and percentage of users as value, used to split users in groups. Users with more popular items rated are grouped into the first group, users with slightly less popular items rated are grouped into the second one, etc. TYPE: Dict [ str , float ] user_profiles one or more Ratings objects containing interactions of the profile of each user (e.g. the train set ). It should be one for each split to evaluate! TYPE: Union [ list , Ratings ] original_ratings Ratings object containing original interactions of the dataset that will be used to compute the popularity of each item (i.e. the number of times it is rated divided by the total number of users) TYPE: Ratings top_n it's a cutoff parameter, if specified the Gini index will be calculated considering only their first 'n' items of every recommendation list of all users. Default is None TYPE: int DEFAULT: None pop_percentage How many (in percentage) most popular items must be considered. Default is 0.2 TYPE: float DEFAULT: 0.2 Source code in clayrs/evaluation/metrics/fairness_metrics.py 449 450 451 452 453 454 455 456 457 458 459 460 461 def __init__ ( self , user_groups : Dict [ str , float ], user_profiles : Union [ list , Ratings ], original_ratings : Ratings , top_n : int = None , pop_percentage : float = 0.2 ): if not 0 < pop_percentage <= 1 : raise ValueError ( 'Incorrect percentage! Valid percentage range: 0 < percentage <= 1' ) super () . __init__ ( user_groups ) self . _pop_by_item = get_item_popularity ( original_ratings ) if not isinstance ( user_profiles , list ): user_profiles = [ user_profiles ] self . _user_profiles = user_profiles self . __top_n = top_n self . _pop_percentage = pop_percentage","title":"DeltaGap"},{"location":"evaluation/metrics/fairness_metrics/#clayrs.evaluation.metrics.fairness_metrics.DeltaGap.calculate_delta_gap","text":"Compute the ratio between the recommendation gap and the user profiles gap PARAMETER DESCRIPTION recs_gap recommendation gap TYPE: float profile_gap user profiles gap TYPE: float RETURNS DESCRIPTION score delta gap measure TYPE: float Source code in clayrs/evaluation/metrics/fairness_metrics.py 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 @staticmethod def calculate_delta_gap ( recs_gap : float , profile_gap : float ) -> float : \"\"\" Compute the ratio between the recommendation gap and the user profiles gap Args: recs_gap: recommendation gap profile_gap: user profiles gap Returns: score: delta gap measure \"\"\" result = 0 if profile_gap != 0.0 : result = ( recs_gap - profile_gap ) / profile_gap return result","title":"calculate_delta_gap()"},{"location":"evaluation/metrics/fairness_metrics/#clayrs.evaluation.metrics.fairness_metrics.DeltaGap.calculate_gap","text":"Compute the GAP (Group Average Popularity) formula \\[ GAP = \\frac{\\sum_{u \\in U}\\cdot \\frac{\\sum_{i \\in i_u} pop_i}{|i_u|}}{|G|} \\] Where: \\(G\\) is the set of users \\(i_u\\) is the set of items rated/recommended by/to user \\(u\\) \\(pop_i\\) is the popularity of item i PARAMETER DESCRIPTION group the set of users (user_id) TYPE: Set [ str ] avg_pop_by_users average popularity by user TYPE: Dict [ str , object ] RETURNS DESCRIPTION score gap score TYPE: float Source code in clayrs/evaluation/metrics/fairness_metrics.py 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 @staticmethod def calculate_gap ( group : Set [ str ], avg_pop_by_users : Dict [ str , object ]) -> float : r \"\"\" Compute the GAP (Group Average Popularity) formula $$ GAP = \\frac{\\sum_{u \\in U}\\cdot \\frac{\\sum_{i \\in i_u} pop_i}{|i_u|}}{|G|} $$ Where: - $G$ is the set of users - $i_u$ is the set of items rated/recommended by/to user $u$ - $pop_i$ is the popularity of item i Args: group: the set of users (user_id) avg_pop_by_users: average popularity by user Returns: score (float): gap score \"\"\" total_pop = 0 for user in group : if avg_pop_by_users . get ( user ): total_pop += avg_pop_by_users [ user ] return total_pop / len ( group )","title":"calculate_gap()"},{"location":"evaluation/metrics/fairness_metrics/#clayrs.evaluation.metrics.fairness_metrics.GiniIndex","text":"Bases: FairnessMetric The Gini Index metric measures inequality in recommendation lists. It's a system wide metric, so only its result it will be returned and not those of every user. The metric is calculated as such: \\[ Gini_{sys} = \\frac{\\sum_i(2i - n - 1)x_i}{n\\cdot\\sum_i x_i} \\] Where: \\(n\\) is the total number of distinct items that are being recommended \\(x_i\\) is the number of times that the item \\(i\\) has been recommended A perfectly equal recommender system should recommend every item the same number of times, in which case the Gini index would be equal to 0. The more the recsys is \"disegual\", the more the Gini Index is closer to 1 If the 'top_n' parameter is specified, then the Gini index will measure inequality considering only the first n items of every recommendation list of all users PARAMETER DESCRIPTION top_n it's a cutoff parameter, if specified the Gini index will be calculated considering only the first 'n' items of every recommendation list of all users. Default is None TYPE: int DEFAULT: None Source code in clayrs/evaluation/metrics/fairness_metrics.py 184 185 def __init__ ( self , top_n : int = None ): self . __top_n = top_n","title":"GiniIndex"},{"location":"evaluation/metrics/fairness_metrics/#clayrs.evaluation.metrics.fairness_metrics.GroupFairnessMetric","text":"Bases: FairnessMetric Abstract class for fairness metrics based on user groups It has some concrete methods useful for group divisions, since every subclass needs to split users into groups. PARAMETER DESCRIPTION user_groups Dict containing group names as keys and percentage of users as value, used to split users in groups. Users with more popular items rated are grouped into the first group, users with slightly less popular items rated are grouped into the second one, etc. TYPE: Dict [ str , float ] Source code in clayrs/evaluation/metrics/fairness_metrics.py 43 44 def __init__ ( self , user_groups : Dict [ str , float ]): self . __user_groups = user_groups","title":"GroupFairnessMetric"},{"location":"evaluation/metrics/fairness_metrics/#clayrs.evaluation.metrics.fairness_metrics.GroupFairnessMetric.get_avg_pop_by_users","text":"Get the average popularity for each user in the data parameter. Average popularity of a single user \\(u\\) is defined as: \\[ avg\\_pop_u = \\frac{\\sum_{i \\in i_u} pop_i}{|i_u|} \\] PARAMETER DESCRIPTION data The Ratings object that will be used to compute average popularity of each user TYPE: Ratings pop_by_items popularity for each label ('label', 'popularity') TYPE: Dict group (optional) the set of users (user_id) TYPE: Set [ str ] DEFAULT: None RETURNS DESCRIPTION Dict [ str , float ] Python dictionary containing as keys each user id and as values the average popularity of each user Source code in clayrs/evaluation/metrics/fairness_metrics.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 @staticmethod def get_avg_pop_by_users ( data : Ratings , pop_by_items : Dict , group : Set [ str ] = None ) -> Dict [ str , float ]: r \"\"\" Get the average popularity for each user in the `data` parameter. Average popularity of a single user $u$ is defined as: $$ avg\\_pop_u = \\frac{\\sum_{i \\in i_u} pop_i}{|i_u|} $$ Args: data: The `Ratings` object that will be used to compute average popularity of each user pop_by_items: popularity for each label ('label', 'popularity') group: (optional) the set of users (user_id) Returns: Python dictionary containing as keys each user id and as values the average popularity of each user \"\"\" if group is None : group = set ( data . user_id_column ) list_by_user = { user : [ interaction . item_id for interaction in data . get_user_interactions ( user )] for user in group } avg_pop_by_users = { user : get_avg_pop ( list_by_user [ user ], pop_by_items ) for user in group } return avg_pop_by_users","title":"get_avg_pop_by_users()"},{"location":"evaluation/metrics/fairness_metrics/#clayrs.evaluation.metrics.fairness_metrics.GroupFairnessMetric.split_user_in_groups","text":"Users are split into groups based on the groups parameter, which contains names of the groups as keys, and percentage of how many user must contain a group as values. For example: groups = {'popular_users': 0.3, 'medium_popular_users': 0.2, 'low_popular_users': 0.5} Every user will be inserted in a group based on how many popular items the user has rated (in relation to the percentage of users we specified as value in the dictionary): users with many popular items will be inserted into the first group users with niche items rated will be inserted into one of the last groups. In general users are grouped by \\(Popularity\\_ratio\\) in a descending order. \\(Popularity\\_ratio\\) for a single user \\(u\\) is defined as: \\[ Popularity\\_ratio_u = n\\_most\\_popular\\_items\\_rated_u / n\\_items\\_rated_u \\] The most popular items are the first pop_percentage % items of all items ordered in a descending order by popularity. The popularity of an item is defined as the number of times it is rated in the original_ratings parameter divided by the total number of users in the original_ratings . PARAMETER DESCRIPTION score_frame the Ratings object TYPE: Ratings groups each key contains the name of the group and each value contains the percentage of the specified group. If the groups don't cover the entire user collection, the rest of the users are considered in a 'default_diverse' group TYPE: Dict [ str , float ] pop_items set of most popular item_id labels TYPE: Set [ str ] RETURNS DESCRIPTION Dict [ str , Set [ str ]] A python dictionary containing as keys each group name and as values the set of user_id belonging to the particular group. Source code in clayrs/evaluation/metrics/fairness_metrics.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 @staticmethod def split_user_in_groups ( score_frame : Ratings , groups : Dict [ str , float ], pop_items : Set [ str ]) -> Dict [ str , Set [ str ]]: r \"\"\" Users are split into groups based on the *groups* parameter, which contains names of the groups as keys, and percentage of how many user must contain a group as values. For example: groups = {'popular_users': 0.3, 'medium_popular_users': 0.2, 'low_popular_users': 0.5} Every user will be inserted in a group based on how many popular items the user has rated (in relation to the percentage of users we specified as value in the dictionary): * users with many popular items will be inserted into the first group * users with niche items rated will be inserted into one of the last groups. In general users are grouped by $Popularity\\_ratio$ in a descending order. $Popularity\\_ratio$ for a single user $u$ is defined as: $$ Popularity\\_ratio_u = n\\_most\\_popular\\_items\\_rated_u / n\\_items\\_rated_u $$ The *most popular items* are the first `pop_percentage`% items of all items ordered in a descending order by popularity. The popularity of an item is defined as the number of times it is rated in the `original_ratings` parameter divided by the total number of users in the `original_ratings`. Args: score_frame: the Ratings object groups: each key contains the name of the group and each value contains the percentage of the specified group. If the groups don't cover the entire user collection, the rest of the users are considered in a 'default_diverse' group pop_items: set of most popular *item_id* labels Returns: A python dictionary containing as keys each group name and as values the set of *user_id* belonging to the particular group. \"\"\" num_of_users = len ( set ( score_frame . user_id_column )) if num_of_users < len ( groups ): raise NotEnoughUsers ( \"You can't split in {} groups {} users! \" \"Try reducing number of groups\" . format ( len ( groups ), num_of_users )) for percentage_chosen in groups . values (): if not 0 < percentage_chosen <= 1 : raise ValueError ( 'Incorrect percentage! Valid percentage range: 0 < percentage <= 1' ) total = sum ( groups . values ()) if total > 1 : raise ValueError ( \"Incorrect percentage! Sum of percentage is > than 1\" ) elif total < 1 : raise ValueError ( \"Sum of percentage is < than 1! Please add another group or redistribute percentages \" \"among already defined group to reach a total of 1!\" ) pop_ratio_by_users = pop_ratio_by_user ( score_frame , most_pop_items = pop_items ) pop_ratio_by_users = sorted ( pop_ratio_by_users , key = pop_ratio_by_users . get , reverse = True ) groups_dict : Dict [ str , Set [ str ]] = {} last_index = 0 percentage = 0.0 for group_name in groups : percentage += groups [ group_name ] group_index = round ( num_of_users * percentage ) if group_index == 0 : logger . warning ( 'Not enough rows for group {} ! It will be discarded' . format ( group_name )) else : groups_dict [ group_name ] = set ( pop_ratio_by_users [ last_index : group_index ]) last_index = group_index return groups_dict","title":"split_user_in_groups()"},{"location":"evaluation/metrics/fairness_metrics/#clayrs.evaluation.metrics.fairness_metrics.PredictionCoverage","text":"Bases: FairnessMetric The Prediction Coverage metric measures in percentage how many distinct items are being recommended in relation to all available items. It's a system wide metric, so only its result it will be returned and not those of every user. The metric is calculated as such: \\[ Prediction Coverage_{sys} = (\\frac{|I_p|}{|I|})\\cdot100 \\] Where: \\(I\\) is the set of all available items \\(I_p\\) is the set of recommended items The \\(I\\) must be specified through the 'catalog' parameter Check the 'Beyond Accuracy: Evaluating Recommender Systems by Coverage and Serendipity' paper for more PARAMETER DESCRIPTION catalog set of item id of the catalog on which the prediction coverage must be computed TYPE: Set [ str ] Source code in clayrs/evaluation/metrics/fairness_metrics.py 255 256 def __init__ ( self , catalog : Set [ str ]): self . __catalog = set ( str ( item_id ) for item_id in catalog )","title":"PredictionCoverage"},{"location":"evaluation/metrics/plot_metrics/","text":"Plot metrics Plot metrics save a plot in the chosen output directory LongTailDistr ( out_dir = '.' , file_name = 'long_tail_distr' , on = 'truth' , format = 'png' , overwrite = False ) Bases: PlotMetric This metric generates the Long Tail Distribution plot and saves it in the output directory with the file name specified. The plot can be generated both for the truth set or the predictions set (based on the on parameter): on = 'truth' : in this case the long tail distribution is useful to see which are the most popular items (the most rated ones) on = 'pred' : in this case the long tail distribution is useful to see which are the most recommended items The plot file will be saved as out_dir/file_name.format Since multiple split could be evaluated at once, the overwrite parameter comes into play: if is set to False, file with the same name will be saved as file_name (1).format , file_name (2).format , etc. so that for every split a plot is generated without overwriting any file previously generated PARAMETER DESCRIPTION out_dir Directory where the plot will be saved. Default is '.', meaning that the plot will be saved in the same directory where the python script it's being executed TYPE: str DEFAULT: '.' file_name Name of the plot file. Default is 'long_tail_distr' TYPE: str DEFAULT: 'long_tail_distr' on Set on which the Long Tail Distribution plot will be generated. Values accepted are 'truth' or 'pred' TYPE: str DEFAULT: 'truth' format Format of the plot file. Could be 'jpg', 'svg', 'png'. Default is 'png' TYPE: str DEFAULT: 'png' overwrite parameter which specifies if the plot saved must overwrite any file that as the same name ('file_name.format'). Default is False TYPE: bool DEFAULT: False RAISES DESCRIPTION ValueError exception raised when a invalid value for the 'on' parameter is specified Source code in clayrs/evaluation/metrics/plot_metrics.py 115 116 117 118 119 120 121 122 123 def __init__ ( self , out_dir : str = '.' , file_name : str = 'long_tail_distr' , on : str = 'truth' , format : str = 'png' , overwrite : bool = False ): valid = { 'truth' , 'pred' } self . __on = on . lower () if self . __on not in valid : raise ValueError ( \"on= {} is not supported! Long Tail can be calculated only on: \\n \" \" {} \" . format ( on , valid )) super () . __init__ ( out_dir , file_name , format , overwrite ) PopRatioProfileVsRecs ( user_groups , user_profiles , original_ratings , out_dir = '.' , file_name = 'pop_ratio_profile_vs_recs' , pop_percentage = 0.2 , store_frame = False , format = 'png' , overwrite = False ) Bases: GroupFairnessMetric , PlotMetric This metric generates a plot where users are split into groups and, for every group, a boxplot comparing profile popularity ratio and recommendations popularity ratio is drawn Users are split into groups based on the user_groups parameter, which contains names of the groups as keys, and percentage of how many user must contain a group as values. For example: user_groups = {'popular_users': 0.3, 'medium_popular_users': 0.2, 'low_popular_users': 0.5} Every user will be inserted in a group based on how many popular items the user has rated (in relation to the percentage of users we specified as value in the dictionary): users with many popular items will be inserted into the first group users with niche items rated will be inserted into one of the last groups. In general users are grouped by \\(Popularity\\_ratio\\) in a descending order. \\(Popularity\\_ratio\\) for a single user \\(u\\) is defined as: \\[ Popularity\\_ratio_u = n\\_most\\_popular\\_items\\_rated_u / n\\_items\\_rated_u \\] The most popular items are the first pop_percentage % items of all items ordered in a descending order by popularity. The popularity of an item is defined as the number of times it is rated in the original_ratings parameter divided by the total number of users in the original_ratings . It can happen that for a particular user of a group no recommendation are available: in that case it will be skipped and it won't be considered in the \\(Popularity\\_ratio\\) computation of its group. In case no user of a group has recs available, a warning will be printed and the whole group won't be considered. The plot file will be saved as out_dir/file_name.format Since multiple split could be evaluated at once, the overwrite parameter comes into play: if is set to False, file with the same name will be saved as file_name (1).format , file_name (2).format , etc. so that for every split a plot is generated without overwriting any file previously generated Thanks to the 'store_frame' parameter it's also possible to store a csv containing the calculations done in order to build every boxplot. Will be saved in the same directory and with the same file name as the plot itself (but with the .csv format): The csv will be saved as out_dir/file_name.csv Please note : once computed, the DeltaGAP class needs to be re-instantiated in case you want to compute it again! PARAMETER DESCRIPTION user_groups Dict containing group names as keys and percentage of users as value, used to split users in groups. Users with more popular items rated are grouped into the first group, users with slightly less popular items rated are grouped into the second one, etc. TYPE: Dict<str, float> user_profiles one or more Ratings objects containing interactions of the profile of each user (e.g. the train set ). It should be one for each split to evaluate! TYPE: Union [ list , Ratings ] original_ratings Ratings object containing original interactions of the dataset that will be used to compute the popularity of each item (i.e. the number of times it is rated divided by the total number of users) TYPE: Ratings out_dir Directory where the plot will be saved. Default is '.', meaning that the plot will be saved in the same directory where the python script it's being executed TYPE: str DEFAULT: '.' file_name Name of the plot file. Default is 'pop_ratio_profile_vs_recs' TYPE: str DEFAULT: 'pop_ratio_profile_vs_recs' pop_percentage How many (in percentage) 'most popular items' must be considered. Default is 0.2 TYPE: float DEFAULT: 0.2 store_frame True if you want to store calculations done in order to build every boxplot in a csv file, False otherwise. Default is set to False TYPE: bool DEFAULT: False format Format of the plot file. Could be 'jpg', 'svg', 'png'. Default is 'png' TYPE: str DEFAULT: 'png' overwrite parameter which specifies if the plot saved must overwrite any file that as the same name ('file_name.format'). Default is False TYPE: bool DEFAULT: False Source code in clayrs/evaluation/metrics/plot_metrics.py 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 def __init__ ( self , user_groups : Dict [ str , float ], user_profiles : Union [ list , Ratings ], original_ratings : Ratings , out_dir : str = '.' , file_name : str = 'pop_ratio_profile_vs_recs' , pop_percentage : float = 0.2 , store_frame : bool = False , format : str = 'png' , overwrite : bool = False ): PlotMetric . __init__ ( self , out_dir , file_name , format , overwrite ) GroupFairnessMetric . __init__ ( self , user_groups ) if not 0 < pop_percentage <= 1 : raise ValueError ( 'Incorrect percentage! Valid percentage range: 0 < percentage <= 1' ) self . _pop_by_item = get_item_popularity ( original_ratings ) if not isinstance ( user_profiles , list ): user_profiles = [ user_profiles ] self . _user_profiles = user_profiles self . __pop_percentage = pop_percentage self . __user_groups = user_groups self . __store_frame = store_frame PopRecsCorrelation ( original_ratings , out_dir = '.' , file_name = 'pop_recs_correlation' , mode = 'both' , format = 'png' , overwrite = False ) Bases: PlotMetric This metric generates a plot which has as the X-axis the popularity of each item and as Y-axis the recommendation frequency, so that it can be easily seen the correlation between popular (niche) items and how many times are being recommended The popularity of an item is defined as the number of times it is rated in the original_ratings parameter divided by the total number of users in the original_ratings . The plot file will be saved as out_dir/file_name.format Since multiple split could be evaluated at once, the overwrite parameter comes into play: if is set to False, file with the same name will be saved as file_name (1).format , file_name (2).format , etc. so that for every split a plot is generated without overwriting any file previously generated There exists cases in which some items are not recommended even once, so in the graph could appear zero recommendations . One could change this behaviour thanks to the 'mode' parameter: mode='both' : two graphs will be created, the first one containing eventual zero recommendations , the second one where zero recommendations are excluded. This additional graph will be stored as out_dir/file_name_no_zeros.format (the string '_no_zeros' will be added to the file_name chosen automatically) mode='w_zeros' : only a graph containing eventual zero recommendations will be created mode='no_zeros' : only a graph excluding eventual zero recommendations will be created. The graph will be saved as out_dir/file_name_no_zeros.format (the string '_no_zeros' will be added to the file_name chosen automatically) PARAMETER DESCRIPTION original_ratings Ratings object containing original interactions of the dataset that will be used to compute the popularity of each item (i.e. the number of times it is rated divided by the total number of users) TYPE: Ratings out_dir Directory where the plot will be saved. Default is '.', meaning that the plot will be saved in the same directory where the python script it's being executed TYPE: str DEFAULT: '.' file_name Name of the plot file. Default is 'pop_recs_correlation' TYPE: str DEFAULT: 'pop_recs_correlation' mode Parameter which dictates which graph must be created. By default is 'both', so the graph with eventual zero recommendations as well as the graph excluding eventual zero recommendations will be created. Check the class documentation for more TYPE: str DEFAULT: 'both' format Format of the plot file. Could be 'jpg', 'svg', 'png'. Default is 'png' TYPE: str DEFAULT: 'png' overwrite parameter which specifies if the plot saved must overwrite any file that as the same name ('file_name.format'). Default is False TYPE: bool DEFAULT: False Source code in clayrs/evaluation/metrics/plot_metrics.py 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 def __init__ ( self , original_ratings : Ratings , out_dir : str = '.' , file_name : str = 'pop_recs_correlation' , mode : str = 'both' , format : str = 'png' , overwrite : bool = False ): valid = { 'both' , 'no_zeros' , 'w_zeros' } self . __mode = mode . lower () if self . __mode not in valid : raise ValueError ( \"Mode {} is not supported! Modes available: \\n \" \" {} \" . format ( mode , valid )) self . _pop_by_item = get_item_popularity ( original_ratings ) super () . __init__ ( out_dir , file_name , format , overwrite ) build_no_zeros_plot ( popularity , recommendations ) Method which builds and saves the plot excluding eventual zero recommendations It saves the plot as out_dir/filename_no_zeros.format , according to their value passed in the constructor. Note that the '_no_zeros' string is automatically added to the file_name chosen PARAMETER DESCRIPTION popularity x-axis values representing popularity of every item TYPE: list recommendations y-axis values representing number of times every item has been recommended TYPE: list Source code in clayrs/evaluation/metrics/plot_metrics.py 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 def build_no_zeros_plot ( self , popularity : list , recommendations : list ): \"\"\" Method which builds and saves the plot **excluding** eventual *zero recommendations* It saves the plot as *out_dir/filename_no_zeros.format*, according to their value passed in the constructor. Note that the '_no_zeros' string is automatically added to the file_name chosen Args: popularity (list): x-axis values representing popularity of every item recommendations (list): y-axis values representing number of times every item has been recommended \"\"\" title = 'Popularity Ratio - Recommendations Correlation (No zeros)' fig = self . build_plot ( popularity , recommendations , title ) file_name = self . file_name + '_no_zeros' self . save_figure ( fig , file_name ) build_plot ( x , y , title ) Method which builds a matplotlib plot given x-axis values, y-axis values and the title of the plot. X-axis label and Y-axis label are hard-coded as 'Popularity' and 'Recommendation frequency' respectively. PARAMETER DESCRIPTION x List containing x-axis values TYPE: list y List containing y-axis values TYPE: list title title of the plot TYPE: str RETURNS DESCRIPTION matplotlib . figure . Figure The matplotlib figure Source code in clayrs/evaluation/metrics/plot_metrics.py 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 def build_plot ( self , x : list , y : list , title : str ) -> matplotlib . figure . Figure : \"\"\" Method which builds a matplotlib plot given x-axis values, y-axis values and the title of the plot. X-axis label and Y-axis label are hard-coded as 'Popularity' and 'Recommendation frequency' respectively. Args: x (list): List containing x-axis values y (list): List containing y-axis values title (str): title of the plot Returns: The matplotlib figure \"\"\" fig = plt . figure () ax = fig . add_subplot () ax . set ( xlabel = 'Popularity Ratio' , ylabel = 'Recommendation frequency' , title = title ) ax . scatter ( x , y , marker = 'o' , s = 20 , c = 'orange' , edgecolors = 'black' , linewidths = 0.05 ) # automatic ticks but only integer ones ax . yaxis . set_major_locator ( plticker . MaxNLocator ( integer = True )) return fig build_w_zeros_plot ( popularity , recommendations ) Method which builds and saves the plot containing eventual zero recommendations It saves the plot as out_dir/filename.format , according to their value passed in the constructor PARAMETER DESCRIPTION popularity x-axis values representing popularity of every item TYPE: list recommendations y-axis values representing number of times every item has been recommended TYPE: list Source code in clayrs/evaluation/metrics/plot_metrics.py 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 def build_w_zeros_plot ( self , popularity : list , recommendations : list ): \"\"\" Method which builds and saves the plot containing eventual *zero recommendations* It saves the plot as *out_dir/filename.format*, according to their value passed in the constructor Args: popularity (list): x-axis values representing popularity of every item recommendations (list): y-axis values representing number of times every item has been recommended \"\"\" title = 'Popularity Ratio - Recommendations Correlation' fig = self . build_plot ( popularity , recommendations , title ) file_name = self . file_name self . save_figure ( fig , file_name )","title":"Plot metrics"},{"location":"evaluation/metrics/plot_metrics/#plot-metrics","text":"Plot metrics save a plot in the chosen output directory","title":"Plot metrics"},{"location":"evaluation/metrics/plot_metrics/#clayrs.evaluation.metrics.plot_metrics.LongTailDistr","text":"Bases: PlotMetric This metric generates the Long Tail Distribution plot and saves it in the output directory with the file name specified. The plot can be generated both for the truth set or the predictions set (based on the on parameter): on = 'truth' : in this case the long tail distribution is useful to see which are the most popular items (the most rated ones) on = 'pred' : in this case the long tail distribution is useful to see which are the most recommended items The plot file will be saved as out_dir/file_name.format Since multiple split could be evaluated at once, the overwrite parameter comes into play: if is set to False, file with the same name will be saved as file_name (1).format , file_name (2).format , etc. so that for every split a plot is generated without overwriting any file previously generated PARAMETER DESCRIPTION out_dir Directory where the plot will be saved. Default is '.', meaning that the plot will be saved in the same directory where the python script it's being executed TYPE: str DEFAULT: '.' file_name Name of the plot file. Default is 'long_tail_distr' TYPE: str DEFAULT: 'long_tail_distr' on Set on which the Long Tail Distribution plot will be generated. Values accepted are 'truth' or 'pred' TYPE: str DEFAULT: 'truth' format Format of the plot file. Could be 'jpg', 'svg', 'png'. Default is 'png' TYPE: str DEFAULT: 'png' overwrite parameter which specifies if the plot saved must overwrite any file that as the same name ('file_name.format'). Default is False TYPE: bool DEFAULT: False RAISES DESCRIPTION ValueError exception raised when a invalid value for the 'on' parameter is specified Source code in clayrs/evaluation/metrics/plot_metrics.py 115 116 117 118 119 120 121 122 123 def __init__ ( self , out_dir : str = '.' , file_name : str = 'long_tail_distr' , on : str = 'truth' , format : str = 'png' , overwrite : bool = False ): valid = { 'truth' , 'pred' } self . __on = on . lower () if self . __on not in valid : raise ValueError ( \"on= {} is not supported! Long Tail can be calculated only on: \\n \" \" {} \" . format ( on , valid )) super () . __init__ ( out_dir , file_name , format , overwrite )","title":"LongTailDistr"},{"location":"evaluation/metrics/plot_metrics/#clayrs.evaluation.metrics.plot_metrics.PopRatioProfileVsRecs","text":"Bases: GroupFairnessMetric , PlotMetric This metric generates a plot where users are split into groups and, for every group, a boxplot comparing profile popularity ratio and recommendations popularity ratio is drawn Users are split into groups based on the user_groups parameter, which contains names of the groups as keys, and percentage of how many user must contain a group as values. For example: user_groups = {'popular_users': 0.3, 'medium_popular_users': 0.2, 'low_popular_users': 0.5} Every user will be inserted in a group based on how many popular items the user has rated (in relation to the percentage of users we specified as value in the dictionary): users with many popular items will be inserted into the first group users with niche items rated will be inserted into one of the last groups. In general users are grouped by \\(Popularity\\_ratio\\) in a descending order. \\(Popularity\\_ratio\\) for a single user \\(u\\) is defined as: \\[ Popularity\\_ratio_u = n\\_most\\_popular\\_items\\_rated_u / n\\_items\\_rated_u \\] The most popular items are the first pop_percentage % items of all items ordered in a descending order by popularity. The popularity of an item is defined as the number of times it is rated in the original_ratings parameter divided by the total number of users in the original_ratings . It can happen that for a particular user of a group no recommendation are available: in that case it will be skipped and it won't be considered in the \\(Popularity\\_ratio\\) computation of its group. In case no user of a group has recs available, a warning will be printed and the whole group won't be considered. The plot file will be saved as out_dir/file_name.format Since multiple split could be evaluated at once, the overwrite parameter comes into play: if is set to False, file with the same name will be saved as file_name (1).format , file_name (2).format , etc. so that for every split a plot is generated without overwriting any file previously generated Thanks to the 'store_frame' parameter it's also possible to store a csv containing the calculations done in order to build every boxplot. Will be saved in the same directory and with the same file name as the plot itself (but with the .csv format): The csv will be saved as out_dir/file_name.csv Please note : once computed, the DeltaGAP class needs to be re-instantiated in case you want to compute it again! PARAMETER DESCRIPTION user_groups Dict containing group names as keys and percentage of users as value, used to split users in groups. Users with more popular items rated are grouped into the first group, users with slightly less popular items rated are grouped into the second one, etc. TYPE: Dict<str, float> user_profiles one or more Ratings objects containing interactions of the profile of each user (e.g. the train set ). It should be one for each split to evaluate! TYPE: Union [ list , Ratings ] original_ratings Ratings object containing original interactions of the dataset that will be used to compute the popularity of each item (i.e. the number of times it is rated divided by the total number of users) TYPE: Ratings out_dir Directory where the plot will be saved. Default is '.', meaning that the plot will be saved in the same directory where the python script it's being executed TYPE: str DEFAULT: '.' file_name Name of the plot file. Default is 'pop_ratio_profile_vs_recs' TYPE: str DEFAULT: 'pop_ratio_profile_vs_recs' pop_percentage How many (in percentage) 'most popular items' must be considered. Default is 0.2 TYPE: float DEFAULT: 0.2 store_frame True if you want to store calculations done in order to build every boxplot in a csv file, False otherwise. Default is set to False TYPE: bool DEFAULT: False format Format of the plot file. Could be 'jpg', 'svg', 'png'. Default is 'png' TYPE: str DEFAULT: 'png' overwrite parameter which specifies if the plot saved must overwrite any file that as the same name ('file_name.format'). Default is False TYPE: bool DEFAULT: False Source code in clayrs/evaluation/metrics/plot_metrics.py 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 def __init__ ( self , user_groups : Dict [ str , float ], user_profiles : Union [ list , Ratings ], original_ratings : Ratings , out_dir : str = '.' , file_name : str = 'pop_ratio_profile_vs_recs' , pop_percentage : float = 0.2 , store_frame : bool = False , format : str = 'png' , overwrite : bool = False ): PlotMetric . __init__ ( self , out_dir , file_name , format , overwrite ) GroupFairnessMetric . __init__ ( self , user_groups ) if not 0 < pop_percentage <= 1 : raise ValueError ( 'Incorrect percentage! Valid percentage range: 0 < percentage <= 1' ) self . _pop_by_item = get_item_popularity ( original_ratings ) if not isinstance ( user_profiles , list ): user_profiles = [ user_profiles ] self . _user_profiles = user_profiles self . __pop_percentage = pop_percentage self . __user_groups = user_groups self . __store_frame = store_frame","title":"PopRatioProfileVsRecs"},{"location":"evaluation/metrics/plot_metrics/#clayrs.evaluation.metrics.plot_metrics.PopRecsCorrelation","text":"Bases: PlotMetric This metric generates a plot which has as the X-axis the popularity of each item and as Y-axis the recommendation frequency, so that it can be easily seen the correlation between popular (niche) items and how many times are being recommended The popularity of an item is defined as the number of times it is rated in the original_ratings parameter divided by the total number of users in the original_ratings . The plot file will be saved as out_dir/file_name.format Since multiple split could be evaluated at once, the overwrite parameter comes into play: if is set to False, file with the same name will be saved as file_name (1).format , file_name (2).format , etc. so that for every split a plot is generated without overwriting any file previously generated There exists cases in which some items are not recommended even once, so in the graph could appear zero recommendations . One could change this behaviour thanks to the 'mode' parameter: mode='both' : two graphs will be created, the first one containing eventual zero recommendations , the second one where zero recommendations are excluded. This additional graph will be stored as out_dir/file_name_no_zeros.format (the string '_no_zeros' will be added to the file_name chosen automatically) mode='w_zeros' : only a graph containing eventual zero recommendations will be created mode='no_zeros' : only a graph excluding eventual zero recommendations will be created. The graph will be saved as out_dir/file_name_no_zeros.format (the string '_no_zeros' will be added to the file_name chosen automatically) PARAMETER DESCRIPTION original_ratings Ratings object containing original interactions of the dataset that will be used to compute the popularity of each item (i.e. the number of times it is rated divided by the total number of users) TYPE: Ratings out_dir Directory where the plot will be saved. Default is '.', meaning that the plot will be saved in the same directory where the python script it's being executed TYPE: str DEFAULT: '.' file_name Name of the plot file. Default is 'pop_recs_correlation' TYPE: str DEFAULT: 'pop_recs_correlation' mode Parameter which dictates which graph must be created. By default is 'both', so the graph with eventual zero recommendations as well as the graph excluding eventual zero recommendations will be created. Check the class documentation for more TYPE: str DEFAULT: 'both' format Format of the plot file. Could be 'jpg', 'svg', 'png'. Default is 'png' TYPE: str DEFAULT: 'png' overwrite parameter which specifies if the plot saved must overwrite any file that as the same name ('file_name.format'). Default is False TYPE: bool DEFAULT: False Source code in clayrs/evaluation/metrics/plot_metrics.py 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 def __init__ ( self , original_ratings : Ratings , out_dir : str = '.' , file_name : str = 'pop_recs_correlation' , mode : str = 'both' , format : str = 'png' , overwrite : bool = False ): valid = { 'both' , 'no_zeros' , 'w_zeros' } self . __mode = mode . lower () if self . __mode not in valid : raise ValueError ( \"Mode {} is not supported! Modes available: \\n \" \" {} \" . format ( mode , valid )) self . _pop_by_item = get_item_popularity ( original_ratings ) super () . __init__ ( out_dir , file_name , format , overwrite )","title":"PopRecsCorrelation"},{"location":"evaluation/metrics/plot_metrics/#clayrs.evaluation.metrics.plot_metrics.PopRecsCorrelation.build_no_zeros_plot","text":"Method which builds and saves the plot excluding eventual zero recommendations It saves the plot as out_dir/filename_no_zeros.format , according to their value passed in the constructor. Note that the '_no_zeros' string is automatically added to the file_name chosen PARAMETER DESCRIPTION popularity x-axis values representing popularity of every item TYPE: list recommendations y-axis values representing number of times every item has been recommended TYPE: list Source code in clayrs/evaluation/metrics/plot_metrics.py 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 def build_no_zeros_plot ( self , popularity : list , recommendations : list ): \"\"\" Method which builds and saves the plot **excluding** eventual *zero recommendations* It saves the plot as *out_dir/filename_no_zeros.format*, according to their value passed in the constructor. Note that the '_no_zeros' string is automatically added to the file_name chosen Args: popularity (list): x-axis values representing popularity of every item recommendations (list): y-axis values representing number of times every item has been recommended \"\"\" title = 'Popularity Ratio - Recommendations Correlation (No zeros)' fig = self . build_plot ( popularity , recommendations , title ) file_name = self . file_name + '_no_zeros' self . save_figure ( fig , file_name )","title":"build_no_zeros_plot()"},{"location":"evaluation/metrics/plot_metrics/#clayrs.evaluation.metrics.plot_metrics.PopRecsCorrelation.build_plot","text":"Method which builds a matplotlib plot given x-axis values, y-axis values and the title of the plot. X-axis label and Y-axis label are hard-coded as 'Popularity' and 'Recommendation frequency' respectively. PARAMETER DESCRIPTION x List containing x-axis values TYPE: list y List containing y-axis values TYPE: list title title of the plot TYPE: str RETURNS DESCRIPTION matplotlib . figure . Figure The matplotlib figure Source code in clayrs/evaluation/metrics/plot_metrics.py 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 def build_plot ( self , x : list , y : list , title : str ) -> matplotlib . figure . Figure : \"\"\" Method which builds a matplotlib plot given x-axis values, y-axis values and the title of the plot. X-axis label and Y-axis label are hard-coded as 'Popularity' and 'Recommendation frequency' respectively. Args: x (list): List containing x-axis values y (list): List containing y-axis values title (str): title of the plot Returns: The matplotlib figure \"\"\" fig = plt . figure () ax = fig . add_subplot () ax . set ( xlabel = 'Popularity Ratio' , ylabel = 'Recommendation frequency' , title = title ) ax . scatter ( x , y , marker = 'o' , s = 20 , c = 'orange' , edgecolors = 'black' , linewidths = 0.05 ) # automatic ticks but only integer ones ax . yaxis . set_major_locator ( plticker . MaxNLocator ( integer = True )) return fig","title":"build_plot()"},{"location":"evaluation/metrics/plot_metrics/#clayrs.evaluation.metrics.plot_metrics.PopRecsCorrelation.build_w_zeros_plot","text":"Method which builds and saves the plot containing eventual zero recommendations It saves the plot as out_dir/filename.format , according to their value passed in the constructor PARAMETER DESCRIPTION popularity x-axis values representing popularity of every item TYPE: list recommendations y-axis values representing number of times every item has been recommended TYPE: list Source code in clayrs/evaluation/metrics/plot_metrics.py 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 def build_w_zeros_plot ( self , popularity : list , recommendations : list ): \"\"\" Method which builds and saves the plot containing eventual *zero recommendations* It saves the plot as *out_dir/filename.format*, according to their value passed in the constructor Args: popularity (list): x-axis values representing popularity of every item recommendations (list): y-axis values representing number of times every item has been recommended \"\"\" title = 'Popularity Ratio - Recommendations Correlation' fig = self . build_plot ( popularity , recommendations , title ) file_name = self . file_name self . save_figure ( fig , file_name )","title":"build_w_zeros_plot()"},{"location":"evaluation/metrics/ranking_metrics/","text":"Ranking metrics Ranking metrics evaluate the quality of the recommendation lists Correlation ( method = 'pearson' , top_n = None ) Bases: RankingMetric The Correlation metric calculates the correlation between the ranking of a user and its ideal ranking. The currently correlation methods implemented are: pearson kendall spearman Every correlation method is implemented by the pandas library, so read its documentation for more The correlation metric is calculated as such for the single user : \\[ Corr_u = Corr(ranking_u, ideal\\_ranking_u) \\] Where: \\(ranking_u\\) is ranking of the user \\(ideal\\_ranking_u\\) is the ideal ranking for the user The ideal ranking is calculated based on the rating inside the ground truth of the user The Correlation metric calculated for the entire system is simply the average of every \\(Corr\\) : \\[ Corr_{sys} = \\frac{\\sum_{u} Corr_u}{|U|} \\] Where: \\(Corr_u\\) is the correlation of the user \\(u\\) \\(U\\) is the set of all users The system average excludes NaN values. It's also possible to specify a cutoff parameter thanks to the 'top_n' parameter: if specified, only the first \\(n\\) results of the recommendation list will be used in order to calculate the correlation PARAMETER DESCRIPTION method The correlation method to use. It must be 'pearson', 'kendall' or 'spearman', otherwise a ValueError exception is raised. By default is 'pearson' TYPE: str DEFAULT: 'pearson' top_n Cutoff parameter, if specified only the first n items of the recommendation list will be used in order to calculate the correlation TYPE: int DEFAULT: None RAISES DESCRIPTION ValueError if an invalid method parameter is passed Source code in clayrs/evaluation/metrics/ranking_metrics.py 482 483 484 485 486 487 488 489 490 def __init__ ( self , method : str = 'pearson' , top_n : int = None ): valid = { 'pearson' , 'kendall' , 'spearman' } self . __method = method . lower () if self . __method not in valid : raise ValueError ( \"Method {} is not supported! Methods available: \\n \" \" {} \" . format ( method , valid )) self . __top_n = top_n MAP ( relevant_threshold = None ) Bases: RankingMetric The \\(MAP\\) metric ( Mean average Precision ) is a ranking metric computed by first calculating the \\(AP\\) ( Average Precision ) for each user and then taking its mean. The \\(AP\\) is calculated as such for the single user: \\[ AP_u = \\frac{1}{m_u}\\sum_{i=1}^{N_u}P(i)\\cdot rel(i) \\] Where: \\(m_u\\) is the number of relevant items for the user \\(u\\) \\(N_u\\) is the number of recommended items for the user \\(u\\) \\(P(i)\\) is the precision computed at cutoff \\(i\\) \\(rel(i)\\) is an indicator variable that says whether the i-th item is relevant ( \\(rel(i)=1\\) ) or not ( \\(rel(i)=0\\) ) After computing the \\(AP\\) for each user, we can compute the \\(MAP\\) for the whole system: \\[ MAP_{sys} = \\frac{1}{|U|}\\sum_{u}AP_u \\] This metric will return the \\(AP\\) computed for each user in the dataframe containing users results, and the \\(MAP\\) computed for the whole system in the dataframe containing system results PARAMETER DESCRIPTION relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None Source code in clayrs/evaluation/metrics/ranking_metrics.py 331 332 def __init__ ( self , relevant_threshold : float = None ): self . relevant_threshold = relevant_threshold MAPAtK ( k , relevant_threshold = None ) Bases: MAP The \\(MAP@K\\) metric ( Mean average Precision At K ) is a ranking metric computed by first calculating the \\(AP@K\\) ( Average Precision At K ) for each user and then taking its mean. The \\(AP@K\\) is calculated as such for the single user: \\[ AP@K_u = \\frac{1}{m_u}\\sum_{i=1}^{K}P(i)\\cdot rel(i) \\] Where: \\(m_u\\) is the number of relevant items for the user \\(u\\) \\(K\\) is the cutoff value \\(P(i)\\) is the precision computed at cutoff \\(i\\) \\(rel(i)\\) is an indicator variable that says whether the i-th item is relevant ( \\(rel(i)=1\\) ) or not ( \\(rel(i)=0\\) ) After computing the \\(AP@K\\) for each user, we can compute the \\(MAP@K\\) for the whole system: \\[ MAP@K_{sys} = \\frac{1}{|U|}\\sum_{u}AP@K_u \\] This metric will return the \\(AP@K\\) computed for each user in the dataframe containing users results, and the \\(MAP@K\\) computed for the whole system in the dataframe containing system results PARAMETER DESCRIPTION k the cutoff parameter. It must be >= 1, otherwise a ValueError exception is raised TYPE: int relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None Source code in clayrs/evaluation/metrics/ranking_metrics.py 420 421 422 def __init__ ( self , k : int , relevant_threshold : float = None ): super () . __init__ ( relevant_threshold ) self . k = k MRR ( relevant_threshold = None ) Bases: RankingMetric The MRR (Mean Reciprocal Rank) metric is a system wide metric, so only its result it will be returned and not those of every user. MRR is calculated as such: \\[ MRR_{sys} = \\frac{1}{|Q|}\\cdot\\sum_{i=1}^{|Q|}\\frac{1}{rank(i)} \\] Where: \\(Q\\) is the set of recommendation lists \\(rank(i)\\) is the position of the first relevant item in the i-th recommendation list The MRR metric needs to discern relevant items from the not relevant ones: in order to do that, one could pass a custom relevant_threshold parameter that will be applied to every user, so that if a rating of an item is >= relevant_threshold, then it's relevant, otherwise it's not. If no relevant_threshold parameter is passed then, for every user, its mean rating score will be used PARAMETER DESCRIPTION relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None Source code in clayrs/evaluation/metrics/ranking_metrics.py 174 175 def __init__ ( self , relevant_threshold : float = None ): self . __relevant_threshold = relevant_threshold calc_reciprocal_rank ( user_predictions , user_truth_relevant_items ) Method which calculates the RR (Reciprocal Rank) for a single user PARAMETER DESCRIPTION user_predictions list of Interactions object of the recommendation list for the user TYPE: List [ Interaction ] user_truth_relevant_items list of relevant Interactions object of the truth set for the user TYPE: Set [ Interaction ] Source code in clayrs/evaluation/metrics/ranking_metrics.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def calc_reciprocal_rank ( self , user_predictions : List [ Interaction ], user_truth_relevant_items : Set [ Interaction ]): \"\"\" Method which calculates the RR (Reciprocal Rank) for a single user Args: user_predictions: list of Interactions object of the recommendation list for the user user_truth_relevant_items: list of relevant Interactions object of the truth set for the user \"\"\" reciprocal_rank = 0 i = 1 for interaction_pred in user_predictions : if interaction_pred . item_id in user_truth_relevant_items : reciprocal_rank = 1 / i break # We only need the first relevant item position in the rank i += 1 return reciprocal_rank MRRAtK ( k , relevant_threshold = None ) Bases: MRR The MRR@K (Mean Reciprocal Rank at K) metric is a system wide metric, so only its result will be returned and not those of every user. MRR@K is calculated as such \\[ MRR@K_{sys} = \\frac{1}{|Q|}\\cdot\\sum_{i=1}^{K}\\frac{1}{rank(i)} \\] Where: \\(K\\) is the cutoff parameter \\(Q\\) is the set of recommendation lists \\(rank(i)\\) is the position of the first relevant item in the i-th recommendation list PARAMETER DESCRIPTION k the cutoff parameter. It must be >= 1, otherwise a ValueError exception is raised TYPE: int relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None RAISES DESCRIPTION ValueError if an invalid cutoff parameter is passed (0 or negative) Source code in clayrs/evaluation/metrics/ranking_metrics.py 270 271 272 273 274 def __init__ ( self , k : int , relevant_threshold : float = None ): if k < 1 : raise ValueError ( 'k= {} not valid! k must be >= 1!' . format ( k )) self . __k = k super () . __init__ ( relevant_threshold ) calc_reciprocal_rank ( user_predictions , user_truth_relevant_items ) Method which calculates the RR (Reciprocal Rank) for a single user PARAMETER DESCRIPTION user_predictions list of Interactions object of the recommendation list for the user TYPE: List [ Interaction ] user_truth_relevant_items list of relevant Interactions object of the truth set for the user TYPE: Set [ Interaction ] Source code in clayrs/evaluation/metrics/ranking_metrics.py 286 287 288 289 290 291 292 293 294 295 296 def calc_reciprocal_rank ( self , user_predictions : List [ Interaction ], user_truth_relevant_items : Set [ Interaction ]): \"\"\" Method which calculates the RR (Reciprocal Rank) for a single user Args: user_predictions: list of Interactions object of the recommendation list for the user user_truth_relevant_items: list of relevant Interactions object of the truth set for the user \"\"\" user_predictions_cut = user_predictions [: self . k ] return super () . calc_reciprocal_rank ( user_predictions_cut , user_truth_relevant_items ) NDCG Bases: RankingMetric The NDCG (Normalized Discounted Cumulative Gain) metric is calculated for the single user by using the sklearn implementation, so be sure to check its documentation . The NDCG of the entire system is calculated instead as such: \\[ NDCG_{sys} = \\frac{\\sum_{u} NDCG_u}{|U|} \\] Where: \\(NDCG_u\\) is the NDCG calculated for user :math: u \\(U\\) is the set of all users The system average excludes NaN values. NDCGAtK ( k ) Bases: NDCG The NDCG@K (Normalized Discounted Cumulative Gain at K) metric is calculated for the single user by using the sklearn implementation, so be sure to check its documentation . The NDCG@K of the entire system is calculated instead as such: \\[ NDCG@K_{sys} = \\frac{\\sum_{u} NDCG@K_u}{|U|} \\] Where: \\(NDCG@K_u\\) is the NDCG@K calculated for user \\(u\\) \\(U\\) is the set of all users The system average excludes NaN values. PARAMETER DESCRIPTION k the cutoff parameter TYPE: int Source code in clayrs/evaluation/metrics/ranking_metrics.py 136 137 def __init__ ( self , k : int ): self . __k = k","title":"Ranking metrics"},{"location":"evaluation/metrics/ranking_metrics/#ranking-metrics","text":"Ranking metrics evaluate the quality of the recommendation lists","title":"Ranking metrics"},{"location":"evaluation/metrics/ranking_metrics/#clayrs.evaluation.metrics.ranking_metrics.Correlation","text":"Bases: RankingMetric The Correlation metric calculates the correlation between the ranking of a user and its ideal ranking. The currently correlation methods implemented are: pearson kendall spearman Every correlation method is implemented by the pandas library, so read its documentation for more The correlation metric is calculated as such for the single user : \\[ Corr_u = Corr(ranking_u, ideal\\_ranking_u) \\] Where: \\(ranking_u\\) is ranking of the user \\(ideal\\_ranking_u\\) is the ideal ranking for the user The ideal ranking is calculated based on the rating inside the ground truth of the user The Correlation metric calculated for the entire system is simply the average of every \\(Corr\\) : \\[ Corr_{sys} = \\frac{\\sum_{u} Corr_u}{|U|} \\] Where: \\(Corr_u\\) is the correlation of the user \\(u\\) \\(U\\) is the set of all users The system average excludes NaN values. It's also possible to specify a cutoff parameter thanks to the 'top_n' parameter: if specified, only the first \\(n\\) results of the recommendation list will be used in order to calculate the correlation PARAMETER DESCRIPTION method The correlation method to use. It must be 'pearson', 'kendall' or 'spearman', otherwise a ValueError exception is raised. By default is 'pearson' TYPE: str DEFAULT: 'pearson' top_n Cutoff parameter, if specified only the first n items of the recommendation list will be used in order to calculate the correlation TYPE: int DEFAULT: None RAISES DESCRIPTION ValueError if an invalid method parameter is passed Source code in clayrs/evaluation/metrics/ranking_metrics.py 482 483 484 485 486 487 488 489 490 def __init__ ( self , method : str = 'pearson' , top_n : int = None ): valid = { 'pearson' , 'kendall' , 'spearman' } self . __method = method . lower () if self . __method not in valid : raise ValueError ( \"Method {} is not supported! Methods available: \\n \" \" {} \" . format ( method , valid )) self . __top_n = top_n","title":"Correlation"},{"location":"evaluation/metrics/ranking_metrics/#clayrs.evaluation.metrics.ranking_metrics.MAP","text":"Bases: RankingMetric The \\(MAP\\) metric ( Mean average Precision ) is a ranking metric computed by first calculating the \\(AP\\) ( Average Precision ) for each user and then taking its mean. The \\(AP\\) is calculated as such for the single user: \\[ AP_u = \\frac{1}{m_u}\\sum_{i=1}^{N_u}P(i)\\cdot rel(i) \\] Where: \\(m_u\\) is the number of relevant items for the user \\(u\\) \\(N_u\\) is the number of recommended items for the user \\(u\\) \\(P(i)\\) is the precision computed at cutoff \\(i\\) \\(rel(i)\\) is an indicator variable that says whether the i-th item is relevant ( \\(rel(i)=1\\) ) or not ( \\(rel(i)=0\\) ) After computing the \\(AP\\) for each user, we can compute the \\(MAP\\) for the whole system: \\[ MAP_{sys} = \\frac{1}{|U|}\\sum_{u}AP_u \\] This metric will return the \\(AP\\) computed for each user in the dataframe containing users results, and the \\(MAP\\) computed for the whole system in the dataframe containing system results PARAMETER DESCRIPTION relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None Source code in clayrs/evaluation/metrics/ranking_metrics.py 331 332 def __init__ ( self , relevant_threshold : float = None ): self . relevant_threshold = relevant_threshold","title":"MAP"},{"location":"evaluation/metrics/ranking_metrics/#clayrs.evaluation.metrics.ranking_metrics.MAPAtK","text":"Bases: MAP The \\(MAP@K\\) metric ( Mean average Precision At K ) is a ranking metric computed by first calculating the \\(AP@K\\) ( Average Precision At K ) for each user and then taking its mean. The \\(AP@K\\) is calculated as such for the single user: \\[ AP@K_u = \\frac{1}{m_u}\\sum_{i=1}^{K}P(i)\\cdot rel(i) \\] Where: \\(m_u\\) is the number of relevant items for the user \\(u\\) \\(K\\) is the cutoff value \\(P(i)\\) is the precision computed at cutoff \\(i\\) \\(rel(i)\\) is an indicator variable that says whether the i-th item is relevant ( \\(rel(i)=1\\) ) or not ( \\(rel(i)=0\\) ) After computing the \\(AP@K\\) for each user, we can compute the \\(MAP@K\\) for the whole system: \\[ MAP@K_{sys} = \\frac{1}{|U|}\\sum_{u}AP@K_u \\] This metric will return the \\(AP@K\\) computed for each user in the dataframe containing users results, and the \\(MAP@K\\) computed for the whole system in the dataframe containing system results PARAMETER DESCRIPTION k the cutoff parameter. It must be >= 1, otherwise a ValueError exception is raised TYPE: int relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None Source code in clayrs/evaluation/metrics/ranking_metrics.py 420 421 422 def __init__ ( self , k : int , relevant_threshold : float = None ): super () . __init__ ( relevant_threshold ) self . k = k","title":"MAPAtK"},{"location":"evaluation/metrics/ranking_metrics/#clayrs.evaluation.metrics.ranking_metrics.MRR","text":"Bases: RankingMetric The MRR (Mean Reciprocal Rank) metric is a system wide metric, so only its result it will be returned and not those of every user. MRR is calculated as such: \\[ MRR_{sys} = \\frac{1}{|Q|}\\cdot\\sum_{i=1}^{|Q|}\\frac{1}{rank(i)} \\] Where: \\(Q\\) is the set of recommendation lists \\(rank(i)\\) is the position of the first relevant item in the i-th recommendation list The MRR metric needs to discern relevant items from the not relevant ones: in order to do that, one could pass a custom relevant_threshold parameter that will be applied to every user, so that if a rating of an item is >= relevant_threshold, then it's relevant, otherwise it's not. If no relevant_threshold parameter is passed then, for every user, its mean rating score will be used PARAMETER DESCRIPTION relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None Source code in clayrs/evaluation/metrics/ranking_metrics.py 174 175 def __init__ ( self , relevant_threshold : float = None ): self . __relevant_threshold = relevant_threshold","title":"MRR"},{"location":"evaluation/metrics/ranking_metrics/#clayrs.evaluation.metrics.ranking_metrics.MRR.calc_reciprocal_rank","text":"Method which calculates the RR (Reciprocal Rank) for a single user PARAMETER DESCRIPTION user_predictions list of Interactions object of the recommendation list for the user TYPE: List [ Interaction ] user_truth_relevant_items list of relevant Interactions object of the truth set for the user TYPE: Set [ Interaction ] Source code in clayrs/evaluation/metrics/ranking_metrics.py 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def calc_reciprocal_rank ( self , user_predictions : List [ Interaction ], user_truth_relevant_items : Set [ Interaction ]): \"\"\" Method which calculates the RR (Reciprocal Rank) for a single user Args: user_predictions: list of Interactions object of the recommendation list for the user user_truth_relevant_items: list of relevant Interactions object of the truth set for the user \"\"\" reciprocal_rank = 0 i = 1 for interaction_pred in user_predictions : if interaction_pred . item_id in user_truth_relevant_items : reciprocal_rank = 1 / i break # We only need the first relevant item position in the rank i += 1 return reciprocal_rank","title":"calc_reciprocal_rank()"},{"location":"evaluation/metrics/ranking_metrics/#clayrs.evaluation.metrics.ranking_metrics.MRRAtK","text":"Bases: MRR The MRR@K (Mean Reciprocal Rank at K) metric is a system wide metric, so only its result will be returned and not those of every user. MRR@K is calculated as such \\[ MRR@K_{sys} = \\frac{1}{|Q|}\\cdot\\sum_{i=1}^{K}\\frac{1}{rank(i)} \\] Where: \\(K\\) is the cutoff parameter \\(Q\\) is the set of recommendation lists \\(rank(i)\\) is the position of the first relevant item in the i-th recommendation list PARAMETER DESCRIPTION k the cutoff parameter. It must be >= 1, otherwise a ValueError exception is raised TYPE: int relevant_threshold parameter needed to discern relevant items and non-relevant items for every user. If not specified, the mean rating score of every user will be used TYPE: float DEFAULT: None RAISES DESCRIPTION ValueError if an invalid cutoff parameter is passed (0 or negative) Source code in clayrs/evaluation/metrics/ranking_metrics.py 270 271 272 273 274 def __init__ ( self , k : int , relevant_threshold : float = None ): if k < 1 : raise ValueError ( 'k= {} not valid! k must be >= 1!' . format ( k )) self . __k = k super () . __init__ ( relevant_threshold )","title":"MRRAtK"},{"location":"evaluation/metrics/ranking_metrics/#clayrs.evaluation.metrics.ranking_metrics.MRRAtK.calc_reciprocal_rank","text":"Method which calculates the RR (Reciprocal Rank) for a single user PARAMETER DESCRIPTION user_predictions list of Interactions object of the recommendation list for the user TYPE: List [ Interaction ] user_truth_relevant_items list of relevant Interactions object of the truth set for the user TYPE: Set [ Interaction ] Source code in clayrs/evaluation/metrics/ranking_metrics.py 286 287 288 289 290 291 292 293 294 295 296 def calc_reciprocal_rank ( self , user_predictions : List [ Interaction ], user_truth_relevant_items : Set [ Interaction ]): \"\"\" Method which calculates the RR (Reciprocal Rank) for a single user Args: user_predictions: list of Interactions object of the recommendation list for the user user_truth_relevant_items: list of relevant Interactions object of the truth set for the user \"\"\" user_predictions_cut = user_predictions [: self . k ] return super () . calc_reciprocal_rank ( user_predictions_cut , user_truth_relevant_items )","title":"calc_reciprocal_rank()"},{"location":"evaluation/metrics/ranking_metrics/#clayrs.evaluation.metrics.ranking_metrics.NDCG","text":"Bases: RankingMetric The NDCG (Normalized Discounted Cumulative Gain) metric is calculated for the single user by using the sklearn implementation, so be sure to check its documentation . The NDCG of the entire system is calculated instead as such: \\[ NDCG_{sys} = \\frac{\\sum_{u} NDCG_u}{|U|} \\] Where: \\(NDCG_u\\) is the NDCG calculated for user :math: u \\(U\\) is the set of all users The system average excludes NaN values.","title":"NDCG"},{"location":"evaluation/metrics/ranking_metrics/#clayrs.evaluation.metrics.ranking_metrics.NDCGAtK","text":"Bases: NDCG The NDCG@K (Normalized Discounted Cumulative Gain at K) metric is calculated for the single user by using the sklearn implementation, so be sure to check its documentation . The NDCG@K of the entire system is calculated instead as such: \\[ NDCG@K_{sys} = \\frac{\\sum_{u} NDCG@K_u}{|U|} \\] Where: \\(NDCG@K_u\\) is the NDCG@K calculated for user \\(u\\) \\(U\\) is the set of all users The system average excludes NaN values. PARAMETER DESCRIPTION k the cutoff parameter TYPE: int Source code in clayrs/evaluation/metrics/ranking_metrics.py 136 137 def __init__ ( self , k : int ): self . __k = k","title":"NDCGAtK"},{"location":"evaluation/statistical_tests/paired/","text":"Paired statistical tests PairedTest Bases: StatisticalTest perform ( df_list ) Method which performs the chosen paired statistical test. Since it's a paired test, the final result is a pandas DataFrame which contains learning schemas compared in pair. For example if you call the perform() method by passing a list containing three different DataFrames, one for each learning schema to compare: # Ttest as example since it's a Paired Test Ttest () . perform ([ user_df1 , user_df2 , user_df3 ]) You will obtain a DataFrame comparing all different combinations: (system1, system2) (system1, system3) (system2, system3) The first value of each cell is the statistic , the second is the p-value PARAMETER DESCRIPTION df_list List containing DataFrames with several metrics to compare, preferably metrics computed for each user. One DataFrame corresponds to one learning schema TYPE: List [ pd . DataFrame ] RETURNS DESCRIPTION pd . DataFrame A Pandas DataFrame where each combination of learning schemas are compared in pair. The first value of each cell is the statistic , the second is the p-value Source code in clayrs/evaluation/statistical_test.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def perform ( self , df_list : List [ pd . DataFrame ]) -> pd . DataFrame : \"\"\" Method which performs the chosen paired statistical test. Since it's a paired test, the final result is a pandas DataFrame which contains learning schemas compared in pair. For example if you call the `perform()` method by passing a list containing three different DataFrames, one for each learning schema to compare: ```python # Ttest as example since it's a Paired Test Ttest().perform([user_df1, user_df2, user_df3]) ``` You will obtain a DataFrame comparing all different combinations: * (system1, system2) * (system1, system3) * (system2, system3) The first value of each cell is the ***statistic***, the second is the ***p-value*** Args: df_list: List containing DataFrames with several metrics to compare, preferably metrics computed for each user. One DataFrame corresponds to one learning schema Returns: A Pandas DataFrame where each combination of learning schemas are compared in pair. The first value of each cell is the ***statistic***, the second is the ***p-value*** \"\"\" # we consider the 'user_id' index as a column df_list = [ df . reset_index () if 'user_id' not in df . columns else df for df in df_list ] final_result = defaultdict ( list ) n_system_evaluated = 1 while len ( df_list ) != 0 : df1 = df_list . pop ( 0 ) for i , other_df in enumerate ( df_list , start = n_system_evaluated + 1 ): common_metrics = [ column for column in df1 . columns if column != 'user_id' and column in other_df . columns ] common_rows = self . _common_users ( df1 , other_df , list ( common_metrics )) final_result [ \"Systems evaluated\" ] . append (( f \"system_ { n_system_evaluated } \" , f \"system_ { i } \" )) for metric in common_metrics : # drop nan values since otherwise test may behave unexpectedly metric_rows = common_rows [[ f \" { metric } _x\" , f \" { metric } _y\" ]] . dropna () score_system1 = metric_rows [ f \" { metric } _x\" ] score_system2 = metric_rows [ f \" { metric } _y\" ] single_metric_result = self . _perform_test ( score_system1 , score_system2 ) final_result [ metric ] . append ( single_metric_result ) n_system_evaluated += 1 return pd . DataFrame ( final_result ) . set_index ( \"Systems evaluated\" ) Ttest Bases: PairedTest Calculate the T-test for the means of two independent samples of scores. This is a two-sided test for the null hypothesis that 2 independent samples have identical average (expected) values. This test assumes that the populations have identical variances by default. Wilcoxon Bases: PairedTest Compute the Wilcoxon rank-sum statistic for two samples. The Wilcoxon rank-sum test tests the null hypothesis that two sets of measurements are drawn from the same distribution. The alternative hypothesis is that values in one sample are more likely to be larger than the values in the other sample.","title":"Paired"},{"location":"evaluation/statistical_tests/paired/#paired-statistical-tests","text":"","title":"Paired statistical tests"},{"location":"evaluation/statistical_tests/paired/#clayrs.evaluation.statistical_test.PairedTest","text":"Bases: StatisticalTest","title":"PairedTest"},{"location":"evaluation/statistical_tests/paired/#clayrs.evaluation.statistical_test.PairedTest.perform","text":"Method which performs the chosen paired statistical test. Since it's a paired test, the final result is a pandas DataFrame which contains learning schemas compared in pair. For example if you call the perform() method by passing a list containing three different DataFrames, one for each learning schema to compare: # Ttest as example since it's a Paired Test Ttest () . perform ([ user_df1 , user_df2 , user_df3 ]) You will obtain a DataFrame comparing all different combinations: (system1, system2) (system1, system3) (system2, system3) The first value of each cell is the statistic , the second is the p-value PARAMETER DESCRIPTION df_list List containing DataFrames with several metrics to compare, preferably metrics computed for each user. One DataFrame corresponds to one learning schema TYPE: List [ pd . DataFrame ] RETURNS DESCRIPTION pd . DataFrame A Pandas DataFrame where each combination of learning schemas are compared in pair. The first value of each cell is the statistic , the second is the p-value Source code in clayrs/evaluation/statistical_test.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def perform ( self , df_list : List [ pd . DataFrame ]) -> pd . DataFrame : \"\"\" Method which performs the chosen paired statistical test. Since it's a paired test, the final result is a pandas DataFrame which contains learning schemas compared in pair. For example if you call the `perform()` method by passing a list containing three different DataFrames, one for each learning schema to compare: ```python # Ttest as example since it's a Paired Test Ttest().perform([user_df1, user_df2, user_df3]) ``` You will obtain a DataFrame comparing all different combinations: * (system1, system2) * (system1, system3) * (system2, system3) The first value of each cell is the ***statistic***, the second is the ***p-value*** Args: df_list: List containing DataFrames with several metrics to compare, preferably metrics computed for each user. One DataFrame corresponds to one learning schema Returns: A Pandas DataFrame where each combination of learning schemas are compared in pair. The first value of each cell is the ***statistic***, the second is the ***p-value*** \"\"\" # we consider the 'user_id' index as a column df_list = [ df . reset_index () if 'user_id' not in df . columns else df for df in df_list ] final_result = defaultdict ( list ) n_system_evaluated = 1 while len ( df_list ) != 0 : df1 = df_list . pop ( 0 ) for i , other_df in enumerate ( df_list , start = n_system_evaluated + 1 ): common_metrics = [ column for column in df1 . columns if column != 'user_id' and column in other_df . columns ] common_rows = self . _common_users ( df1 , other_df , list ( common_metrics )) final_result [ \"Systems evaluated\" ] . append (( f \"system_ { n_system_evaluated } \" , f \"system_ { i } \" )) for metric in common_metrics : # drop nan values since otherwise test may behave unexpectedly metric_rows = common_rows [[ f \" { metric } _x\" , f \" { metric } _y\" ]] . dropna () score_system1 = metric_rows [ f \" { metric } _x\" ] score_system2 = metric_rows [ f \" { metric } _y\" ] single_metric_result = self . _perform_test ( score_system1 , score_system2 ) final_result [ metric ] . append ( single_metric_result ) n_system_evaluated += 1 return pd . DataFrame ( final_result ) . set_index ( \"Systems evaluated\" )","title":"perform()"},{"location":"evaluation/statistical_tests/paired/#clayrs.evaluation.statistical_test.Ttest","text":"Bases: PairedTest Calculate the T-test for the means of two independent samples of scores. This is a two-sided test for the null hypothesis that 2 independent samples have identical average (expected) values. This test assumes that the populations have identical variances by default.","title":"Ttest"},{"location":"evaluation/statistical_tests/paired/#clayrs.evaluation.statistical_test.Wilcoxon","text":"Bases: PairedTest Compute the Wilcoxon rank-sum statistic for two samples. The Wilcoxon rank-sum test tests the null hypothesis that two sets of measurements are drawn from the same distribution. The alternative hypothesis is that values in one sample are more likely to be larger than the values in the other sample.","title":"Wilcoxon"},{"location":"first_steps/colab_examples/","text":"Colab examples The GitHub repository hosts some IPython notebooks to get you start and running with the framework! To use them you could use Google colab : Go to Colab and open File > Open notebook Then go to GitHub section, write swapUniba/ClayRS in the first text box and choose the example you want to run! Available examples All the following use the Movielens 100k dataset 1_tfidf_centroid.ipynb : the easiest example, a good starting point for newcomers of the framework. It guides you in how to represent via TfIdf technique a field of the raw source , how to instantiate a CentroidVector algorithm and how to evaluate recommendations generated with several state-of-the-art metrics; 2_embeddings_randomforest.ipynb : a slightly more complex example, where several fields are represented with several techniques , including embedding techniques . For the recommendation phase a Random Forest classifier is used; 3_graph_pagerank.ipynb : it will guide you on how to perform graph based recommendation via ClayRS (how to instantiate a graph, how to manipulate it, how to load exogenous properties). The Personalized PageRank algorithm is used in the recsys phase; 4_evaluate_other_recs.ipynb : a jolly example which shows how to export results (and intermediate results) obtained by ClayRS , but also how to evaluate external recommendation lists (i.e. recommendations generated via other tools)","title":"Colab examples"},{"location":"first_steps/colab_examples/#colab-examples","text":"The GitHub repository hosts some IPython notebooks to get you start and running with the framework! To use them you could use Google colab : Go to Colab and open File > Open notebook Then go to GitHub section, write swapUniba/ClayRS in the first text box and choose the example you want to run!","title":"Colab examples"},{"location":"first_steps/colab_examples/#available-examples","text":"All the following use the Movielens 100k dataset 1_tfidf_centroid.ipynb : the easiest example, a good starting point for newcomers of the framework. It guides you in how to represent via TfIdf technique a field of the raw source , how to instantiate a CentroidVector algorithm and how to evaluate recommendations generated with several state-of-the-art metrics; 2_embeddings_randomforest.ipynb : a slightly more complex example, where several fields are represented with several techniques , including embedding techniques . For the recommendation phase a Random Forest classifier is used; 3_graph_pagerank.ipynb : it will guide you on how to perform graph based recommendation via ClayRS (how to instantiate a graph, how to manipulate it, how to load exogenous properties). The Personalized PageRank algorithm is used in the recsys phase; 4_evaluate_other_recs.ipynb : a jolly example which shows how to export results (and intermediate results) obtained by ClayRS , but also how to evaluate external recommendation lists (i.e. recommendations generated via other tools)","title":"Available examples"},{"location":"first_steps/installation/","text":"Installation Via PIP recommended ClayRS requires Python 3.7 or later, while package dependencies are in requirements.txt and are all installable via pip , as ClayRS itself. To install it execute the following command: Latest pip install clayrs This will automatically install compatible versions of all dependencies. Tip : We suggest installing ClayRS (or any python package, for that matters) in a virtual environment Virtual environments are special isolated environments where all the packages and versions you install only apply to that specific environment. It\u2019s like a private island! \u2014 but for code. Read this Medium article for understanding all the advantages and the official python guide on how to set up one","title":"Installation"},{"location":"first_steps/installation/#installation","text":"","title":"Installation"},{"location":"first_steps/installation/#via-pip-recommended","text":"ClayRS requires Python 3.7 or later, while package dependencies are in requirements.txt and are all installable via pip , as ClayRS itself. To install it execute the following command: Latest pip install clayrs This will automatically install compatible versions of all dependencies. Tip : We suggest installing ClayRS (or any python package, for that matters) in a virtual environment Virtual environments are special isolated environments where all the packages and versions you install only apply to that specific environment. It\u2019s like a private island! \u2014 but for code. Read this Medium article for understanding all the advantages and the official python guide on how to set up one","title":"Via PIP"},{"location":"first_steps/quickstart/","text":"Quickstart Content Analyzer The first thing to do is to import the Content Analyzer module * We will access its methods and classes via dot notation import clayrs.content_analyzer as ca Then, let's point to the source containing raw information to process raw_source = ca . JSONFile ( 'items_info.json' ) We can now start building the configuration for the items Info Note that same operations that can be specified for items could be also specified for users via the ca . UserAnalyzerConfig class # Configuration of item representation movies_ca_config = ca . ItemAnalyzerConfig ( source = raw_source , id = 'movielens_id' , # (1) output_directory = 'movies_codified/' # (2) ) The id in the raw source which uniquely identifies each item Directory which will contain items complexly represented Let's represent the plot field of each content with a TfIdf representation Since the preprocessing parameter has been specified, then each field is first preprocessed with the specified operations movies_ca_config . add_single_config ( 'plot' , ca . FieldConfig ( ca . SkLearnTfIdf (), preprocessing = ca . NLTK ( stopwords_removal = True , lemmatization = True ), id = 'tfidf' ) # (1) ) User defined id for the representation To finalize the Content Analyzer part, let's instantiate the ContentAnalyzer class by passing the built configuration and by calling its fit() method ca . ContentAnalyzer ( movies_ca_config ) . fit () The items will be created with the specified representations and serialized RecSys Similarly above, we must first import the RecSys module import clayrs.recsys as rs Then we load the rating frame from a TSV file Info In this case in our file the first three columns are user_id, item_id, score in this order If your file has a different structure you must specify how to map the column via parameters, check documentation for more ratings = ca . Ratings ( ca . CSVFile ( 'ratings.tsv' , separator = ' \\t ' )) Let's split with the KFold technique the loaded rating frame into train set and test set since n_splits=2 , train_list will contain two train_sets and test_list will contain two test_sets train_list , test_list = rs . KFoldPartitioning ( n_splits = 2 ) . split_all ( ratings ) In order to recommend items to users, we must choose an algorithm to use In this case we are using the CentroidVector algorithm which will work by using the first representation specified for the plot field You can freely choose which representation to use among all representation codified for the fields in the Content Analyzer phase centroid_vec = rs . CentroidVector ( { 'plot' : 'tfidf' }, # (1) similarity = rs . CosineSimilarity () ) We can reference the representation specified for the 'plot' field with the assigned custom id in the Content Analyzer phase Let's now compute the top-10 ranking for each user of the train set By default the candidate items are those in the test set of the user, but you can change this behaviour with the methodology parameter Since we used the kfold technique, we iterate over all train sets and test sets result_list = [] for train_set , test_set in zip ( train_list , test_list ): cbrs = rs . ContentBasedRS ( centroid_vec , train_set , 'movies_codified/' ) rank = cbrs . fit_rank ( test_set , n_recs = 10 ) result_list . append ( rank ) result_list will contain two Rank objects in this case, one for each split Evaluation module Similarly to the Content Analyzer and RecSys module, we must first import the evaluation module import clayrs.evaluation as eva The class responsible for evaluating recommendation lists is the EvalModel class. It needs the following parameters: A list of computed rank/predictions (in case multiple splits must be evaluated) A list of truths (in case multiple splits must be evaluated) List of metrics to compute Obviously the list of computed rank/predictions and list of truths must have the same length, and the rank/prediction in position \\(i\\) will be compared with the truth at position \\(i\\) em = eva . EvalModel ( pred_list = result_list , truth_list = test_list , metric_list = [ eva . NDCG (), eva . Precision (), eva . RecallAtK ( k = 5 ) ] ) Then simply call the fit () method of the instantiated object It will return two pandas DataFrame: the first one contains the metrics aggregated for the system, while the second contains the metrics computed for each user (where possible) sys_result , users_result = em . fit () Note Note that the EvalModel is able to compute evaluation of recommendations generated by other tools/frameworks, check documentation for more","title":"Quickstart"},{"location":"first_steps/quickstart/#quickstart","text":"","title":"Quickstart"},{"location":"first_steps/quickstart/#content-analyzer","text":"The first thing to do is to import the Content Analyzer module * We will access its methods and classes via dot notation import clayrs.content_analyzer as ca Then, let's point to the source containing raw information to process raw_source = ca . JSONFile ( 'items_info.json' ) We can now start building the configuration for the items Info Note that same operations that can be specified for items could be also specified for users via the ca . UserAnalyzerConfig class # Configuration of item representation movies_ca_config = ca . ItemAnalyzerConfig ( source = raw_source , id = 'movielens_id' , # (1) output_directory = 'movies_codified/' # (2) ) The id in the raw source which uniquely identifies each item Directory which will contain items complexly represented Let's represent the plot field of each content with a TfIdf representation Since the preprocessing parameter has been specified, then each field is first preprocessed with the specified operations movies_ca_config . add_single_config ( 'plot' , ca . FieldConfig ( ca . SkLearnTfIdf (), preprocessing = ca . NLTK ( stopwords_removal = True , lemmatization = True ), id = 'tfidf' ) # (1) ) User defined id for the representation To finalize the Content Analyzer part, let's instantiate the ContentAnalyzer class by passing the built configuration and by calling its fit() method ca . ContentAnalyzer ( movies_ca_config ) . fit () The items will be created with the specified representations and serialized","title":"Content Analyzer"},{"location":"first_steps/quickstart/#recsys","text":"Similarly above, we must first import the RecSys module import clayrs.recsys as rs Then we load the rating frame from a TSV file Info In this case in our file the first three columns are user_id, item_id, score in this order If your file has a different structure you must specify how to map the column via parameters, check documentation for more ratings = ca . Ratings ( ca . CSVFile ( 'ratings.tsv' , separator = ' \\t ' )) Let's split with the KFold technique the loaded rating frame into train set and test set since n_splits=2 , train_list will contain two train_sets and test_list will contain two test_sets train_list , test_list = rs . KFoldPartitioning ( n_splits = 2 ) . split_all ( ratings ) In order to recommend items to users, we must choose an algorithm to use In this case we are using the CentroidVector algorithm which will work by using the first representation specified for the plot field You can freely choose which representation to use among all representation codified for the fields in the Content Analyzer phase centroid_vec = rs . CentroidVector ( { 'plot' : 'tfidf' }, # (1) similarity = rs . CosineSimilarity () ) We can reference the representation specified for the 'plot' field with the assigned custom id in the Content Analyzer phase Let's now compute the top-10 ranking for each user of the train set By default the candidate items are those in the test set of the user, but you can change this behaviour with the methodology parameter Since we used the kfold technique, we iterate over all train sets and test sets result_list = [] for train_set , test_set in zip ( train_list , test_list ): cbrs = rs . ContentBasedRS ( centroid_vec , train_set , 'movies_codified/' ) rank = cbrs . fit_rank ( test_set , n_recs = 10 ) result_list . append ( rank ) result_list will contain two Rank objects in this case, one for each split","title":"RecSys"},{"location":"first_steps/quickstart/#evaluation-module","text":"Similarly to the Content Analyzer and RecSys module, we must first import the evaluation module import clayrs.evaluation as eva The class responsible for evaluating recommendation lists is the EvalModel class. It needs the following parameters: A list of computed rank/predictions (in case multiple splits must be evaluated) A list of truths (in case multiple splits must be evaluated) List of metrics to compute Obviously the list of computed rank/predictions and list of truths must have the same length, and the rank/prediction in position \\(i\\) will be compared with the truth at position \\(i\\) em = eva . EvalModel ( pred_list = result_list , truth_list = test_list , metric_list = [ eva . NDCG (), eva . Precision (), eva . RecallAtK ( k = 5 ) ] ) Then simply call the fit () method of the instantiated object It will return two pandas DataFrame: the first one contains the metrics aggregated for the system, while the second contains the metrics computed for each user (where possible) sys_result , users_result = em . fit () Note Note that the EvalModel is able to compute evaluation of recommendations generated by other tools/frameworks, check documentation for more","title":"Evaluation module"},{"location":"recsys/experiment/","text":"Experiment class ContentBasedExperiment ( original_ratings , partitioning_technique , algorithm_list , items_directory , users_directory = None , metric_list = None , report = False , output_folder = 'experiment_result' , overwrite_if_exists = False ) Bases: Experiment The Experiment class for content based algorithms It provides an easy interface to perform a complete experiment by comparing different cb-algorithms, starting from splitting the dataset to evaluating predictions computed. It is also capable of producing a yml report for both the recsys phase and the evaluation phase. Both the evaluation phase and the report are optional and are produced only if specified. All the results ( split , ranking , evaluation results , etc.) will be saved in the folder specified with the output_folder parameter. For each algorithm a different sub-folder will be created and named after it: If multiple instances of the same algorithm are present in the algorithm_list , sub-folders will be disambiguated depending on the order of execution ( algName_1 , algName_2 , algName_3 , etc.) Info Please remember that by default if a folder with same name of the output_folder parameter is present, the experiment won't run and an exception will be raised. To overcome this, simply set the overwrite_if_exists parameter to True or change the output_folder . Examples: Suppose you want to compare: A CentroidVector algorithm The SVC classifier The KNN classifier For the three different configuration, an HoldOut partitioning technique should be used and results should be evaluated on \\(Precision\\) and \\(Recall\\) from clayrs.utils import ContentBasedExperiment from clayrs import content_analyzer as ca from clayrs import content_analyzer as rs original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) alg1 = rs . CentroidVector ({ 'Plot' : 'tfidf' }, similarity = rs . CosineSimilarity ()) # (1) alg2 = rs . ClassifierRecommender ({ 'Plot' : 'tfidf' }, classifier = rs . SkSVC ()) # (2) alg3 = rs . ClassifierRecommender ({ 'Plot' : 'tfidf' }, classifier = rs . SkKNN ()) # (3) a = ContentBasedExperiment ( original_ratings = rat , partitioning_technique = rs . HoldOutPartitioning (), algorithm_list = [ alg1 , alg2 , alg3 ], items_directory = movies_dir , metric_list = [ eva . Precision (), eva . Recall ()] output_folder = \"my_experiment\" ) a . rank () Results will be saved in my_experiment/CentroidVector_1 Results will be saved in my_experiment/ClassifierRecommender_1 Results will be saved in my_experiment/ClassifierRecommender_2 PARAMETER DESCRIPTION original_ratings Ratings object containing original interactions between users and items TYPE: Ratings partitioning_technique Partitioning object which specifies how the original ratings should be split TYPE: Partitioning algorithm_list List of Content Based algorithms for which the whole experiment will be conducted TYPE: List [ ContentBasedAlgorithm ] items_directory Path to the folder containing serialized complexly represented items TYPE: str users_directory Path to the folder containing serialized complexly represented items. Needed only if one or more algorithms in algorithm_list needs it TYPE: str DEFAULT: None metric_list List of metric with which predictions computed by the CBRS will be evaluated TYPE: List [ Metric ] DEFAULT: None report If True , a yml report will be produced for the recsys phase. It will be also produced for the evaluation phase, but only if the metric_list parameter is set TYPE: bool DEFAULT: False output_folder Path of the folder where all the results of the experiment will be saved TYPE: str DEFAULT: 'experiment_result' overwrite_if_exists If True and the path set in output_folder points to an already existent directory, it will be deleted and replaced by the folder containing the experiment results TYPE: bool DEFAULT: False Source code in clayrs/recsys/experiment.py 302 303 304 305 306 307 308 309 310 311 312 313 def __init__ ( self , original_ratings : Ratings , partitioning_technique : Partitioning , algorithm_list : List [ ContentBasedAlgorithm ], items_directory : str , users_directory : str = None , metric_list : List [ Metric ] = None , report : bool = False , output_folder : str = \"experiment_result\" , overwrite_if_exists : bool = False ): super () . __init__ ( original_ratings , partitioning_technique , algorithm_list , items_directory , users_directory , metric_list , report , output_folder , overwrite_if_exists ) predict ( methodology = TestRatingsMethodology (), num_cpus = 0 , skip_alg_error = True ) Method used to perform an experiment which involves score predictions . The method will first split the original ratings passed in the constructor in train and test set, then the Recommender System will be fit for each user in the train set. If the algorithm can't be fit for some users, a warning message is printed and no score predictions will be computed for said user Info BE CAREFUL : not all algorithms are able to perform score prediction . In case a pure ranking algorithm is asked to perform score prediction, the NotPredictionAlg will be raised. if the skip_alg_error is set to True , then said exception will be caught, a warning will be printed, and the experiment will go on with the next algorithm Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be considered for score prediction PARAMETER DESCRIPTION methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 0 skip_alg_error If set to True , a pure ranking algorithm will be skipped and the experiment will continue with the following algorithm. Otherwise, the NotPredictionAlg exception raised will be re-raised TYPE: bool DEFAULT: True RAISES DESCRIPTION NotPredictionAlg When a pure ranking algorithm is asked to perform score prediction and skip_alg_error == False Source code in clayrs/recsys/experiment.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 def predict ( self , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 0 , skip_alg_error : bool = True ) -> None : \"\"\" Method used to perform an experiment which involves ***score predictions***. The method will first split the original ratings passed in the constructor in train and test set, then the Recommender System will be fit for each user in the train set. If the algorithm can't be fit for some users, a warning message is printed and no score predictions will be computed for said user !!! info **BE CAREFUL**: not all algorithms are able to perform *score prediction*. In case a pure ranking algorithm is asked to perform score prediction, the `NotPredictionAlg` will be raised. if the `skip_alg_error` is set to `True`, then said exception will be caught, a warning will be printed, and the experiment will go on with the next algorithm Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be considered for score prediction Args: methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. skip_alg_error: If set to `True`, a pure ranking algorithm will be skipped and the experiment will continue with the following algorithm. Otherwise, the `NotPredictionAlg` exception raised will be re-raised Raises: NotPredictionAlg: When a pure ranking algorithm is asked to perform score prediction and `skip_alg_error` == False \"\"\" def cb_fit_predict ( split_num , alg , train_set , test_set , dirname ): cbrs = ContentBasedRS ( alg , train_set , self . items_directory ) predict_alg = cbrs . fit_predict ( test_set , methodology = methodology , num_cpus = num_cpus ) predict_alg . to_csv ( f \" { self . output_folder } / { dirname } \" , file_name = f \"rs_predict_split { split_num } \" ) if self . report : Report ( output_dir = f \" { self . output_folder } / { dirname } \" ) . yaml ( original_ratings = self . original_ratings , partitioning_technique = self . pt , recsys = cbrs ) return predict_alg self . main_experiment ( cb_fit_predict , skip_alg_error = skip_alg_error ) rank ( n_recs = 10 , methodology = TestRatingsMethodology (), num_cpus = 0 ) Method used to perform an experiment which involves rankings . The method will first split the original ratings passed in the constructor in train and test set, then the Recommender System will be fit for each user in the train. If the algorithm can't be fit for some users, a warning message is printed and no ranking will be computed for said user Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be considered as eligible for ranking PARAMETER DESCRIPTION n_recs Number of the top items that will be present in the ranking of each user. If None all candidate items will be returned for the user TYPE: int DEFAULT: 10 methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected TYPE: int DEFAULT: 0 Source code in clayrs/recsys/experiment.py 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 def rank ( self , n_recs : int = 10 , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 0 ): \"\"\" Method used to perform an experiment which involves ***rankings***. The method will first split the original ratings passed in the constructor in train and test set, then the Recommender System will be fit for each user in the train. If the algorithm can't be fit for some users, a warning message is printed and no ranking will be computed for said user Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be considered as eligible for ranking Args: n_recs: Number of the top items that will be present in the ranking of each user. If `None` all candidate items will be returned for the user methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected \"\"\" def cb_fit_rank ( split_num , alg , train_set , test_set , dirname ): cbrs = ContentBasedRS ( alg , train_set , self . items_directory ) predict_alg = cbrs . fit_rank ( test_set , n_recs = n_recs , methodology = methodology , num_cpus = num_cpus ) predict_alg . to_csv ( f \" { self . output_folder } / { dirname } \" , file_name = f \"rs_rank_split { split_num } \" ) if self . report : Report ( output_dir = f \" { self . output_folder } / { dirname } \" ) . yaml ( original_ratings = self . original_ratings , partitioning_technique = self . pt , recsys = cbrs ) return predict_alg self . main_experiment ( cb_fit_rank ) GraphBasedExperiment ( original_ratings , partitioning_technique , algorithm_list , items_directory = None , item_exo_properties = None , users_directory = None , user_exo_properties = None , link_label = None , metric_list = None , report = False , output_folder = 'experiment_result' , overwrite_if_exists = False ) Bases: Experiment The Experiment class for graph based algorithms It provides an easy interface to perform a complete experiment by comparing different gb-algorithms, starting from splitting the dataset to evaluating predictions computed. Every graph based algorithm expects a graph: that's why right before computing ranking/score predictions, a graph will be created depending on the current train and test split (if multiple are available): All the nodes from the original graph will be present, The interactions in the test set will be missing (It won't be represented as a link between a user node and an item node) The class is also capable of producing a yml report for both the recsys phase and the evaluation phase. Both the evaluation phase and the report are optional and are produced only if specified. All the results ( split , ranking , evaluation results , etc.) will be saved in the folder specified with the output_folder parameter. For each algorithm a different sub-folder will be created and named after it: If multiple instances of the same algorithm are present in the algorithm_list , sub-folders will be disambiguated depending on the order of execution ( algName_1 , algName_2 , algName_3 , etc.) Info Please remember that by default if a folder with same name of the output_folder parameter is present, the experiment won't run and an exception will be raised. To overcome this, simply set the overwrite_if_exists parameter to True or change the output_folder . Examples: Suppose you want to compare: The PageRank algorithm with alpha=0.8 The PageRank algorithm with alpha=0.9 The Personalized PageRank algorithm For the three different configuration, a KFold partitioning technique with three splits should be used and results should be evaluated on \\(Precision\\) , \\(Recall\\) , \\(NDCG\\) from clayrs.utils import GraphBasedExperiment from clayrs import content_analyzer as ca from clayrs import content_analyzer as rs original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) alg1 = rs . NXPageRank ( alpha = 0.8 ) # (1) alg2 = rs . NXPageRank ( alpha = 0.9 ) # (2) alg3 = rs . NXPageRank ( personalized = True ) # (3) a = GraphBasedExperiment ( original_ratings = rat , partitioning_technique = rs . KFoldPartitioning ( n_splits = 3 ), algorithm_list = [ alg1 , alg2 , alg3 ], items_directory = movies_dir , metric_list = [ eva . Precision (), eva . Recall ()] output_folder = \"my_experiment\" ) a . rank () Results will be saved in my_experiment/NXPageRank_1 Results will be saved in my_experiment/NXPageRank_2 Results will be saved in my_experiment/NXPageRank_3 PARAMETER DESCRIPTION original_ratings Ratings object containing original interactions between users and items TYPE: Ratings partitioning_technique Partitioning object which specifies how the original ratings should be split TYPE: Partitioning algorithm_list List of Graph Based algorithms for which the whole experiment will be conducted TYPE: List [ GraphBasedAlgorithm ] items_directory Path to the folder containing serialized complexly represented items with one or more exogenous property to load TYPE: str DEFAULT: None item_exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] DEFAULT: None users_directory Path to the folder containing serialized complexly represented users with one or more exogenous property to load TYPE: str DEFAULT: None user_exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] DEFAULT: None link_label If specified, each link between user and item nodes will be labeled with the given label. Default is None TYPE: str DEFAULT: None metric_list List of metric with which predictions computed by the GBRS will be evaluated TYPE: List [ Metric ] DEFAULT: None report If True , a yml report will be produced for the recsys phase. It will be also produced for the evaluation phase, but only if the metric_list parameter is set TYPE: bool DEFAULT: False output_folder Path of the folder where all the results of the experiment will be saved TYPE: str DEFAULT: 'experiment_result' overwrite_if_exists If True and the path set in output_folder points to an already existent directory, it will be deleted and replaced by the folder containing the experiment results TYPE: bool DEFAULT: False Source code in clayrs/recsys/experiment.py 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 def __init__ ( self , original_ratings : Ratings , partitioning_technique : Partitioning , algorithm_list : List [ GraphBasedAlgorithm ], items_directory : str = None , item_exo_properties : Union [ Dict , set ] = None , users_directory : str = None , user_exo_properties : Union [ Dict , set ] = None , link_label : str = None , metric_list : List [ Metric ] = None , report : bool = False , output_folder : str = \"experiment_result\" , overwrite_if_exists : bool = False ): super () . __init__ ( original_ratings , partitioning_technique , algorithm_list , items_directory , users_directory , metric_list , report , output_folder , overwrite_if_exists ) self . item_exo_properties = item_exo_properties self . user_exo_properties = user_exo_properties self . link_label = link_label predict ( methodology = TestRatingsMethodology (), num_cpus = 0 , skip_alg_error = True ) Method used to perform an experiment which involves score predictions . The method will first split the original ratings passed in the constructor in train and test set, then a graph will be built depending on them: All nodes of the original ratings will be present, but the links ( interactions ) that are present in the test set will be missing, so to make the training phase fair Info BE CAREFUL : not all algorithms are able to perform score prediction . In case a pure ranking algorithm is asked to perform score prediction, the NotPredictionAlg will be raised. if the skip_alg_error is set to True , then said exception will be caught, a warning will be printed, and the experiment will go on with the next algorithm Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be considered for score prediction PARAMETER DESCRIPTION methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 0 skip_alg_error If set to True , a pure ranking algorithm will be skipped and the experiment will continue with the following algorithm. Otherwise, the NotPredictionAlg exception raised will be re-raised TYPE: bool DEFAULT: True RAISES DESCRIPTION NotPredictionAlg When a pure ranking algorithm is asked to perform score prediction and skip_alg_error == False Source code in clayrs/recsys/experiment.py 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 def predict ( self , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 0 , skip_alg_error : bool = True ): \"\"\" Method used to perform an experiment which involves ***score predictions***. The method will first split the original ratings passed in the constructor in train and test set, then a graph will be built depending on them: * All nodes of the original ratings will be present, but the *links* (***interactions***) that are present in the test set will be missing, so to make the training phase *fair* !!! info **BE CAREFUL**: not all algorithms are able to perform *score prediction*. In case a pure ranking algorithm is asked to perform score prediction, the `NotPredictionAlg` will be raised. if the `skip_alg_error` is set to `True`, then said exception will be caught, a warning will be printed, and the experiment will go on with the next algorithm Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be considered for score prediction Args: methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. skip_alg_error: If set to `True`, a pure ranking algorithm will be skipped and the experiment will continue with the following algorithm. Otherwise, the `NotPredictionAlg` exception raised will be re-raised Raises: NotPredictionAlg: When a pure ranking algorithm is asked to perform score prediction and `skip_alg_error` == False \"\"\" def gb_fit_predict ( split_num , alg , train_set , test_set , dirname ): graph = NXFullGraph ( self . original_ratings , item_contents_dir = self . items_directory , item_exo_properties = self . item_exo_properties , user_contents_dir = self . users_directory , user_exo_properties = self . user_exo_properties , link_label = self . link_label ) for user , item in zip ( test_set . user_id_column , test_set . item_id_column ): graph . remove_link ( UserNode ( user ), ItemNode ( item )) gbrs = GraphBasedRS ( alg , graph ) predict_alg = gbrs . predict ( test_set , methodology = methodology , num_cpus = num_cpus ) predict_alg . to_csv ( f \" { self . output_folder } / { dirname } \" , file_name = f \"rs_predict_split { split_num } \" ) if self . report : Report ( output_dir = f \" { self . output_folder } / { dirname } \" ) . yaml ( original_ratings = self . original_ratings , partitioning_technique = self . pt , recsys = gbrs ) return predict_alg self . main_experiment ( gb_fit_predict , skip_alg_error = skip_alg_error ) rank ( n_recs = 10 , methodology = TestRatingsMethodology (), num_cpus = 0 ) Method used to perform an experiment which involves rankings . The method will first split the original ratings passed in the constructor in train and test set, then a graph will be built depending on them: All nodes of the original ratings will be present, but the links ( interactions ) that are present in the test set will be missing, so to make the training phase fair Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used, so for each user, items in its test set only will be eligible for ranking PARAMETER DESCRIPTION n_recs Number of the top items that will be present in the ranking of each user. If None all candidate items will be returned for the user TYPE: int DEFAULT: 10 methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 0 Source code in clayrs/recsys/experiment.py 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 def rank ( self , n_recs : int = 10 , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 0 ): \"\"\" Method used to perform an experiment which involves ***rankings***. The method will first split the original ratings passed in the constructor in train and test set, then a graph will be built depending on them: * All nodes of the original ratings will be present, but the *links* (***interactions***) that are present in the test set will be missing, so to make the training phase *fair* Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used, so for each user, items in its test set only will be eligible for ranking Args: n_recs: Number of the top items that will be present in the ranking of each user. If `None` all candidate items will be returned for the user methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. \"\"\" def gb_fit_rank ( split_num , alg , train_set , test_set , dirname ): graph = NXFullGraph ( self . original_ratings , item_contents_dir = self . items_directory , item_exo_properties = self . item_exo_properties , user_contents_dir = self . users_directory , user_exo_properties = self . user_exo_properties , link_label = self . link_label ) for user , item in zip ( test_set . user_id_column , test_set . item_id_column ): graph . remove_link ( UserNode ( user ), ItemNode ( item )) gbrs = GraphBasedRS ( alg , graph ) predict_alg = gbrs . rank ( test_set , n_recs = n_recs , methodology = methodology , num_cpus = num_cpus ) predict_alg . to_csv ( f \" { self . output_folder } / { dirname } \" , file_name = f \"rs_rank_split { split_num } \" ) if self . report : Report ( output_dir = f \" { self . output_folder } / { dirname } \" ) . yaml ( original_ratings = self . original_ratings , partitioning_technique = self . pt , recsys = gbrs ) return predict_alg self . main_experiment ( gb_fit_rank )","title":"Experiment class"},{"location":"recsys/experiment/#experiment-class","text":"","title":"Experiment class"},{"location":"recsys/experiment/#clayrs.recsys.ContentBasedExperiment","text":"Bases: Experiment The Experiment class for content based algorithms It provides an easy interface to perform a complete experiment by comparing different cb-algorithms, starting from splitting the dataset to evaluating predictions computed. It is also capable of producing a yml report for both the recsys phase and the evaluation phase. Both the evaluation phase and the report are optional and are produced only if specified. All the results ( split , ranking , evaluation results , etc.) will be saved in the folder specified with the output_folder parameter. For each algorithm a different sub-folder will be created and named after it: If multiple instances of the same algorithm are present in the algorithm_list , sub-folders will be disambiguated depending on the order of execution ( algName_1 , algName_2 , algName_3 , etc.) Info Please remember that by default if a folder with same name of the output_folder parameter is present, the experiment won't run and an exception will be raised. To overcome this, simply set the overwrite_if_exists parameter to True or change the output_folder . Examples: Suppose you want to compare: A CentroidVector algorithm The SVC classifier The KNN classifier For the three different configuration, an HoldOut partitioning technique should be used and results should be evaluated on \\(Precision\\) and \\(Recall\\) from clayrs.utils import ContentBasedExperiment from clayrs import content_analyzer as ca from clayrs import content_analyzer as rs original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) alg1 = rs . CentroidVector ({ 'Plot' : 'tfidf' }, similarity = rs . CosineSimilarity ()) # (1) alg2 = rs . ClassifierRecommender ({ 'Plot' : 'tfidf' }, classifier = rs . SkSVC ()) # (2) alg3 = rs . ClassifierRecommender ({ 'Plot' : 'tfidf' }, classifier = rs . SkKNN ()) # (3) a = ContentBasedExperiment ( original_ratings = rat , partitioning_technique = rs . HoldOutPartitioning (), algorithm_list = [ alg1 , alg2 , alg3 ], items_directory = movies_dir , metric_list = [ eva . Precision (), eva . Recall ()] output_folder = \"my_experiment\" ) a . rank () Results will be saved in my_experiment/CentroidVector_1 Results will be saved in my_experiment/ClassifierRecommender_1 Results will be saved in my_experiment/ClassifierRecommender_2 PARAMETER DESCRIPTION original_ratings Ratings object containing original interactions between users and items TYPE: Ratings partitioning_technique Partitioning object which specifies how the original ratings should be split TYPE: Partitioning algorithm_list List of Content Based algorithms for which the whole experiment will be conducted TYPE: List [ ContentBasedAlgorithm ] items_directory Path to the folder containing serialized complexly represented items TYPE: str users_directory Path to the folder containing serialized complexly represented items. Needed only if one or more algorithms in algorithm_list needs it TYPE: str DEFAULT: None metric_list List of metric with which predictions computed by the CBRS will be evaluated TYPE: List [ Metric ] DEFAULT: None report If True , a yml report will be produced for the recsys phase. It will be also produced for the evaluation phase, but only if the metric_list parameter is set TYPE: bool DEFAULT: False output_folder Path of the folder where all the results of the experiment will be saved TYPE: str DEFAULT: 'experiment_result' overwrite_if_exists If True and the path set in output_folder points to an already existent directory, it will be deleted and replaced by the folder containing the experiment results TYPE: bool DEFAULT: False Source code in clayrs/recsys/experiment.py 302 303 304 305 306 307 308 309 310 311 312 313 def __init__ ( self , original_ratings : Ratings , partitioning_technique : Partitioning , algorithm_list : List [ ContentBasedAlgorithm ], items_directory : str , users_directory : str = None , metric_list : List [ Metric ] = None , report : bool = False , output_folder : str = \"experiment_result\" , overwrite_if_exists : bool = False ): super () . __init__ ( original_ratings , partitioning_technique , algorithm_list , items_directory , users_directory , metric_list , report , output_folder , overwrite_if_exists )","title":"ContentBasedExperiment"},{"location":"recsys/experiment/#clayrs.recsys.experiment.ContentBasedExperiment.predict","text":"Method used to perform an experiment which involves score predictions . The method will first split the original ratings passed in the constructor in train and test set, then the Recommender System will be fit for each user in the train set. If the algorithm can't be fit for some users, a warning message is printed and no score predictions will be computed for said user Info BE CAREFUL : not all algorithms are able to perform score prediction . In case a pure ranking algorithm is asked to perform score prediction, the NotPredictionAlg will be raised. if the skip_alg_error is set to True , then said exception will be caught, a warning will be printed, and the experiment will go on with the next algorithm Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be considered for score prediction PARAMETER DESCRIPTION methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 0 skip_alg_error If set to True , a pure ranking algorithm will be skipped and the experiment will continue with the following algorithm. Otherwise, the NotPredictionAlg exception raised will be re-raised TYPE: bool DEFAULT: True RAISES DESCRIPTION NotPredictionAlg When a pure ranking algorithm is asked to perform score prediction and skip_alg_error == False Source code in clayrs/recsys/experiment.py 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 def predict ( self , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 0 , skip_alg_error : bool = True ) -> None : \"\"\" Method used to perform an experiment which involves ***score predictions***. The method will first split the original ratings passed in the constructor in train and test set, then the Recommender System will be fit for each user in the train set. If the algorithm can't be fit for some users, a warning message is printed and no score predictions will be computed for said user !!! info **BE CAREFUL**: not all algorithms are able to perform *score prediction*. In case a pure ranking algorithm is asked to perform score prediction, the `NotPredictionAlg` will be raised. if the `skip_alg_error` is set to `True`, then said exception will be caught, a warning will be printed, and the experiment will go on with the next algorithm Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be considered for score prediction Args: methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. skip_alg_error: If set to `True`, a pure ranking algorithm will be skipped and the experiment will continue with the following algorithm. Otherwise, the `NotPredictionAlg` exception raised will be re-raised Raises: NotPredictionAlg: When a pure ranking algorithm is asked to perform score prediction and `skip_alg_error` == False \"\"\" def cb_fit_predict ( split_num , alg , train_set , test_set , dirname ): cbrs = ContentBasedRS ( alg , train_set , self . items_directory ) predict_alg = cbrs . fit_predict ( test_set , methodology = methodology , num_cpus = num_cpus ) predict_alg . to_csv ( f \" { self . output_folder } / { dirname } \" , file_name = f \"rs_predict_split { split_num } \" ) if self . report : Report ( output_dir = f \" { self . output_folder } / { dirname } \" ) . yaml ( original_ratings = self . original_ratings , partitioning_technique = self . pt , recsys = cbrs ) return predict_alg self . main_experiment ( cb_fit_predict , skip_alg_error = skip_alg_error )","title":"predict()"},{"location":"recsys/experiment/#clayrs.recsys.experiment.ContentBasedExperiment.rank","text":"Method used to perform an experiment which involves rankings . The method will first split the original ratings passed in the constructor in train and test set, then the Recommender System will be fit for each user in the train. If the algorithm can't be fit for some users, a warning message is printed and no ranking will be computed for said user Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be considered as eligible for ranking PARAMETER DESCRIPTION n_recs Number of the top items that will be present in the ranking of each user. If None all candidate items will be returned for the user TYPE: int DEFAULT: 10 methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected TYPE: int DEFAULT: 0 Source code in clayrs/recsys/experiment.py 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 def rank ( self , n_recs : int = 10 , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 0 ): \"\"\" Method used to perform an experiment which involves ***rankings***. The method will first split the original ratings passed in the constructor in train and test set, then the Recommender System will be fit for each user in the train. If the algorithm can't be fit for some users, a warning message is printed and no ranking will be computed for said user Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be considered as eligible for ranking Args: n_recs: Number of the top items that will be present in the ranking of each user. If `None` all candidate items will be returned for the user methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected \"\"\" def cb_fit_rank ( split_num , alg , train_set , test_set , dirname ): cbrs = ContentBasedRS ( alg , train_set , self . items_directory ) predict_alg = cbrs . fit_rank ( test_set , n_recs = n_recs , methodology = methodology , num_cpus = num_cpus ) predict_alg . to_csv ( f \" { self . output_folder } / { dirname } \" , file_name = f \"rs_rank_split { split_num } \" ) if self . report : Report ( output_dir = f \" { self . output_folder } / { dirname } \" ) . yaml ( original_ratings = self . original_ratings , partitioning_technique = self . pt , recsys = cbrs ) return predict_alg self . main_experiment ( cb_fit_rank )","title":"rank()"},{"location":"recsys/experiment/#clayrs.recsys.GraphBasedExperiment","text":"Bases: Experiment The Experiment class for graph based algorithms It provides an easy interface to perform a complete experiment by comparing different gb-algorithms, starting from splitting the dataset to evaluating predictions computed. Every graph based algorithm expects a graph: that's why right before computing ranking/score predictions, a graph will be created depending on the current train and test split (if multiple are available): All the nodes from the original graph will be present, The interactions in the test set will be missing (It won't be represented as a link between a user node and an item node) The class is also capable of producing a yml report for both the recsys phase and the evaluation phase. Both the evaluation phase and the report are optional and are produced only if specified. All the results ( split , ranking , evaluation results , etc.) will be saved in the folder specified with the output_folder parameter. For each algorithm a different sub-folder will be created and named after it: If multiple instances of the same algorithm are present in the algorithm_list , sub-folders will be disambiguated depending on the order of execution ( algName_1 , algName_2 , algName_3 , etc.) Info Please remember that by default if a folder with same name of the output_folder parameter is present, the experiment won't run and an exception will be raised. To overcome this, simply set the overwrite_if_exists parameter to True or change the output_folder . Examples: Suppose you want to compare: The PageRank algorithm with alpha=0.8 The PageRank algorithm with alpha=0.9 The Personalized PageRank algorithm For the three different configuration, a KFold partitioning technique with three splits should be used and results should be evaluated on \\(Precision\\) , \\(Recall\\) , \\(NDCG\\) from clayrs.utils import GraphBasedExperiment from clayrs import content_analyzer as ca from clayrs import content_analyzer as rs original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) alg1 = rs . NXPageRank ( alpha = 0.8 ) # (1) alg2 = rs . NXPageRank ( alpha = 0.9 ) # (2) alg3 = rs . NXPageRank ( personalized = True ) # (3) a = GraphBasedExperiment ( original_ratings = rat , partitioning_technique = rs . KFoldPartitioning ( n_splits = 3 ), algorithm_list = [ alg1 , alg2 , alg3 ], items_directory = movies_dir , metric_list = [ eva . Precision (), eva . Recall ()] output_folder = \"my_experiment\" ) a . rank () Results will be saved in my_experiment/NXPageRank_1 Results will be saved in my_experiment/NXPageRank_2 Results will be saved in my_experiment/NXPageRank_3 PARAMETER DESCRIPTION original_ratings Ratings object containing original interactions between users and items TYPE: Ratings partitioning_technique Partitioning object which specifies how the original ratings should be split TYPE: Partitioning algorithm_list List of Graph Based algorithms for which the whole experiment will be conducted TYPE: List [ GraphBasedAlgorithm ] items_directory Path to the folder containing serialized complexly represented items with one or more exogenous property to load TYPE: str DEFAULT: None item_exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] DEFAULT: None users_directory Path to the folder containing serialized complexly represented users with one or more exogenous property to load TYPE: str DEFAULT: None user_exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] DEFAULT: None link_label If specified, each link between user and item nodes will be labeled with the given label. Default is None TYPE: str DEFAULT: None metric_list List of metric with which predictions computed by the GBRS will be evaluated TYPE: List [ Metric ] DEFAULT: None report If True , a yml report will be produced for the recsys phase. It will be also produced for the evaluation phase, but only if the metric_list parameter is set TYPE: bool DEFAULT: False output_folder Path of the folder where all the results of the experiment will be saved TYPE: str DEFAULT: 'experiment_result' overwrite_if_exists If True and the path set in output_folder points to an already existent directory, it will be deleted and replaced by the folder containing the experiment results TYPE: bool DEFAULT: False Source code in clayrs/recsys/experiment.py 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 def __init__ ( self , original_ratings : Ratings , partitioning_technique : Partitioning , algorithm_list : List [ GraphBasedAlgorithm ], items_directory : str = None , item_exo_properties : Union [ Dict , set ] = None , users_directory : str = None , user_exo_properties : Union [ Dict , set ] = None , link_label : str = None , metric_list : List [ Metric ] = None , report : bool = False , output_folder : str = \"experiment_result\" , overwrite_if_exists : bool = False ): super () . __init__ ( original_ratings , partitioning_technique , algorithm_list , items_directory , users_directory , metric_list , report , output_folder , overwrite_if_exists ) self . item_exo_properties = item_exo_properties self . user_exo_properties = user_exo_properties self . link_label = link_label","title":"GraphBasedExperiment"},{"location":"recsys/experiment/#clayrs.recsys.experiment.GraphBasedExperiment.predict","text":"Method used to perform an experiment which involves score predictions . The method will first split the original ratings passed in the constructor in train and test set, then a graph will be built depending on them: All nodes of the original ratings will be present, but the links ( interactions ) that are present in the test set will be missing, so to make the training phase fair Info BE CAREFUL : not all algorithms are able to perform score prediction . In case a pure ranking algorithm is asked to perform score prediction, the NotPredictionAlg will be raised. if the skip_alg_error is set to True , then said exception will be caught, a warning will be printed, and the experiment will go on with the next algorithm Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be considered for score prediction PARAMETER DESCRIPTION methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 0 skip_alg_error If set to True , a pure ranking algorithm will be skipped and the experiment will continue with the following algorithm. Otherwise, the NotPredictionAlg exception raised will be re-raised TYPE: bool DEFAULT: True RAISES DESCRIPTION NotPredictionAlg When a pure ranking algorithm is asked to perform score prediction and skip_alg_error == False Source code in clayrs/recsys/experiment.py 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 def predict ( self , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 0 , skip_alg_error : bool = True ): \"\"\" Method used to perform an experiment which involves ***score predictions***. The method will first split the original ratings passed in the constructor in train and test set, then a graph will be built depending on them: * All nodes of the original ratings will be present, but the *links* (***interactions***) that are present in the test set will be missing, so to make the training phase *fair* !!! info **BE CAREFUL**: not all algorithms are able to perform *score prediction*. In case a pure ranking algorithm is asked to perform score prediction, the `NotPredictionAlg` will be raised. if the `skip_alg_error` is set to `True`, then said exception will be caught, a warning will be printed, and the experiment will go on with the next algorithm Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be considered for score prediction Args: methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. skip_alg_error: If set to `True`, a pure ranking algorithm will be skipped and the experiment will continue with the following algorithm. Otherwise, the `NotPredictionAlg` exception raised will be re-raised Raises: NotPredictionAlg: When a pure ranking algorithm is asked to perform score prediction and `skip_alg_error` == False \"\"\" def gb_fit_predict ( split_num , alg , train_set , test_set , dirname ): graph = NXFullGraph ( self . original_ratings , item_contents_dir = self . items_directory , item_exo_properties = self . item_exo_properties , user_contents_dir = self . users_directory , user_exo_properties = self . user_exo_properties , link_label = self . link_label ) for user , item in zip ( test_set . user_id_column , test_set . item_id_column ): graph . remove_link ( UserNode ( user ), ItemNode ( item )) gbrs = GraphBasedRS ( alg , graph ) predict_alg = gbrs . predict ( test_set , methodology = methodology , num_cpus = num_cpus ) predict_alg . to_csv ( f \" { self . output_folder } / { dirname } \" , file_name = f \"rs_predict_split { split_num } \" ) if self . report : Report ( output_dir = f \" { self . output_folder } / { dirname } \" ) . yaml ( original_ratings = self . original_ratings , partitioning_technique = self . pt , recsys = gbrs ) return predict_alg self . main_experiment ( gb_fit_predict , skip_alg_error = skip_alg_error )","title":"predict()"},{"location":"recsys/experiment/#clayrs.recsys.experiment.GraphBasedExperiment.rank","text":"Method used to perform an experiment which involves rankings . The method will first split the original ratings passed in the constructor in train and test set, then a graph will be built depending on them: All nodes of the original ratings will be present, but the links ( interactions ) that are present in the test set will be missing, so to make the training phase fair Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used, so for each user, items in its test set only will be eligible for ranking PARAMETER DESCRIPTION n_recs Number of the top items that will be present in the ranking of each user. If None all candidate items will be returned for the user TYPE: int DEFAULT: 10 methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 0 Source code in clayrs/recsys/experiment.py 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 def rank ( self , n_recs : int = 10 , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 0 ): \"\"\" Method used to perform an experiment which involves ***rankings***. The method will first split the original ratings passed in the constructor in train and test set, then a graph will be built depending on them: * All nodes of the original ratings will be present, but the *links* (***interactions***) that are present in the test set will be missing, so to make the training phase *fair* Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used, so for each user, items in its test set only will be eligible for ranking Args: n_recs: Number of the top items that will be present in the ranking of each user. If `None` all candidate items will be returned for the user methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. \"\"\" def gb_fit_rank ( split_num , alg , train_set , test_set , dirname ): graph = NXFullGraph ( self . original_ratings , item_contents_dir = self . items_directory , item_exo_properties = self . item_exo_properties , user_contents_dir = self . users_directory , user_exo_properties = self . user_exo_properties , link_label = self . link_label ) for user , item in zip ( test_set . user_id_column , test_set . item_id_column ): graph . remove_link ( UserNode ( user ), ItemNode ( item )) gbrs = GraphBasedRS ( alg , graph ) predict_alg = gbrs . rank ( test_set , n_recs = n_recs , methodology = methodology , num_cpus = num_cpus ) predict_alg . to_csv ( f \" { self . output_folder } / { dirname } \" , file_name = f \"rs_rank_split { split_num } \" ) if self . report : Report ( output_dir = f \" { self . output_folder } / { dirname } \" ) . yaml ( original_ratings = self . original_ratings , partitioning_technique = self . pt , recsys = gbrs ) return predict_alg self . main_experiment ( gb_fit_rank )","title":"rank()"},{"location":"recsys/introduction/","text":"Warning Docs are complete, but revision is still a Work in Progress. Sorry for any typos! Introduction The Recommender System module lets you easily build a Content Based Recommender System ( CBRS ) or a Graph Based Recommender system ( GBRS ) with various algorithms. Info The Recsys module is grounded on contents created with the Content Analyzer The following will introduce you to the standard usage pipeline for this module, starting from importing the dataset to generating recommendation lists. Importing the dataset The Ratings class allows you to import rating from a source file (or also from an existent dataframe) into a custom object. If the source file contains users, items and ratings in this order, no additional parameters are needed, otherwise the mapping must be explictly specified using: 'user_id' column, 'item_id' column, 'score' column In this case the dataset we want to import is a CSV file with the following header: user_id,item_id,rating,timestamp As you can see the user id column , item id column and score column are the first three column and are already in sequential order, so no additional parameter is required to the Ratings class: import clayrs.content_analyzer as ca ratings_raw_source = ca . CSVFile ( 'ratings.csv' ) # (1) ratings = ca . Ratings ( ratings_raw_source ) In this case our raw source is a CSV file, but ClayRS can also read from JSON files, DAT files and more Splitting the dataset Once you imported the dataset, the first thing you may want to do is to split it with a Partitioning technique The output of any partitioning technique are two lists. The first containing all the train set produced by the partitioning technique (two train set in the below example), the other containing all the test set produced by the partitioning technique (two test set in the below example) import clayrs.recsys as rs # kfold partitioning technique kf = rs . KFoldPartitioning ( n_splits = 2 ) train_list , test_list = kf . split_all ( ratings ) # (1) You can pass to the split_all() method a specific user_id_list in case you only want to perform the splitting operation for a specific subset of users (e.g. select only users with more than x ratings) Defining a Content Based Recommender System A Content Based Recommender System needs an algorithm for ranking or predicting items to users. There are many available, in the following example we will use the CentroidVector algorithm: It computes the centroid vector of the features of items liked by the user It computes the similarity between the centroid vector and unrated items The items liked by a user are those having a rating higher or equal than a specific threshold . If the threshold is not specified, the average score of all items liked by the user is used. As already said, the Recommender System leverages the representations defined by the Content Analyzer. Suppose you have complexly represented the 'plot' with a simple TfIdf technique and assigned to this representation the tfidf id: import clayrs.recsys as rs centroid_vec = rs . CentroidVector ( { 'plot' : 'tfidf' }, similarity = rs . CosineSimilarity () ) You can reference representation for a field also with an integer, in case you didn't assign any custom id during Content Analyzer phase. centroid_vec = rs . CentroidVector ( { 'plot' : 0 }, # (1) similarity = rs . CosineSimilarity () ) This means that you want to use the first representation with which the 'plot' field was complexly represented Please note that multiple representations could be adopted for a single field, and also multiple representations for multiple fields can be combined together! Simply specify them in the item_field dict that must be passed to any Content Based algorithm: centroid_vec = rs . CentroidVector ( { 'plot' : [ 0 , 'glove-50' , 'glove-100' ], 'genre' : [ 'tfidf' , 'fasttext' ]}, similarity = rs . CosineSimilarity () ) After choosing the algorithm, you are ready to instantiate the ContentBasedRS class. A CBRS needs the following parameters: The recommendation algorithm The train set The path of the items serialized by the Content Analyzer train_set = test_list [ 0 ] # (1) cbrs = rs . ContentBasedRS ( random_forests , train_set , 'movies_codified/' ) Since every partitioning technique returns a list of train sets ( here ), in this way we are using only the first train set produced. Just below there's an example on how to produce recommendation for more than one split Defining a Graph Based Recommender System A Graph Based Recommender System ( GBRS ) requires to first define a graph Ratings imported are used to create a Full Graph where property nodes (e.g. gender for users, budget for movies) can be linked to every node without any restriction The framework also allows to create a Bipartite Graph (a graph without property node) and a Tripartite Graph (where property nodes are only linked to item nodes) In order to load properties in the graph, we must specify where users and items are serialized and which properties to add (the following is the same for item_exo_properties ): If user_exo_properties is specified as a set , then the graph will try to load all properties from said exogenous representation # example { 'my_exo_id' } If user_exo_properties is specified as a dict , then the graph will try to load said properties from said exogenous representation # example { 'my_exo_id' : [ 'my_prop1' , 'my_prop2' ]]} Let's now create the graph loading all properties: full_graph = rs . NXFullGraph ( ratings , user_contents_dir = 'users_codified/' , # (1) item_contents_dir = 'movies_codified/' , # (2) user_exo_properties = { 0 }, # (3) item_exo_properties = { 'dbpedia' }, # (4) link_label = 'score' ) Where users complexly represented have been serialized during Content Analyzer phase Where items complexly represented have been serialized during Content Analyzer phase This means that you want to use the first exogenous representation with which each user has been expanded You can also access exogenous representation with custom id, if specified during Content Analyzer phase The last step to perform before defining the GBRS is to instantiate an algorithm for ranking or predicting items to users. In the following example we use the Personalized PageRank algorithm: pr = rs . NXPageRank ( personalized = True ) Finally we can instantiate the GBRS! gbrs = rs . GraphBasedRS ( pr , full_graph ) Generating recommendations Info The following procedure works both for CBRS and GBRS . In the following we will consider a cbrs as an example For GBRS there is no fit() method, only rank() or predict() method must be called Now the cbrs must be fit before we can compute the rank: We could do this in two separate steps, by first calling the fit(..) method and then the rank(...) method Or by calling directly the fit_rank(...) method, which performs both in one step In this case we choose the first method: cbrs . fit () test_set = test_list [ 0 ] # (1) rank = cbrs . rank ( test_set , n_recs = 10 ) # top-10 recommendation for each user Since every partitioning technique returns a list of test sets ( here ), in this way we are using only the first train set produced. Just below there's an example on how to produce recommendation for more than one split In case you perform a splitting of the dataset which returns a multiple train and test sets (KFold technique): original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) train_list , test_list = rs . KFoldPartitioning ( n_splits = 5 ) . split_all ( original_rat ) alg = rs . CentroidVector () # any cb algorithm for train_set , test_set in zip ( train_list , test_list ): cbrs = rs . ContentBasedRS ( alg , train_set , items_path ) rank_to_append = cbrs . fit_rank ( test_set ) result_list . append ( rank_to_append ) result_list will contain recommendation lists for each split Customizing the ranking process You can customize the ranking process by changing the parameters of the rank(...) method You can choice for which users to produce recommendations: rank = cbrs . rank ( test_set , user_id_list = [ 'u1' , 'u23' , 'u56' ]) If a cut rank list for each user must be produced: rank = cbrs . rank ( test_set , n_recs = 10 ) If a different methodology must be used: Info A methodology lets you customize which items must be ranked for each user. For each target user \\(u\\) , the following 4 different methodologies are available for defining those lists: TestRatings (default): the list of items to be evaluated consists of items rated by \\(u\\) in the test set TestItems : every item in the test set of every user except those in the training set of \\(u\\) will be predicted TrainingItems : every item in the training set of every user will be predicted except those in the training set of \\(u\\) AllItems : the whole set of items defined will be predicted, except those in the training set of \\(u\\) More information on this paper . By default the methodology used is the TestRatings methodology rank = cbrs . rank ( test_set , methodology = rs . TrainingItems ()) Generating score predictions Some algorithm (e.g. LinearPredictor algorithm) are able to predict the numeric rating that a user would give to unseen items. The usage is exactly the same of generating recommendations and customizing the ranking process , the only thing that changes is the method to call: score_prediction = cbrs . fit_predict ( test_set ) or: cbrs . fit () score_prediction = cbrs . predict ( test_set ) Note : if the predict() or the fit_predict() method is called for an algorithm that is not able to perform score prediction, the NotPredictionAlg exception is raised","title":"Introduction"},{"location":"recsys/introduction/#introduction","text":"The Recommender System module lets you easily build a Content Based Recommender System ( CBRS ) or a Graph Based Recommender system ( GBRS ) with various algorithms. Info The Recsys module is grounded on contents created with the Content Analyzer The following will introduce you to the standard usage pipeline for this module, starting from importing the dataset to generating recommendation lists.","title":"Introduction"},{"location":"recsys/introduction/#importing-the-dataset","text":"The Ratings class allows you to import rating from a source file (or also from an existent dataframe) into a custom object. If the source file contains users, items and ratings in this order, no additional parameters are needed, otherwise the mapping must be explictly specified using: 'user_id' column, 'item_id' column, 'score' column In this case the dataset we want to import is a CSV file with the following header: user_id,item_id,rating,timestamp As you can see the user id column , item id column and score column are the first three column and are already in sequential order, so no additional parameter is required to the Ratings class: import clayrs.content_analyzer as ca ratings_raw_source = ca . CSVFile ( 'ratings.csv' ) # (1) ratings = ca . Ratings ( ratings_raw_source ) In this case our raw source is a CSV file, but ClayRS can also read from JSON files, DAT files and more","title":"Importing the dataset"},{"location":"recsys/introduction/#splitting-the-dataset","text":"Once you imported the dataset, the first thing you may want to do is to split it with a Partitioning technique The output of any partitioning technique are two lists. The first containing all the train set produced by the partitioning technique (two train set in the below example), the other containing all the test set produced by the partitioning technique (two test set in the below example) import clayrs.recsys as rs # kfold partitioning technique kf = rs . KFoldPartitioning ( n_splits = 2 ) train_list , test_list = kf . split_all ( ratings ) # (1) You can pass to the split_all() method a specific user_id_list in case you only want to perform the splitting operation for a specific subset of users (e.g. select only users with more than x ratings)","title":"Splitting the dataset"},{"location":"recsys/introduction/#defining-a-content-based-recommender-system","text":"A Content Based Recommender System needs an algorithm for ranking or predicting items to users. There are many available, in the following example we will use the CentroidVector algorithm: It computes the centroid vector of the features of items liked by the user It computes the similarity between the centroid vector and unrated items The items liked by a user are those having a rating higher or equal than a specific threshold . If the threshold is not specified, the average score of all items liked by the user is used. As already said, the Recommender System leverages the representations defined by the Content Analyzer. Suppose you have complexly represented the 'plot' with a simple TfIdf technique and assigned to this representation the tfidf id: import clayrs.recsys as rs centroid_vec = rs . CentroidVector ( { 'plot' : 'tfidf' }, similarity = rs . CosineSimilarity () ) You can reference representation for a field also with an integer, in case you didn't assign any custom id during Content Analyzer phase. centroid_vec = rs . CentroidVector ( { 'plot' : 0 }, # (1) similarity = rs . CosineSimilarity () ) This means that you want to use the first representation with which the 'plot' field was complexly represented Please note that multiple representations could be adopted for a single field, and also multiple representations for multiple fields can be combined together! Simply specify them in the item_field dict that must be passed to any Content Based algorithm: centroid_vec = rs . CentroidVector ( { 'plot' : [ 0 , 'glove-50' , 'glove-100' ], 'genre' : [ 'tfidf' , 'fasttext' ]}, similarity = rs . CosineSimilarity () ) After choosing the algorithm, you are ready to instantiate the ContentBasedRS class. A CBRS needs the following parameters: The recommendation algorithm The train set The path of the items serialized by the Content Analyzer train_set = test_list [ 0 ] # (1) cbrs = rs . ContentBasedRS ( random_forests , train_set , 'movies_codified/' ) Since every partitioning technique returns a list of train sets ( here ), in this way we are using only the first train set produced. Just below there's an example on how to produce recommendation for more than one split","title":"Defining a Content Based Recommender System"},{"location":"recsys/introduction/#defining-a-graph-based-recommender-system","text":"A Graph Based Recommender System ( GBRS ) requires to first define a graph Ratings imported are used to create a Full Graph where property nodes (e.g. gender for users, budget for movies) can be linked to every node without any restriction The framework also allows to create a Bipartite Graph (a graph without property node) and a Tripartite Graph (where property nodes are only linked to item nodes) In order to load properties in the graph, we must specify where users and items are serialized and which properties to add (the following is the same for item_exo_properties ): If user_exo_properties is specified as a set , then the graph will try to load all properties from said exogenous representation # example { 'my_exo_id' } If user_exo_properties is specified as a dict , then the graph will try to load said properties from said exogenous representation # example { 'my_exo_id' : [ 'my_prop1' , 'my_prop2' ]]} Let's now create the graph loading all properties: full_graph = rs . NXFullGraph ( ratings , user_contents_dir = 'users_codified/' , # (1) item_contents_dir = 'movies_codified/' , # (2) user_exo_properties = { 0 }, # (3) item_exo_properties = { 'dbpedia' }, # (4) link_label = 'score' ) Where users complexly represented have been serialized during Content Analyzer phase Where items complexly represented have been serialized during Content Analyzer phase This means that you want to use the first exogenous representation with which each user has been expanded You can also access exogenous representation with custom id, if specified during Content Analyzer phase The last step to perform before defining the GBRS is to instantiate an algorithm for ranking or predicting items to users. In the following example we use the Personalized PageRank algorithm: pr = rs . NXPageRank ( personalized = True ) Finally we can instantiate the GBRS! gbrs = rs . GraphBasedRS ( pr , full_graph )","title":"Defining a Graph Based Recommender System"},{"location":"recsys/introduction/#generating-recommendations","text":"Info The following procedure works both for CBRS and GBRS . In the following we will consider a cbrs as an example For GBRS there is no fit() method, only rank() or predict() method must be called Now the cbrs must be fit before we can compute the rank: We could do this in two separate steps, by first calling the fit(..) method and then the rank(...) method Or by calling directly the fit_rank(...) method, which performs both in one step In this case we choose the first method: cbrs . fit () test_set = test_list [ 0 ] # (1) rank = cbrs . rank ( test_set , n_recs = 10 ) # top-10 recommendation for each user Since every partitioning technique returns a list of test sets ( here ), in this way we are using only the first train set produced. Just below there's an example on how to produce recommendation for more than one split In case you perform a splitting of the dataset which returns a multiple train and test sets (KFold technique): original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) train_list , test_list = rs . KFoldPartitioning ( n_splits = 5 ) . split_all ( original_rat ) alg = rs . CentroidVector () # any cb algorithm for train_set , test_set in zip ( train_list , test_list ): cbrs = rs . ContentBasedRS ( alg , train_set , items_path ) rank_to_append = cbrs . fit_rank ( test_set ) result_list . append ( rank_to_append ) result_list will contain recommendation lists for each split","title":"Generating recommendations"},{"location":"recsys/introduction/#customizing-the-ranking-process","text":"You can customize the ranking process by changing the parameters of the rank(...) method You can choice for which users to produce recommendations: rank = cbrs . rank ( test_set , user_id_list = [ 'u1' , 'u23' , 'u56' ]) If a cut rank list for each user must be produced: rank = cbrs . rank ( test_set , n_recs = 10 ) If a different methodology must be used: Info A methodology lets you customize which items must be ranked for each user. For each target user \\(u\\) , the following 4 different methodologies are available for defining those lists: TestRatings (default): the list of items to be evaluated consists of items rated by \\(u\\) in the test set TestItems : every item in the test set of every user except those in the training set of \\(u\\) will be predicted TrainingItems : every item in the training set of every user will be predicted except those in the training set of \\(u\\) AllItems : the whole set of items defined will be predicted, except those in the training set of \\(u\\) More information on this paper . By default the methodology used is the TestRatings methodology rank = cbrs . rank ( test_set , methodology = rs . TrainingItems ())","title":"Customizing the ranking process"},{"location":"recsys/introduction/#generating-score-predictions","text":"Some algorithm (e.g. LinearPredictor algorithm) are able to predict the numeric rating that a user would give to unseen items. The usage is exactly the same of generating recommendations and customizing the ranking process , the only thing that changes is the method to call: score_prediction = cbrs . fit_predict ( test_set ) or: cbrs . fit () score_prediction = cbrs . predict ( test_set ) Note : if the predict() or the fit_predict() method is called for an algorithm that is not able to perform score prediction, the NotPredictionAlg exception is raised","title":"Generating score predictions"},{"location":"recsys/content_based/content_based_recsys/","text":"Content Based RecSys ContentBasedRS ( algorithm , train_set , items_directory , users_directory = None ) Bases: RecSys Class for recommender systems which use the items' content in order to make predictions, some algorithms may also use users' content, so it's an optional parameter. Every CBRS differ from each other based the algorithm used. Examples: In case you perform a splitting of the dataset which returns a single train and test set (e.g. HoldOut technique): Single split train from clayrs import recsys as rs from clayrs import content_analyzer as ca original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) [ train ], [ test ] = rs . HoldOutPartitioning () . split_all ( original_rat ) alg = rs . CentroidVector () # any cb algorithm cbrs = rs . ContentBasedRS ( alg , train , items_path ) rank = cbrs . fit_rank ( test , n_recs = 10 ) In case you perform a splitting of the dataset which returns a multiple train and test sets (KFold technique): Multiple split train from clayrs import recsys as rs from clayrs import content_analyzer as ca original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) train_list , test_list = rs . KFoldPartitioning ( n_splits = 5 ) . split_all ( original_rat ) alg = rs . CentroidVector () # any cb algorithm for train_set , test_set in zip ( train_list , test_list ): cbrs = rs . ContentBasedRS ( alg , train_set , items_path ) rank_to_append = cbrs . fit_rank ( test_set ) result_list . append ( rank_to_append ) result_list will contain recommendation lists for each split PARAMETER DESCRIPTION algorithm the content based algorithm that will be used in order to rank or make score prediction TYPE: ContentBasedAlgorithm train_set a Ratings object containing interactions between users and items TYPE: Ratings items_directory the path of the items serialized by the Content Analyzer TYPE: str users_directory the path of the users serialized by the Content Analyzer TYPE: str DEFAULT: None Source code in clayrs/recsys/recsys.py 112 113 114 115 116 117 118 119 120 121 122 def __init__ ( self , algorithm : ContentBasedAlgorithm , train_set : Ratings , items_directory : str , users_directory : str = None ): super () . __init__ ( algorithm ) self . __train_set = train_set self . __items_directory = items_directory self . __users_directory = users_directory self . _user_fit_dic = {} algorithm () property The content based algorithm chosen Source code in clayrs/recsys/recsys.py 124 125 126 127 128 129 130 @property def algorithm ( self ): \"\"\" The content based algorithm chosen \"\"\" alg : ContentBasedAlgorithm = super () . algorithm return alg fit ( num_cpus = 0 ) Method which will fit the algorithm chosen for each user in the train set passed in the constructor If the algorithm can't be fit for some users, a warning message is printed Source code in clayrs/recsys/recsys.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def fit ( self , num_cpus : int = 0 ): \"\"\" Method which will fit the algorithm chosen for each user in the train set passed in the constructor If the algorithm can't be fit for some users, a warning message is printed \"\"\" def compute_single_fit ( user_id ): user_train = self . train_set . get_user_interactions ( user_id ) user_alg = deepcopy ( self . algorithm ) try : user_alg . process_rated ( user_train , loaded_items_interface ) user_alg . fit () except UserSkipAlgFit as e : warning_message = str ( e ) + f \" \\n No algorithm will be fitted for the user { user_id } \" logger . warning ( warning_message ) user_alg = None return user_id , user_alg items_to_load = set ( self . train_set . item_id_column ) all_users = set ( self . train_set . user_id_column ) loaded_items_interface = self . algorithm . _load_available_contents ( self . items_directory , items_to_load ) with get_iterator_parallel ( num_cpus , compute_single_fit , all_users , progress_bar = True , total = len ( all_users )) as pbar : pbar . set_description ( \"Fitting algorithm\" ) for user_id , fitted_user_alg in pbar : self . _user_fit_dic [ user_id ] = fitted_user_alg # we force the garbage collector after freeing loaded items del loaded_items_interface gc . collect () return self fit_predict ( test_set , user_id_list = None , methodology = TestRatingsMethodology (), save_fit = False , num_cpus = 1 ) Method used to both fit and calculate score prediction for all users in test set or all users in user_id_list parameter. The Recommender System will first be fit for each user in the train set passed in the constructor. If the algorithm can't be fit for some users, a warning message is printed BE CAREFUL : not all algorithms are able to perform score prediction Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be considered for score prediction If the algorithm was not fit for some users, they will be skipped and a warning is printed With the save_fit parameter you can decide if you want that you recommender system remains fit even after the complete execution of this method, in case you want to compute ranking/score prediction with other methodologies, or with a different n_recs parameter. Be mindful since it can be memory-expensive, thus by default this behaviour is disabled PARAMETER DESCRIPTION test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings user_id_list List of users for which you want to compute score prediction. If None, the ranking will be computed for all users of the test_set TYPE: List DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() save_fit Boolean value which let you choose if the Recommender System should remain fit even after the complete execution of this method. Default is False TYPE: bool DEFAULT: False num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RETURNS DESCRIPTION Prediction Rank object containing recommendation lists for all users of the test set or for all users in user_id_list Source code in clayrs/recsys/recsys.py 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 def fit_predict ( self , test_set : Ratings , user_id_list : List = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), save_fit : bool = False , num_cpus : int = 1 ) -> Prediction : \"\"\" Method used to both fit and calculate score prediction for all users in test set or all users in `user_id_list` parameter. The Recommender System will first be fit for each user in the train set passed in the constructor. If the algorithm can't be fit for some users, a warning message is printed **BE CAREFUL**: not all algorithms are able to perform *score prediction* Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be considered for score prediction If the algorithm was not fit for some users, they will be skipped and a warning is printed With the `save_fit` parameter you can decide if you want that you recommender system remains *fit* even after the complete execution of this method, in case you want to compute ranking/score prediction with other methodologies, or with a different `n_recs` parameter. Be mindful since it can be memory-expensive, thus by default this behaviour is disabled Args: test_set: Ratings object which represents the ground truth of the split considered user_id_list: List of users for which you want to compute score prediction. If None, the ranking will be computed for all users of the `test_set` methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` save_fit: Boolean value which let you choose if the Recommender System should remain fit even after the complete execution of this method. Default is False num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Returns: Rank object containing recommendation lists for all users of the test set or for all users in `user_id_list` \"\"\" def compute_single_fit_predict ( user_id ): user_train = self . train_set . get_user_interactions ( user_id ) alg = self . algorithm if save_fit : alg = deepcopy ( alg ) self . _user_fit_dic [ user_id ] = alg try : alg . process_rated ( user_train , loaded_items_interface ) alg . fit () except UserSkipAlgFit as e : warning_message = str ( e ) + f \" \\n The algorithm can't be fitted for the user { user_id } \" logger . warning ( warning_message ) if save_fit : self . _user_fit_dic [ user_id ] = None return user_id , [] filter_list = None if methodology is not None : filter_list = set ( methodology . filter_single ( user_id , self . train_set , test_set )) user_pred = alg . predict ( user_train , loaded_items_interface , filter_list = filter_list ) return user_id , user_pred all_users = set ( test_set . user_id_column ) if user_id_list is not None : all_users = set ( user_id_list ) loaded_items_interface = self . algorithm . _load_available_contents ( self . items_directory , set ()) pred = [] logger . info ( \"Don't worry if it looks stuck at first\" ) logger . info ( \"First iterations will stabilize the estimated remaining time\" ) with get_iterator_parallel ( num_cpus , compute_single_fit_predict , all_users , progress_bar = True , total = len ( all_users )) as pbar : pbar . set_description ( f \"Loading first items from memory...\" ) for user_id , user_pred in pbar : pbar . set_description ( f \"Computing fit_predict for user { user_id } \" ) pred . append ( user_pred ) pred = itertools . chain . from_iterable ( pred ) pred = Prediction . from_list ( pred ) # we force the garbage collector after freeing loaded items del loaded_items_interface gc . collect () self . _yaml_report = { 'mode' : 'score_prediction' , 'methodology' : repr ( methodology )} return pred fit_rank ( test_set , n_recs = 10 , user_id_list = None , methodology = TestRatingsMethodology (), save_fit = False , num_cpus = 1 ) Method used to both fit and calculate ranking for all users in test set or all users in user_id_list parameter. The Recommender System will first be fit for each user in the train set passed in the constructor. If the algorithm can't be fit for some users, a warning message is printed If the n_recs is specified, then the rank will contain the top-n items for the users. Otherwise, the rank will contain all unrated items of the particular users Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be ranked If the algorithm was not fit for some users, they will be skipped and a warning is printed With the save_fit parameter you can decide if you want that you recommender system remains fit even after the complete execution of this method, in case you want to compute ranking with other methodologies, or with a different n_recs parameter. Be mindful since it can be memory-expensive, thus by default this behaviour is disabled PARAMETER DESCRIPTION test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings n_recs Number of the top items that will be present in the ranking of each user. If None all candidate items will be returned for the user TYPE: int DEFAULT: 10 user_id_list List of users for which you want to compute the ranking. If None, the ranking will be computed for all users of the test_set TYPE: List DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() save_fit Boolean value which let you choose if the Recommender System should remain fit even after the complete execution of this method. Default is False TYPE: bool DEFAULT: False num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RAISES DESCRIPTION NotFittedAlg Exception raised when this method is called without first calling the fit method RETURNS DESCRIPTION Rank Rank object containing recommendation lists for all users of the test set or for all users in user_id_list Source code in clayrs/recsys/recsys.py 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 def fit_rank ( self , test_set : Ratings , n_recs : int = 10 , user_id_list : List = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), save_fit : bool = False , num_cpus : int = 1 ) -> Rank : \"\"\" Method used to both fit and calculate ranking for all users in test set or all users in `user_id_list` parameter. The Recommender System will first be fit for each user in the train set passed in the constructor. If the algorithm can't be fit for some users, a warning message is printed If the `n_recs` is specified, then the rank will contain the top-n items for the users. Otherwise, the rank will contain all unrated items of the particular users Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be ranked If the algorithm was not fit for some users, they will be skipped and a warning is printed With the `save_fit` parameter you can decide if you want that you recommender system remains *fit* even after the complete execution of this method, in case you want to compute ranking with other methodologies, or with a different `n_recs` parameter. Be mindful since it can be memory-expensive, thus by default this behaviour is disabled Args: test_set: Ratings object which represents the ground truth of the split considered n_recs: Number of the top items that will be present in the ranking of each user. If `None` all candidate items will be returned for the user user_id_list: List of users for which you want to compute the ranking. If None, the ranking will be computed for all users of the `test_set` methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` save_fit: Boolean value which let you choose if the Recommender System should remain fit even after the complete execution of this method. Default is False num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Raises: NotFittedAlg: Exception raised when this method is called without first calling the `fit` method Returns: Rank object containing recommendation lists for all users of the test set or for all users in `user_id_list` \"\"\" def compute_single_fit_rank ( user_id ): user_train = self . train_set . get_user_interactions ( user_id ) alg = self . algorithm if save_fit : alg = deepcopy ( alg ) self . _user_fit_dic [ user_id ] = alg try : alg . process_rated ( user_train , loaded_items_interface ) alg . fit () except UserSkipAlgFit as e : warning_message = str ( e ) + f \" \\n The algorithm can't be fitted for the user { user_id } \" logger . warning ( warning_message ) if save_fit : self . _user_fit_dic [ user_id ] = None return user_id , [] filter_list = None if methodology is not None : filter_list = set ( methodology . filter_single ( user_id , self . train_set , test_set )) user_rank = alg . rank ( user_train , loaded_items_interface , n_recs , filter_list = filter_list ) return user_id , user_rank all_users = set ( test_set . user_id_column ) if user_id_list is not None : all_users = set ( user_id_list ) loaded_items_interface = self . algorithm . _load_available_contents ( self . items_directory , set ()) rank = [] logger . info ( \"Don't worry if it looks stuck at first\" ) logger . info ( \"First iterations will stabilize the estimated remaining time\" ) with get_iterator_parallel ( num_cpus , compute_single_fit_rank , all_users , progress_bar = True , total = len ( all_users )) as pbar : pbar . set_description ( f \"Loading first items from memory...\" ) for user_id , user_rank in pbar : pbar . set_description ( f \"Computing fit_rank for user { user_id } \" ) rank . append ( user_rank ) rank = itertools . chain . from_iterable ( rank ) rank = Rank . from_list ( rank ) # we force the garbage collector after freeing loaded items del loaded_items_interface gc . collect () self . _yaml_report = { 'mode' : 'rank' , 'n_recs' : repr ( n_recs ), 'methodology' : repr ( methodology )} return rank items_directory () property Path of the serialized items by the Content Analyzer Source code in clayrs/recsys/recsys.py 139 140 141 142 143 144 @property def items_directory ( self ): \"\"\" Path of the serialized items by the Content Analyzer \"\"\" return self . __items_directory predict ( test_set , user_id_list = None , methodology = TestRatingsMethodology (), num_cpus = 1 ) Method used to calculate score predictions for all users in test set or all users in user_id_list parameter. You must first call the fit() method before you can compute score predictions. BE CAREFUL : not all algorithms are able to perform score prediction Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be considered for score prediction If the algorithm was not fit for some users, they will be skipped and a warning is printed PARAMETER DESCRIPTION test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings user_id_list List of users for which you want to compute score prediction. If None, the ranking will be computed for all users of the test_set TYPE: List DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RAISES DESCRIPTION NotFittedAlg Exception raised when this method is called without first calling the fit method RETURNS DESCRIPTION Prediction Prediction object containing score prediction lists for all users of the test set or for all users in user_id_list Source code in clayrs/recsys/recsys.py 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 def predict ( self , test_set : Ratings , user_id_list : List = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 1 ) -> Prediction : \"\"\" Method used to calculate score predictions for all users in test set or all users in `user_id_list` parameter. You must first call the `fit()` method before you can compute score predictions. **BE CAREFUL**: not all algorithms are able to perform *score prediction* Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be considered for score prediction If the algorithm was not fit for some users, they will be skipped and a warning is printed Args: test_set: Ratings object which represents the ground truth of the split considered user_id_list: List of users for which you want to compute score prediction. If None, the ranking will be computed for all users of the `test_set` methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Raises: NotFittedAlg: Exception raised when this method is called without first calling the `fit` method Returns: Prediction object containing score prediction lists for all users of the test set or for all users in `user_id_list` \"\"\" def compute_single_predict ( user_id ): user_id = str ( user_id ) user_train = self . train_set . get_user_interactions ( user_id ) filter_list = None if methodology is not None : filter_list = set ( methodology . filter_single ( user_id , self . train_set , test_set )) user_fitted_alg = self . _user_fit_dic . get ( user_id ) if user_fitted_alg is not None : user_pred = user_fitted_alg . predict ( user_train , loaded_items_interface , filter_list = filter_list ) else : user_pred = [] logger . warning ( f \"No algorithm fitted for user { user_id } ! It will be skipped\" ) return user_id , user_pred if len ( self . _user_fit_dic ) == 0 : raise NotFittedAlg ( \"Algorithm not fit! You must call the fit() method first, or fit_rank().\" ) all_users = set ( test_set . user_id_column ) if user_id_list is not None : all_users = set ( user_id_list ) loaded_items_interface = self . algorithm . _load_available_contents ( self . items_directory , set ()) pred = [] logger . info ( \"Don't worry if it looks stuck at first\" ) logger . info ( \"First iterations will stabilize the estimated remaining time\" ) with get_iterator_parallel ( num_cpus , compute_single_predict , all_users , progress_bar = True , total = len ( all_users )) as pbar : pbar . set_description ( f \"Loading first items from memory...\" ) for user_id , user_pred in pbar : pbar . set_description ( f \"Computing score prediction for user { user_id } \" ) pred . append ( user_pred ) pred = itertools . chain . from_iterable ( pred ) pred = Prediction . from_list ( pred ) # we force the garbage collector after freeing loaded items del loaded_items_interface gc . collect () self . _yaml_report = { 'mode' : 'score_prediction' , 'methodology' : repr ( methodology )} return pred rank ( test_set , n_recs = 10 , user_id_list = None , methodology = TestRatingsMethodology (), num_cpus = 1 ) Method used to calculate ranking for all users in test set or all users in user_id_list parameter. You must first call the fit() method before you can compute the ranking. If the n_recs is specified, then the rank will contain the top-n items for the users. Otherwise, the rank will contain all unrated items of the particular users Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be ranked If the algorithm was not fit for some users, they will be skipped and a warning is printed PARAMETER DESCRIPTION test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings n_recs Number of the top items that will be present in the ranking of each user. If None all candidate items will be returned for the user TYPE: int DEFAULT: 10 user_id_list List of users for which you want to compute the ranking. If None, the ranking will be computed for all users of the test_set TYPE: List DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RAISES DESCRIPTION NotFittedAlg Exception raised when this method is called without first calling the fit method RETURNS DESCRIPTION Rank Rank object containing recommendation lists for all users of the test set or for all users in user_id_list Source code in clayrs/recsys/recsys.py 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 def rank ( self , test_set : Ratings , n_recs : int = 10 , user_id_list : List = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 1 ) -> Rank : \"\"\" Method used to calculate ranking for all users in test set or all users in `user_id_list` parameter. You must first call the `fit()` method before you can compute the ranking. If the `n_recs` is specified, then the rank will contain the top-n items for the users. Otherwise, the rank will contain all unrated items of the particular users Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be ranked If the algorithm was not fit for some users, they will be skipped and a warning is printed Args: test_set: Ratings object which represents the ground truth of the split considered n_recs: Number of the top items that will be present in the ranking of each user. If `None` all candidate items will be returned for the user user_id_list: List of users for which you want to compute the ranking. If None, the ranking will be computed for all users of the `test_set` methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Raises: NotFittedAlg: Exception raised when this method is called without first calling the `fit` method Returns: Rank object containing recommendation lists for all users of the test set or for all users in `user_id_list` \"\"\" def compute_single_rank ( user_id ): user_id = str ( user_id ) user_train = self . train_set . get_user_interactions ( user_id ) filter_list = None if methodology is not None : filter_list = set ( methodology . filter_single ( user_id , self . train_set , test_set )) user_fitted_alg = self . _user_fit_dic . get ( user_id ) if user_fitted_alg is not None : user_rank = user_fitted_alg . rank ( user_train , loaded_items_interface , n_recs , filter_list = filter_list ) else : user_rank = [] logger . warning ( f \"No algorithm fitted for user { user_id } ! It will be skipped\" ) return user_id , user_rank if len ( self . _user_fit_dic ) == 0 : raise NotFittedAlg ( \"Algorithm not fit! You must call the fit() method first, or fit_rank().\" ) all_users = set ( test_set . user_id_column ) if user_id_list is not None : all_users = set ( user_id_list ) loaded_items_interface = self . algorithm . _load_available_contents ( self . items_directory , set ()) rank = [] logger . info ( \"Don't worry if it looks stuck at first\" ) logger . info ( \"First iterations will stabilize the estimated remaining time\" ) with get_iterator_parallel ( num_cpus , compute_single_rank , all_users , progress_bar = True , total = len ( all_users )) as pbar : pbar . set_description ( f \"Loading first items from memory...\" ) for user_id , user_rank in pbar : pbar . set_description ( f \"Computing rank for user { user_id } \" ) rank . append ( user_rank ) rank = itertools . chain . from_iterable ( rank ) rank = Rank . from_list ( rank ) # we force the garbage collector after freeing loaded items del loaded_items_interface gc . collect () self . _yaml_report = { 'mode' : 'rank' , 'n_recs' : repr ( n_recs ), 'methodology' : repr ( methodology )} return rank train_set () property The train set of the Content Based RecSys Source code in clayrs/recsys/recsys.py 132 133 134 135 136 137 @property def train_set ( self ): \"\"\" The train set of the Content Based RecSys \"\"\" return self . __train_set users_directory () property Path of the serialized users by the Content Analyzer Source code in clayrs/recsys/recsys.py 146 147 148 149 150 151 @property def users_directory ( self ): \"\"\" Path of the serialized users by the Content Analyzer \"\"\" return self . __users_directory","title":"Content Based recsys"},{"location":"recsys/content_based/content_based_recsys/#content-based-recsys","text":"","title":"Content Based RecSys"},{"location":"recsys/content_based/content_based_recsys/#clayrs.recsys.recsys.ContentBasedRS","text":"Bases: RecSys Class for recommender systems which use the items' content in order to make predictions, some algorithms may also use users' content, so it's an optional parameter. Every CBRS differ from each other based the algorithm used. Examples: In case you perform a splitting of the dataset which returns a single train and test set (e.g. HoldOut technique): Single split train from clayrs import recsys as rs from clayrs import content_analyzer as ca original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) [ train ], [ test ] = rs . HoldOutPartitioning () . split_all ( original_rat ) alg = rs . CentroidVector () # any cb algorithm cbrs = rs . ContentBasedRS ( alg , train , items_path ) rank = cbrs . fit_rank ( test , n_recs = 10 ) In case you perform a splitting of the dataset which returns a multiple train and test sets (KFold technique): Multiple split train from clayrs import recsys as rs from clayrs import content_analyzer as ca original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) train_list , test_list = rs . KFoldPartitioning ( n_splits = 5 ) . split_all ( original_rat ) alg = rs . CentroidVector () # any cb algorithm for train_set , test_set in zip ( train_list , test_list ): cbrs = rs . ContentBasedRS ( alg , train_set , items_path ) rank_to_append = cbrs . fit_rank ( test_set ) result_list . append ( rank_to_append ) result_list will contain recommendation lists for each split PARAMETER DESCRIPTION algorithm the content based algorithm that will be used in order to rank or make score prediction TYPE: ContentBasedAlgorithm train_set a Ratings object containing interactions between users and items TYPE: Ratings items_directory the path of the items serialized by the Content Analyzer TYPE: str users_directory the path of the users serialized by the Content Analyzer TYPE: str DEFAULT: None Source code in clayrs/recsys/recsys.py 112 113 114 115 116 117 118 119 120 121 122 def __init__ ( self , algorithm : ContentBasedAlgorithm , train_set : Ratings , items_directory : str , users_directory : str = None ): super () . __init__ ( algorithm ) self . __train_set = train_set self . __items_directory = items_directory self . __users_directory = users_directory self . _user_fit_dic = {}","title":"ContentBasedRS"},{"location":"recsys/content_based/content_based_recsys/#clayrs.recsys.recsys.ContentBasedRS.algorithm","text":"The content based algorithm chosen Source code in clayrs/recsys/recsys.py 124 125 126 127 128 129 130 @property def algorithm ( self ): \"\"\" The content based algorithm chosen \"\"\" alg : ContentBasedAlgorithm = super () . algorithm return alg","title":"algorithm()"},{"location":"recsys/content_based/content_based_recsys/#clayrs.recsys.recsys.ContentBasedRS.fit","text":"Method which will fit the algorithm chosen for each user in the train set passed in the constructor If the algorithm can't be fit for some users, a warning message is printed Source code in clayrs/recsys/recsys.py 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 def fit ( self , num_cpus : int = 0 ): \"\"\" Method which will fit the algorithm chosen for each user in the train set passed in the constructor If the algorithm can't be fit for some users, a warning message is printed \"\"\" def compute_single_fit ( user_id ): user_train = self . train_set . get_user_interactions ( user_id ) user_alg = deepcopy ( self . algorithm ) try : user_alg . process_rated ( user_train , loaded_items_interface ) user_alg . fit () except UserSkipAlgFit as e : warning_message = str ( e ) + f \" \\n No algorithm will be fitted for the user { user_id } \" logger . warning ( warning_message ) user_alg = None return user_id , user_alg items_to_load = set ( self . train_set . item_id_column ) all_users = set ( self . train_set . user_id_column ) loaded_items_interface = self . algorithm . _load_available_contents ( self . items_directory , items_to_load ) with get_iterator_parallel ( num_cpus , compute_single_fit , all_users , progress_bar = True , total = len ( all_users )) as pbar : pbar . set_description ( \"Fitting algorithm\" ) for user_id , fitted_user_alg in pbar : self . _user_fit_dic [ user_id ] = fitted_user_alg # we force the garbage collector after freeing loaded items del loaded_items_interface gc . collect () return self","title":"fit()"},{"location":"recsys/content_based/content_based_recsys/#clayrs.recsys.recsys.ContentBasedRS.fit_predict","text":"Method used to both fit and calculate score prediction for all users in test set or all users in user_id_list parameter. The Recommender System will first be fit for each user in the train set passed in the constructor. If the algorithm can't be fit for some users, a warning message is printed BE CAREFUL : not all algorithms are able to perform score prediction Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be considered for score prediction If the algorithm was not fit for some users, they will be skipped and a warning is printed With the save_fit parameter you can decide if you want that you recommender system remains fit even after the complete execution of this method, in case you want to compute ranking/score prediction with other methodologies, or with a different n_recs parameter. Be mindful since it can be memory-expensive, thus by default this behaviour is disabled PARAMETER DESCRIPTION test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings user_id_list List of users for which you want to compute score prediction. If None, the ranking will be computed for all users of the test_set TYPE: List DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() save_fit Boolean value which let you choose if the Recommender System should remain fit even after the complete execution of this method. Default is False TYPE: bool DEFAULT: False num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RETURNS DESCRIPTION Prediction Rank object containing recommendation lists for all users of the test set or for all users in user_id_list Source code in clayrs/recsys/recsys.py 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 def fit_predict ( self , test_set : Ratings , user_id_list : List = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), save_fit : bool = False , num_cpus : int = 1 ) -> Prediction : \"\"\" Method used to both fit and calculate score prediction for all users in test set or all users in `user_id_list` parameter. The Recommender System will first be fit for each user in the train set passed in the constructor. If the algorithm can't be fit for some users, a warning message is printed **BE CAREFUL**: not all algorithms are able to perform *score prediction* Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be considered for score prediction If the algorithm was not fit for some users, they will be skipped and a warning is printed With the `save_fit` parameter you can decide if you want that you recommender system remains *fit* even after the complete execution of this method, in case you want to compute ranking/score prediction with other methodologies, or with a different `n_recs` parameter. Be mindful since it can be memory-expensive, thus by default this behaviour is disabled Args: test_set: Ratings object which represents the ground truth of the split considered user_id_list: List of users for which you want to compute score prediction. If None, the ranking will be computed for all users of the `test_set` methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` save_fit: Boolean value which let you choose if the Recommender System should remain fit even after the complete execution of this method. Default is False num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Returns: Rank object containing recommendation lists for all users of the test set or for all users in `user_id_list` \"\"\" def compute_single_fit_predict ( user_id ): user_train = self . train_set . get_user_interactions ( user_id ) alg = self . algorithm if save_fit : alg = deepcopy ( alg ) self . _user_fit_dic [ user_id ] = alg try : alg . process_rated ( user_train , loaded_items_interface ) alg . fit () except UserSkipAlgFit as e : warning_message = str ( e ) + f \" \\n The algorithm can't be fitted for the user { user_id } \" logger . warning ( warning_message ) if save_fit : self . _user_fit_dic [ user_id ] = None return user_id , [] filter_list = None if methodology is not None : filter_list = set ( methodology . filter_single ( user_id , self . train_set , test_set )) user_pred = alg . predict ( user_train , loaded_items_interface , filter_list = filter_list ) return user_id , user_pred all_users = set ( test_set . user_id_column ) if user_id_list is not None : all_users = set ( user_id_list ) loaded_items_interface = self . algorithm . _load_available_contents ( self . items_directory , set ()) pred = [] logger . info ( \"Don't worry if it looks stuck at first\" ) logger . info ( \"First iterations will stabilize the estimated remaining time\" ) with get_iterator_parallel ( num_cpus , compute_single_fit_predict , all_users , progress_bar = True , total = len ( all_users )) as pbar : pbar . set_description ( f \"Loading first items from memory...\" ) for user_id , user_pred in pbar : pbar . set_description ( f \"Computing fit_predict for user { user_id } \" ) pred . append ( user_pred ) pred = itertools . chain . from_iterable ( pred ) pred = Prediction . from_list ( pred ) # we force the garbage collector after freeing loaded items del loaded_items_interface gc . collect () self . _yaml_report = { 'mode' : 'score_prediction' , 'methodology' : repr ( methodology )} return pred","title":"fit_predict()"},{"location":"recsys/content_based/content_based_recsys/#clayrs.recsys.recsys.ContentBasedRS.fit_rank","text":"Method used to both fit and calculate ranking for all users in test set or all users in user_id_list parameter. The Recommender System will first be fit for each user in the train set passed in the constructor. If the algorithm can't be fit for some users, a warning message is printed If the n_recs is specified, then the rank will contain the top-n items for the users. Otherwise, the rank will contain all unrated items of the particular users Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be ranked If the algorithm was not fit for some users, they will be skipped and a warning is printed With the save_fit parameter you can decide if you want that you recommender system remains fit even after the complete execution of this method, in case you want to compute ranking with other methodologies, or with a different n_recs parameter. Be mindful since it can be memory-expensive, thus by default this behaviour is disabled PARAMETER DESCRIPTION test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings n_recs Number of the top items that will be present in the ranking of each user. If None all candidate items will be returned for the user TYPE: int DEFAULT: 10 user_id_list List of users for which you want to compute the ranking. If None, the ranking will be computed for all users of the test_set TYPE: List DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() save_fit Boolean value which let you choose if the Recommender System should remain fit even after the complete execution of this method. Default is False TYPE: bool DEFAULT: False num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RAISES DESCRIPTION NotFittedAlg Exception raised when this method is called without first calling the fit method RETURNS DESCRIPTION Rank Rank object containing recommendation lists for all users of the test set or for all users in user_id_list Source code in clayrs/recsys/recsys.py 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 def fit_rank ( self , test_set : Ratings , n_recs : int = 10 , user_id_list : List = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), save_fit : bool = False , num_cpus : int = 1 ) -> Rank : \"\"\" Method used to both fit and calculate ranking for all users in test set or all users in `user_id_list` parameter. The Recommender System will first be fit for each user in the train set passed in the constructor. If the algorithm can't be fit for some users, a warning message is printed If the `n_recs` is specified, then the rank will contain the top-n items for the users. Otherwise, the rank will contain all unrated items of the particular users Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be ranked If the algorithm was not fit for some users, they will be skipped and a warning is printed With the `save_fit` parameter you can decide if you want that you recommender system remains *fit* even after the complete execution of this method, in case you want to compute ranking with other methodologies, or with a different `n_recs` parameter. Be mindful since it can be memory-expensive, thus by default this behaviour is disabled Args: test_set: Ratings object which represents the ground truth of the split considered n_recs: Number of the top items that will be present in the ranking of each user. If `None` all candidate items will be returned for the user user_id_list: List of users for which you want to compute the ranking. If None, the ranking will be computed for all users of the `test_set` methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` save_fit: Boolean value which let you choose if the Recommender System should remain fit even after the complete execution of this method. Default is False num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Raises: NotFittedAlg: Exception raised when this method is called without first calling the `fit` method Returns: Rank object containing recommendation lists for all users of the test set or for all users in `user_id_list` \"\"\" def compute_single_fit_rank ( user_id ): user_train = self . train_set . get_user_interactions ( user_id ) alg = self . algorithm if save_fit : alg = deepcopy ( alg ) self . _user_fit_dic [ user_id ] = alg try : alg . process_rated ( user_train , loaded_items_interface ) alg . fit () except UserSkipAlgFit as e : warning_message = str ( e ) + f \" \\n The algorithm can't be fitted for the user { user_id } \" logger . warning ( warning_message ) if save_fit : self . _user_fit_dic [ user_id ] = None return user_id , [] filter_list = None if methodology is not None : filter_list = set ( methodology . filter_single ( user_id , self . train_set , test_set )) user_rank = alg . rank ( user_train , loaded_items_interface , n_recs , filter_list = filter_list ) return user_id , user_rank all_users = set ( test_set . user_id_column ) if user_id_list is not None : all_users = set ( user_id_list ) loaded_items_interface = self . algorithm . _load_available_contents ( self . items_directory , set ()) rank = [] logger . info ( \"Don't worry if it looks stuck at first\" ) logger . info ( \"First iterations will stabilize the estimated remaining time\" ) with get_iterator_parallel ( num_cpus , compute_single_fit_rank , all_users , progress_bar = True , total = len ( all_users )) as pbar : pbar . set_description ( f \"Loading first items from memory...\" ) for user_id , user_rank in pbar : pbar . set_description ( f \"Computing fit_rank for user { user_id } \" ) rank . append ( user_rank ) rank = itertools . chain . from_iterable ( rank ) rank = Rank . from_list ( rank ) # we force the garbage collector after freeing loaded items del loaded_items_interface gc . collect () self . _yaml_report = { 'mode' : 'rank' , 'n_recs' : repr ( n_recs ), 'methodology' : repr ( methodology )} return rank","title":"fit_rank()"},{"location":"recsys/content_based/content_based_recsys/#clayrs.recsys.recsys.ContentBasedRS.items_directory","text":"Path of the serialized items by the Content Analyzer Source code in clayrs/recsys/recsys.py 139 140 141 142 143 144 @property def items_directory ( self ): \"\"\" Path of the serialized items by the Content Analyzer \"\"\" return self . __items_directory","title":"items_directory()"},{"location":"recsys/content_based/content_based_recsys/#clayrs.recsys.recsys.ContentBasedRS.predict","text":"Method used to calculate score predictions for all users in test set or all users in user_id_list parameter. You must first call the fit() method before you can compute score predictions. BE CAREFUL : not all algorithms are able to perform score prediction Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be considered for score prediction If the algorithm was not fit for some users, they will be skipped and a warning is printed PARAMETER DESCRIPTION test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings user_id_list List of users for which you want to compute score prediction. If None, the ranking will be computed for all users of the test_set TYPE: List DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RAISES DESCRIPTION NotFittedAlg Exception raised when this method is called without first calling the fit method RETURNS DESCRIPTION Prediction Prediction object containing score prediction lists for all users of the test set or for all users in user_id_list Source code in clayrs/recsys/recsys.py 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 def predict ( self , test_set : Ratings , user_id_list : List = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 1 ) -> Prediction : \"\"\" Method used to calculate score predictions for all users in test set or all users in `user_id_list` parameter. You must first call the `fit()` method before you can compute score predictions. **BE CAREFUL**: not all algorithms are able to perform *score prediction* Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be considered for score prediction If the algorithm was not fit for some users, they will be skipped and a warning is printed Args: test_set: Ratings object which represents the ground truth of the split considered user_id_list: List of users for which you want to compute score prediction. If None, the ranking will be computed for all users of the `test_set` methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Raises: NotFittedAlg: Exception raised when this method is called without first calling the `fit` method Returns: Prediction object containing score prediction lists for all users of the test set or for all users in `user_id_list` \"\"\" def compute_single_predict ( user_id ): user_id = str ( user_id ) user_train = self . train_set . get_user_interactions ( user_id ) filter_list = None if methodology is not None : filter_list = set ( methodology . filter_single ( user_id , self . train_set , test_set )) user_fitted_alg = self . _user_fit_dic . get ( user_id ) if user_fitted_alg is not None : user_pred = user_fitted_alg . predict ( user_train , loaded_items_interface , filter_list = filter_list ) else : user_pred = [] logger . warning ( f \"No algorithm fitted for user { user_id } ! It will be skipped\" ) return user_id , user_pred if len ( self . _user_fit_dic ) == 0 : raise NotFittedAlg ( \"Algorithm not fit! You must call the fit() method first, or fit_rank().\" ) all_users = set ( test_set . user_id_column ) if user_id_list is not None : all_users = set ( user_id_list ) loaded_items_interface = self . algorithm . _load_available_contents ( self . items_directory , set ()) pred = [] logger . info ( \"Don't worry if it looks stuck at first\" ) logger . info ( \"First iterations will stabilize the estimated remaining time\" ) with get_iterator_parallel ( num_cpus , compute_single_predict , all_users , progress_bar = True , total = len ( all_users )) as pbar : pbar . set_description ( f \"Loading first items from memory...\" ) for user_id , user_pred in pbar : pbar . set_description ( f \"Computing score prediction for user { user_id } \" ) pred . append ( user_pred ) pred = itertools . chain . from_iterable ( pred ) pred = Prediction . from_list ( pred ) # we force the garbage collector after freeing loaded items del loaded_items_interface gc . collect () self . _yaml_report = { 'mode' : 'score_prediction' , 'methodology' : repr ( methodology )} return pred","title":"predict()"},{"location":"recsys/content_based/content_based_recsys/#clayrs.recsys.recsys.ContentBasedRS.rank","text":"Method used to calculate ranking for all users in test set or all users in user_id_list parameter. You must first call the fit() method before you can compute the ranking. If the n_recs is specified, then the rank will contain the top-n items for the users. Otherwise, the rank will contain all unrated items of the particular users Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be ranked If the algorithm was not fit for some users, they will be skipped and a warning is printed PARAMETER DESCRIPTION test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings n_recs Number of the top items that will be present in the ranking of each user. If None all candidate items will be returned for the user TYPE: int DEFAULT: 10 user_id_list List of users for which you want to compute the ranking. If None, the ranking will be computed for all users of the test_set TYPE: List DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RAISES DESCRIPTION NotFittedAlg Exception raised when this method is called without first calling the fit method RETURNS DESCRIPTION Rank Rank object containing recommendation lists for all users of the test set or for all users in user_id_list Source code in clayrs/recsys/recsys.py 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 def rank ( self , test_set : Ratings , n_recs : int = 10 , user_id_list : List = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 1 ) -> Rank : \"\"\" Method used to calculate ranking for all users in test set or all users in `user_id_list` parameter. You must first call the `fit()` method before you can compute the ranking. If the `n_recs` is specified, then the rank will contain the top-n items for the users. Otherwise, the rank will contain all unrated items of the particular users Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be ranked If the algorithm was not fit for some users, they will be skipped and a warning is printed Args: test_set: Ratings object which represents the ground truth of the split considered n_recs: Number of the top items that will be present in the ranking of each user. If `None` all candidate items will be returned for the user user_id_list: List of users for which you want to compute the ranking. If None, the ranking will be computed for all users of the `test_set` methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Raises: NotFittedAlg: Exception raised when this method is called without first calling the `fit` method Returns: Rank object containing recommendation lists for all users of the test set or for all users in `user_id_list` \"\"\" def compute_single_rank ( user_id ): user_id = str ( user_id ) user_train = self . train_set . get_user_interactions ( user_id ) filter_list = None if methodology is not None : filter_list = set ( methodology . filter_single ( user_id , self . train_set , test_set )) user_fitted_alg = self . _user_fit_dic . get ( user_id ) if user_fitted_alg is not None : user_rank = user_fitted_alg . rank ( user_train , loaded_items_interface , n_recs , filter_list = filter_list ) else : user_rank = [] logger . warning ( f \"No algorithm fitted for user { user_id } ! It will be skipped\" ) return user_id , user_rank if len ( self . _user_fit_dic ) == 0 : raise NotFittedAlg ( \"Algorithm not fit! You must call the fit() method first, or fit_rank().\" ) all_users = set ( test_set . user_id_column ) if user_id_list is not None : all_users = set ( user_id_list ) loaded_items_interface = self . algorithm . _load_available_contents ( self . items_directory , set ()) rank = [] logger . info ( \"Don't worry if it looks stuck at first\" ) logger . info ( \"First iterations will stabilize the estimated remaining time\" ) with get_iterator_parallel ( num_cpus , compute_single_rank , all_users , progress_bar = True , total = len ( all_users )) as pbar : pbar . set_description ( f \"Loading first items from memory...\" ) for user_id , user_rank in pbar : pbar . set_description ( f \"Computing rank for user { user_id } \" ) rank . append ( user_rank ) rank = itertools . chain . from_iterable ( rank ) rank = Rank . from_list ( rank ) # we force the garbage collector after freeing loaded items del loaded_items_interface gc . collect () self . _yaml_report = { 'mode' : 'rank' , 'n_recs' : repr ( n_recs ), 'methodology' : repr ( methodology )} return rank","title":"rank()"},{"location":"recsys/content_based/content_based_recsys/#clayrs.recsys.recsys.ContentBasedRS.train_set","text":"The train set of the Content Based RecSys Source code in clayrs/recsys/recsys.py 132 133 134 135 136 137 @property def train_set ( self ): \"\"\" The train set of the Content Based RecSys \"\"\" return self . __train_set","title":"train_set()"},{"location":"recsys/content_based/content_based_recsys/#clayrs.recsys.recsys.ContentBasedRS.users_directory","text":"Path of the serialized users by the Content Analyzer Source code in clayrs/recsys/recsys.py 146 147 148 149 150 151 @property def users_directory ( self ): \"\"\" Path of the serialized users by the Content Analyzer \"\"\" return self . __users_directory","title":"users_directory()"},{"location":"recsys/content_based/content_based_algorithms/centroid_vector/","text":"Centroid Vector CentroidVector ( item_field , similarity , threshold = None , embedding_combiner = Centroid ()) Bases: ContentBasedAlgorithm Class that implements a centroid-like recommender. It first gets the centroid of the items that the user liked. Then computes the similarity between the centroid and the item of which the ranking score must be predicted. It's a ranking algorithm, so it can't do score prediction It computes the centroid vector of the features of items liked by the user It computes the similarity between the centroid vector and the items of which the ranking score must be predicted The items liked by a user are those having a rating higher or equal than a specific threshold . If the threshold is not specified, the average score of all items liked by the user is used. Examples: Interested in only a field representation, CosineSimilarity as similarity, \\(threshold = 3\\) (Every item with rating \\(>= 3\\) will be considered as positive) >>> from clayrs import recsys as rs >>> alg = rs . CentroidVector ({ \"Plot\" : 0 }, rs . CosineSimilarity (), 3 ) Interested in multiple field representations of the items, CosineSimilarity as similarity, \\(threshold = None\\) (Every item with rating \\(>=\\) mean rating of the user will be considered as positive) >>> alg = rs . CentroidVector ( >>> item_field = { \"Plot\" : [ 0 , \"tfidf\" ], >>> \"Genre\" : [ 0 , 1 ], >>> \"Director\" : \"doc2vec\" }, >>> similarity = rs . CosineSimilarity (), >>> threshold = None ) Info After instantiating the CentroidVector algorithm, pass it in the initialization of a CBRS and the use its method to calculate ranking for single user or multiple users: Examples: >>> cbrs = rs.ContentBasedRS(algorithm=alg, ...) >>> cbrs.fit_rank(...) >>> # ... PARAMETER DESCRIPTION item_field dict where the key is the name of the field that contains the content to use, value is the representation(s) id(s) that will be used for the said item. The value of a field can be a string or a list, use a list if you want to use multiple representations for a particular field. TYPE: dict similarity Kind of similarity to use TYPE: Similarity threshold Threshold for the ratings. If the rating is greater than the threshold, it will be considered as positive. If the threshold is not specified, the average score of all items liked by the user is used. TYPE: float DEFAULT: None embedding_combiner CombiningTechnique used when embeddings representation must be used but they are in a matrix form instead of a single vector (e.g. when WordEmbedding representations must be used you have one vector for each word). By default, the Centroid of the rows of the matrix is computed TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/recsys/content_based_algorithm/centroid_vector/centroid_vector.py 76 77 78 79 80 81 82 83 def __init__ ( self , item_field : dict , similarity : Similarity , threshold : float = None , embedding_combiner : CombiningTechnique = Centroid ()): super () . __init__ ( item_field , threshold ) self . _similarity = similarity self . _emb_combiner = embedding_combiner self . _centroid : Optional [ np . ndarray ] = None self . _positive_rated_list : Optional [ List ] = None fit () The fit process for the CentroidVector consists in calculating the centroid of the features of the positive items ONLY. This method uses extracted features of the positive items stored in a private attribute, so process_rated() must be called before this method. The built centroid will also be stored in a private attribute. Source code in clayrs/recsys/content_based_algorithm/centroid_vector/centroid_vector.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 def fit ( self ): \"\"\" The fit process for the CentroidVector consists in calculating the centroid of the features of the positive items ONLY. This method uses extracted features of the positive items stored in a private attribute, so `process_rated()` must be called before this method. The built centroid will also be stored in a private attribute. \"\"\" positive_rated_features_fused = self . fuse_representations ( self . _positive_rated_list , self . _emb_combiner , as_array = True ) self . _centroid = positive_rated_features_fused . mean ( axis = 0 ) # we delete variable used to fit since will no longer be used self . _positive_rated_list = None predict ( user_ratings , available_loaded_items , filter_list = None ) CentroidVector is not a score prediction algorithm, calling this method will raise the NotPredictionAlg exception! RAISES DESCRIPTION NotPredictionAlg exception raised since the CentroidVector algorithm is not a score prediction algorithm Source code in clayrs/recsys/content_based_algorithm/centroid_vector/centroid_vector.py 154 155 156 157 158 159 160 161 162 163 def predict ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" CentroidVector is not a score prediction algorithm, calling this method will raise the `NotPredictionAlg` exception! Raises: NotPredictionAlg: exception raised since the CentroidVector algorithm is not a score prediction algorithm \"\"\" raise NotPredictionAlg ( \"CentroidVector is not a Score Prediction Algorithm!\" ) process_rated ( user_ratings , available_loaded_items ) Function that extracts features from positive rated items ONLY! The extracted features will be used to fit the algorithm (build the centroid). Features extracted will be stored in a private attributes of the class. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict Source code in clayrs/recsys/content_based_algorithm/centroid_vector/centroid_vector.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def process_rated ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict ): \"\"\" Function that extracts features from positive rated items ONLY! The extracted features will be used to fit the algorithm (build the centroid). Features extracted will be stored in a private attributes of the class. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents \"\"\" # a list since there could be duplicate interaction (eg bootstrap partitioning) items_scores_dict = defaultdict ( list ) for interaction in user_ratings : items_scores_dict [ interaction . item_id ] . append ( interaction . score ) items_scores_dict = dict ( sorted ( items_scores_dict . items ())) # sort dictionary based on key for reproducibility # Load rated items from the path loaded_rated_items : List [ Union [ Content , None ]] = available_loaded_items . get_list ([ item_id for item_id in items_scores_dict . keys ()]) # If threshold wasn't passed in the constructor, then we take the mean rating # given by the user as its threshold threshold = self . threshold if threshold is None : threshold = self . _calc_mean_user_threshold ( user_ratings ) # we extract feature of each POSITIVE item sorted based on its key: IMPORTANT for reproducibility!! # otherwise the matrix we feed to sklearn will have input item in different rows each run! positive_rated_list = [] for item in loaded_rated_items : if item is not None : score_assigned = map ( float , items_scores_dict [ item . content_id ]) for score in score_assigned : if score >= threshold : positive_rated_list . append ( self . extract_features_item ( item )) if len ( user_ratings ) == 0 : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_id = user_ratings [ 0 ] . user_id if len ( loaded_rated_items ) == 0 or ( loaded_rated_items . count ( None ) == len ( loaded_rated_items )): raise NoRatedItems ( \"User {} - No rated items available locally!\" . format ( user_id )) if len ( positive_rated_list ) == 0 : raise OnlyNegativeItems ( \"User {} - There are only negative items available locally!\" ) self . _positive_rated_list = positive_rated_list rank ( user_ratings , available_loaded_items , recs_number = None , filter_list = None ) Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the filter_list parameter, in this case ONLY items in the filter_list parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, ALL unrated items will be ranked. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict recs_number number of the top ranked items to return, if None all ranked items will be returned TYPE: int DEFAULT: None filter_list list of the items to rank, if None all unrated items for the user will be ranked TYPE: list DEFAULT: None RETURNS DESCRIPTION List [ Interaction ] List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user Source code in clayrs/recsys/content_based_algorithm/centroid_vector/centroid_vector.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 def rank ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict , recs_number : int = None , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the `filter_list` parameter, in this case ONLY items in the `filter_list` parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, **ALL** unrated items will be ranked. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents recs_number: number of the top ranked items to return, if None all ranked items will be returned filter_list (list): list of the items to rank, if None all unrated items for the user will be ranked Returns: List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user \"\"\" try : user_id = user_ratings [ 0 ] . user_id except IndexError : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_seen_items = set ([ interaction . item_id for interaction in user_ratings ]) # Load items to predict if filter_list is None : items_to_predict = available_loaded_items . get_list ([ item_id for item_id in available_loaded_items if item_id not in user_seen_items ]) else : items_to_predict = available_loaded_items . get_list ( filter_list ) # Extract features of the items to predict id_items_to_predict = [] features_items_to_predict = [] for item in items_to_predict : if item is not None : id_items_to_predict . append ( item . content_id ) features_items_to_predict . append ( self . extract_features_item ( item )) if len ( id_items_to_predict ) > 0 : # Calculate predictions, they are the similarity of the new items with the centroid vector features_fused = self . fuse_representations ( features_items_to_predict , self . _emb_combiner , as_array = True ) similarities = [ self . _similarity . perform ( self . _centroid , item ) for item in features_fused ] else : similarities = [] # Build the item_score dict (key is item_id, value is rank score predicted) # and order the keys in descending order item_score_dict = dict ( zip ( id_items_to_predict , similarities )) ordered_item_ids = sorted ( item_score_dict , key = item_score_dict . get , reverse = True ) # we only save the top-n items_ids corresponding to top-n recommendations # (if recs_number is None ordered_item_ids will contain all item_ids as the original list) ordered_item_ids = ordered_item_ids [: recs_number ] # we construct the output data rank_interaction_list = [ Interaction ( user_id , item_id , item_score_dict [ item_id ]) for item_id in ordered_item_ids ] return rank_interaction_list Similarities implemented The following are similarities you can use in the similarity parameter of the CentroidVector class CosineSimilarity () Bases: Similarity Computes cosine similarity Source code in clayrs/recsys/content_based_algorithm/centroid_vector/similarities.py 25 26 def __init__ ( self ): super () . __init__ () perform ( v1 , v2 ) Calculates the cosine similarity between v1 and v2 PARAMETER DESCRIPTION v1 first numpy array TYPE: np . ndarray v2 second numpy array TYPE: np . ndarray Source code in clayrs/recsys/content_based_algorithm/centroid_vector/similarities.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def perform ( self , v1 : np . ndarray , v2 : np . ndarray ): \"\"\" Calculates the cosine similarity between v1 and v2 Args: v1: first numpy array v2: second numpy array \"\"\" if not v1 . any () or not v2 . any (): return 0 else : # Cosine_distance is defined in the scipy library as 1 - cosine_similarity, so: # 1 - cosine_distance = 1 - (1 - cosine_similarity) = cosine_similarity return 1 - cosine_distance ( v1 , v2 )","title":"Centroid Vector"},{"location":"recsys/content_based/content_based_algorithms/centroid_vector/#centroid-vector","text":"","title":"Centroid Vector"},{"location":"recsys/content_based/content_based_algorithms/centroid_vector/#clayrs.recsys.content_based_algorithm.centroid_vector.CentroidVector","text":"Bases: ContentBasedAlgorithm Class that implements a centroid-like recommender. It first gets the centroid of the items that the user liked. Then computes the similarity between the centroid and the item of which the ranking score must be predicted. It's a ranking algorithm, so it can't do score prediction It computes the centroid vector of the features of items liked by the user It computes the similarity between the centroid vector and the items of which the ranking score must be predicted The items liked by a user are those having a rating higher or equal than a specific threshold . If the threshold is not specified, the average score of all items liked by the user is used. Examples: Interested in only a field representation, CosineSimilarity as similarity, \\(threshold = 3\\) (Every item with rating \\(>= 3\\) will be considered as positive) >>> from clayrs import recsys as rs >>> alg = rs . CentroidVector ({ \"Plot\" : 0 }, rs . CosineSimilarity (), 3 ) Interested in multiple field representations of the items, CosineSimilarity as similarity, \\(threshold = None\\) (Every item with rating \\(>=\\) mean rating of the user will be considered as positive) >>> alg = rs . CentroidVector ( >>> item_field = { \"Plot\" : [ 0 , \"tfidf\" ], >>> \"Genre\" : [ 0 , 1 ], >>> \"Director\" : \"doc2vec\" }, >>> similarity = rs . CosineSimilarity (), >>> threshold = None ) Info After instantiating the CentroidVector algorithm, pass it in the initialization of a CBRS and the use its method to calculate ranking for single user or multiple users: Examples: >>> cbrs = rs.ContentBasedRS(algorithm=alg, ...) >>> cbrs.fit_rank(...) >>> # ... PARAMETER DESCRIPTION item_field dict where the key is the name of the field that contains the content to use, value is the representation(s) id(s) that will be used for the said item. The value of a field can be a string or a list, use a list if you want to use multiple representations for a particular field. TYPE: dict similarity Kind of similarity to use TYPE: Similarity threshold Threshold for the ratings. If the rating is greater than the threshold, it will be considered as positive. If the threshold is not specified, the average score of all items liked by the user is used. TYPE: float DEFAULT: None embedding_combiner CombiningTechnique used when embeddings representation must be used but they are in a matrix form instead of a single vector (e.g. when WordEmbedding representations must be used you have one vector for each word). By default, the Centroid of the rows of the matrix is computed TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/recsys/content_based_algorithm/centroid_vector/centroid_vector.py 76 77 78 79 80 81 82 83 def __init__ ( self , item_field : dict , similarity : Similarity , threshold : float = None , embedding_combiner : CombiningTechnique = Centroid ()): super () . __init__ ( item_field , threshold ) self . _similarity = similarity self . _emb_combiner = embedding_combiner self . _centroid : Optional [ np . ndarray ] = None self . _positive_rated_list : Optional [ List ] = None","title":"CentroidVector"},{"location":"recsys/content_based/content_based_algorithms/centroid_vector/#clayrs.recsys.content_based_algorithm.centroid_vector.centroid_vector.CentroidVector.fit","text":"The fit process for the CentroidVector consists in calculating the centroid of the features of the positive items ONLY. This method uses extracted features of the positive items stored in a private attribute, so process_rated() must be called before this method. The built centroid will also be stored in a private attribute. Source code in clayrs/recsys/content_based_algorithm/centroid_vector/centroid_vector.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 def fit ( self ): \"\"\" The fit process for the CentroidVector consists in calculating the centroid of the features of the positive items ONLY. This method uses extracted features of the positive items stored in a private attribute, so `process_rated()` must be called before this method. The built centroid will also be stored in a private attribute. \"\"\" positive_rated_features_fused = self . fuse_representations ( self . _positive_rated_list , self . _emb_combiner , as_array = True ) self . _centroid = positive_rated_features_fused . mean ( axis = 0 ) # we delete variable used to fit since will no longer be used self . _positive_rated_list = None","title":"fit()"},{"location":"recsys/content_based/content_based_algorithms/centroid_vector/#clayrs.recsys.content_based_algorithm.centroid_vector.centroid_vector.CentroidVector.predict","text":"CentroidVector is not a score prediction algorithm, calling this method will raise the NotPredictionAlg exception! RAISES DESCRIPTION NotPredictionAlg exception raised since the CentroidVector algorithm is not a score prediction algorithm Source code in clayrs/recsys/content_based_algorithm/centroid_vector/centroid_vector.py 154 155 156 157 158 159 160 161 162 163 def predict ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" CentroidVector is not a score prediction algorithm, calling this method will raise the `NotPredictionAlg` exception! Raises: NotPredictionAlg: exception raised since the CentroidVector algorithm is not a score prediction algorithm \"\"\" raise NotPredictionAlg ( \"CentroidVector is not a Score Prediction Algorithm!\" )","title":"predict()"},{"location":"recsys/content_based/content_based_algorithms/centroid_vector/#clayrs.recsys.content_based_algorithm.centroid_vector.centroid_vector.CentroidVector.process_rated","text":"Function that extracts features from positive rated items ONLY! The extracted features will be used to fit the algorithm (build the centroid). Features extracted will be stored in a private attributes of the class. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict Source code in clayrs/recsys/content_based_algorithm/centroid_vector/centroid_vector.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def process_rated ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict ): \"\"\" Function that extracts features from positive rated items ONLY! The extracted features will be used to fit the algorithm (build the centroid). Features extracted will be stored in a private attributes of the class. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents \"\"\" # a list since there could be duplicate interaction (eg bootstrap partitioning) items_scores_dict = defaultdict ( list ) for interaction in user_ratings : items_scores_dict [ interaction . item_id ] . append ( interaction . score ) items_scores_dict = dict ( sorted ( items_scores_dict . items ())) # sort dictionary based on key for reproducibility # Load rated items from the path loaded_rated_items : List [ Union [ Content , None ]] = available_loaded_items . get_list ([ item_id for item_id in items_scores_dict . keys ()]) # If threshold wasn't passed in the constructor, then we take the mean rating # given by the user as its threshold threshold = self . threshold if threshold is None : threshold = self . _calc_mean_user_threshold ( user_ratings ) # we extract feature of each POSITIVE item sorted based on its key: IMPORTANT for reproducibility!! # otherwise the matrix we feed to sklearn will have input item in different rows each run! positive_rated_list = [] for item in loaded_rated_items : if item is not None : score_assigned = map ( float , items_scores_dict [ item . content_id ]) for score in score_assigned : if score >= threshold : positive_rated_list . append ( self . extract_features_item ( item )) if len ( user_ratings ) == 0 : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_id = user_ratings [ 0 ] . user_id if len ( loaded_rated_items ) == 0 or ( loaded_rated_items . count ( None ) == len ( loaded_rated_items )): raise NoRatedItems ( \"User {} - No rated items available locally!\" . format ( user_id )) if len ( positive_rated_list ) == 0 : raise OnlyNegativeItems ( \"User {} - There are only negative items available locally!\" ) self . _positive_rated_list = positive_rated_list","title":"process_rated()"},{"location":"recsys/content_based/content_based_algorithms/centroid_vector/#clayrs.recsys.content_based_algorithm.centroid_vector.centroid_vector.CentroidVector.rank","text":"Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the filter_list parameter, in this case ONLY items in the filter_list parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, ALL unrated items will be ranked. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict recs_number number of the top ranked items to return, if None all ranked items will be returned TYPE: int DEFAULT: None filter_list list of the items to rank, if None all unrated items for the user will be ranked TYPE: list DEFAULT: None RETURNS DESCRIPTION List [ Interaction ] List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user Source code in clayrs/recsys/content_based_algorithm/centroid_vector/centroid_vector.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 def rank ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict , recs_number : int = None , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the `filter_list` parameter, in this case ONLY items in the `filter_list` parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, **ALL** unrated items will be ranked. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents recs_number: number of the top ranked items to return, if None all ranked items will be returned filter_list (list): list of the items to rank, if None all unrated items for the user will be ranked Returns: List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user \"\"\" try : user_id = user_ratings [ 0 ] . user_id except IndexError : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_seen_items = set ([ interaction . item_id for interaction in user_ratings ]) # Load items to predict if filter_list is None : items_to_predict = available_loaded_items . get_list ([ item_id for item_id in available_loaded_items if item_id not in user_seen_items ]) else : items_to_predict = available_loaded_items . get_list ( filter_list ) # Extract features of the items to predict id_items_to_predict = [] features_items_to_predict = [] for item in items_to_predict : if item is not None : id_items_to_predict . append ( item . content_id ) features_items_to_predict . append ( self . extract_features_item ( item )) if len ( id_items_to_predict ) > 0 : # Calculate predictions, they are the similarity of the new items with the centroid vector features_fused = self . fuse_representations ( features_items_to_predict , self . _emb_combiner , as_array = True ) similarities = [ self . _similarity . perform ( self . _centroid , item ) for item in features_fused ] else : similarities = [] # Build the item_score dict (key is item_id, value is rank score predicted) # and order the keys in descending order item_score_dict = dict ( zip ( id_items_to_predict , similarities )) ordered_item_ids = sorted ( item_score_dict , key = item_score_dict . get , reverse = True ) # we only save the top-n items_ids corresponding to top-n recommendations # (if recs_number is None ordered_item_ids will contain all item_ids as the original list) ordered_item_ids = ordered_item_ids [: recs_number ] # we construct the output data rank_interaction_list = [ Interaction ( user_id , item_id , item_score_dict [ item_id ]) for item_id in ordered_item_ids ] return rank_interaction_list","title":"rank()"},{"location":"recsys/content_based/content_based_algorithms/centroid_vector/#similarities-implemented","text":"The following are similarities you can use in the similarity parameter of the CentroidVector class","title":"Similarities implemented"},{"location":"recsys/content_based/content_based_algorithms/centroid_vector/#clayrs.recsys.content_based_algorithm.centroid_vector.similarities.CosineSimilarity","text":"Bases: Similarity Computes cosine similarity Source code in clayrs/recsys/content_based_algorithm/centroid_vector/similarities.py 25 26 def __init__ ( self ): super () . __init__ ()","title":"CosineSimilarity"},{"location":"recsys/content_based/content_based_algorithms/centroid_vector/#clayrs.recsys.content_based_algorithm.centroid_vector.similarities.CosineSimilarity.perform","text":"Calculates the cosine similarity between v1 and v2 PARAMETER DESCRIPTION v1 first numpy array TYPE: np . ndarray v2 second numpy array TYPE: np . ndarray Source code in clayrs/recsys/content_based_algorithm/centroid_vector/similarities.py 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def perform ( self , v1 : np . ndarray , v2 : np . ndarray ): \"\"\" Calculates the cosine similarity between v1 and v2 Args: v1: first numpy array v2: second numpy array \"\"\" if not v1 . any () or not v2 . any (): return 0 else : # Cosine_distance is defined in the scipy library as 1 - cosine_similarity, so: # 1 - cosine_distance = 1 - (1 - cosine_similarity) = cosine_similarity return 1 - cosine_distance ( v1 , v2 )","title":"perform()"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/","text":"Classifier Recommender ClassifierRecommender ( item_field , classifier , threshold = None , embedding_combiner = Centroid ()) Bases: ContentBasedAlgorithm Class that implements recommendation through a specified Classifier . It's a ranking algorithm so it can't do score prediction. Examples: Interested in only a field representation, DecisionTree classifier from sklearn, \\(threshold = 3\\) (Every item with rating score \\(>= 3\\) will be considered as positive ) >>> from clayrs import recsys as rs >>> alg = rs . ClassifierRecommender ({ \"Plot\" : 0 }, rs . SkDecisionTree (), 3 ) Interested in only a field representation, KNN classifier with custom parameters from sklearn, \\(threshold = 3\\) (Every item with rating score \\(>= 3\\) will be considered as positive) >>> alg = rs . ClassifierRecommender ({ \"Plot\" : 0 }, rs . SkKNN ( n_neighbors = 3 ), 0 ) Interested in multiple field representations of the items, KNN classifier with custom parameters from sklearn, \\(threshold = None\\) (Every item with rating \\(>=\\) mean rating of the user will be considered as positive) >>> alg = ClassifierRecommender ( >>> item_field = { \"Plot\" : [ 0 , \"tfidf\" ], >>> \"Genre\" : [ 0 , 1 ], >>> \"Director\" : \"doc2vec\" }, >>> classifier = rs . SkKNN ( n_neighbors = 3 ), >>> threshold = None ) Info After instantiating the ClassifierRecommender algorithm, pass it in the initialization of a CBRS and the use its method to calculate ranking for single user or multiple users: Examples: >>> cbrs = rs.ContentBasedRS(algorithm=alg, ...) >>> cbrs.fit_rank(...) >>> # ... PARAMETER DESCRIPTION item_field dict where the key is the name of the field that contains the content to use, value is the representation(s) id(s) that will be used for the said item. The value of a field can be a string or a list, use a list if you want to use multiple representations for a particular field. TYPE: dict classifier classifier that will be used. Can be one object of the Classifier class. TYPE: Classifier threshold Threshold for the ratings. If the rating is greater than the threshold, it will be considered as positive. If the threshold is not specified, the average score of all items liked by the user is used. TYPE: float DEFAULT: None embedding_combiner CombiningTechnique used when embeddings representation must be used but they are in a matrix form instead of a single vector (e.g. when WordEmbedding representations must be used you have one vector for each word). By default the Centroid of the rows of the matrix is computed TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/recsys/content_based_algorithm/classifier/classifier_recommender.py 73 74 75 76 77 78 79 def __init__ ( self , item_field : dict , classifier : Classifier , threshold : float = None , embedding_combiner : CombiningTechnique = Centroid ()): super () . __init__ ( item_field , threshold ) self . _classifier = classifier self . _embedding_combiner = embedding_combiner self . _labels : Optional [ list ] = None self . _items_features : Optional [ list ] = None fit () Fit the classifier specified in the constructor with the features and labels extracted with the process_rated() method. It uses private attributes to fit the classifier, so process_rated() must be called before this method. Source code in clayrs/recsys/content_based_algorithm/classifier/classifier_recommender.py 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def fit ( self ): \"\"\" Fit the classifier specified in the constructor with the features and labels extracted with the `process_rated()` method. It uses private attributes to fit the classifier, so `process_rated()` must be called before this method. \"\"\" # Fuse the input if there are dicts, multiple representation, etc. fused_features = self . fuse_representations ( self . _items_features , self . _embedding_combiner ) self . _classifier . fit ( fused_features , self . _labels ) # we delete variables used to fit since will no longer be used self . _items_features = None self . _labels = None predict ( user_ratings , available_loaded_items , filter_list = None ) ClassifierRecommender is not a score prediction algorithm, calling this method will raise the NotPredictionAlg exception! RAISES DESCRIPTION NotPredictionAlg exception raised since the CentroidVector algorithm is not a score prediction algorithm Source code in clayrs/recsys/content_based_algorithm/classifier/classifier_recommender.py 169 170 171 172 173 174 175 176 177 178 def predict ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" ClassifierRecommender is not a score prediction algorithm, calling this method will raise the `NotPredictionAlg` exception! Raises: NotPredictionAlg: exception raised since the CentroidVector algorithm is not a score prediction algorithm \"\"\" raise NotPredictionAlg ( \"ClassifierRecommender is not a Score Prediction Algorithm!\" ) process_rated ( user_ratings , available_loaded_items ) Function that extracts features from rated item and labels them. The extracted features will be later used to fit the classifier. Features and labels will be stored in private attributes of the class. IF there are no rated_items available locally or if there are only positive/negative items, an exception is thrown. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict RAISES DESCRIPTION NoRatedItems Exception raised when there isn't any item available locally rated by the user OnlyPositiveItems Exception raised when there are only positive items available locally for the user (Items that the user liked) OnlyNegativeitems Exception raised when there are only negative items available locally for the user (Items that the user disliked) Source code in clayrs/recsys/content_based_algorithm/classifier/classifier_recommender.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def process_rated ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict ): \"\"\" Function that extracts features from rated item and labels them. The extracted features will be later used to fit the classifier. Features and labels will be stored in private attributes of the class. IF there are no rated_items available locally or if there are only positive/negative items, an exception is thrown. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents Raises: NoRatedItems: Exception raised when there isn't any item available locally rated by the user OnlyPositiveItems: Exception raised when there are only positive items available locally for the user (Items that the user liked) OnlyNegativeitems: Exception raised when there are only negative items available locally for the user (Items that the user disliked) \"\"\" # a list since there could be duplicate interaction (eg bootstrap partitioning) items_scores_dict = defaultdict ( list ) for interaction in user_ratings : items_scores_dict [ interaction . item_id ] . append ( interaction . score ) items_scores_dict = dict ( sorted ( items_scores_dict . items ())) # sort dictionary based on key for reproducibility # Load rated items from the path loaded_rated_items : List [ Union [ Content , None ]] = available_loaded_items . get_list ([ item_id for item_id in items_scores_dict . keys ()]) threshold = self . threshold if threshold is None : threshold = self . _calc_mean_user_threshold ( user_ratings ) # Assign label and extract features from the rated items labels = [] items_features = [] # we extract feature of each item sorted based on its key: IMPORTANT for reproducibility!! # otherwise the matrix we feed to sklearn will have input item in different rows each run! for item in loaded_rated_items : if item is not None : score_assigned = map ( float , items_scores_dict [ item . content_id ]) for score in score_assigned : items_features . append ( self . extract_features_item ( item )) if score >= threshold : labels . append ( 1 ) else : labels . append ( 0 ) if len ( user_ratings ) == 0 : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_id = user_ratings [ 0 ] . user_id if len ( items_features ) == 0 : raise NoRatedItems ( \"User {} - No rated item available locally!\" . format ( user_id )) if 0 not in labels : raise OnlyPositiveItems ( \"User {} - There are only positive items available locally!\" . format ( user_id )) elif 1 not in labels : raise OnlyNegativeItems ( \"User {} - There are only negative items available locally!\" . format ( user_id )) self . _labels = labels self . _items_features = items_features rank ( user_ratings , available_loaded_items , recs_number = None , filter_list = None ) Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the filter_list parameter, in this case ONLY items in the filter_list parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, ALL unrated items will be ranked. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict recs_number number of the top ranked items to return, if None all ranked items will be returned TYPE: int DEFAULT: None filter_list list of the items to rank, if None all unrated items for the user will be ranked TYPE: list DEFAULT: None RETURNS DESCRIPTION List [ Interaction ] List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user Source code in clayrs/recsys/content_based_algorithm/classifier/classifier_recommender.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 def rank ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict , recs_number : int = None , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the `filter_list` parameter, in this case ONLY items in the `filter_list` parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, **ALL** unrated items will be ranked. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents recs_number: number of the top ranked items to return, if None all ranked items will be returned filter_list (list): list of the items to rank, if None all unrated items for the user will be ranked Returns: List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user \"\"\" try : user_id = user_ratings [ 0 ] . user_id except IndexError : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_seen_items = set ([ interaction . item_id for interaction in user_ratings ]) # Load items to predict if filter_list is None : items_to_predict = available_loaded_items . get_list ([ item_id for item_id in available_loaded_items if item_id not in user_seen_items ]) else : items_to_predict = available_loaded_items . get_list ( filter_list ) # Extract features of the items to predict id_items_to_predict = [] features_items_to_predict = [] for item in items_to_predict : if item is not None : id_items_to_predict . append ( item . content_id ) features_items_to_predict . append ( self . extract_features_item ( item )) if len ( id_items_to_predict ) > 0 : # Fuse the input if there are dicts, multiple representation, etc. fused_features_items_to_pred = self . fuse_representations ( features_items_to_predict , self . _embedding_combiner ) class_prob = self . _classifier . predict_proba ( fused_features_items_to_pred ) else : class_prob = [] # for each item we extract the probability that the item is liked (class 1) score_labels = ( prob [ 1 ] for prob in class_prob ) # Build the item_score dict (key is item_id, value is rank score predicted) # and order the keys in descending order item_score_dict = dict ( zip ( id_items_to_predict , score_labels )) ordered_item_ids = sorted ( item_score_dict , key = item_score_dict . get , reverse = True ) # we only save the top-n items_ids corresponding to top-n recommendations # (if recs_number is None ordered_item_ids will contain all item_ids as the original list) ordered_item_ids = ordered_item_ids [: recs_number ] # we construct the output data rank_interaction_list = [ Interaction ( user_id , item_id , item_score_dict [ item_id ]) for item_id in ordered_item_ids ] return rank_interaction_list Classifiers Implemented The following are the classifiers you can use in the classifier parameter of the ClassifierRecommender class SkDecisionTree ( * , criterion = 'gini' , splitter = 'best' , max_depth = None , min_samples_split = 2 , min_samples_leaf = 1 , min_weight_fraction_leaf = 0.0 , max_features = None , random_state = None , max_leaf_nodes = None , min_impurity_decrease = 0.0 , class_weight = None , ccp_alpha = 0.0 ) Bases: Classifier Class that implements the Decision Tree Classifier from sklearn. The parameters one could pass are the same ones you would pass instantiating the classifier directly from sklearn Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/classifier/classifiers.py 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 def __init__ ( self , * , criterion : Any = \"gini\" , splitter : Any = \"best\" , max_depth : Any = None , min_samples_split : Any = 2 , min_samples_leaf : Any = 1 , min_weight_fraction_leaf : Any = 0.0 , max_features : Any = None , random_state : Any = None , max_leaf_nodes : Any = None , min_impurity_decrease : Any = 0.0 , class_weight : Any = None , ccp_alpha : Any = 0.0 ): clf = DecisionTreeClassifier ( criterion = criterion , splitter = splitter , max_depth = max_depth , min_samples_split = min_samples_split , min_samples_leaf = min_samples_leaf , min_weight_fraction_leaf = min_weight_fraction_leaf , max_features = max_features , random_state = random_state , max_leaf_nodes = max_leaf_nodes , min_impurity_decrease = min_impurity_decrease , class_weight = class_weight , ccp_alpha = ccp_alpha ) super () . __init__ ( clf , inspect . currentframe ()) SkGaussianProcess ( kernel = None , * , optimizer = 'fmin_l_bfgs_b' , n_restarts_optimizer = 0 , max_iter_predict = 100 , warm_start = False , copy_X_train = True , random_state = None , multi_class = 'one_vs_rest' , n_jobs = None ) Bases: Classifier Class that implements the Gaussian Process Classifier from sklearn. The parameters one could pass are the same ones you would pass instantiating the classifier directly from sklearn Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/classifier/classifiers.py 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 def __init__ ( self , kernel : Any = None , * , optimizer : Any = \"fmin_l_bfgs_b\" , n_restarts_optimizer : Any = 0 , max_iter_predict : Any = 100 , warm_start : Any = False , copy_X_train : Any = True , random_state : Any = None , multi_class : Any = \"one_vs_rest\" , n_jobs : Any = None ): clf = GaussianProcessClassifier ( kernel = kernel , optimizer = optimizer , n_restarts_optimizer = n_restarts_optimizer , max_iter_predict = max_iter_predict , warm_start = warm_start , copy_X_train = copy_X_train , random_state = random_state , multi_class = multi_class , n_jobs = n_jobs ) super () . __init__ ( clf , inspect . currentframe ()) SkKNN ( n_neighbors = 5 , * , weights = 'uniform' , algorithm = 'auto' , leaf_size = 30 , p = 2 , metric = 'minkowski' , metric_params = None , n_jobs = None ) Bases: Classifier Class that implements the KNN Classifier from sklearn. The parameters one could pass are the same ones you would pass instantiating the classifier KNN directly from sklearn. Sklearn documentation: here Since KNN implementation of sklearn has n_neighbors = 5 as default, it can throw an exception if less sample in the training data are provided, so we change dynamically the n_neighbors parameter according to the number of samples if the dataset is too small and if no manual n_neighbors is set Source code in clayrs/recsys/content_based_algorithm/classifier/classifiers.py 129 130 131 132 133 134 135 136 137 138 139 140 141 def __init__ ( self , n_neighbors : Any = 5 , * , weights : Any = \"uniform\" , algorithm : Any = \"auto\" , leaf_size : Any = 30 , p : Any = 2 , metric : Any = \"minkowski\" , metric_params : Any = None , n_jobs : Any = None ): clf = KNeighborsClassifier ( n_neighbors = n_neighbors , weights = weights , algorithm = algorithm , leaf_size = leaf_size , p = p , metric = metric , metric_params = metric_params , n_jobs = n_jobs ) super () . __init__ ( clf , inspect . currentframe ()) SkLogisticRegression ( penalty = 'l2' , * , dual = False , tol = 0.0001 , C = 1.0 , fit_intercept = True , intercept_scaling = 1 , class_weight = None , random_state = None , solver = 'lbfgs' , max_iter = 100 , multi_class = 'auto' , verbose = 0 , warm_start = False , n_jobs = None , l1_ratio = None ) Bases: Classifier Class that implements the Logistic Regression Classifier from sklearn. The parameters one could pass are the same ones you would pass instantiating the classifier directly from sklearn Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/classifier/classifiers.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 def __init__ ( self , penalty : Any = \"l2\" , * , dual : Any = False , tol : Any = 1e-4 , C : Any = 1.0 , fit_intercept : Any = True , intercept_scaling : Any = 1 , class_weight : Any = None , random_state : Any = None , solver : Any = \"lbfgs\" , max_iter : Any = 100 , multi_class : Any = \"auto\" , verbose : Any = 0 , warm_start : Any = False , n_jobs : Any = None , l1_ratio : Any = None ): clf = LogisticRegression ( penalty = penalty , dual = dual , tol = tol , C = C , fit_intercept = fit_intercept , intercept_scaling = intercept_scaling , class_weight = class_weight , random_state = random_state , solver = solver , max_iter = max_iter , multi_class = multi_class , verbose = verbose , warm_start = warm_start , n_jobs = n_jobs , l1_ratio = l1_ratio ) super () . __init__ ( clf , inspect . currentframe ()) SkRandomForest ( n_estimators = 100 , * , criterion = 'gini' , max_depth = None , min_samples_split = 2 , min_samples_leaf = 1 , min_weight_fraction_leaf = 0.0 , max_features = 'auto' , max_leaf_nodes = None , min_impurity_decrease = 0.0 , bootstrap = True , oob_score = False , n_jobs = None , random_state = None , verbose = 0 , warm_start = False , class_weight = None , ccp_alpha = 0.0 , max_samples = None ) Bases: Classifier Class that implements the Random Forest Classifier from sklearn. The parameters one could pass are the same ones you would pass instantiating the classifier directly from sklearn Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/classifier/classifiers.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def __init__ ( self , n_estimators : Any = 100 , * , criterion : Any = \"gini\" , max_depth : Any = None , min_samples_split : Any = 2 , min_samples_leaf : Any = 1 , min_weight_fraction_leaf : Any = 0.0 , max_features : Any = \"auto\" , max_leaf_nodes : Any = None , min_impurity_decrease : Any = 0.0 , bootstrap : Any = True , oob_score : Any = False , n_jobs : Any = None , random_state : Any = None , verbose : Any = 0 , warm_start : Any = False , class_weight : Any = None , ccp_alpha : Any = 0.0 , max_samples : Any = None ): clf = RandomForestClassifier ( n_estimators = n_estimators , criterion = criterion , max_depth = max_depth , min_samples_split = min_samples_split , min_samples_leaf = min_samples_leaf , min_weight_fraction_leaf = min_weight_fraction_leaf , max_features = max_features , max_leaf_nodes = max_leaf_nodes , min_impurity_decrease = min_impurity_decrease , bootstrap = bootstrap , oob_score = oob_score , n_jobs = n_jobs , random_state = random_state , verbose = verbose , warm_start = warm_start , class_weight = class_weight , ccp_alpha = ccp_alpha , max_samples = max_samples ) super () . __init__ ( clf , inspect . currentframe ()) SkSVC ( * , C = 1.0 , kernel = 'rbf' , degree = 3 , gamma = 'scale' , coef0 = 0.0 , shrinking = True , tol = 0.001 , cache_size = 200 , class_weight = None , verbose = False , max_iter =- 1 , decision_function_shape = 'ovr' , break_ties = False , random_state = None ) Bases: Classifier Class that implements the SVC Classifier from sklearn. The parameters one could pass are the same ones you would pass instantiating the classifier SVC directly from sklearn. Sklearn documentation: here The only parameter from sklearn that cannot be passed is the 'probability' parameter: it is set to True and cannot be changed Source code in clayrs/recsys/content_based_algorithm/classifier/classifiers.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def __init__ ( self , * , C : Any = 1.0 , kernel : Any = \"rbf\" , degree : Any = 3 , gamma : Any = \"scale\" , coef0 : Any = 0.0 , shrinking : Any = True , tol : Any = 1e-3 , cache_size : Any = 200 , class_weight : Any = None , verbose : Any = False , max_iter : Any = - 1 , decision_function_shape : Any = \"ovr\" , break_ties : Any = False , random_state : Any = None ): # Force the probability parameter at True, otherwise SVC won't predict_proba clf = SVC ( C = C , kernel = kernel , degree = degree , gamma = gamma , coef0 = coef0 , shrinking = shrinking , tol = tol , cache_size = cache_size , class_weight = class_weight , verbose = verbose , max_iter = max_iter , decision_function_shape = decision_function_shape , break_ties = break_ties , random_state = random_state , probability = True ) super () . __init__ ( clf , inspect . currentframe ())","title":"Classifier Recommender"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/#classifier-recommender","text":"","title":"Classifier Recommender"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/#clayrs.recsys.content_based_algorithm.classifier.classifier_recommender.ClassifierRecommender","text":"Bases: ContentBasedAlgorithm Class that implements recommendation through a specified Classifier . It's a ranking algorithm so it can't do score prediction. Examples: Interested in only a field representation, DecisionTree classifier from sklearn, \\(threshold = 3\\) (Every item with rating score \\(>= 3\\) will be considered as positive ) >>> from clayrs import recsys as rs >>> alg = rs . ClassifierRecommender ({ \"Plot\" : 0 }, rs . SkDecisionTree (), 3 ) Interested in only a field representation, KNN classifier with custom parameters from sklearn, \\(threshold = 3\\) (Every item with rating score \\(>= 3\\) will be considered as positive) >>> alg = rs . ClassifierRecommender ({ \"Plot\" : 0 }, rs . SkKNN ( n_neighbors = 3 ), 0 ) Interested in multiple field representations of the items, KNN classifier with custom parameters from sklearn, \\(threshold = None\\) (Every item with rating \\(>=\\) mean rating of the user will be considered as positive) >>> alg = ClassifierRecommender ( >>> item_field = { \"Plot\" : [ 0 , \"tfidf\" ], >>> \"Genre\" : [ 0 , 1 ], >>> \"Director\" : \"doc2vec\" }, >>> classifier = rs . SkKNN ( n_neighbors = 3 ), >>> threshold = None ) Info After instantiating the ClassifierRecommender algorithm, pass it in the initialization of a CBRS and the use its method to calculate ranking for single user or multiple users: Examples: >>> cbrs = rs.ContentBasedRS(algorithm=alg, ...) >>> cbrs.fit_rank(...) >>> # ... PARAMETER DESCRIPTION item_field dict where the key is the name of the field that contains the content to use, value is the representation(s) id(s) that will be used for the said item. The value of a field can be a string or a list, use a list if you want to use multiple representations for a particular field. TYPE: dict classifier classifier that will be used. Can be one object of the Classifier class. TYPE: Classifier threshold Threshold for the ratings. If the rating is greater than the threshold, it will be considered as positive. If the threshold is not specified, the average score of all items liked by the user is used. TYPE: float DEFAULT: None embedding_combiner CombiningTechnique used when embeddings representation must be used but they are in a matrix form instead of a single vector (e.g. when WordEmbedding representations must be used you have one vector for each word). By default the Centroid of the rows of the matrix is computed TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/recsys/content_based_algorithm/classifier/classifier_recommender.py 73 74 75 76 77 78 79 def __init__ ( self , item_field : dict , classifier : Classifier , threshold : float = None , embedding_combiner : CombiningTechnique = Centroid ()): super () . __init__ ( item_field , threshold ) self . _classifier = classifier self . _embedding_combiner = embedding_combiner self . _labels : Optional [ list ] = None self . _items_features : Optional [ list ] = None","title":"ClassifierRecommender"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/#clayrs.recsys.content_based_algorithm.classifier.classifier_recommender.ClassifierRecommender.fit","text":"Fit the classifier specified in the constructor with the features and labels extracted with the process_rated() method. It uses private attributes to fit the classifier, so process_rated() must be called before this method. Source code in clayrs/recsys/content_based_algorithm/classifier/classifier_recommender.py 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 def fit ( self ): \"\"\" Fit the classifier specified in the constructor with the features and labels extracted with the `process_rated()` method. It uses private attributes to fit the classifier, so `process_rated()` must be called before this method. \"\"\" # Fuse the input if there are dicts, multiple representation, etc. fused_features = self . fuse_representations ( self . _items_features , self . _embedding_combiner ) self . _classifier . fit ( fused_features , self . _labels ) # we delete variables used to fit since will no longer be used self . _items_features = None self . _labels = None","title":"fit()"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/#clayrs.recsys.content_based_algorithm.classifier.classifier_recommender.ClassifierRecommender.predict","text":"ClassifierRecommender is not a score prediction algorithm, calling this method will raise the NotPredictionAlg exception! RAISES DESCRIPTION NotPredictionAlg exception raised since the CentroidVector algorithm is not a score prediction algorithm Source code in clayrs/recsys/content_based_algorithm/classifier/classifier_recommender.py 169 170 171 172 173 174 175 176 177 178 def predict ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" ClassifierRecommender is not a score prediction algorithm, calling this method will raise the `NotPredictionAlg` exception! Raises: NotPredictionAlg: exception raised since the CentroidVector algorithm is not a score prediction algorithm \"\"\" raise NotPredictionAlg ( \"ClassifierRecommender is not a Score Prediction Algorithm!\" )","title":"predict()"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/#clayrs.recsys.content_based_algorithm.classifier.classifier_recommender.ClassifierRecommender.process_rated","text":"Function that extracts features from rated item and labels them. The extracted features will be later used to fit the classifier. Features and labels will be stored in private attributes of the class. IF there are no rated_items available locally or if there are only positive/negative items, an exception is thrown. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict RAISES DESCRIPTION NoRatedItems Exception raised when there isn't any item available locally rated by the user OnlyPositiveItems Exception raised when there are only positive items available locally for the user (Items that the user liked) OnlyNegativeitems Exception raised when there are only negative items available locally for the user (Items that the user disliked) Source code in clayrs/recsys/content_based_algorithm/classifier/classifier_recommender.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def process_rated ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict ): \"\"\" Function that extracts features from rated item and labels them. The extracted features will be later used to fit the classifier. Features and labels will be stored in private attributes of the class. IF there are no rated_items available locally or if there are only positive/negative items, an exception is thrown. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents Raises: NoRatedItems: Exception raised when there isn't any item available locally rated by the user OnlyPositiveItems: Exception raised when there are only positive items available locally for the user (Items that the user liked) OnlyNegativeitems: Exception raised when there are only negative items available locally for the user (Items that the user disliked) \"\"\" # a list since there could be duplicate interaction (eg bootstrap partitioning) items_scores_dict = defaultdict ( list ) for interaction in user_ratings : items_scores_dict [ interaction . item_id ] . append ( interaction . score ) items_scores_dict = dict ( sorted ( items_scores_dict . items ())) # sort dictionary based on key for reproducibility # Load rated items from the path loaded_rated_items : List [ Union [ Content , None ]] = available_loaded_items . get_list ([ item_id for item_id in items_scores_dict . keys ()]) threshold = self . threshold if threshold is None : threshold = self . _calc_mean_user_threshold ( user_ratings ) # Assign label and extract features from the rated items labels = [] items_features = [] # we extract feature of each item sorted based on its key: IMPORTANT for reproducibility!! # otherwise the matrix we feed to sklearn will have input item in different rows each run! for item in loaded_rated_items : if item is not None : score_assigned = map ( float , items_scores_dict [ item . content_id ]) for score in score_assigned : items_features . append ( self . extract_features_item ( item )) if score >= threshold : labels . append ( 1 ) else : labels . append ( 0 ) if len ( user_ratings ) == 0 : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_id = user_ratings [ 0 ] . user_id if len ( items_features ) == 0 : raise NoRatedItems ( \"User {} - No rated item available locally!\" . format ( user_id )) if 0 not in labels : raise OnlyPositiveItems ( \"User {} - There are only positive items available locally!\" . format ( user_id )) elif 1 not in labels : raise OnlyNegativeItems ( \"User {} - There are only negative items available locally!\" . format ( user_id )) self . _labels = labels self . _items_features = items_features","title":"process_rated()"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/#clayrs.recsys.content_based_algorithm.classifier.classifier_recommender.ClassifierRecommender.rank","text":"Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the filter_list parameter, in this case ONLY items in the filter_list parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, ALL unrated items will be ranked. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict recs_number number of the top ranked items to return, if None all ranked items will be returned TYPE: int DEFAULT: None filter_list list of the items to rank, if None all unrated items for the user will be ranked TYPE: list DEFAULT: None RETURNS DESCRIPTION List [ Interaction ] List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user Source code in clayrs/recsys/content_based_algorithm/classifier/classifier_recommender.py 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 def rank ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict , recs_number : int = None , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the `filter_list` parameter, in this case ONLY items in the `filter_list` parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, **ALL** unrated items will be ranked. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents recs_number: number of the top ranked items to return, if None all ranked items will be returned filter_list (list): list of the items to rank, if None all unrated items for the user will be ranked Returns: List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user \"\"\" try : user_id = user_ratings [ 0 ] . user_id except IndexError : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_seen_items = set ([ interaction . item_id for interaction in user_ratings ]) # Load items to predict if filter_list is None : items_to_predict = available_loaded_items . get_list ([ item_id for item_id in available_loaded_items if item_id not in user_seen_items ]) else : items_to_predict = available_loaded_items . get_list ( filter_list ) # Extract features of the items to predict id_items_to_predict = [] features_items_to_predict = [] for item in items_to_predict : if item is not None : id_items_to_predict . append ( item . content_id ) features_items_to_predict . append ( self . extract_features_item ( item )) if len ( id_items_to_predict ) > 0 : # Fuse the input if there are dicts, multiple representation, etc. fused_features_items_to_pred = self . fuse_representations ( features_items_to_predict , self . _embedding_combiner ) class_prob = self . _classifier . predict_proba ( fused_features_items_to_pred ) else : class_prob = [] # for each item we extract the probability that the item is liked (class 1) score_labels = ( prob [ 1 ] for prob in class_prob ) # Build the item_score dict (key is item_id, value is rank score predicted) # and order the keys in descending order item_score_dict = dict ( zip ( id_items_to_predict , score_labels )) ordered_item_ids = sorted ( item_score_dict , key = item_score_dict . get , reverse = True ) # we only save the top-n items_ids corresponding to top-n recommendations # (if recs_number is None ordered_item_ids will contain all item_ids as the original list) ordered_item_ids = ordered_item_ids [: recs_number ] # we construct the output data rank_interaction_list = [ Interaction ( user_id , item_id , item_score_dict [ item_id ]) for item_id in ordered_item_ids ] return rank_interaction_list","title":"rank()"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/#classifiers-implemented","text":"The following are the classifiers you can use in the classifier parameter of the ClassifierRecommender class","title":"Classifiers Implemented"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/#clayrs.recsys.content_based_algorithm.classifier.classifiers.SkDecisionTree","text":"Bases: Classifier Class that implements the Decision Tree Classifier from sklearn. The parameters one could pass are the same ones you would pass instantiating the classifier directly from sklearn Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/classifier/classifiers.py 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 def __init__ ( self , * , criterion : Any = \"gini\" , splitter : Any = \"best\" , max_depth : Any = None , min_samples_split : Any = 2 , min_samples_leaf : Any = 1 , min_weight_fraction_leaf : Any = 0.0 , max_features : Any = None , random_state : Any = None , max_leaf_nodes : Any = None , min_impurity_decrease : Any = 0.0 , class_weight : Any = None , ccp_alpha : Any = 0.0 ): clf = DecisionTreeClassifier ( criterion = criterion , splitter = splitter , max_depth = max_depth , min_samples_split = min_samples_split , min_samples_leaf = min_samples_leaf , min_weight_fraction_leaf = min_weight_fraction_leaf , max_features = max_features , random_state = random_state , max_leaf_nodes = max_leaf_nodes , min_impurity_decrease = min_impurity_decrease , class_weight = class_weight , ccp_alpha = ccp_alpha ) super () . __init__ ( clf , inspect . currentframe ())","title":"SkDecisionTree"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/#clayrs.recsys.content_based_algorithm.classifier.classifiers.SkGaussianProcess","text":"Bases: Classifier Class that implements the Gaussian Process Classifier from sklearn. The parameters one could pass are the same ones you would pass instantiating the classifier directly from sklearn Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/classifier/classifiers.py 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 def __init__ ( self , kernel : Any = None , * , optimizer : Any = \"fmin_l_bfgs_b\" , n_restarts_optimizer : Any = 0 , max_iter_predict : Any = 100 , warm_start : Any = False , copy_X_train : Any = True , random_state : Any = None , multi_class : Any = \"one_vs_rest\" , n_jobs : Any = None ): clf = GaussianProcessClassifier ( kernel = kernel , optimizer = optimizer , n_restarts_optimizer = n_restarts_optimizer , max_iter_predict = max_iter_predict , warm_start = warm_start , copy_X_train = copy_X_train , random_state = random_state , multi_class = multi_class , n_jobs = n_jobs ) super () . __init__ ( clf , inspect . currentframe ())","title":"SkGaussianProcess"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/#clayrs.recsys.content_based_algorithm.classifier.classifiers.SkKNN","text":"Bases: Classifier Class that implements the KNN Classifier from sklearn. The parameters one could pass are the same ones you would pass instantiating the classifier KNN directly from sklearn. Sklearn documentation: here Since KNN implementation of sklearn has n_neighbors = 5 as default, it can throw an exception if less sample in the training data are provided, so we change dynamically the n_neighbors parameter according to the number of samples if the dataset is too small and if no manual n_neighbors is set Source code in clayrs/recsys/content_based_algorithm/classifier/classifiers.py 129 130 131 132 133 134 135 136 137 138 139 140 141 def __init__ ( self , n_neighbors : Any = 5 , * , weights : Any = \"uniform\" , algorithm : Any = \"auto\" , leaf_size : Any = 30 , p : Any = 2 , metric : Any = \"minkowski\" , metric_params : Any = None , n_jobs : Any = None ): clf = KNeighborsClassifier ( n_neighbors = n_neighbors , weights = weights , algorithm = algorithm , leaf_size = leaf_size , p = p , metric = metric , metric_params = metric_params , n_jobs = n_jobs ) super () . __init__ ( clf , inspect . currentframe ())","title":"SkKNN"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/#clayrs.recsys.content_based_algorithm.classifier.classifiers.SkLogisticRegression","text":"Bases: Classifier Class that implements the Logistic Regression Classifier from sklearn. The parameters one could pass are the same ones you would pass instantiating the classifier directly from sklearn Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/classifier/classifiers.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 def __init__ ( self , penalty : Any = \"l2\" , * , dual : Any = False , tol : Any = 1e-4 , C : Any = 1.0 , fit_intercept : Any = True , intercept_scaling : Any = 1 , class_weight : Any = None , random_state : Any = None , solver : Any = \"lbfgs\" , max_iter : Any = 100 , multi_class : Any = \"auto\" , verbose : Any = 0 , warm_start : Any = False , n_jobs : Any = None , l1_ratio : Any = None ): clf = LogisticRegression ( penalty = penalty , dual = dual , tol = tol , C = C , fit_intercept = fit_intercept , intercept_scaling = intercept_scaling , class_weight = class_weight , random_state = random_state , solver = solver , max_iter = max_iter , multi_class = multi_class , verbose = verbose , warm_start = warm_start , n_jobs = n_jobs , l1_ratio = l1_ratio ) super () . __init__ ( clf , inspect . currentframe ())","title":"SkLogisticRegression"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/#clayrs.recsys.content_based_algorithm.classifier.classifiers.SkRandomForest","text":"Bases: Classifier Class that implements the Random Forest Classifier from sklearn. The parameters one could pass are the same ones you would pass instantiating the classifier directly from sklearn Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/classifier/classifiers.py 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 def __init__ ( self , n_estimators : Any = 100 , * , criterion : Any = \"gini\" , max_depth : Any = None , min_samples_split : Any = 2 , min_samples_leaf : Any = 1 , min_weight_fraction_leaf : Any = 0.0 , max_features : Any = \"auto\" , max_leaf_nodes : Any = None , min_impurity_decrease : Any = 0.0 , bootstrap : Any = True , oob_score : Any = False , n_jobs : Any = None , random_state : Any = None , verbose : Any = 0 , warm_start : Any = False , class_weight : Any = None , ccp_alpha : Any = 0.0 , max_samples : Any = None ): clf = RandomForestClassifier ( n_estimators = n_estimators , criterion = criterion , max_depth = max_depth , min_samples_split = min_samples_split , min_samples_leaf = min_samples_leaf , min_weight_fraction_leaf = min_weight_fraction_leaf , max_features = max_features , max_leaf_nodes = max_leaf_nodes , min_impurity_decrease = min_impurity_decrease , bootstrap = bootstrap , oob_score = oob_score , n_jobs = n_jobs , random_state = random_state , verbose = verbose , warm_start = warm_start , class_weight = class_weight , ccp_alpha = ccp_alpha , max_samples = max_samples ) super () . __init__ ( clf , inspect . currentframe ())","title":"SkRandomForest"},{"location":"recsys/content_based/content_based_algorithms/classifier_recommender/#clayrs.recsys.content_based_algorithm.classifier.classifiers.SkSVC","text":"Bases: Classifier Class that implements the SVC Classifier from sklearn. The parameters one could pass are the same ones you would pass instantiating the classifier SVC directly from sklearn. Sklearn documentation: here The only parameter from sklearn that cannot be passed is the 'probability' parameter: it is set to True and cannot be changed Source code in clayrs/recsys/content_based_algorithm/classifier/classifiers.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def __init__ ( self , * , C : Any = 1.0 , kernel : Any = \"rbf\" , degree : Any = 3 , gamma : Any = \"scale\" , coef0 : Any = 0.0 , shrinking : Any = True , tol : Any = 1e-3 , cache_size : Any = 200 , class_weight : Any = None , verbose : Any = False , max_iter : Any = - 1 , decision_function_shape : Any = \"ovr\" , break_ties : Any = False , random_state : Any = None ): # Force the probability parameter at True, otherwise SVC won't predict_proba clf = SVC ( C = C , kernel = kernel , degree = degree , gamma = gamma , coef0 = coef0 , shrinking = shrinking , tol = tol , cache_size = cache_size , class_weight = class_weight , verbose = verbose , max_iter = max_iter , decision_function_shape = decision_function_shape , break_ties = break_ties , random_state = random_state , probability = True ) super () . __init__ ( clf , inspect . currentframe ())","title":"SkSVC"},{"location":"recsys/content_based/content_based_algorithms/index_query/","text":"IndexQuery ( item_field , classic_similarity = True , threshold = None ) Bases: ContentBasedAlgorithm Class for the search engine recommender using an index. It firsts builds a query using the representation(s) specified of the positive items, then uses the mentioned query to do an actual search inside the index: every items will have a score of \"closeness\" in relation to the query, we use this score to rank every item. Just be sure to use textual representation(s) to build a significant query and to make a significant search! Examples: Interested in only a field representation, classic tfidf similarity, \\(threshold = 3\\) (Every item with rating \\(>= 3\\) will be considered as positive) >>> from clayrs import recsys as rs >>> alg = rs . IndexQuery ({ \"Plot\" : 0 }, threshold = 3 ) Interested in multiple field representations of the items, BM25 similarity, \\(threshold = None\\) (Every item with rating \\(>=\\) mean rating of the user will be considered as positive) >>> alg = rs . IndexQuery ( >>> item_field = { \"Plot\" : [ 0 , \"original_text\" ], >>> \"Genre\" : [ 0 , 1 ], >>> \"Director\" : \"preprocessed_text\" }, >>> classic_similarity = False , >>> threshold = 3 ) Info After instantiating the IndexQuery algorithm, pass it in the initialization of a CBRS and the use its method to calculate ranking for single user or multiple users: Examples: >>> cbrs = rs.ContentBasedRS(algorithm=alg, ...) >>> cbrs.fit_rank(...) >>> # ... PARAMETER DESCRIPTION item_field dict where the key is the name of the field that contains the content to use, value is the representation(s) id(s) that will be used for the said item, just BE SURE to use textual representation(s). The value of a field can be a string or a list, use a list if you want to use multiple representations for a particular field. TYPE: dict classic_similarity True if you want to use the classic implementation of tfidf in Whoosh, False if you want BM25F TYPE: bool DEFAULT: True threshold Threshold for the ratings. If the rating is greater than the threshold, it will be considered as positive. If the threshold is not specified, the average score of all items liked by the user is used. TYPE: float DEFAULT: None Source code in clayrs/recsys/content_based_algorithm/index_query/index_query.py 62 63 64 65 66 67 def __init__ ( self , item_field : dict , classic_similarity : bool = True , threshold : float = None ): super () . __init__ ( item_field , threshold ) self . _string_query : Optional [ str ] = None self . _scores : Optional [ list ] = None self . _positive_user_docs : Optional [ dict ] = None self . _classic_similarity : bool = classic_similarity fit () The fit process for the IndexQuery consists in building a query using the features of the positive items ONLY (items that the user liked). The terms relative to these 'positive' items are boosted by the rating he/she gave. This method uses extracted features of the positive items stored in a private attribute, so process_rated() must be called before this method. The built query will also be stored in a private attribute. Source code in clayrs/recsys/content_based_algorithm/index_query/index_query.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 def fit ( self ): \"\"\" The fit process for the IndexQuery consists in building a query using the features of the positive items ONLY (items that the user liked). The terms relative to these 'positive' items are boosted by the rating he/she gave. This method uses extracted features of the positive items stored in a private attribute, so process_rated() must be called before this method. The built query will also be stored in a private attribute. \"\"\" # For each field of each document one string (containing the name of the field and the data in it) # is created and added to the query. # Also each part of the query that refers to a document # is boosted by the score given by the user to said document string_query = \"(\" for ( doc_id , doc_data ), score in zip ( self . _positive_user_docs , self . _scores ): string_query += \"(\" for field_name in doc_data : if field_name == 'content_id' : continue word_list = doc_data [ field_name ] . split () string_query += field_name + \":(\" for term in word_list : string_query += term + \" \" string_query += \") \" string_query += \")^\" + str ( score ) + \" \" string_query += \") \" self . _string_query = string_query predict ( user_ratings , available_loaded_items , filter_list = None ) IndexQuery is not a Prediction Score Algorithm, so if this method is called, a NotPredictionAlg exception is raised RAISES DESCRIPTION NotPredictionAlg exception raised since the CentroidVector algorithm is not a score prediction algorithm Source code in clayrs/recsys/content_based_algorithm/index_query/index_query.py 215 216 217 218 219 220 221 222 223 224 def predict ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsIndex , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" IndexQuery is not a Prediction Score Algorithm, so if this method is called, a NotPredictionAlg exception is raised Raises: NotPredictionAlg: exception raised since the CentroidVector algorithm is not a score prediction algorithm \"\"\" raise NotPredictionAlg ( \"IndexQuery is not a Score Prediction Algorithm!\" ) process_rated ( user_ratings , available_loaded_items ) Function that extracts features from positive rated items ONLY! The extracted features will be used to fit the algorithm (build the query). Features extracted will be stored in private attributes of the class. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsIndex Source code in clayrs/recsys/content_based_algorithm/index_query/index_query.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 def process_rated ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsIndex ): \"\"\" Function that extracts features from positive rated items ONLY! The extracted features will be used to fit the algorithm (build the query). Features extracted will be stored in private attributes of the class. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents \"\"\" # a list since there could be duplicate interaction (eg bootstrap partitioning) items_scores_dict = defaultdict ( list ) for interaction in user_ratings : items_scores_dict [ interaction . item_id ] . append ( interaction . score ) items_scores_dict = dict ( sorted ( items_scores_dict . items ())) # sort dictionary based on key for reproducibility threshold = self . threshold if threshold is None : threshold = self . _calc_mean_user_threshold ( user_ratings ) # Initializes positive_user_docs which is a list that has tuples with document_id as first element and # a dictionary as second. The dictionary value has the name of the field as key # and its contents as value. By doing so we obtain the data of the fields while # also storing information regarding the field and the document where it was scores = [] positive_user_docs = [] ix = available_loaded_items . get_contents_interface () # we extract feature of each item sorted based on its key: IMPORTANT for reproducibility!! for item_id , score_list in items_scores_dict . items (): score_assigned = map ( float , score_list ) for score in score_assigned : if score >= threshold : # {item_id: {\"item\": item_dictionary, \"score\": item_score}} item_query = ix . query ( item_id , results_number = 1 , classic_similarity = self . _classic_similarity ) if len ( item_query ) != 0 : item = item_query . pop ( item_id ) . get ( 'item' ) scores . append ( score ) positive_user_docs . append (( item_id , self . _get_representations ( item ))) if len ( user_ratings ) == 0 : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_id = user_ratings [ 0 ] . user_id if len ( positive_user_docs ) == 0 : raise OnlyNegativeItems ( f \"User { user_id } - There are no rated items available locally or there are only \" f \"negative items available locally!\" ) self . _positive_user_docs = positive_user_docs self . _scores = scores rank ( user_ratings , available_loaded_items , recs_number = None , filter_list = None ) Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the filter_list parameter, in this case ONLY items in the filter_list parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, ALL unrated items will be ranked. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents. In this case it will be a LoadedContentsIndex TYPE: LoadedContentsIndex recs_number number of the top ranked items to return, if None all ranked items will be returned TYPE: int DEFAULT: None filter_list list of the items to rank, if None all unrated items for the user will be ranked TYPE: list DEFAULT: None RETURNS DESCRIPTION List [ Interaction ] List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user Source code in clayrs/recsys/content_based_algorithm/index_query/index_query.py 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 def rank ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsIndex , recs_number : int = None , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the `filter_list` parameter, in this case ONLY items in the `filter_list` parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, **ALL** unrated items will be ranked. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents. In this case it will be a `LoadedContentsIndex` recs_number: number of the top ranked items to return, if None all ranked items will be returned filter_list (list): list of the items to rank, if None all unrated items for the user will be ranked Returns: List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user \"\"\" try : user_id = user_ratings [ 0 ] . user_id except IndexError : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_seen_items = set ([ interaction . item_id for interaction in user_ratings ]) mask_list = self . _build_mask_list ( user_seen_items , filter_list ) ix = available_loaded_items . get_contents_interface () score_docs = ix . query ( self . _string_query , recs_number , mask_list , filter_list , self . _classic_similarity ) # we construct the output data rank_interaction_list = [ Interaction ( user_id , item_id , score_docs [ item_id ][ 'score' ]) for item_id in score_docs ] return rank_interaction_list","title":"Index Query"},{"location":"recsys/content_based/content_based_algorithms/index_query/#clayrs.recsys.content_based_algorithm.index_query.index_query.IndexQuery","text":"Bases: ContentBasedAlgorithm Class for the search engine recommender using an index. It firsts builds a query using the representation(s) specified of the positive items, then uses the mentioned query to do an actual search inside the index: every items will have a score of \"closeness\" in relation to the query, we use this score to rank every item. Just be sure to use textual representation(s) to build a significant query and to make a significant search! Examples: Interested in only a field representation, classic tfidf similarity, \\(threshold = 3\\) (Every item with rating \\(>= 3\\) will be considered as positive) >>> from clayrs import recsys as rs >>> alg = rs . IndexQuery ({ \"Plot\" : 0 }, threshold = 3 ) Interested in multiple field representations of the items, BM25 similarity, \\(threshold = None\\) (Every item with rating \\(>=\\) mean rating of the user will be considered as positive) >>> alg = rs . IndexQuery ( >>> item_field = { \"Plot\" : [ 0 , \"original_text\" ], >>> \"Genre\" : [ 0 , 1 ], >>> \"Director\" : \"preprocessed_text\" }, >>> classic_similarity = False , >>> threshold = 3 ) Info After instantiating the IndexQuery algorithm, pass it in the initialization of a CBRS and the use its method to calculate ranking for single user or multiple users: Examples: >>> cbrs = rs.ContentBasedRS(algorithm=alg, ...) >>> cbrs.fit_rank(...) >>> # ... PARAMETER DESCRIPTION item_field dict where the key is the name of the field that contains the content to use, value is the representation(s) id(s) that will be used for the said item, just BE SURE to use textual representation(s). The value of a field can be a string or a list, use a list if you want to use multiple representations for a particular field. TYPE: dict classic_similarity True if you want to use the classic implementation of tfidf in Whoosh, False if you want BM25F TYPE: bool DEFAULT: True threshold Threshold for the ratings. If the rating is greater than the threshold, it will be considered as positive. If the threshold is not specified, the average score of all items liked by the user is used. TYPE: float DEFAULT: None Source code in clayrs/recsys/content_based_algorithm/index_query/index_query.py 62 63 64 65 66 67 def __init__ ( self , item_field : dict , classic_similarity : bool = True , threshold : float = None ): super () . __init__ ( item_field , threshold ) self . _string_query : Optional [ str ] = None self . _scores : Optional [ list ] = None self . _positive_user_docs : Optional [ dict ] = None self . _classic_similarity : bool = classic_similarity","title":"IndexQuery"},{"location":"recsys/content_based/content_based_algorithms/index_query/#clayrs.recsys.content_based_algorithm.index_query.index_query.IndexQuery.fit","text":"The fit process for the IndexQuery consists in building a query using the features of the positive items ONLY (items that the user liked). The terms relative to these 'positive' items are boosted by the rating he/she gave. This method uses extracted features of the positive items stored in a private attribute, so process_rated() must be called before this method. The built query will also be stored in a private attribute. Source code in clayrs/recsys/content_based_algorithm/index_query/index_query.py 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 def fit ( self ): \"\"\" The fit process for the IndexQuery consists in building a query using the features of the positive items ONLY (items that the user liked). The terms relative to these 'positive' items are boosted by the rating he/she gave. This method uses extracted features of the positive items stored in a private attribute, so process_rated() must be called before this method. The built query will also be stored in a private attribute. \"\"\" # For each field of each document one string (containing the name of the field and the data in it) # is created and added to the query. # Also each part of the query that refers to a document # is boosted by the score given by the user to said document string_query = \"(\" for ( doc_id , doc_data ), score in zip ( self . _positive_user_docs , self . _scores ): string_query += \"(\" for field_name in doc_data : if field_name == 'content_id' : continue word_list = doc_data [ field_name ] . split () string_query += field_name + \":(\" for term in word_list : string_query += term + \" \" string_query += \") \" string_query += \")^\" + str ( score ) + \" \" string_query += \") \" self . _string_query = string_query","title":"fit()"},{"location":"recsys/content_based/content_based_algorithms/index_query/#clayrs.recsys.content_based_algorithm.index_query.index_query.IndexQuery.predict","text":"IndexQuery is not a Prediction Score Algorithm, so if this method is called, a NotPredictionAlg exception is raised RAISES DESCRIPTION NotPredictionAlg exception raised since the CentroidVector algorithm is not a score prediction algorithm Source code in clayrs/recsys/content_based_algorithm/index_query/index_query.py 215 216 217 218 219 220 221 222 223 224 def predict ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsIndex , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" IndexQuery is not a Prediction Score Algorithm, so if this method is called, a NotPredictionAlg exception is raised Raises: NotPredictionAlg: exception raised since the CentroidVector algorithm is not a score prediction algorithm \"\"\" raise NotPredictionAlg ( \"IndexQuery is not a Score Prediction Algorithm!\" )","title":"predict()"},{"location":"recsys/content_based/content_based_algorithms/index_query/#clayrs.recsys.content_based_algorithm.index_query.index_query.IndexQuery.process_rated","text":"Function that extracts features from positive rated items ONLY! The extracted features will be used to fit the algorithm (build the query). Features extracted will be stored in private attributes of the class. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsIndex Source code in clayrs/recsys/content_based_algorithm/index_query/index_query.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 def process_rated ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsIndex ): \"\"\" Function that extracts features from positive rated items ONLY! The extracted features will be used to fit the algorithm (build the query). Features extracted will be stored in private attributes of the class. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents \"\"\" # a list since there could be duplicate interaction (eg bootstrap partitioning) items_scores_dict = defaultdict ( list ) for interaction in user_ratings : items_scores_dict [ interaction . item_id ] . append ( interaction . score ) items_scores_dict = dict ( sorted ( items_scores_dict . items ())) # sort dictionary based on key for reproducibility threshold = self . threshold if threshold is None : threshold = self . _calc_mean_user_threshold ( user_ratings ) # Initializes positive_user_docs which is a list that has tuples with document_id as first element and # a dictionary as second. The dictionary value has the name of the field as key # and its contents as value. By doing so we obtain the data of the fields while # also storing information regarding the field and the document where it was scores = [] positive_user_docs = [] ix = available_loaded_items . get_contents_interface () # we extract feature of each item sorted based on its key: IMPORTANT for reproducibility!! for item_id , score_list in items_scores_dict . items (): score_assigned = map ( float , score_list ) for score in score_assigned : if score >= threshold : # {item_id: {\"item\": item_dictionary, \"score\": item_score}} item_query = ix . query ( item_id , results_number = 1 , classic_similarity = self . _classic_similarity ) if len ( item_query ) != 0 : item = item_query . pop ( item_id ) . get ( 'item' ) scores . append ( score ) positive_user_docs . append (( item_id , self . _get_representations ( item ))) if len ( user_ratings ) == 0 : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_id = user_ratings [ 0 ] . user_id if len ( positive_user_docs ) == 0 : raise OnlyNegativeItems ( f \"User { user_id } - There are no rated items available locally or there are only \" f \"negative items available locally!\" ) self . _positive_user_docs = positive_user_docs self . _scores = scores","title":"process_rated()"},{"location":"recsys/content_based/content_based_algorithms/index_query/#clayrs.recsys.content_based_algorithm.index_query.index_query.IndexQuery.rank","text":"Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the filter_list parameter, in this case ONLY items in the filter_list parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, ALL unrated items will be ranked. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents. In this case it will be a LoadedContentsIndex TYPE: LoadedContentsIndex recs_number number of the top ranked items to return, if None all ranked items will be returned TYPE: int DEFAULT: None filter_list list of the items to rank, if None all unrated items for the user will be ranked TYPE: list DEFAULT: None RETURNS DESCRIPTION List [ Interaction ] List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user Source code in clayrs/recsys/content_based_algorithm/index_query/index_query.py 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 def rank ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsIndex , recs_number : int = None , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the `filter_list` parameter, in this case ONLY items in the `filter_list` parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, **ALL** unrated items will be ranked. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents. In this case it will be a `LoadedContentsIndex` recs_number: number of the top ranked items to return, if None all ranked items will be returned filter_list (list): list of the items to rank, if None all unrated items for the user will be ranked Returns: List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user \"\"\" try : user_id = user_ratings [ 0 ] . user_id except IndexError : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_seen_items = set ([ interaction . item_id for interaction in user_ratings ]) mask_list = self . _build_mask_list ( user_seen_items , filter_list ) ix = available_loaded_items . get_contents_interface () score_docs = ix . query ( self . _string_query , recs_number , mask_list , filter_list , self . _classic_similarity ) # we construct the output data rank_interaction_list = [ Interaction ( user_id , item_id , score_docs [ item_id ][ 'score' ]) for item_id in score_docs ] return rank_interaction_list","title":"rank()"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/","text":"Linear Predictor LinearPredictor ( item_field , regressor , only_greater_eq = None , embedding_combiner = Centroid ()) Bases: ContentBasedAlgorithm Class that implements recommendation through a specified linear predictor. It's a score prediction algorithm, so it can predict what rating a user would give to an unseen item. As such, it's also a ranking algorithm (it simply ranks in descending order unseen items by the predicted rating) Examples: Interested in only a field representation, LinearRegression regressor from sklearn >>> from clayrs import recsys as rs >>> alg = rs . LinearPredictor ({ \"Plot\" : 0 }, rs . SkLinearRegression ()) Interested in only a field representation, Ridge regressor from sklearn with custom parameters >>> alg = rs . LinearPredictor ({ \"Plot\" : 0 }, rs . SkRidge ( alpha = 0.8 )) Interested in multiple field representations of the items, Ridge regressor from sklearn with custom parameters, \\(only_greater_eq = 2\\) (Every item with rating \\(>= 2\\) will be discarded and not considered in the ranking/score prediction task) >>> alg = rs . LinearPredictor ( >>> item_field = { \"Plot\" : [ 0 , \"tfidf\" ], >>> \"Genre\" : [ 0 , 1 ], >>> \"Director\" : \"doc2vec\" }, >>> regressor = rs . SkRidge ( alpha = 0.8 ), >>> only_greater_eq = 2 ) Info After instantiating the LinearPredictor algorithm, pass it in the initialization of a CBRS and the use its method to predict ratings or calculate ranking for a single user or multiple users: Examples: >>> cbrs = rs.ContentBasedRS(algorithm=alg, ...) >>> cbrs.fit_predict(...) >>> cbrs.fit_rank(...) >>> # ... PARAMETER DESCRIPTION item_field dict where the key is the name of the field that contains the content to use, value is the representation(s) id(s) that will be used for the said item. The value of a field can be a string or a list, use a list if you want to use multiple representations for a particular field. TYPE: dict regressor regressor that will be used. Can be one object of the Regressor class. TYPE: Regressor only_greater_eq Threshold for the ratings. Only items with rating greater or equal than the threshold will be considered, items with lower rating will be discarded. If None, no item will be filter out TYPE: float DEFAULT: None embedding_combiner CombiningTechnique used when embeddings representation must be used but they are in a matrix form instead of a single vector (e.g. when WordEmbedding representations must be used you have one vector for each word). By default the Centroid of the rows of the matrix is computed TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/recsys/content_based_algorithm/regressor/linear_predictor.py 73 74 75 76 77 78 79 def __init__ ( self , item_field : dict , regressor : Regressor , only_greater_eq : float = None , embedding_combiner : CombiningTechnique = Centroid ()): super () . __init__ ( item_field , only_greater_eq ) self . _regressor = regressor self . _labels : Optional [ list ] = None self . _items_features : Optional [ list ] = None self . _embedding_combiner = embedding_combiner fit () Fit the regressor specified in the constructor with the features and labels (rating scores) extracted with the process_rated() method. It uses private attributes to fit the classifier, so process_rated() must be called before this method. Source code in clayrs/recsys/content_based_algorithm/regressor/linear_predictor.py 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def fit ( self ): \"\"\" Fit the regressor specified in the constructor with the features and labels (rating scores) extracted with the process_rated() method. It uses private attributes to fit the classifier, so process_rated() must be called before this method. \"\"\" # Fuse the input if there are dicts, multiple representation, etc. fused_features = self . fuse_representations ( self . _items_features , self . _embedding_combiner ) self . _regressor . fit ( fused_features , self . _labels ) # we delete variables used to fit since will no longer be used self . _labels = None self . _items_features = None predict ( user_ratings , available_loaded_items , filter_list = None ) Predicts how much a user will like unrated items. One can specify which items must be predicted with the filter_list parameter, in this case ONLY items in the filter_list will be predicted. One can also pass items already seen by the user with the filter_list parameter. Otherwise, ALL unrated items will be predicted. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict filter_list List of the items to predict, if None all unrated items for the user will be predicted TYPE: List [ str ] DEFAULT: None RETURNS DESCRIPTION List [ Interaction ] List of Interactions object where the 'score' attribute is the rating predicted by the algorithm Source code in clayrs/recsys/content_based_algorithm/regressor/linear_predictor.py 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 def predict ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" Predicts how much a user will like unrated items. One can specify which items must be predicted with the filter_list parameter, in this case ONLY items in the filter_list will be predicted. One can also pass items already seen by the user with the filter_list parameter. Otherwise, ALL unrated items will be predicted. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents filter_list: List of the items to predict, if None all unrated items for the user will be predicted Returns: List of Interactions object where the 'score' attribute is the rating predicted by the algorithm \"\"\" try : user_id = user_ratings [ 0 ] . user_id except IndexError : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) id_items_to_predict , score_labels = self . _common_prediction_process ( user_ratings , available_loaded_items , filter_list ) # Build the output data pred_interaction_list = [ Interaction ( user_id , item_id , score ) for item_id , score in zip ( id_items_to_predict , score_labels )] return pred_interaction_list process_rated ( user_ratings , available_loaded_items ) Function that extracts features from rated item and labels them. The extracted features will be later used to fit the classifier. Features and labels (in this case the rating score) will be stored in private attributes of the class. IF there are no rated items available locally, an exception is thrown. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict RAISES DESCRIPTION NoRatedItems Exception raised when there isn't any item available locally rated by the user Source code in clayrs/recsys/content_based_algorithm/regressor/linear_predictor.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def process_rated ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict ): \"\"\" Function that extracts features from rated item and labels them. The extracted features will be later used to fit the classifier. Features and labels (in this case the rating score) will be stored in private attributes of the class. IF there are no rated items available locally, an exception is thrown. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents Raises: NoRatedItems: Exception raised when there isn't any item available locally rated by the user \"\"\" # a list since there could be duplicate interaction (eg bootstrap partitioning) items_scores_dict = defaultdict ( list ) for interaction in user_ratings : items_scores_dict [ interaction . item_id ] . append ( interaction . score ) items_scores_dict = dict ( sorted ( items_scores_dict . items ())) # sort dictionary based on key for reproducibility # Create list of all the available items that are useful for the user loaded_rated_items : List [ Union [ Content , None ]] = available_loaded_items . get_list ([ item_id for item_id in items_scores_dict . keys ()]) # Assign label and extract features from the rated items labels = [] items_features = [] for item in loaded_rated_items : if item is not None : score_assigned = map ( float , items_scores_dict [ item . content_id ]) for score in score_assigned : if self . threshold is None or score >= self . threshold : items_features . append ( self . extract_features_item ( item )) labels . append ( score ) if len ( user_ratings ) == 0 : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_id = user_ratings [ 0 ] . user_id if len ( items_features ) == 0 : raise NoRatedItems ( \"User {} - No rated item available locally!\" . format ( user_id )) self . _labels = labels self . _items_features = items_features rank ( user_ratings , available_loaded_items , recs_number = None , filter_list = None ) Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the filter_list parameter, in this case ONLY items in the filter_list parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, ALL unrated items will be ranked. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict recs_number number of the top ranked items to return, if None all ranked items will be returned TYPE: int DEFAULT: None filter_list list of the items to rank, if None all unrated items for the user will be ranked TYPE: list DEFAULT: None RETURNS DESCRIPTION List [ Interaction ] List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user Source code in clayrs/recsys/content_based_algorithm/regressor/linear_predictor.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 def rank ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict , recs_number : int = None , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the `filter_list` parameter, in this case ONLY items in the `filter_list` parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, **ALL** unrated items will be ranked. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents recs_number: number of the top ranked items to return, if None all ranked items will be returned filter_list (list): list of the items to rank, if None all unrated items for the user will be ranked Returns: List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user \"\"\" try : user_id = user_ratings [ 0 ] . user_id except IndexError : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) # Predict the rating for the items and sort them in descending order id_items_to_predict , score_labels = self . _common_prediction_process ( user_ratings , available_loaded_items , filter_list ) # Build the item_score dict (key is item_id, value is rank score predicted) # and order the keys in descending order item_score_dict = dict ( zip ( id_items_to_predict , score_labels )) ordered_item_ids = sorted ( item_score_dict , key = item_score_dict . get , reverse = True ) # we only save the top-n items_ids corresponding to top-n recommendations # (if recs_number is None ordered_item_ids will contain all item_ids as the original list) ordered_item_ids = ordered_item_ids [: recs_number ] # we construct the output data rank_interaction_list = [ Interaction ( user_id , item_id , item_score_dict [ item_id ]) for item_id in ordered_item_ids ] return rank_interaction_list Regressors Implemented The following are the regressors you can use in the regressor parameter of the LinearPredictor class SkARDRegression ( * , n_iter = 300 , tol = 0.001 , alpha_1 = 1e-06 , alpha_2 = 1e-06 , lambda_1 = 1e-06 , lambda_2 = 1e-06 , compute_score = False , threshold_lambda = 10000.0 , fit_intercept = True , normalize = 'deprecated' , copy_X = True , verbose = False ) Bases: Regressor Class that implements the ARD regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor ARD directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 def __init__ ( self , * , n_iter : Any = 300 , tol : Any = 1.0e-3 , alpha_1 : Any = 1.0e-6 , alpha_2 : Any = 1.0e-6 , lambda_1 : Any = 1.0e-6 , lambda_2 : Any = 1.0e-6 , compute_score : Any = False , threshold_lambda : Any = 1.0e4 , fit_intercept : Any = True , normalize : Any = \"deprecated\" , copy_X : Any = True , verbose : Any = False ): model = ARDRegression ( n_iter = n_iter , tol = tol , alpha_1 = alpha_1 , alpha_2 = alpha_2 , lambda_1 = lambda_1 , lambda_2 = lambda_2 , compute_score = compute_score , threshold_lambda = threshold_lambda , fit_intercept = fit_intercept , normalize = normalize , copy_X = copy_X , verbose = verbose ) super () . __init__ ( model , inspect . currentframe ()) SkBayesianRidge ( * , n_iter = 300 , tol = 0.001 , alpha_1 = 1e-06 , alpha_2 = 1e-06 , lambda_1 = 1e-06 , lambda_2 = 1e-06 , alpha_init = None , lambda_init = None , compute_score = False , fit_intercept = True , normalize = 'deprecated' , copy_X = True , verbose = False ) Bases: Regressor Class that implements the BayesianRidge regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor BayesianRidge directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def __init__ ( self , * , n_iter : Any = 300 , tol : Any = 1.0e-3 , alpha_1 : Any = 1.0e-6 , alpha_2 : Any = 1.0e-6 , lambda_1 : Any = 1.0e-6 , lambda_2 : Any = 1.0e-6 , alpha_init : Any = None , lambda_init : Any = None , compute_score : Any = False , fit_intercept : Any = True , normalize : Any = \"deprecated\" , copy_X : Any = True , verbose : Any = False ): model = BayesianRidge ( n_iter = n_iter , tol = tol , alpha_1 = alpha_1 , alpha_2 = alpha_2 , lambda_1 = lambda_1 , lambda_2 = lambda_2 , alpha_init = alpha_init , lambda_init = lambda_init , compute_score = compute_score , fit_intercept = fit_intercept , normalize = normalize , copy_X = copy_X , verbose = verbose ) super () . __init__ ( model , inspect . currentframe ()) SkHuberRegressor ( * , epsilon = 1.35 , max_iter = 100 , alpha = 0.0001 , warm_start = False , fit_intercept = True , tol = 1e-05 ) Bases: Regressor Class that implements the Huber regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor Huber directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 256 257 258 259 260 261 262 263 264 265 266 def __init__ ( self , * , epsilon : Any = 1.35 , max_iter : Any = 100 , alpha : Any = 0.0001 , warm_start : Any = False , fit_intercept : Any = True , tol : Any = 1e-05 ): model = HuberRegressor ( epsilon = epsilon , max_iter = max_iter , alpha = alpha , warm_start = warm_start , fit_intercept = fit_intercept , tol = tol ) super () . __init__ ( model , inspect . currentframe ()) SkLinearRegression ( * , fit_intercept = True , normalize = 'deprecated' , copy_X = True , n_jobs = None , positive = False ) Bases: Regressor Class that implements the LinearRegression regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor LinearRegression directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 80 81 82 83 84 85 86 87 88 def __init__ ( self , * , fit_intercept : Any = True , normalize : Any = \"deprecated\" , copy_X : Any = True , n_jobs : Any = None , positive : Any = False ): model = LinearRegression ( fit_intercept = fit_intercept , normalize = normalize , copy_X = copy_X , n_jobs = n_jobs , positive = positive ) super () . __init__ ( model , inspect . currentframe ()) SkPassiveAggressiveRegressor ( * , C = 1.0 , fit_intercept = True , max_iter = 1000 , tol = 0.001 , early_stopping = False , validation_fraction = 0.1 , n_iter_no_change = 5 , shuffle = True , verbose = 0 , loss = 'epsilon_insensitive' , epsilon = DEFAULT_EPSILON , random_state = None , warm_start = False , average = False ) Bases: Regressor Class that implements the PassiveAggressive regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor PassiveAggressive directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 def __init__ ( self , * , C : Any = 1.0 , fit_intercept : Any = True , max_iter : Any = 1000 , tol : Any = 1e-3 , early_stopping : Any = False , validation_fraction : Any = 0.1 , n_iter_no_change : Any = 5 , shuffle : Any = True , verbose : Any = 0 , loss : Any = \"epsilon_insensitive\" , epsilon : Any = DEFAULT_EPSILON , random_state : Any = None , warm_start : Any = False , average : Any = False ): model = PassiveAggressiveRegressor ( C = C , fit_intercept = fit_intercept , max_iter = max_iter , tol = tol , early_stopping = early_stopping , validation_fraction = validation_fraction , n_iter_no_change = n_iter_no_change , shuffle = shuffle , verbose = verbose , loss = loss , epsilon = epsilon , random_state = random_state , warm_start = warm_start , average = average ) super () . __init__ ( model , inspect . currentframe ()) SkRidge ( alpha = 1.0 , * , fit_intercept = True , normalize = 'deprecated' , copy_X = True , max_iter = None , tol = 0.001 , solver = 'auto' , positive = False , random_state = None ) Bases: Regressor Class that implements the Ridge regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor Ridge directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 def __init__ ( self , alpha : Any = 1.0 , * , fit_intercept : Any = True , normalize : Any = \"deprecated\" , copy_X : Any = True , max_iter : Any = None , tol : Any = 1e-3 , solver : Any = \"auto\" , positive : Any = False , random_state : Any = None ): model = Ridge ( alpha = alpha , fit_intercept = fit_intercept , normalize = normalize , copy_X = copy_X , max_iter = max_iter , tol = tol , solver = solver , positive = positive , random_state = random_state ) super () . __init__ ( model , inspect . currentframe ()) SkSGDRegressor ( loss = 'squared_error' , * , penalty = 'l2' , alpha = 0.0001 , l1_ratio = 0.15 , fit_intercept = True , max_iter = 1000 , tol = 0.001 , shuffle = True , verbose = 0 , epsilon = DEFAULT_EPSILON , random_state = None , learning_rate = 'invscaling' , eta0 = 0.01 , power_t = 0.25 , early_stopping = False , validation_fraction = 0.1 , n_iter_no_change = 5 , warm_start = False , average = False ) Bases: Regressor Class that implements the SGD regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor SGD directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def __init__ ( self , loss : Any = \"squared_error\" , * , penalty : Any = \"l2\" , alpha : Any = 0.0001 , l1_ratio : Any = 0.15 , fit_intercept : Any = True , max_iter : Any = 1000 , tol : Any = 1e-3 , shuffle : Any = True , verbose : Any = 0 , epsilon : Any = DEFAULT_EPSILON , random_state : Any = None , learning_rate : Any = \"invscaling\" , eta0 : Any = 0.01 , power_t : Any = 0.25 , early_stopping : Any = False , validation_fraction : Any = 0.1 , n_iter_no_change : Any = 5 , warm_start : Any = False , average : Any = False ): model = SGDRegressor ( loss = loss , penalty = penalty , alpha = alpha , l1_ratio = l1_ratio , fit_intercept = fit_intercept , max_iter = max_iter , tol = tol , shuffle = shuffle , verbose = verbose , epsilon = epsilon , random_state = random_state , learning_rate = learning_rate , eta0 = eta0 , power_t = power_t , early_stopping = early_stopping , validation_fraction = validation_fraction , n_iter_no_change = n_iter_no_change , warm_start = warm_start , average = average ) super () . __init__ ( model , inspect . currentframe ())","title":"Linear Predictor"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#linear-predictor","text":"","title":"Linear Predictor"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#clayrs.recsys.content_based_algorithm.regressor.linear_predictor.LinearPredictor","text":"Bases: ContentBasedAlgorithm Class that implements recommendation through a specified linear predictor. It's a score prediction algorithm, so it can predict what rating a user would give to an unseen item. As such, it's also a ranking algorithm (it simply ranks in descending order unseen items by the predicted rating) Examples: Interested in only a field representation, LinearRegression regressor from sklearn >>> from clayrs import recsys as rs >>> alg = rs . LinearPredictor ({ \"Plot\" : 0 }, rs . SkLinearRegression ()) Interested in only a field representation, Ridge regressor from sklearn with custom parameters >>> alg = rs . LinearPredictor ({ \"Plot\" : 0 }, rs . SkRidge ( alpha = 0.8 )) Interested in multiple field representations of the items, Ridge regressor from sklearn with custom parameters, \\(only_greater_eq = 2\\) (Every item with rating \\(>= 2\\) will be discarded and not considered in the ranking/score prediction task) >>> alg = rs . LinearPredictor ( >>> item_field = { \"Plot\" : [ 0 , \"tfidf\" ], >>> \"Genre\" : [ 0 , 1 ], >>> \"Director\" : \"doc2vec\" }, >>> regressor = rs . SkRidge ( alpha = 0.8 ), >>> only_greater_eq = 2 ) Info After instantiating the LinearPredictor algorithm, pass it in the initialization of a CBRS and the use its method to predict ratings or calculate ranking for a single user or multiple users: Examples: >>> cbrs = rs.ContentBasedRS(algorithm=alg, ...) >>> cbrs.fit_predict(...) >>> cbrs.fit_rank(...) >>> # ... PARAMETER DESCRIPTION item_field dict where the key is the name of the field that contains the content to use, value is the representation(s) id(s) that will be used for the said item. The value of a field can be a string or a list, use a list if you want to use multiple representations for a particular field. TYPE: dict regressor regressor that will be used. Can be one object of the Regressor class. TYPE: Regressor only_greater_eq Threshold for the ratings. Only items with rating greater or equal than the threshold will be considered, items with lower rating will be discarded. If None, no item will be filter out TYPE: float DEFAULT: None embedding_combiner CombiningTechnique used when embeddings representation must be used but they are in a matrix form instead of a single vector (e.g. when WordEmbedding representations must be used you have one vector for each word). By default the Centroid of the rows of the matrix is computed TYPE: CombiningTechnique DEFAULT: Centroid() Source code in clayrs/recsys/content_based_algorithm/regressor/linear_predictor.py 73 74 75 76 77 78 79 def __init__ ( self , item_field : dict , regressor : Regressor , only_greater_eq : float = None , embedding_combiner : CombiningTechnique = Centroid ()): super () . __init__ ( item_field , only_greater_eq ) self . _regressor = regressor self . _labels : Optional [ list ] = None self . _items_features : Optional [ list ] = None self . _embedding_combiner = embedding_combiner","title":"LinearPredictor"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#clayrs.recsys.content_based_algorithm.regressor.linear_predictor.LinearPredictor.fit","text":"Fit the regressor specified in the constructor with the features and labels (rating scores) extracted with the process_rated() method. It uses private attributes to fit the classifier, so process_rated() must be called before this method. Source code in clayrs/recsys/content_based_algorithm/regressor/linear_predictor.py 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def fit ( self ): \"\"\" Fit the regressor specified in the constructor with the features and labels (rating scores) extracted with the process_rated() method. It uses private attributes to fit the classifier, so process_rated() must be called before this method. \"\"\" # Fuse the input if there are dicts, multiple representation, etc. fused_features = self . fuse_representations ( self . _items_features , self . _embedding_combiner ) self . _regressor . fit ( fused_features , self . _labels ) # we delete variables used to fit since will no longer be used self . _labels = None self . _items_features = None","title":"fit()"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#clayrs.recsys.content_based_algorithm.regressor.linear_predictor.LinearPredictor.predict","text":"Predicts how much a user will like unrated items. One can specify which items must be predicted with the filter_list parameter, in this case ONLY items in the filter_list will be predicted. One can also pass items already seen by the user with the filter_list parameter. Otherwise, ALL unrated items will be predicted. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict filter_list List of the items to predict, if None all unrated items for the user will be predicted TYPE: List [ str ] DEFAULT: None RETURNS DESCRIPTION List [ Interaction ] List of Interactions object where the 'score' attribute is the rating predicted by the algorithm Source code in clayrs/recsys/content_based_algorithm/regressor/linear_predictor.py 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 def predict ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" Predicts how much a user will like unrated items. One can specify which items must be predicted with the filter_list parameter, in this case ONLY items in the filter_list will be predicted. One can also pass items already seen by the user with the filter_list parameter. Otherwise, ALL unrated items will be predicted. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents filter_list: List of the items to predict, if None all unrated items for the user will be predicted Returns: List of Interactions object where the 'score' attribute is the rating predicted by the algorithm \"\"\" try : user_id = user_ratings [ 0 ] . user_id except IndexError : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) id_items_to_predict , score_labels = self . _common_prediction_process ( user_ratings , available_loaded_items , filter_list ) # Build the output data pred_interaction_list = [ Interaction ( user_id , item_id , score ) for item_id , score in zip ( id_items_to_predict , score_labels )] return pred_interaction_list","title":"predict()"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#clayrs.recsys.content_based_algorithm.regressor.linear_predictor.LinearPredictor.process_rated","text":"Function that extracts features from rated item and labels them. The extracted features will be later used to fit the classifier. Features and labels (in this case the rating score) will be stored in private attributes of the class. IF there are no rated items available locally, an exception is thrown. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict RAISES DESCRIPTION NoRatedItems Exception raised when there isn't any item available locally rated by the user Source code in clayrs/recsys/content_based_algorithm/regressor/linear_predictor.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 def process_rated ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict ): \"\"\" Function that extracts features from rated item and labels them. The extracted features will be later used to fit the classifier. Features and labels (in this case the rating score) will be stored in private attributes of the class. IF there are no rated items available locally, an exception is thrown. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents Raises: NoRatedItems: Exception raised when there isn't any item available locally rated by the user \"\"\" # a list since there could be duplicate interaction (eg bootstrap partitioning) items_scores_dict = defaultdict ( list ) for interaction in user_ratings : items_scores_dict [ interaction . item_id ] . append ( interaction . score ) items_scores_dict = dict ( sorted ( items_scores_dict . items ())) # sort dictionary based on key for reproducibility # Create list of all the available items that are useful for the user loaded_rated_items : List [ Union [ Content , None ]] = available_loaded_items . get_list ([ item_id for item_id in items_scores_dict . keys ()]) # Assign label and extract features from the rated items labels = [] items_features = [] for item in loaded_rated_items : if item is not None : score_assigned = map ( float , items_scores_dict [ item . content_id ]) for score in score_assigned : if self . threshold is None or score >= self . threshold : items_features . append ( self . extract_features_item ( item )) labels . append ( score ) if len ( user_ratings ) == 0 : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) user_id = user_ratings [ 0 ] . user_id if len ( items_features ) == 0 : raise NoRatedItems ( \"User {} - No rated item available locally!\" . format ( user_id )) self . _labels = labels self . _items_features = items_features","title":"process_rated()"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#clayrs.recsys.content_based_algorithm.regressor.linear_predictor.LinearPredictor.rank","text":"Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the filter_list parameter, in this case ONLY items in the filter_list parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, ALL unrated items will be ranked. PARAMETER DESCRIPTION user_ratings List of Interaction objects for a single user TYPE: List [ Interaction ] available_loaded_items The LoadedContents interface which contains loaded contents TYPE: LoadedContentsDict recs_number number of the top ranked items to return, if None all ranked items will be returned TYPE: int DEFAULT: None filter_list list of the items to rank, if None all unrated items for the user will be ranked TYPE: list DEFAULT: None RETURNS DESCRIPTION List [ Interaction ] List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user Source code in clayrs/recsys/content_based_algorithm/regressor/linear_predictor.py 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 def rank ( self , user_ratings : List [ Interaction ], available_loaded_items : LoadedContentsDict , recs_number : int = None , filter_list : List [ str ] = None ) -> List [ Interaction ]: \"\"\" Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked with the `filter_list` parameter, in this case ONLY items in the `filter_list` parameter will be ranked. One can also pass items already seen by the user with the filter_list parameter. Otherwise, **ALL** unrated items will be ranked. Args: user_ratings: List of Interaction objects for a single user available_loaded_items: The LoadedContents interface which contains loaded contents recs_number: number of the top ranked items to return, if None all ranked items will be returned filter_list (list): list of the items to rank, if None all unrated items for the user will be ranked Returns: List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user \"\"\" try : user_id = user_ratings [ 0 ] . user_id except IndexError : raise EmptyUserRatings ( \"The user selected doesn't have any ratings!\" ) # Predict the rating for the items and sort them in descending order id_items_to_predict , score_labels = self . _common_prediction_process ( user_ratings , available_loaded_items , filter_list ) # Build the item_score dict (key is item_id, value is rank score predicted) # and order the keys in descending order item_score_dict = dict ( zip ( id_items_to_predict , score_labels )) ordered_item_ids = sorted ( item_score_dict , key = item_score_dict . get , reverse = True ) # we only save the top-n items_ids corresponding to top-n recommendations # (if recs_number is None ordered_item_ids will contain all item_ids as the original list) ordered_item_ids = ordered_item_ids [: recs_number ] # we construct the output data rank_interaction_list = [ Interaction ( user_id , item_id , item_score_dict [ item_id ]) for item_id in ordered_item_ids ] return rank_interaction_list","title":"rank()"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#regressors-implemented","text":"The following are the regressors you can use in the regressor parameter of the LinearPredictor class","title":"Regressors Implemented"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#clayrs.recsys.content_based_algorithm.regressor.regressors.SkARDRegression","text":"Bases: Regressor Class that implements the ARD regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor ARD directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 def __init__ ( self , * , n_iter : Any = 300 , tol : Any = 1.0e-3 , alpha_1 : Any = 1.0e-6 , alpha_2 : Any = 1.0e-6 , lambda_1 : Any = 1.0e-6 , lambda_2 : Any = 1.0e-6 , compute_score : Any = False , threshold_lambda : Any = 1.0e4 , fit_intercept : Any = True , normalize : Any = \"deprecated\" , copy_X : Any = True , verbose : Any = False ): model = ARDRegression ( n_iter = n_iter , tol = tol , alpha_1 = alpha_1 , alpha_2 = alpha_2 , lambda_1 = lambda_1 , lambda_2 = lambda_2 , compute_score = compute_score , threshold_lambda = threshold_lambda , fit_intercept = fit_intercept , normalize = normalize , copy_X = copy_X , verbose = verbose ) super () . __init__ ( model , inspect . currentframe ())","title":"SkARDRegression"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#clayrs.recsys.content_based_algorithm.regressor.regressors.SkBayesianRidge","text":"Bases: Regressor Class that implements the BayesianRidge regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor BayesianRidge directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def __init__ ( self , * , n_iter : Any = 300 , tol : Any = 1.0e-3 , alpha_1 : Any = 1.0e-6 , alpha_2 : Any = 1.0e-6 , lambda_1 : Any = 1.0e-6 , lambda_2 : Any = 1.0e-6 , alpha_init : Any = None , lambda_init : Any = None , compute_score : Any = False , fit_intercept : Any = True , normalize : Any = \"deprecated\" , copy_X : Any = True , verbose : Any = False ): model = BayesianRidge ( n_iter = n_iter , tol = tol , alpha_1 = alpha_1 , alpha_2 = alpha_2 , lambda_1 = lambda_1 , lambda_2 = lambda_2 , alpha_init = alpha_init , lambda_init = lambda_init , compute_score = compute_score , fit_intercept = fit_intercept , normalize = normalize , copy_X = copy_X , verbose = verbose ) super () . __init__ ( model , inspect . currentframe ())","title":"SkBayesianRidge"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#clayrs.recsys.content_based_algorithm.regressor.regressors.SkHuberRegressor","text":"Bases: Regressor Class that implements the Huber regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor Huber directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 256 257 258 259 260 261 262 263 264 265 266 def __init__ ( self , * , epsilon : Any = 1.35 , max_iter : Any = 100 , alpha : Any = 0.0001 , warm_start : Any = False , fit_intercept : Any = True , tol : Any = 1e-05 ): model = HuberRegressor ( epsilon = epsilon , max_iter = max_iter , alpha = alpha , warm_start = warm_start , fit_intercept = fit_intercept , tol = tol ) super () . __init__ ( model , inspect . currentframe ())","title":"SkHuberRegressor"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#clayrs.recsys.content_based_algorithm.regressor.regressors.SkLinearRegression","text":"Bases: Regressor Class that implements the LinearRegression regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor LinearRegression directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 80 81 82 83 84 85 86 87 88 def __init__ ( self , * , fit_intercept : Any = True , normalize : Any = \"deprecated\" , copy_X : Any = True , n_jobs : Any = None , positive : Any = False ): model = LinearRegression ( fit_intercept = fit_intercept , normalize = normalize , copy_X = copy_X , n_jobs = n_jobs , positive = positive ) super () . __init__ ( model , inspect . currentframe ())","title":"SkLinearRegression"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#clayrs.recsys.content_based_algorithm.regressor.regressors.SkPassiveAggressiveRegressor","text":"Bases: Regressor Class that implements the PassiveAggressive regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor PassiveAggressive directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 def __init__ ( self , * , C : Any = 1.0 , fit_intercept : Any = True , max_iter : Any = 1000 , tol : Any = 1e-3 , early_stopping : Any = False , validation_fraction : Any = 0.1 , n_iter_no_change : Any = 5 , shuffle : Any = True , verbose : Any = 0 , loss : Any = \"epsilon_insensitive\" , epsilon : Any = DEFAULT_EPSILON , random_state : Any = None , warm_start : Any = False , average : Any = False ): model = PassiveAggressiveRegressor ( C = C , fit_intercept = fit_intercept , max_iter = max_iter , tol = tol , early_stopping = early_stopping , validation_fraction = validation_fraction , n_iter_no_change = n_iter_no_change , shuffle = shuffle , verbose = verbose , loss = loss , epsilon = epsilon , random_state = random_state , warm_start = warm_start , average = average ) super () . __init__ ( model , inspect . currentframe ())","title":"SkPassiveAggressiveRegressor"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#clayrs.recsys.content_based_algorithm.regressor.regressors.SkRidge","text":"Bases: Regressor Class that implements the Ridge regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor Ridge directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 def __init__ ( self , alpha : Any = 1.0 , * , fit_intercept : Any = True , normalize : Any = \"deprecated\" , copy_X : Any = True , max_iter : Any = None , tol : Any = 1e-3 , solver : Any = \"auto\" , positive : Any = False , random_state : Any = None ): model = Ridge ( alpha = alpha , fit_intercept = fit_intercept , normalize = normalize , copy_X = copy_X , max_iter = max_iter , tol = tol , solver = solver , positive = positive , random_state = random_state ) super () . __init__ ( model , inspect . currentframe ())","title":"SkRidge"},{"location":"recsys/content_based/content_based_algorithms/linear_predictor/#clayrs.recsys.content_based_algorithm.regressor.regressors.SkSGDRegressor","text":"Bases: Regressor Class that implements the SGD regressor from sklearn. The parameters one could pass are the same ones you would pass instantiating the regressor SGD directly from sklearn. Sklearn documentation: here Source code in clayrs/recsys/content_based_algorithm/regressor/regressors.py 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def __init__ ( self , loss : Any = \"squared_error\" , * , penalty : Any = \"l2\" , alpha : Any = 0.0001 , l1_ratio : Any = 0.15 , fit_intercept : Any = True , max_iter : Any = 1000 , tol : Any = 1e-3 , shuffle : Any = True , verbose : Any = 0 , epsilon : Any = DEFAULT_EPSILON , random_state : Any = None , learning_rate : Any = \"invscaling\" , eta0 : Any = 0.01 , power_t : Any = 0.25 , early_stopping : Any = False , validation_fraction : Any = 0.1 , n_iter_no_change : Any = 5 , warm_start : Any = False , average : Any = False ): model = SGDRegressor ( loss = loss , penalty = penalty , alpha = alpha , l1_ratio = l1_ratio , fit_intercept = fit_intercept , max_iter = max_iter , tol = tol , shuffle = shuffle , verbose = verbose , epsilon = epsilon , random_state = random_state , learning_rate = learning_rate , eta0 = eta0 , power_t = power_t , early_stopping = early_stopping , validation_fraction = validation_fraction , n_iter_no_change = n_iter_no_change , warm_start = warm_start , average = average ) super () . __init__ ( model , inspect . currentframe ())","title":"SkSGDRegressor"},{"location":"recsys/graph_based/feature_selection/","text":"Feature Selection Via the feature_selecter function you are able to perform feature selection on a given graph, by keeping properties that are the most important according to a given feature selection algorithm . Check the documentation of the method for more and for a usage example feature_selector ( graph , fs_algorithm_user = None , fs_algorithm_item = None , user_target_nodes = None , item_target_nodes = None , inplace = False ) Given a FullGraph, this method performs feature selection on it and returns the \"reduced\" graph. You can choose to reduce only user properties ( evaluate the fs_algorithm_user parameter ), to reduce only item properties ( evaluate the fs_algorithm_item parameter ) or both ( evaluate the fs_algorithm_user parameter and the fs_algorithm_item parameter ). You can also choose different feature selection algorithms* for users and items. You can also define a custom list of user and item nodes: In this case only properties of those nodes will be considered during the feature selection process (instead of using properties of all users and items) This function changes a copy of the original graph by default, but you can change this behaviour with the inplace parameter. Examples: # create a full graph full_graph = rs . NXFullGraph ( ratings , user_contents_dir = 'users_codified/' , # (1) item_contents_dir = 'movies_codified/' , # (2) user_exo_properties = { 0 }, # (3) item_exo_properties = { 'dbpedia' }, # (4) link_label = 'score' ) # perform feature selection by keeping only top 5 property labels # according to page rank algorithm fs_graph = rs . feature_selector ( full_graph , fs_algorithm_item = rs . TopKPageRank ( k = 5 )) PARAMETER DESCRIPTION graph Original graph on which feature selection will be performed TYPE: FullDiGraph fs_algorithm_user FeatureSelectionAlgorithm that will be performed on user properties. Can be different from fs_algorithm_item TYPE: FeatureSelectionAlgorithm DEFAULT: None fs_algorithm_item FeatureSelectionAlgorithm that will be performed on item properties. Can be different from fs_algorithm_user TYPE: FeatureSelectionAlgorithm DEFAULT: None user_target_nodes List of user nodes to consider in the feature selection process: only properties of user nodes in this list will be \"reduced\" TYPE: list DEFAULT: None item_target_nodes List of item nodes to consider in the feature selection process: only properties of item nodes in this list will be \"reduced\" TYPE: list DEFAULT: None inplace Boolean parameter that let you choose if changes must be performed on the original graph ( inplace=True ) or on its copy ( inplace=False ). Default is False TYPE: bool DEFAULT: False RETURNS DESCRIPTION FullDiGraph Copy of the original graph from which the less important Property nodes (the ones having edges with less FullDiGraph important property labels) will be removed Source code in clayrs/recsys/graphs/feature_selection/feature_selection_fn.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def feature_selector ( graph : FullDiGraph , fs_algorithm_user : FeatureSelectionAlgorithm = None , fs_algorithm_item : FeatureSelectionAlgorithm = None , user_target_nodes : Iterable [ UserNode ] = None , item_target_nodes : Iterable [ ItemNode ] = None , inplace : bool = False ) -> FullDiGraph : \"\"\" Given a FullGraph, this method performs feature selection on it and returns the \"reduced\" graph. You can choose to reduce only *user properties* (*evaluate the `fs_algorithm_user` parameter*), to reduce only *item properties* (*evaluate the `fs_algorithm_item` parameter*) or both (*evaluate the `fs_algorithm_user` parameter* and the `fs_algorithm_item` parameter*). You can also choose different *feature selection algorithms* for users and items. You can also define a custom list of user and item nodes: * In this case only properties of those nodes will be considered during the feature selection process (instead of using properties of all users and items) This function changes a *copy* of the original graph by default, but you can change this behaviour with the `inplace` parameter. Examples: ```python # create a full graph full_graph = rs.NXFullGraph(ratings, user_contents_dir='users_codified/', # (1) item_contents_dir='movies_codified/', # (2) user_exo_properties={0}, # (3) item_exo_properties={'dbpedia'}, # (4) link_label='score') # perform feature selection by keeping only top 5 property labels # according to page rank algorithm fs_graph = rs.feature_selector(full_graph, fs_algorithm_item=rs.TopKPageRank(k=5)) ``` Args: graph: Original graph on which feature selection will be performed fs_algorithm_user: FeatureSelectionAlgorithm that will be performed on user properties. Can be different from `fs_algorithm_item` fs_algorithm_item: FeatureSelectionAlgorithm that will be performed on item properties. Can be different from `fs_algorithm_user` user_target_nodes (list): List of user nodes to consider in the feature selection process: only properties of user nodes in this list will be \"reduced\" item_target_nodes (list): List of item nodes to consider in the feature selection process: only properties of item nodes in this list will be \"reduced\" inplace: Boolean parameter that let you choose if changes must be performed on the original graph (`inplace=True`) or on its copy (`inplace=False`). Default is False Returns: Copy of the original graph from which the less important Property nodes (the ones having edges with less important property labels) will be removed \"\"\" if fs_algorithm_user is not None and user_target_nodes is None : user_target_nodes = graph . user_nodes if fs_algorithm_item is not None and item_target_nodes is None : item_target_nodes = graph . item_nodes property_labels_to_remove = list () user_fs_failed = False item_fs_failed = False if fs_algorithm_user is not None : logger . info ( \"Performing Feature Selection on users\" ) try : user_props_to_remove = fs_algorithm_user . perform ( graph , list ( user_target_nodes ), mode = 'to_remove' ) property_labels_to_remove . extend ( user_props_to_remove ) except FeatureSelectionException as e : logger . warning ( str ( e ) + \"! \\n Users original properties will be kept\" ) user_fs_failed = True if fs_algorithm_item is not None : logger . info ( \"Performing Feature Selection on items\" ) try : item_props_to_remove = fs_algorithm_item . perform ( graph , list ( item_target_nodes ), mode = 'to_remove' ) property_labels_to_remove . extend ( item_props_to_remove ) except FeatureSelectionException as e : logger . warning ( str ( e ) + \"! \\n Items original properties will be kept\" ) item_fs_failed = True # in case user feature selection or item feature selection failed # if both failed the original graph is returned # if only one of them failed, the original properties (either for items or users) are retrieved if user_fs_failed and item_fs_failed : logger . warning ( \"Since both feature selection on items and feature selection on users failed or no fs algorithm\" \"has been defined, \\n the original graph will be returned\" ) if inplace is True : graph_fs = _delete_property_nodes ( graph , property_labels_to_remove ) else : graph_copy = graph . copy () graph_fs = _delete_property_nodes ( graph_copy , property_labels_to_remove ) return graph_fs Feature Selection algorithms The following are the feature selection algorithms you can use in the fs_algorithms_user and/or in the fs_algorithm_item TopKPageRank ( k = 10 , alpha = 0.85 , personalization = None , max_iter = 100 , tol = 1e-06 , nstart = None , weight = True , dangling = None ) Bases: TopKFeatureSelection Computes the PageRank as FeatureSelection algorithm. Property labels of the original graph will be scored with their page rank score and only the top-k labels will be kept in the feature selected graph , while discarding the others PARAMETER DESCRIPTION k Top-k property labels to keep in the feature selected graph TYPE: int DEFAULT: 10 alpha Damping parameter for PageRank, default=0.85. TYPE: Any DEFAULT: 0.85 personalization The \"personalization vector\" consisting of a dictionary with a key some subset of graph nodes and personalization value each of those. At least one personalization value must be non-zero. If not specfiied, a nodes personalization value will be zero. By default, a uniform distribution is used. TYPE: Any DEFAULT: None max_iter Maximum number of iterations in power method eigenvalue solver. TYPE: Any DEFAULT: 100 tol Error tolerance used to check convergence in power method solver. TYPE: Any DEFAULT: 1e-06 nstart Starting value of PageRank iteration for each node. TYPE: Any DEFAULT: None weight Edge data key to use as weight. If None weights are set to 1. TYPE: bool DEFAULT: True dangling The outedges to be assigned to any \"dangling\" nodes, i.e., nodes without any outedges. The dict key is the node the outedge points to and the dict value is the weight of that outedge. By default, dangling nodes are given outedges according to the personalization vector (uniform if not specified). This must be selected to result in an irreducible transition matrix (see notes under google_matrix). It may be common to have the dangling dict to be the same as the personalization dict. TYPE: Any DEFAULT: None Source code in clayrs/recsys/graphs/feature_selection/feature_selection_alg.py 204 205 206 207 208 209 210 211 212 213 214 def __init__ ( self , k : int = 10 , alpha : Any = 0.85 , personalization : Any = None , max_iter : Any = 100 , tol : Any = 1.0e-6 , nstart : Any = None , weight : bool = True , dangling : Any = None ): super () . __init__ ( k ) self . alpha = alpha self . personalization = personalization self . max_iter = max_iter self . tol = tol self . nstart = nstart self . weight = 'weight' if weight is True else None self . dangling = dangling TopKEigenVectorCentrality ( k = 10 , max_iter = 100 , tol = 1e-06 , nstart = None , weight = False ) Bases: TopKFeatureSelection Computes the Eigen Vector Centrality as FeatureSelection algorithm. Property labels of the original graph will be scored with their eigen vector centrality score and only the top-k labels will be kept in the feature selected graph , while discarding the others PARAMETER DESCRIPTION k Top-k property labels to keep in the feature selected graph TYPE: int DEFAULT: 10 max_iter Maximum number of iterations in power method. TYPE: Any DEFAULT: 100 tol Error tolerance used to check convergence in power method iteration. TYPE: Any DEFAULT: 1e-06 nstart Starting value of eigenvector iteration for each node. TYPE: Any DEFAULT: None weight Boolean value which tells the algorithm if weight of the edges must be considered or not. Default is True TYPE: bool DEFAULT: False Source code in clayrs/recsys/graphs/feature_selection/feature_selection_alg.py 237 238 239 240 241 242 243 def __init__ ( self , k : int = 10 , max_iter : Any = 100 , tol : Any = 1.0e-6 , nstart : Any = None , weight : bool = False ): super () . __init__ ( k ) self . max_iter = max_iter self . tol = tol self . nstart = nstart self . weight = 'weight' if weight is True else None TopKDegreeCentrality ( k = 10 ) Bases: TopKFeatureSelection Computes the Degree Centrality as FeatureSelection algorithm. Property labels of the original graph will be scored with their degree centrality score and only the top-k labels will be kept in the feature selected graph , while discarding the others Source code in clayrs/recsys/graphs/feature_selection/feature_selection_alg.py 257 258 def __init__ ( self , k : int = 10 ): super () . __init__ ( k )","title":"Feature Selection"},{"location":"recsys/graph_based/feature_selection/#feature-selection","text":"Via the feature_selecter function you are able to perform feature selection on a given graph, by keeping properties that are the most important according to a given feature selection algorithm . Check the documentation of the method for more and for a usage example","title":"Feature Selection"},{"location":"recsys/graph_based/feature_selection/#clayrs.recsys.graphs.feature_selection.feature_selection_fn.feature_selector","text":"Given a FullGraph, this method performs feature selection on it and returns the \"reduced\" graph. You can choose to reduce only user properties ( evaluate the fs_algorithm_user parameter ), to reduce only item properties ( evaluate the fs_algorithm_item parameter ) or both ( evaluate the fs_algorithm_user parameter and the fs_algorithm_item parameter ). You can also choose different feature selection algorithms* for users and items. You can also define a custom list of user and item nodes: In this case only properties of those nodes will be considered during the feature selection process (instead of using properties of all users and items) This function changes a copy of the original graph by default, but you can change this behaviour with the inplace parameter. Examples: # create a full graph full_graph = rs . NXFullGraph ( ratings , user_contents_dir = 'users_codified/' , # (1) item_contents_dir = 'movies_codified/' , # (2) user_exo_properties = { 0 }, # (3) item_exo_properties = { 'dbpedia' }, # (4) link_label = 'score' ) # perform feature selection by keeping only top 5 property labels # according to page rank algorithm fs_graph = rs . feature_selector ( full_graph , fs_algorithm_item = rs . TopKPageRank ( k = 5 )) PARAMETER DESCRIPTION graph Original graph on which feature selection will be performed TYPE: FullDiGraph fs_algorithm_user FeatureSelectionAlgorithm that will be performed on user properties. Can be different from fs_algorithm_item TYPE: FeatureSelectionAlgorithm DEFAULT: None fs_algorithm_item FeatureSelectionAlgorithm that will be performed on item properties. Can be different from fs_algorithm_user TYPE: FeatureSelectionAlgorithm DEFAULT: None user_target_nodes List of user nodes to consider in the feature selection process: only properties of user nodes in this list will be \"reduced\" TYPE: list DEFAULT: None item_target_nodes List of item nodes to consider in the feature selection process: only properties of item nodes in this list will be \"reduced\" TYPE: list DEFAULT: None inplace Boolean parameter that let you choose if changes must be performed on the original graph ( inplace=True ) or on its copy ( inplace=False ). Default is False TYPE: bool DEFAULT: False RETURNS DESCRIPTION FullDiGraph Copy of the original graph from which the less important Property nodes (the ones having edges with less FullDiGraph important property labels) will be removed Source code in clayrs/recsys/graphs/feature_selection/feature_selection_fn.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def feature_selector ( graph : FullDiGraph , fs_algorithm_user : FeatureSelectionAlgorithm = None , fs_algorithm_item : FeatureSelectionAlgorithm = None , user_target_nodes : Iterable [ UserNode ] = None , item_target_nodes : Iterable [ ItemNode ] = None , inplace : bool = False ) -> FullDiGraph : \"\"\" Given a FullGraph, this method performs feature selection on it and returns the \"reduced\" graph. You can choose to reduce only *user properties* (*evaluate the `fs_algorithm_user` parameter*), to reduce only *item properties* (*evaluate the `fs_algorithm_item` parameter*) or both (*evaluate the `fs_algorithm_user` parameter* and the `fs_algorithm_item` parameter*). You can also choose different *feature selection algorithms* for users and items. You can also define a custom list of user and item nodes: * In this case only properties of those nodes will be considered during the feature selection process (instead of using properties of all users and items) This function changes a *copy* of the original graph by default, but you can change this behaviour with the `inplace` parameter. Examples: ```python # create a full graph full_graph = rs.NXFullGraph(ratings, user_contents_dir='users_codified/', # (1) item_contents_dir='movies_codified/', # (2) user_exo_properties={0}, # (3) item_exo_properties={'dbpedia'}, # (4) link_label='score') # perform feature selection by keeping only top 5 property labels # according to page rank algorithm fs_graph = rs.feature_selector(full_graph, fs_algorithm_item=rs.TopKPageRank(k=5)) ``` Args: graph: Original graph on which feature selection will be performed fs_algorithm_user: FeatureSelectionAlgorithm that will be performed on user properties. Can be different from `fs_algorithm_item` fs_algorithm_item: FeatureSelectionAlgorithm that will be performed on item properties. Can be different from `fs_algorithm_user` user_target_nodes (list): List of user nodes to consider in the feature selection process: only properties of user nodes in this list will be \"reduced\" item_target_nodes (list): List of item nodes to consider in the feature selection process: only properties of item nodes in this list will be \"reduced\" inplace: Boolean parameter that let you choose if changes must be performed on the original graph (`inplace=True`) or on its copy (`inplace=False`). Default is False Returns: Copy of the original graph from which the less important Property nodes (the ones having edges with less important property labels) will be removed \"\"\" if fs_algorithm_user is not None and user_target_nodes is None : user_target_nodes = graph . user_nodes if fs_algorithm_item is not None and item_target_nodes is None : item_target_nodes = graph . item_nodes property_labels_to_remove = list () user_fs_failed = False item_fs_failed = False if fs_algorithm_user is not None : logger . info ( \"Performing Feature Selection on users\" ) try : user_props_to_remove = fs_algorithm_user . perform ( graph , list ( user_target_nodes ), mode = 'to_remove' ) property_labels_to_remove . extend ( user_props_to_remove ) except FeatureSelectionException as e : logger . warning ( str ( e ) + \"! \\n Users original properties will be kept\" ) user_fs_failed = True if fs_algorithm_item is not None : logger . info ( \"Performing Feature Selection on items\" ) try : item_props_to_remove = fs_algorithm_item . perform ( graph , list ( item_target_nodes ), mode = 'to_remove' ) property_labels_to_remove . extend ( item_props_to_remove ) except FeatureSelectionException as e : logger . warning ( str ( e ) + \"! \\n Items original properties will be kept\" ) item_fs_failed = True # in case user feature selection or item feature selection failed # if both failed the original graph is returned # if only one of them failed, the original properties (either for items or users) are retrieved if user_fs_failed and item_fs_failed : logger . warning ( \"Since both feature selection on items and feature selection on users failed or no fs algorithm\" \"has been defined, \\n the original graph will be returned\" ) if inplace is True : graph_fs = _delete_property_nodes ( graph , property_labels_to_remove ) else : graph_copy = graph . copy () graph_fs = _delete_property_nodes ( graph_copy , property_labels_to_remove ) return graph_fs","title":"feature_selector()"},{"location":"recsys/graph_based/feature_selection/#feature-selection-algorithms","text":"The following are the feature selection algorithms you can use in the fs_algorithms_user and/or in the fs_algorithm_item","title":"Feature Selection algorithms"},{"location":"recsys/graph_based/feature_selection/#clayrs.recsys.graphs.feature_selection.feature_selection_alg.TopKPageRank","text":"Bases: TopKFeatureSelection Computes the PageRank as FeatureSelection algorithm. Property labels of the original graph will be scored with their page rank score and only the top-k labels will be kept in the feature selected graph , while discarding the others PARAMETER DESCRIPTION k Top-k property labels to keep in the feature selected graph TYPE: int DEFAULT: 10 alpha Damping parameter for PageRank, default=0.85. TYPE: Any DEFAULT: 0.85 personalization The \"personalization vector\" consisting of a dictionary with a key some subset of graph nodes and personalization value each of those. At least one personalization value must be non-zero. If not specfiied, a nodes personalization value will be zero. By default, a uniform distribution is used. TYPE: Any DEFAULT: None max_iter Maximum number of iterations in power method eigenvalue solver. TYPE: Any DEFAULT: 100 tol Error tolerance used to check convergence in power method solver. TYPE: Any DEFAULT: 1e-06 nstart Starting value of PageRank iteration for each node. TYPE: Any DEFAULT: None weight Edge data key to use as weight. If None weights are set to 1. TYPE: bool DEFAULT: True dangling The outedges to be assigned to any \"dangling\" nodes, i.e., nodes without any outedges. The dict key is the node the outedge points to and the dict value is the weight of that outedge. By default, dangling nodes are given outedges according to the personalization vector (uniform if not specified). This must be selected to result in an irreducible transition matrix (see notes under google_matrix). It may be common to have the dangling dict to be the same as the personalization dict. TYPE: Any DEFAULT: None Source code in clayrs/recsys/graphs/feature_selection/feature_selection_alg.py 204 205 206 207 208 209 210 211 212 213 214 def __init__ ( self , k : int = 10 , alpha : Any = 0.85 , personalization : Any = None , max_iter : Any = 100 , tol : Any = 1.0e-6 , nstart : Any = None , weight : bool = True , dangling : Any = None ): super () . __init__ ( k ) self . alpha = alpha self . personalization = personalization self . max_iter = max_iter self . tol = tol self . nstart = nstart self . weight = 'weight' if weight is True else None self . dangling = dangling","title":"TopKPageRank"},{"location":"recsys/graph_based/feature_selection/#clayrs.recsys.graphs.feature_selection.feature_selection_alg.TopKEigenVectorCentrality","text":"Bases: TopKFeatureSelection Computes the Eigen Vector Centrality as FeatureSelection algorithm. Property labels of the original graph will be scored with their eigen vector centrality score and only the top-k labels will be kept in the feature selected graph , while discarding the others PARAMETER DESCRIPTION k Top-k property labels to keep in the feature selected graph TYPE: int DEFAULT: 10 max_iter Maximum number of iterations in power method. TYPE: Any DEFAULT: 100 tol Error tolerance used to check convergence in power method iteration. TYPE: Any DEFAULT: 1e-06 nstart Starting value of eigenvector iteration for each node. TYPE: Any DEFAULT: None weight Boolean value which tells the algorithm if weight of the edges must be considered or not. Default is True TYPE: bool DEFAULT: False Source code in clayrs/recsys/graphs/feature_selection/feature_selection_alg.py 237 238 239 240 241 242 243 def __init__ ( self , k : int = 10 , max_iter : Any = 100 , tol : Any = 1.0e-6 , nstart : Any = None , weight : bool = False ): super () . __init__ ( k ) self . max_iter = max_iter self . tol = tol self . nstart = nstart self . weight = 'weight' if weight is True else None","title":"TopKEigenVectorCentrality"},{"location":"recsys/graph_based/feature_selection/#clayrs.recsys.graphs.feature_selection.feature_selection_alg.TopKDegreeCentrality","text":"Bases: TopKFeatureSelection Computes the Degree Centrality as FeatureSelection algorithm. Property labels of the original graph will be scored with their degree centrality score and only the top-k labels will be kept in the feature selected graph , while discarding the others Source code in clayrs/recsys/graphs/feature_selection/feature_selection_alg.py 257 258 def __init__ ( self , k : int = 10 ): super () . __init__ ( k )","title":"TopKDegreeCentrality"},{"location":"recsys/graph_based/graph_based_recsys/","text":"Graph Based RecSys GraphBasedRS ( algorithm , graph ) Bases: RecSys Class for recommender systems which use a graph in order to make predictions Every GBRS differ from each other based the algorithm used. Examples: In case you perform a splitting of the dataset which returns a single train and test set (e.g. HoldOut technique): Single split train from clayrs import recsys as rs from clayrs import content_analyzer as ca original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) [ train ], [ test ] = rs . HoldOutPartitioning () . split_all ( original_rat ) alg = rs . NXPageRank () # any gb algorithm graph = rs . NXBipartiteGraph ( train ) gbrs = rs . GraphBasedRS ( alg , graph ) rank = gbrs . rank ( test , n_recs = 10 ) In case you perform a splitting of the dataset which returns a multiple train and test sets (KFold technique): Multiple split train from clayrs import recsys as rs from clayrs import content_analyzer as ca original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) train_list , test_list = rs . KFoldPartitioning ( n_splits = 5 ) . split_all ( original_rat ) alg = rs . NXPageRank () # any gb algorithm for train_set , test_set in zip ( train_list , test_list ): graph = rs . NXBipartiteGraph ( train_set ) gbrs = rs . GraphBasedRS ( alg , graph ) rank_to_append = gbrs . rank ( test_set ) result_list . append ( rank_to_append ) result_list will contain recommendation lists for each split PARAMETER DESCRIPTION algorithm the graph based algorithm that will be used in order to rank or make score prediction TYPE: GraphBasedAlgorithm graph a Graph object containing interactions TYPE: FullDiGraph Source code in clayrs/recsys/recsys.py 617 618 619 620 621 622 def __init__ ( self , algorithm : GraphBasedAlgorithm , graph : FullDiGraph ): self . __graph = graph super () . __init__ ( algorithm ) algorithm () property The graph based algorithm chosen Source code in clayrs/recsys/recsys.py 635 636 637 638 639 640 641 @property def algorithm ( self ): \"\"\" The graph based algorithm chosen \"\"\" alg : GraphBasedAlgorithm = super () . algorithm return alg graph () property The graph containing interactions Source code in clayrs/recsys/recsys.py 628 629 630 631 632 633 @property def graph ( self ): \"\"\" The graph containing interactions \"\"\" return self . __graph predict ( test_set , user_id_list = None , methodology = TestRatingsMethodology (), num_cpus = 1 ) Method used to calculate score predictions for all users in test set or all users in user_id_list parameter. BE CAREFUL : not all algorithms are able to perform score prediction Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so for each user items in its test set only will be considered for score prediction If the algorithm was not fit for some users, they will be skipped and a warning is printed PARAMETER DESCRIPTION test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings user_id_list List of users for which you want to compute score prediction. If None, the ranking will be computed for all users of the test_set TYPE: List DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RETURNS DESCRIPTION Prediction Prediction object containing score prediction lists for all users of the test set or for all users in user_id_list Source code in clayrs/recsys/recsys.py 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 def predict ( self , test_set : Ratings , user_id_list : List = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 1 ) -> Prediction : \"\"\" Method used to calculate score predictions for all users in test set or all users in `user_id_list` parameter. **BE CAREFUL**: not all algorithms are able to perform *score prediction* Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so for each user items in its test set only will be considered for score prediction If the algorithm was not fit for some users, they will be skipped and a warning is printed Args: test_set: Ratings object which represents the ground truth of the split considered user_id_list: List of users for which you want to compute score prediction. If None, the ranking will be computed for all users of the `test_set` methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Returns: Prediction object containing score prediction lists for all users of the test set or for all users in `user_id_list` \"\"\" all_users = set ( test_set . user_id_column ) if user_id_list is not None : all_users = set ( user_id_list ) total_predict_list = self . algorithm . predict ( all_users , self . graph , test_set , methodology , num_cpus ) total_predict = Prediction . from_list ( total_predict_list ) self . _yaml_report = { 'graph' : repr ( self . graph ), 'mode' : 'score_prediction' , 'methodology' : repr ( methodology )} return total_predict rank ( test_set , n_recs = 10 , user_id_list = None , methodology = TestRatingsMethodology (), num_cpus = 1 ) Method used to calculate ranking for all users in test set or all users in user_id_list parameter. You must first call the fit() method before you can compute the ranking. If the n_recs is specified, then the rank will contain the top-n items for the users. Otherwise, the rank will contain all unrated items of the particular users Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be ranked If the algorithm was not fit for some users, they will be skipped and a warning is printed PARAMETER DESCRIPTION test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings n_recs Number of the top items that will be present in the ranking of each user. If None all candidate items will be returned for the user TYPE: int DEFAULT: 10 user_id_list List of users for which you want to compute the ranking. If None, the ranking will be computed for all users of the test_set TYPE: List DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RAISES DESCRIPTION NotFittedAlg Exception raised when this method is called without first calling the fit method RETURNS DESCRIPTION Rank Rank object containing recommendation lists for all users of the test set or for all users in user_id_list Source code in clayrs/recsys/recsys.py 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 def rank ( self , test_set : Ratings , n_recs : int = 10 , user_id_list : List = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 1 ) -> Rank : \"\"\" Method used to calculate ranking for all users in test set or all users in `user_id_list` parameter. You must first call the `fit()` method before you can compute the ranking. If the `n_recs` is specified, then the rank will contain the top-n items for the users. Otherwise, the rank will contain all unrated items of the particular users Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be ranked If the algorithm was not fit for some users, they will be skipped and a warning is printed Args: test_set: Ratings object which represents the ground truth of the split considered n_recs: Number of the top items that will be present in the ranking of each user. If `None` all candidate items will be returned for the user user_id_list: List of users for which you want to compute the ranking. If None, the ranking will be computed for all users of the `test_set` methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Raises: NotFittedAlg: Exception raised when this method is called without first calling the `fit` method Returns: Rank object containing recommendation lists for all users of the test set or for all users in `user_id_list` \"\"\" all_users = set ( test_set . user_id_column ) if user_id_list is not None : all_users = set ( user_id_list ) total_rank_list = self . algorithm . rank ( all_users , self . graph , test_set , n_recs , methodology , num_cpus ) total_rank = Rank . from_list ( total_rank_list ) if len ( total_rank ) == 0 : logger . warning ( \"No items could be ranked for any users! Remember that items to rank must be present \" \"in the graph. \\n \" \"Try changing methodology!\" ) elif len ( set ( total_rank . user_id_column )) != len ( all_users ): logger . warning ( f \"No items could be ranked for users { all_users - set ( total_rank . user_id_column ) } \\n \" f \"No nodes to rank for them found in the graph. Try changing methodology! \" ) self . _yaml_report = { 'graph' : repr ( self . graph ), 'mode' : 'rank' , 'n_recs' : repr ( n_recs ), 'methodology' : repr ( methodology )} return total_rank","title":"Graph Based recsys"},{"location":"recsys/graph_based/graph_based_recsys/#graph-based-recsys","text":"","title":"Graph Based RecSys"},{"location":"recsys/graph_based/graph_based_recsys/#clayrs.recsys.recsys.GraphBasedRS","text":"Bases: RecSys Class for recommender systems which use a graph in order to make predictions Every GBRS differ from each other based the algorithm used. Examples: In case you perform a splitting of the dataset which returns a single train and test set (e.g. HoldOut technique): Single split train from clayrs import recsys as rs from clayrs import content_analyzer as ca original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) [ train ], [ test ] = rs . HoldOutPartitioning () . split_all ( original_rat ) alg = rs . NXPageRank () # any gb algorithm graph = rs . NXBipartiteGraph ( train ) gbrs = rs . GraphBasedRS ( alg , graph ) rank = gbrs . rank ( test , n_recs = 10 ) In case you perform a splitting of the dataset which returns a multiple train and test sets (KFold technique): Multiple split train from clayrs import recsys as rs from clayrs import content_analyzer as ca original_rat = ca . Ratings ( ca . CSVFile ( ratings_path )) train_list , test_list = rs . KFoldPartitioning ( n_splits = 5 ) . split_all ( original_rat ) alg = rs . NXPageRank () # any gb algorithm for train_set , test_set in zip ( train_list , test_list ): graph = rs . NXBipartiteGraph ( train_set ) gbrs = rs . GraphBasedRS ( alg , graph ) rank_to_append = gbrs . rank ( test_set ) result_list . append ( rank_to_append ) result_list will contain recommendation lists for each split PARAMETER DESCRIPTION algorithm the graph based algorithm that will be used in order to rank or make score prediction TYPE: GraphBasedAlgorithm graph a Graph object containing interactions TYPE: FullDiGraph Source code in clayrs/recsys/recsys.py 617 618 619 620 621 622 def __init__ ( self , algorithm : GraphBasedAlgorithm , graph : FullDiGraph ): self . __graph = graph super () . __init__ ( algorithm )","title":"GraphBasedRS"},{"location":"recsys/graph_based/graph_based_recsys/#clayrs.recsys.recsys.GraphBasedRS.algorithm","text":"The graph based algorithm chosen Source code in clayrs/recsys/recsys.py 635 636 637 638 639 640 641 @property def algorithm ( self ): \"\"\" The graph based algorithm chosen \"\"\" alg : GraphBasedAlgorithm = super () . algorithm return alg","title":"algorithm()"},{"location":"recsys/graph_based/graph_based_recsys/#clayrs.recsys.recsys.GraphBasedRS.graph","text":"The graph containing interactions Source code in clayrs/recsys/recsys.py 628 629 630 631 632 633 @property def graph ( self ): \"\"\" The graph containing interactions \"\"\" return self . __graph","title":"graph()"},{"location":"recsys/graph_based/graph_based_recsys/#clayrs.recsys.recsys.GraphBasedRS.predict","text":"Method used to calculate score predictions for all users in test set or all users in user_id_list parameter. BE CAREFUL : not all algorithms are able to perform score prediction Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so for each user items in its test set only will be considered for score prediction If the algorithm was not fit for some users, they will be skipped and a warning is printed PARAMETER DESCRIPTION test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings user_id_list List of users for which you want to compute score prediction. If None, the ranking will be computed for all users of the test_set TYPE: List DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RETURNS DESCRIPTION Prediction Prediction object containing score prediction lists for all users of the test set or for all users in user_id_list Source code in clayrs/recsys/recsys.py 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 def predict ( self , test_set : Ratings , user_id_list : List = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 1 ) -> Prediction : \"\"\" Method used to calculate score predictions for all users in test set or all users in `user_id_list` parameter. **BE CAREFUL**: not all algorithms are able to perform *score prediction* Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so for each user items in its test set only will be considered for score prediction If the algorithm was not fit for some users, they will be skipped and a warning is printed Args: test_set: Ratings object which represents the ground truth of the split considered user_id_list: List of users for which you want to compute score prediction. If None, the ranking will be computed for all users of the `test_set` methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Returns: Prediction object containing score prediction lists for all users of the test set or for all users in `user_id_list` \"\"\" all_users = set ( test_set . user_id_column ) if user_id_list is not None : all_users = set ( user_id_list ) total_predict_list = self . algorithm . predict ( all_users , self . graph , test_set , methodology , num_cpus ) total_predict = Prediction . from_list ( total_predict_list ) self . _yaml_report = { 'graph' : repr ( self . graph ), 'mode' : 'score_prediction' , 'methodology' : repr ( methodology )} return total_predict","title":"predict()"},{"location":"recsys/graph_based/graph_based_recsys/#clayrs.recsys.recsys.GraphBasedRS.rank","text":"Method used to calculate ranking for all users in test set or all users in user_id_list parameter. You must first call the fit() method before you can compute the ranking. If the n_recs is specified, then the rank will contain the top-n items for the users. Otherwise, the rank will contain all unrated items of the particular users Via the methodology parameter you can perform different candidate item selection. By default, the TestRatingsMethodology() is used: so, for each user, items in its test set only will be ranked If the algorithm was not fit for some users, they will be skipped and a warning is printed PARAMETER DESCRIPTION test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings n_recs Number of the top items that will be present in the ranking of each user. If None all candidate items will be returned for the user TYPE: int DEFAULT: 10 user_id_list List of users for which you want to compute the ranking. If None, the ranking will be computed for all users of the test_set TYPE: List DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RAISES DESCRIPTION NotFittedAlg Exception raised when this method is called without first calling the fit method RETURNS DESCRIPTION Rank Rank object containing recommendation lists for all users of the test set or for all users in user_id_list Source code in clayrs/recsys/recsys.py 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 def rank ( self , test_set : Ratings , n_recs : int = 10 , user_id_list : List = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 1 ) -> Rank : \"\"\" Method used to calculate ranking for all users in test set or all users in `user_id_list` parameter. You must first call the `fit()` method before you can compute the ranking. If the `n_recs` is specified, then the rank will contain the top-n items for the users. Otherwise, the rank will contain all unrated items of the particular users Via the `methodology` parameter you can perform different candidate item selection. By default, the `TestRatingsMethodology()` is used: so, for each user, items in its test set only will be ranked If the algorithm was not fit for some users, they will be skipped and a warning is printed Args: test_set: Ratings object which represents the ground truth of the split considered n_recs: Number of the top items that will be present in the ranking of each user. If `None` all candidate items will be returned for the user user_id_list: List of users for which you want to compute the ranking. If None, the ranking will be computed for all users of the `test_set` methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Raises: NotFittedAlg: Exception raised when this method is called without first calling the `fit` method Returns: Rank object containing recommendation lists for all users of the test set or for all users in `user_id_list` \"\"\" all_users = set ( test_set . user_id_column ) if user_id_list is not None : all_users = set ( user_id_list ) total_rank_list = self . algorithm . rank ( all_users , self . graph , test_set , n_recs , methodology , num_cpus ) total_rank = Rank . from_list ( total_rank_list ) if len ( total_rank ) == 0 : logger . warning ( \"No items could be ranked for any users! Remember that items to rank must be present \" \"in the graph. \\n \" \"Try changing methodology!\" ) elif len ( set ( total_rank . user_id_column )) != len ( all_users ): logger . warning ( f \"No items could be ranked for users { all_users - set ( total_rank . user_id_column ) } \\n \" f \"No nodes to rank for them found in the graph. Try changing methodology! \" ) self . _yaml_report = { 'graph' : repr ( self . graph ), 'mode' : 'rank' , 'n_recs' : repr ( n_recs ), 'methodology' : repr ( methodology )} return total_rank","title":"rank()"},{"location":"recsys/graph_based/graph_based_algorithms/nx_pagerank/","text":"Page Rank NXPageRank ( alpha = 0.85 , personalized = False , max_iter = 100 , tol = 1e-06 , nstart = None , weight = True ) Bases: PageRank Page Rank algorithm based on the networkx implementation. Please note that it can only be used for instantiated NXGraphs The PageRank can be personalized , in this case the PageRank will be calculated with a personalization vector made by items in the user profile weighted by the score given to them. PARAMETER DESCRIPTION alpha Damping parameter for PageRank, default=0.85. TYPE: Any DEFAULT: 0.85 personalized Boolean value that specifies if the page rank must be calculated considering the user profile as personalization vector. Default is False TYPE: bool DEFAULT: False max_iter Maximum number of iterations in power method eigenvalue solver. TYPE: Any DEFAULT: 100 tol Error tolerance used to check convergence in power method solver. TYPE: Any DEFAULT: 1e-06 nstart Starting value of PageRank iteration for each node. TYPE: Any DEFAULT: None weight Boolean value which tells the algorithm if weight of the edges must be considered or not. Default is True TYPE: bool DEFAULT: True Source code in clayrs/recsys/graph_based_algorithm/page_rank/nx_page_rank.py 38 39 40 41 42 43 44 45 46 def __init__ ( self , alpha : Any = 0.85 , personalized : bool = False , max_iter : Any = 100 , tol : Any = 1.0e-6 , nstart : Any = None , weight : bool = True ): self . alpha = alpha self . max_iter = max_iter self . tol = tol self . nstart = nstart self . weight = weight super () . __init__ ( personalized ) rank ( all_users , graph , test_set , recs_number = None , methodology = TestRatingsMethodology (), num_cpus = 1 ) Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked for each user with the filter_dict parameter, in this case every user is mapped with a list of items for which a ranking score must be computed. Otherwise, ALL unrated items will be ranked for each user. PARAMETER DESCRIPTION all_users Set of user id for which a recommendation list must be generated TYPE: Set [ str ] graph A NX graph previously instantiated TYPE: NXBipartiteGraph recs_number number of the top ranked items to return, if None all ranked items will be returned TYPE: int DEFAULT: None test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings recs_number number of the top ranked items to return, if None all ranked items will be returned TYPE: int DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RETURNS DESCRIPTION List [ Interaction ] List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user Source code in clayrs/recsys/graph_based_algorithm/page_rank/nx_page_rank.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 def rank ( self , all_users : Set [ str ], graph : NXBipartiteGraph , test_set : Ratings , recs_number : int = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 1 ) -> List [ Interaction ]: \"\"\" Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked for each user with the `filter_dict` parameter, in this case every user is mapped with a list of items for which a ranking score must be computed. Otherwise, **ALL** unrated items will be ranked for each user. Args: all_users: Set of user id for which a recommendation list must be generated graph: A NX graph previously instantiated recs_number: number of the top ranked items to return, if None all ranked items will be returned test_set: Ratings object which represents the ground truth of the split considered recs_number: number of the top ranked items to return, if None all ranked items will be returned methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Returns: List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user \"\"\" def compute_single_rank ( user_id ): # nonlocal keyword allows to modify the score variable nonlocal scores user_node = UserNode ( user_id ) filter_list = None if methodology is not None : filter_list = set ( ItemNode ( item_to_rank ) for item_to_rank in methodology . filter_single ( user_id , train_set , test_set )) # run the pageRank if self . _personalized is True : # the personalization vector is formed by the nodes that the user voted with their weight # + all the other nodes in the graph with weight as the min weight given by the user # (This because if a node isn't specified in the personalization vector will have 0 score in page # rank) succ = graph . get_successors ( user_node ) profile = { scored_node : graph . get_link_data ( user_node , scored_node ) . get ( 'weight' ) for scored_node in succ if graph . get_link_data ( user_node , scored_node ) . get ( 'weight' ) is not None } pers = { node : profile [ node ] if node in profile else min ( set ( profile . values ())) for node in graph . to_networkx () . nodes } scores = nx . pagerank ( graph . to_networkx (), personalization = pers , alpha = self . alpha , max_iter = self . max_iter , tol = self . tol , nstart = self . nstart , weight = weight ) # if scores is None it means this is the first time we are running normal pagerank # for all the other users the pagerank won't be computed again elif scores is None : scores = nx . pagerank ( graph . to_networkx (), alpha = self . alpha , max_iter = self . max_iter , tol = self . tol , nstart = self . nstart , weight = weight ) # clean the results removing user nodes, selected user profile and eventually properties user_scores = self . filter_result ( graph , scores , filter_list , user_node ) # Build the item_score dict (key is item_id, value is rank score predicted) # and order the keys in descending order item_score_dict = dict ( zip ([ node . value for node in user_scores . keys ()], user_scores . values ())) ordered_item_ids = sorted ( item_score_dict , key = item_score_dict . get , reverse = True ) # we only save the top-n items_ids corresponding to top-n recommendations # (if recs_number is None ordered_item_ids will contain all item_ids as the original list) ordered_item_ids = ordered_item_ids [: recs_number ] # we construct the output data single_rank_interaction_list = [ Interaction ( user_id , item_id , item_score_dict [ item_id ]) for item_id in ordered_item_ids ] return user_id , single_rank_interaction_list # scores will contain pagerank scores scores = None all_rank_interaction_list = [] weight = 'weight' if self . weight is True else None train_set = graph . to_ratings () with get_iterator_parallel ( num_cpus , compute_single_rank , all_users , progress_bar = True , total = len ( all_users )) as pbar : pbar . set_description ( \"Prepping rank...\" ) for user_id , user_rank in pbar : all_rank_interaction_list . append ( user_rank ) pbar . set_description ( f \"Computing rank for user { user_id } \" ) return list ( itertools . chain . from_iterable ( all_rank_interaction_list ))","title":"Page Rank"},{"location":"recsys/graph_based/graph_based_algorithms/nx_pagerank/#page-rank","text":"","title":"Page Rank"},{"location":"recsys/graph_based/graph_based_algorithms/nx_pagerank/#clayrs.recsys.graph_based_algorithm.page_rank.nx_page_rank.NXPageRank","text":"Bases: PageRank Page Rank algorithm based on the networkx implementation. Please note that it can only be used for instantiated NXGraphs The PageRank can be personalized , in this case the PageRank will be calculated with a personalization vector made by items in the user profile weighted by the score given to them. PARAMETER DESCRIPTION alpha Damping parameter for PageRank, default=0.85. TYPE: Any DEFAULT: 0.85 personalized Boolean value that specifies if the page rank must be calculated considering the user profile as personalization vector. Default is False TYPE: bool DEFAULT: False max_iter Maximum number of iterations in power method eigenvalue solver. TYPE: Any DEFAULT: 100 tol Error tolerance used to check convergence in power method solver. TYPE: Any DEFAULT: 1e-06 nstart Starting value of PageRank iteration for each node. TYPE: Any DEFAULT: None weight Boolean value which tells the algorithm if weight of the edges must be considered or not. Default is True TYPE: bool DEFAULT: True Source code in clayrs/recsys/graph_based_algorithm/page_rank/nx_page_rank.py 38 39 40 41 42 43 44 45 46 def __init__ ( self , alpha : Any = 0.85 , personalized : bool = False , max_iter : Any = 100 , tol : Any = 1.0e-6 , nstart : Any = None , weight : bool = True ): self . alpha = alpha self . max_iter = max_iter self . tol = tol self . nstart = nstart self . weight = weight super () . __init__ ( personalized )","title":"NXPageRank"},{"location":"recsys/graph_based/graph_based_algorithms/nx_pagerank/#clayrs.recsys.graph_based_algorithm.page_rank.nx_page_rank.NXPageRank.rank","text":"Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked for each user with the filter_dict parameter, in this case every user is mapped with a list of items for which a ranking score must be computed. Otherwise, ALL unrated items will be ranked for each user. PARAMETER DESCRIPTION all_users Set of user id for which a recommendation list must be generated TYPE: Set [ str ] graph A NX graph previously instantiated TYPE: NXBipartiteGraph recs_number number of the top ranked items to return, if None all ranked items will be returned TYPE: int DEFAULT: None test_set Ratings object which represents the ground truth of the split considered TYPE: Ratings recs_number number of the top ranked items to return, if None all ranked items will be returned TYPE: int DEFAULT: None methodology Methodology object which governs the candidate item selection. Default is TestRatingsMethodology TYPE: Union [ Methodology , None] DEFAULT: TestRatingsMethodology() num_cpus number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. TYPE: int DEFAULT: 1 RETURNS DESCRIPTION List [ Interaction ] List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user Source code in clayrs/recsys/graph_based_algorithm/page_rank/nx_page_rank.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 def rank ( self , all_users : Set [ str ], graph : NXBipartiteGraph , test_set : Ratings , recs_number : int = None , methodology : Union [ Methodology , None ] = TestRatingsMethodology (), num_cpus : int = 1 ) -> List [ Interaction ]: \"\"\" Rank the top-n recommended items for the user. If the recs_number parameter isn't specified, All unrated items for the user will be ranked (or only items in the filter list, if specified). One can specify which items must be ranked for each user with the `filter_dict` parameter, in this case every user is mapped with a list of items for which a ranking score must be computed. Otherwise, **ALL** unrated items will be ranked for each user. Args: all_users: Set of user id for which a recommendation list must be generated graph: A NX graph previously instantiated recs_number: number of the top ranked items to return, if None all ranked items will be returned test_set: Ratings object which represents the ground truth of the split considered recs_number: number of the top ranked items to return, if None all ranked items will be returned methodology: `Methodology` object which governs the candidate item selection. Default is `TestRatingsMethodology` num_cpus: number of processors that must be reserved for the method. Default is 0, meaning that the number of cpus will be automatically detected. Returns: List of Interactions object in a descending order w.r.t the 'score' attribute, representing the ranking for a single user \"\"\" def compute_single_rank ( user_id ): # nonlocal keyword allows to modify the score variable nonlocal scores user_node = UserNode ( user_id ) filter_list = None if methodology is not None : filter_list = set ( ItemNode ( item_to_rank ) for item_to_rank in methodology . filter_single ( user_id , train_set , test_set )) # run the pageRank if self . _personalized is True : # the personalization vector is formed by the nodes that the user voted with their weight # + all the other nodes in the graph with weight as the min weight given by the user # (This because if a node isn't specified in the personalization vector will have 0 score in page # rank) succ = graph . get_successors ( user_node ) profile = { scored_node : graph . get_link_data ( user_node , scored_node ) . get ( 'weight' ) for scored_node in succ if graph . get_link_data ( user_node , scored_node ) . get ( 'weight' ) is not None } pers = { node : profile [ node ] if node in profile else min ( set ( profile . values ())) for node in graph . to_networkx () . nodes } scores = nx . pagerank ( graph . to_networkx (), personalization = pers , alpha = self . alpha , max_iter = self . max_iter , tol = self . tol , nstart = self . nstart , weight = weight ) # if scores is None it means this is the first time we are running normal pagerank # for all the other users the pagerank won't be computed again elif scores is None : scores = nx . pagerank ( graph . to_networkx (), alpha = self . alpha , max_iter = self . max_iter , tol = self . tol , nstart = self . nstart , weight = weight ) # clean the results removing user nodes, selected user profile and eventually properties user_scores = self . filter_result ( graph , scores , filter_list , user_node ) # Build the item_score dict (key is item_id, value is rank score predicted) # and order the keys in descending order item_score_dict = dict ( zip ([ node . value for node in user_scores . keys ()], user_scores . values ())) ordered_item_ids = sorted ( item_score_dict , key = item_score_dict . get , reverse = True ) # we only save the top-n items_ids corresponding to top-n recommendations # (if recs_number is None ordered_item_ids will contain all item_ids as the original list) ordered_item_ids = ordered_item_ids [: recs_number ] # we construct the output data single_rank_interaction_list = [ Interaction ( user_id , item_id , item_score_dict [ item_id ]) for item_id in ordered_item_ids ] return user_id , single_rank_interaction_list # scores will contain pagerank scores scores = None all_rank_interaction_list = [] weight = 'weight' if self . weight is True else None train_set = graph . to_ratings () with get_iterator_parallel ( num_cpus , compute_single_rank , all_users , progress_bar = True , total = len ( all_users )) as pbar : pbar . set_description ( \"Prepping rank...\" ) for user_id , user_rank in pbar : all_rank_interaction_list . append ( user_rank ) pbar . set_description ( f \"Computing rank for user { user_id } \" ) return list ( itertools . chain . from_iterable ( all_rank_interaction_list ))","title":"rank()"},{"location":"recsys/graph_based/graphs/nodes/","text":"Nodes categories The followings are all the various category of nodes that can be added to a graph. Info Please note that there exists Bipartite Graph , Tripartite Graph and Full Graph , all with their peculiarities and restrictions. Check their documentation for more! UserNode ( value ) Bases: Node Class that represents 'user' nodes PARAMETER DESCRIPTION value the value to store in the node TYPE: object Source code in clayrs/recsys/graphs/graph.py 64 65 def __init__ ( self , value : str ): super () . __init__ ( value ) ItemNode ( value ) Bases: Node Class that represents 'item' nodes PARAMETER DESCRIPTION value the value to store in the node TYPE: object Source code in clayrs/recsys/graphs/graph.py 82 83 def __init__ ( self , value : str ): super () . __init__ ( value ) PropertyNode ( value ) Bases: Node Class that represents 'property' nodes PARAMETER DESCRIPTION value the value to store in the node TYPE: object Source code in clayrs/recsys/graphs/graph.py 100 101 def __init__ ( self , value : str ): super () . __init__ ( value )","title":"Nodes categories"},{"location":"recsys/graph_based/graphs/nodes/#nodes-categories","text":"The followings are all the various category of nodes that can be added to a graph. Info Please note that there exists Bipartite Graph , Tripartite Graph and Full Graph , all with their peculiarities and restrictions. Check their documentation for more!","title":"Nodes categories"},{"location":"recsys/graph_based/graphs/nodes/#clayrs.recsys.graphs.UserNode","text":"Bases: Node Class that represents 'user' nodes PARAMETER DESCRIPTION value the value to store in the node TYPE: object Source code in clayrs/recsys/graphs/graph.py 64 65 def __init__ ( self , value : str ): super () . __init__ ( value )","title":"UserNode"},{"location":"recsys/graph_based/graphs/nodes/#clayrs.recsys.graphs.ItemNode","text":"Bases: Node Class that represents 'item' nodes PARAMETER DESCRIPTION value the value to store in the node TYPE: object Source code in clayrs/recsys/graphs/graph.py 82 83 def __init__ ( self , value : str ): super () . __init__ ( value )","title":"ItemNode"},{"location":"recsys/graph_based/graphs/nodes/#clayrs.recsys.graphs.PropertyNode","text":"Bases: Node Class that represents 'property' nodes PARAMETER DESCRIPTION value the value to store in the node TYPE: object Source code in clayrs/recsys/graphs/graph.py 100 101 def __init__ ( self , value : str ): super () . __init__ ( value )","title":"PropertyNode"},{"location":"recsys/graph_based/graphs/nx_bipartite/","text":"Bipartite Graph NXBipartiteGraph ( source_frame = None , link_label = None ) Bases: BipartiteDiGraph Class that implements a Bipartite graph through networkx library. Info A Bipartite Graph is a graph which supports only User nodes and Item nodes. If you need to model also other node categories, consider using a Tripartite Graph or a Full Graph It creates a graph from an initial Rating object. Consider the following matrix representation of the Rating object +------+-----------+-------+ | User | Item | Score | +------+-----------+-------+ | u1 | Tenet | 4 | | u2 | Inception | 5 | | ... | ... | ... | +------+-----------+-------+ The graph will be created with the following interactions: 4 u1 -----> Tenet 5 u2 -----> Inception where u1 and u2 become User nodes and Tenet and Inception become Item nodes , with the edge weighted depending on the score given If the link_label parameter is specified, then each link between users and items will be labeled with the label specified (e.g. link_label='score' ): (4, 'score') u1 -------------> Tenet (5, 'score') u2 -------------> Inception PARAMETER DESCRIPTION source_frame the initial Ratings object needed to create the graph TYPE: Ratings DEFAULT: None link_label If specified, each link will be labeled with the given label. Default is None TYPE: str DEFAULT: None Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def __init__ ( self , source_frame : Ratings = None , link_label : str = None ): self . _graph = nx . DiGraph () if source_frame is not None : not_none_dict = {} if link_label is not None : not_none_dict [ 'label' ] = link_label with get_progbar ( source_frame ) as progbar : progbar . set_description ( \"Creating User->Item links\" ) if len ( source_frame . timestamp_column ) != 0 : edges_with_attributes_gen = (( UserNode ( interaction . user_id ), ItemNode ( interaction . item_id ), # {**x, **y} merges the dicts x and y { ** not_none_dict , ** { 'weight' : interaction . score , 'timestamp' : interaction . timestamp }} ) for interaction in progbar ) else : edges_with_attributes_gen = (( UserNode ( interaction . user_id ), ItemNode ( interaction . item_id ), # {**x, **y} merges the dicts x and y { ** not_none_dict , ** { 'weight' : interaction . score }}) for interaction in progbar ) self . _graph . add_edges_from ( edges_with_attributes_gen ) add_link ( start_node , final_node , weight = None , label = None , timestamp = None ) Creates a link connecting the start_node to the final_node . If two lists are passed, then the node in position \\(i\\) in the start_node list will be linked to the node in position \\(i\\) in the final_node list. If nodes to link do not exist, they will be added automatically to the graph. Please remember that since this is a Bipartite Graph, only User nodes and Item nodes can be added! A link can be weighted with the weight parameter and labeled with the label parameter. A timestamp can also be specified via timestamp parameter. All three are optional parameters, so they are not required PARAMETER DESCRIPTION start_node Single Node object or a list of Node objects. They will be the 'head' of the link, since it's a directed graph TYPE: Union [ Node , List [ Node ]] final_node Single Node object or a list Node objects. They will be the 'tail' of the link, since it's a directed graph TYPE: object weight weight of the link, default is None (no weight) TYPE: float DEFAULT: None label label of the link, default is None (no label) TYPE: str DEFAULT: None timestamp timestamp of the link, default is None (no timestamp) TYPE: str DEFAULT: None Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def add_link ( self , start_node : Union [ Node , List [ Node ]], final_node : Union [ Node , List [ Node ]], weight : float = None , label : str = None , timestamp : str = None ): \"\"\" Creates a link connecting the `start_node` to the `final_node`. If two lists are passed, then the node in position $i$ in the `start_node` list will be linked to the node in position $i$ in the `final_node` list. If nodes to link do not exist, they will be added automatically to the graph. Please remember that since this is a Bipartite Graph, only *User nodes* and *Item nodes* can be added! A link can be weighted with the `weight` parameter and labeled with the `label` parameter. A timestamp can also be specified via `timestamp` parameter. All three are optional parameters, so they are not required Args: start_node: Single Node object or a list of Node objects. They will be the 'head' of the link, since it's a directed graph final_node (object): Single Node object or a list Node objects. They will be the 'tail' of the link, since it's a directed graph weight: weight of the link, default is None (no weight) label: label of the link, default is None (no label) timestamp: timestamp of the link, default is None (no timestamp) \"\"\" if not isinstance ( start_node , list ): start_node = [ start_node ] if not isinstance ( final_node , list ): final_node = [ final_node ] self . add_node ( start_node ) self . add_node ( final_node ) not_none_dict = {} if label is not None : not_none_dict [ 'label' ] = label if weight is not None : not_none_dict [ 'weight' ] = weight if timestamp is not None : not_none_dict [ 'timestamp' ] = timestamp self . _graph . add_edges_from ( zip ( start_node , final_node ), ** not_none_dict ) add_node ( node ) Adds one or multiple Node objects to the graph. Since this is a Bipartite Graph, only User Node and Item Node can be added! No duplicates are allowed, but different category nodes with same id are (e.g. ItemNode('1') and UserNode('1') ) PARAMETER DESCRIPTION node Node(s) object(s) that needs to be added to the graph TYPE: Union [ Node , List [ Node ]] RAISES DESCRIPTION ValueError Exception raised when one of the node to add to the graph is not a User or Item node Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def add_node ( self , node : Union [ Node , List [ Node ]]): \"\"\" Adds one or multiple Node objects to the graph. Since this is a Bipartite Graph, only `User Node` and `Item Node` can be added! No duplicates are allowed, but different category nodes with same id are (e.g. `ItemNode('1')` and `UserNode('1')`) Args: node: Node(s) object(s) that needs to be added to the graph Raises: ValueError: Exception raised when one of the node to add to the graph is not a User or Item node \"\"\" if not isinstance ( node , list ): node = [ node ] if any ( not isinstance ( n , ( UserNode , ItemNode )) for n in node ): raise ValueError ( \"You can only add UserNodes or ItemNodes to a bipartite graph!\" ) self . _graph . add_nodes_from ( node ) closeness_centrality () Calculate the closeness centrality for every node in the graph RETURNS DESCRIPTION Dict Dictionary containing the closeness centrality for each node in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 295 296 297 298 299 300 301 302 def closeness_centrality ( self ) -> Dict : \"\"\" Calculate the closeness centrality for every node in the graph Returns: Dictionary containing the closeness centrality for each node in the graph \"\"\" return nx . closeness_centrality ( self . _graph ) degree_centrality () Calculate the degree centrality for every node in the graph RETURNS DESCRIPTION Dict Dictionary containing the degree centrality for each node in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 286 287 288 289 290 291 292 293 def degree_centrality ( self ) -> Dict : \"\"\" Calculate the degree centrality for every node in the graph Returns: Dictionary containing the degree centrality for each node in the graph \"\"\" return nx . degree_centrality ( self . _graph ) dispersion () Calculate the dispersion for every node in the graph RETURNS DESCRIPTION Dict Dictionary containing the dispersion computed for each node in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 304 305 306 307 308 309 310 311 def dispersion ( self ) -> Dict : \"\"\" Calculate the dispersion for every node in the graph Returns: Dictionary containing the dispersion computed for each node in the graph \"\"\" return nx . dispersion ( self . _graph ) get_link_data ( start_node , final_node ) Get link data such as weight, label, timestamp. between the start_node and the final_node . Returns None if said link doesn't exists Remember that this is a directed graph so the result differs if 'start_node' and 'final_node' are switched. PARAMETER DESCRIPTION start_node Node object from where the link starts TYPE: Node final_node Node object to where the link ends TYPE: Node Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 187 188 189 190 191 192 193 194 195 196 197 198 199 def get_link_data ( self , start_node : Node , final_node : Node ): \"\"\" Get link data such as weight, label, timestamp. between the `start_node` and the `final_node`. Returns None if said link doesn't exists Remember that this is a directed graph so the result differs if 'start_node' and 'final_node' are switched. Args: start_node: Node object from where the link starts final_node: Node object to where the link ends \"\"\" return self . _graph . get_edge_data ( start_node , final_node ) get_predecessors ( node ) Returns a list containing the predecessors of the node passed. Raises TypeError exception if the node doesn't exists in the graph. Taken from networkx library: A predecessor of n is a node m such that there exists a directed edge from m to n For example: # GRAPH: I1 <-- U1 \u2191 U2 >>> graph . get_predecessors ( ItemNode ( 'I1' )) [ User U1 , User U2 ] PARAMETER DESCRIPTION node Node for which we want to know the predecessors TYPE: Node RAISES DESCRIPTION TypeError Exception raised when the node it's not in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 def get_predecessors ( self , node : Node ) -> List [ Node ]: \"\"\" Returns a list containing the *predecessors* of the node passed. Raises TypeError exception if the node doesn't exists in the graph. Taken from networkx library: > A predecessor of n is a node m such that there exists a directed edge from m to n For example: ``` # GRAPH: I1 <-- U1 \u2191 U2 ``` ```python >>> graph.get_predecessors(ItemNode('I1')) [User U1, User U2] ``` Args: node: Node for which we want to know the predecessors Raises: TypeError: Exception raised when the node it's not in the graph \"\"\" try : return list ( self . _graph . predecessors ( node )) except nx . NetworkXError : raise TypeError ( \"The node specified is not in the graph!\" ) get_successors ( node ) Returns a list containing the successors of the node passed. Returns None if the node doesn't exists in the graph. Taken from networkx library: A successor of n is a node m such that there exists a directed edge from n to m For example: U1 --> I2 \u2193 I1 >>> graph . get_successors ( UserNode ( 'U1' )) [ Item I1 , Item I2 ] PARAMETER DESCRIPTION node Node for which we want to know the successors TYPE: Node RAISES DESCRIPTION TypeError Exception raised when the node it's not in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 def get_successors ( self , node : Node ) -> List [ Node ]: \"\"\" Returns a list containing the successors of the node passed. Returns None if the node doesn't exists in the graph. Taken from networkx library: > A successor of n is a node m such that there exists a directed edge from n to m For example: ``` U1 --> I2 \u2193 I1 ``` ```python >>> graph.get_successors(UserNode('U1')) [Item I1, Item I2] ``` Args: node: Node for which we want to know the successors Raises: TypeError: Exception raised when the node it's not in the graph \"\"\" try : return list ( self . _graph . successors ( node )) except nx . NetworkXError : raise TypeError ( \"The node specified is not in the graph!\" ) item_nodes () property Returns a set of all Item nodes in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 101 102 103 104 105 106 @property def item_nodes ( self ) -> Set [ ItemNode ]: \"\"\" Returns a set of all *Item nodes* in the graph \"\"\" return set ([ node for node in self . _graph . nodes if isinstance ( node , ItemNode )]) node_exists ( node ) Returns True if the node passed exists in the graph, False otherwise PARAMETER DESCRIPTION node Node to check whether it's present in the graph or not TYPE: Node Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 270 271 272 273 274 275 276 277 278 def node_exists ( self , node : Node ) -> bool : \"\"\" Returns True if the node passed exists in the graph, False otherwise Args: node: Node to check whether it's present in the graph or not \"\"\" r = self . _graph . nodes . get ( node ) return r is not None remove_link ( start_node , final_node ) Removes the link connecting the start_node to the final_node . If there's no link between the two nodes, then a warning is printed PARAMETER DESCRIPTION start_node head node of the link to remove TYPE: Node final_node tail node of the link to remove TYPE: Node Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def remove_link ( self , start_node : Node , final_node : Node ): \"\"\" Removes the link connecting the `start_node` to the `final_node`. If there's no link between the two nodes, then a warning is printed Args: start_node: *head* node of the link to remove final_node: *tail* node of the link to remove \"\"\" try : self . _graph . remove_edge ( start_node , final_node ) except nx . NetworkXError : logger . warning ( \"No link exists between the start node and the final node! \\n \" \"No link will be removed\" ) remove_node ( node_to_remove ) Removes one or multiple nodes from the graph. If one of the nodes to remove is not present in the graph, it is silently ignored PARAMETER DESCRIPTION node_to_remove Single Node object or a list of Node objects to remove from the graph TYPE: Union [ Node , List [ Node ]] Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 313 314 315 316 317 318 319 320 321 322 323 324 def remove_node ( self , node_to_remove : Union [ Node , List [ Node ]]): \"\"\" Removes one or multiple nodes from the graph. If one of the nodes to remove is not present in the graph, it is silently ignored Args: node_to_remove: Single Node object or a list of Node objects to remove from the graph \"\"\" if not isinstance ( node_to_remove , list ): node_to_remove = [ node_to_remove ] self . _graph . remove_nodes_from ( node_to_remove ) to_networkx () Returns underlying networkx implementation of the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 280 281 282 283 284 def to_networkx ( self ) -> nx . DiGraph : \"\"\" Returns underlying networkx implementation of the graph \"\"\" return self . _graph user_nodes () property Returns a set of all User nodes in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 94 95 96 97 98 99 @property def user_nodes ( self ) -> Set [ UserNode ]: \"\"\" Returns a set of all *User nodes* in the graph \"\"\" return set ([ node for node in self . _graph . nodes if isinstance ( node , UserNode )])","title":"Bipartite Graph"},{"location":"recsys/graph_based/graphs/nx_bipartite/#bipartite-graph","text":"","title":"Bipartite Graph"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph","text":"Bases: BipartiteDiGraph Class that implements a Bipartite graph through networkx library. Info A Bipartite Graph is a graph which supports only User nodes and Item nodes. If you need to model also other node categories, consider using a Tripartite Graph or a Full Graph It creates a graph from an initial Rating object. Consider the following matrix representation of the Rating object +------+-----------+-------+ | User | Item | Score | +------+-----------+-------+ | u1 | Tenet | 4 | | u2 | Inception | 5 | | ... | ... | ... | +------+-----------+-------+ The graph will be created with the following interactions: 4 u1 -----> Tenet 5 u2 -----> Inception where u1 and u2 become User nodes and Tenet and Inception become Item nodes , with the edge weighted depending on the score given If the link_label parameter is specified, then each link between users and items will be labeled with the label specified (e.g. link_label='score' ): (4, 'score') u1 -------------> Tenet (5, 'score') u2 -------------> Inception PARAMETER DESCRIPTION source_frame the initial Ratings object needed to create the graph TYPE: Ratings DEFAULT: None link_label If specified, each link will be labeled with the given label. Default is None TYPE: str DEFAULT: None Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def __init__ ( self , source_frame : Ratings = None , link_label : str = None ): self . _graph = nx . DiGraph () if source_frame is not None : not_none_dict = {} if link_label is not None : not_none_dict [ 'label' ] = link_label with get_progbar ( source_frame ) as progbar : progbar . set_description ( \"Creating User->Item links\" ) if len ( source_frame . timestamp_column ) != 0 : edges_with_attributes_gen = (( UserNode ( interaction . user_id ), ItemNode ( interaction . item_id ), # {**x, **y} merges the dicts x and y { ** not_none_dict , ** { 'weight' : interaction . score , 'timestamp' : interaction . timestamp }} ) for interaction in progbar ) else : edges_with_attributes_gen = (( UserNode ( interaction . user_id ), ItemNode ( interaction . item_id ), # {**x, **y} merges the dicts x and y { ** not_none_dict , ** { 'weight' : interaction . score }}) for interaction in progbar ) self . _graph . add_edges_from ( edges_with_attributes_gen )","title":"NXBipartiteGraph"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.add_link","text":"Creates a link connecting the start_node to the final_node . If two lists are passed, then the node in position \\(i\\) in the start_node list will be linked to the node in position \\(i\\) in the final_node list. If nodes to link do not exist, they will be added automatically to the graph. Please remember that since this is a Bipartite Graph, only User nodes and Item nodes can be added! A link can be weighted with the weight parameter and labeled with the label parameter. A timestamp can also be specified via timestamp parameter. All three are optional parameters, so they are not required PARAMETER DESCRIPTION start_node Single Node object or a list of Node objects. They will be the 'head' of the link, since it's a directed graph TYPE: Union [ Node , List [ Node ]] final_node Single Node object or a list Node objects. They will be the 'tail' of the link, since it's a directed graph TYPE: object weight weight of the link, default is None (no weight) TYPE: float DEFAULT: None label label of the link, default is None (no label) TYPE: str DEFAULT: None timestamp timestamp of the link, default is None (no timestamp) TYPE: str DEFAULT: None Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def add_link ( self , start_node : Union [ Node , List [ Node ]], final_node : Union [ Node , List [ Node ]], weight : float = None , label : str = None , timestamp : str = None ): \"\"\" Creates a link connecting the `start_node` to the `final_node`. If two lists are passed, then the node in position $i$ in the `start_node` list will be linked to the node in position $i$ in the `final_node` list. If nodes to link do not exist, they will be added automatically to the graph. Please remember that since this is a Bipartite Graph, only *User nodes* and *Item nodes* can be added! A link can be weighted with the `weight` parameter and labeled with the `label` parameter. A timestamp can also be specified via `timestamp` parameter. All three are optional parameters, so they are not required Args: start_node: Single Node object or a list of Node objects. They will be the 'head' of the link, since it's a directed graph final_node (object): Single Node object or a list Node objects. They will be the 'tail' of the link, since it's a directed graph weight: weight of the link, default is None (no weight) label: label of the link, default is None (no label) timestamp: timestamp of the link, default is None (no timestamp) \"\"\" if not isinstance ( start_node , list ): start_node = [ start_node ] if not isinstance ( final_node , list ): final_node = [ final_node ] self . add_node ( start_node ) self . add_node ( final_node ) not_none_dict = {} if label is not None : not_none_dict [ 'label' ] = label if weight is not None : not_none_dict [ 'weight' ] = weight if timestamp is not None : not_none_dict [ 'timestamp' ] = timestamp self . _graph . add_edges_from ( zip ( start_node , final_node ), ** not_none_dict )","title":"add_link()"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.add_node","text":"Adds one or multiple Node objects to the graph. Since this is a Bipartite Graph, only User Node and Item Node can be added! No duplicates are allowed, but different category nodes with same id are (e.g. ItemNode('1') and UserNode('1') ) PARAMETER DESCRIPTION node Node(s) object(s) that needs to be added to the graph TYPE: Union [ Node , List [ Node ]] RAISES DESCRIPTION ValueError Exception raised when one of the node to add to the graph is not a User or Item node Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def add_node ( self , node : Union [ Node , List [ Node ]]): \"\"\" Adds one or multiple Node objects to the graph. Since this is a Bipartite Graph, only `User Node` and `Item Node` can be added! No duplicates are allowed, but different category nodes with same id are (e.g. `ItemNode('1')` and `UserNode('1')`) Args: node: Node(s) object(s) that needs to be added to the graph Raises: ValueError: Exception raised when one of the node to add to the graph is not a User or Item node \"\"\" if not isinstance ( node , list ): node = [ node ] if any ( not isinstance ( n , ( UserNode , ItemNode )) for n in node ): raise ValueError ( \"You can only add UserNodes or ItemNodes to a bipartite graph!\" ) self . _graph . add_nodes_from ( node )","title":"add_node()"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.closeness_centrality","text":"Calculate the closeness centrality for every node in the graph RETURNS DESCRIPTION Dict Dictionary containing the closeness centrality for each node in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 295 296 297 298 299 300 301 302 def closeness_centrality ( self ) -> Dict : \"\"\" Calculate the closeness centrality for every node in the graph Returns: Dictionary containing the closeness centrality for each node in the graph \"\"\" return nx . closeness_centrality ( self . _graph )","title":"closeness_centrality()"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.degree_centrality","text":"Calculate the degree centrality for every node in the graph RETURNS DESCRIPTION Dict Dictionary containing the degree centrality for each node in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 286 287 288 289 290 291 292 293 def degree_centrality ( self ) -> Dict : \"\"\" Calculate the degree centrality for every node in the graph Returns: Dictionary containing the degree centrality for each node in the graph \"\"\" return nx . degree_centrality ( self . _graph )","title":"degree_centrality()"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.dispersion","text":"Calculate the dispersion for every node in the graph RETURNS DESCRIPTION Dict Dictionary containing the dispersion computed for each node in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 304 305 306 307 308 309 310 311 def dispersion ( self ) -> Dict : \"\"\" Calculate the dispersion for every node in the graph Returns: Dictionary containing the dispersion computed for each node in the graph \"\"\" return nx . dispersion ( self . _graph )","title":"dispersion()"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.get_link_data","text":"Get link data such as weight, label, timestamp. between the start_node and the final_node . Returns None if said link doesn't exists Remember that this is a directed graph so the result differs if 'start_node' and 'final_node' are switched. PARAMETER DESCRIPTION start_node Node object from where the link starts TYPE: Node final_node Node object to where the link ends TYPE: Node Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 187 188 189 190 191 192 193 194 195 196 197 198 199 def get_link_data ( self , start_node : Node , final_node : Node ): \"\"\" Get link data such as weight, label, timestamp. between the `start_node` and the `final_node`. Returns None if said link doesn't exists Remember that this is a directed graph so the result differs if 'start_node' and 'final_node' are switched. Args: start_node: Node object from where the link starts final_node: Node object to where the link ends \"\"\" return self . _graph . get_edge_data ( start_node , final_node )","title":"get_link_data()"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.get_predecessors","text":"Returns a list containing the predecessors of the node passed. Raises TypeError exception if the node doesn't exists in the graph. Taken from networkx library: A predecessor of n is a node m such that there exists a directed edge from m to n For example: # GRAPH: I1 <-- U1 \u2191 U2 >>> graph . get_predecessors ( ItemNode ( 'I1' )) [ User U1 , User U2 ] PARAMETER DESCRIPTION node Node for which we want to know the predecessors TYPE: Node RAISES DESCRIPTION TypeError Exception raised when the node it's not in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 def get_predecessors ( self , node : Node ) -> List [ Node ]: \"\"\" Returns a list containing the *predecessors* of the node passed. Raises TypeError exception if the node doesn't exists in the graph. Taken from networkx library: > A predecessor of n is a node m such that there exists a directed edge from m to n For example: ``` # GRAPH: I1 <-- U1 \u2191 U2 ``` ```python >>> graph.get_predecessors(ItemNode('I1')) [User U1, User U2] ``` Args: node: Node for which we want to know the predecessors Raises: TypeError: Exception raised when the node it's not in the graph \"\"\" try : return list ( self . _graph . predecessors ( node )) except nx . NetworkXError : raise TypeError ( \"The node specified is not in the graph!\" )","title":"get_predecessors()"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.get_successors","text":"Returns a list containing the successors of the node passed. Returns None if the node doesn't exists in the graph. Taken from networkx library: A successor of n is a node m such that there exists a directed edge from n to m For example: U1 --> I2 \u2193 I1 >>> graph . get_successors ( UserNode ( 'U1' )) [ Item I1 , Item I2 ] PARAMETER DESCRIPTION node Node for which we want to know the successors TYPE: Node RAISES DESCRIPTION TypeError Exception raised when the node it's not in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 def get_successors ( self , node : Node ) -> List [ Node ]: \"\"\" Returns a list containing the successors of the node passed. Returns None if the node doesn't exists in the graph. Taken from networkx library: > A successor of n is a node m such that there exists a directed edge from n to m For example: ``` U1 --> I2 \u2193 I1 ``` ```python >>> graph.get_successors(UserNode('U1')) [Item I1, Item I2] ``` Args: node: Node for which we want to know the successors Raises: TypeError: Exception raised when the node it's not in the graph \"\"\" try : return list ( self . _graph . successors ( node )) except nx . NetworkXError : raise TypeError ( \"The node specified is not in the graph!\" )","title":"get_successors()"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.item_nodes","text":"Returns a set of all Item nodes in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 101 102 103 104 105 106 @property def item_nodes ( self ) -> Set [ ItemNode ]: \"\"\" Returns a set of all *Item nodes* in the graph \"\"\" return set ([ node for node in self . _graph . nodes if isinstance ( node , ItemNode )])","title":"item_nodes()"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.node_exists","text":"Returns True if the node passed exists in the graph, False otherwise PARAMETER DESCRIPTION node Node to check whether it's present in the graph or not TYPE: Node Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 270 271 272 273 274 275 276 277 278 def node_exists ( self , node : Node ) -> bool : \"\"\" Returns True if the node passed exists in the graph, False otherwise Args: node: Node to check whether it's present in the graph or not \"\"\" r = self . _graph . nodes . get ( node ) return r is not None","title":"node_exists()"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.remove_link","text":"Removes the link connecting the start_node to the final_node . If there's no link between the two nodes, then a warning is printed PARAMETER DESCRIPTION start_node head node of the link to remove TYPE: Node final_node tail node of the link to remove TYPE: Node Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def remove_link ( self , start_node : Node , final_node : Node ): \"\"\" Removes the link connecting the `start_node` to the `final_node`. If there's no link between the two nodes, then a warning is printed Args: start_node: *head* node of the link to remove final_node: *tail* node of the link to remove \"\"\" try : self . _graph . remove_edge ( start_node , final_node ) except nx . NetworkXError : logger . warning ( \"No link exists between the start node and the final node! \\n \" \"No link will be removed\" )","title":"remove_link()"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.remove_node","text":"Removes one or multiple nodes from the graph. If one of the nodes to remove is not present in the graph, it is silently ignored PARAMETER DESCRIPTION node_to_remove Single Node object or a list of Node objects to remove from the graph TYPE: Union [ Node , List [ Node ]] Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 313 314 315 316 317 318 319 320 321 322 323 324 def remove_node ( self , node_to_remove : Union [ Node , List [ Node ]]): \"\"\" Removes one or multiple nodes from the graph. If one of the nodes to remove is not present in the graph, it is silently ignored Args: node_to_remove: Single Node object or a list of Node objects to remove from the graph \"\"\" if not isinstance ( node_to_remove , list ): node_to_remove = [ node_to_remove ] self . _graph . remove_nodes_from ( node_to_remove )","title":"remove_node()"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.to_networkx","text":"Returns underlying networkx implementation of the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 280 281 282 283 284 def to_networkx ( self ) -> nx . DiGraph : \"\"\" Returns underlying networkx implementation of the graph \"\"\" return self . _graph","title":"to_networkx()"},{"location":"recsys/graph_based/graphs/nx_bipartite/#clayrs.recsys.graphs.nx_implementation.nx_bipartite_graphs.NXBipartiteGraph.user_nodes","text":"Returns a set of all User nodes in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_bipartite_graphs.py 94 95 96 97 98 99 @property def user_nodes ( self ) -> Set [ UserNode ]: \"\"\" Returns a set of all *User nodes* in the graph \"\"\" return set ([ node for node in self . _graph . nodes if isinstance ( node , UserNode )])","title":"user_nodes()"},{"location":"recsys/graph_based/graphs/nx_full/","text":"Full Graph Please remember that this class is a subclass of NXTripartiteGraph , so it inherits all its methods. You can check their documentation as well! NXFullGraph ( source_frame = None , item_exo_properties = None , item_contents_dir = None , user_exo_properties = None , user_contents_dir = None , link_label = None ) Bases: NXTripartiteGraph , FullDiGraph Class that implements a Full graph through networkx library. Info A Full Graph is a graph which doesn't impose any particular restriction It creates a graph from an initial Rating object. Consider the following matrix representation of the Rating object +------+-----------+-------+ | User | Item | Score | +------+-----------+-------+ | u1 | Tenet | 4 | | u2 | Inception | 5 | | ... | ... | ... | +------+-----------+-------+ The graph will be created with the following interactions: 4 u1 -----> Tenet 5 u2 -----> Inception where u1 and u2 become User nodes and Tenet and Inception become Item nodes , with the edge weighted depending on the score given If the link_label parameter is specified, then each link between users and items will be labeled with the label specified (e.g. link_label='score' ): (4, 'score') u1 -------------> Tenet (5, 'score') u2 -------------> Inception Then the framework tries to load 'Tenet' and 'Inception' from the item_contents_dir and 'u1' and 'u2' from user_contents_dir if they are specified and if it succeeds, adds in the graph their loaded properties as specified in the item_exo_properties parameter and user_exo_properties . Load exogenous properties In order to load properties in the graph, we must specify where users (and/or) items are serialized and which properties to add (the following is the same for item_exo_properties ): If user_exo_properties is specified as a set , then the graph will try to load all properties from said exogenous representation { 'my_exo_id' } If user_exo_properties is specified as a dict , then the graph will try to load said properties from said exogenous representation { 'my_exo_id' : [ 'my_prop1' , 'my_prop2' ]]} PARAMETER DESCRIPTION source_frame The initial Ratings object needed to create the graph TYPE: Ratings DEFAULT: None item_exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] DEFAULT: None item_contents_dir The path containing items serialized with the Content Analyzer TYPE: str DEFAULT: None user_exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] DEFAULT: None user_contents_dir The path containing users serialized with the Content Analyzer TYPE: str DEFAULT: None link_label If specified, each link will be labeled with the given label. Default is None TYPE: str DEFAULT: None Source code in clayrs/recsys/graphs/nx_implementation/nx_full_graphs.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 def __init__ ( self , source_frame : Ratings = None , item_exo_properties : Union [ Dict , set ] = None , item_contents_dir : str = None , user_exo_properties : Union [ Dict , set ] = None , user_contents_dir : str = None , link_label : str = None ): NXTripartiteGraph . __init__ ( self , source_frame , item_exo_properties , item_contents_dir , link_label ) if user_exo_properties and not user_contents_dir : logger . warning ( \"`user_exo_properties` parameter set but `user_contents_dir` is None! \" \"No property will be loaded\" ) elif not user_exo_properties and user_contents_dir : logger . warning ( \"`user_contents_dir` parameter set but `user_exo_properties` is None! \" \"No property will be loaded\" ) if source_frame is not None and user_contents_dir is not None and user_exo_properties is not None : self . add_node_with_prop ([ UserNode ( user_id ) for user_id in set ( source_frame . user_id_column )], user_exo_properties , user_contents_dir ) add_link ( start_node , final_node , weight = None , label = None , timestamp = None ) Creates a weighted link connecting the 'start_node' to the 'final_node' Both nodes must be present in the graph before calling this method 'weight' and 'label' are optional parameters, if not specified default values will be used. PARAMETER DESCRIPTION start_node starting node of the link TYPE: object final_node ending node of the link TYPE: object weight weight of the link, default is 0.5 TYPE: float DEFAULT: None label label of the link, default is 'score_label' TYPE: str DEFAULT: None Source code in clayrs/recsys/graphs/nx_implementation/nx_full_graphs.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 def add_link ( self , start_node : Union [ Node , List [ Node ]], final_node : Union [ Node , List [ Node ]], weight : float = None , label : str = None , timestamp : str = None ): \"\"\" Creates a weighted link connecting the 'start_node' to the 'final_node' Both nodes must be present in the graph before calling this method 'weight' and 'label' are optional parameters, if not specified default values will be used. Args: start_node (object): starting node of the link final_node (object): ending node of the link weight (float): weight of the link, default is 0.5 label (str): label of the link, default is 'score_label' \"\"\" if not isinstance ( start_node , list ): start_node = [ start_node ] if not isinstance ( final_node , list ): final_node = [ final_node ] self . add_node ( start_node ) self . add_node ( final_node ) not_none_dict = {} if label is not None : not_none_dict [ 'label' ] = label if weight is not None : not_none_dict [ 'weight' ] = weight if timestamp is not None : not_none_dict [ 'timestamp' ] = timestamp self . _graph . add_edges_from ( zip ( start_node , final_node ), ** not_none_dict ) add_node ( node ) Adds one or multiple Node objects to the graph. Since this is a Full Graph, any category of node is allowed No duplicates are allowed, but different category nodes with same id are (e.g. ItemNode('1') and UserNode('1') ) PARAMETER DESCRIPTION node Node(s) object(s) that needs to be added to the graph TYPE: Union [ Node , List [ Node ]] Source code in clayrs/recsys/graphs/nx_implementation/nx_full_graphs.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def add_node ( self , node : Union [ Node , List [ Node ]]): \"\"\" Adds one or multiple Node objects to the graph. Since this is a Full Graph, any category of node is allowed No duplicates are allowed, but different category nodes with same id are (e.g. `ItemNode('1')` and `UserNode('1')`) Args: node: Node(s) object(s) that needs to be added to the graph \"\"\" if not isinstance ( node , list ): node = [ node ] self . _graph . add_nodes_from ( node ) add_node_with_prop ( node , exo_properties , contents_dir , content_filename = None ) Adds one or multiple Node objects and its/their properties to the graph Since this is a Full Graph, no restriction are imposed and you can add any category of node together with its properties. In order to load properties in the graph, we must specify where contents are serialized and which properties to add (the following is the same for item_exo_properties ): If exo_properties is specified as a set , then the graph will try to load all properties from said exogenous representation { 'my_exo_id' } If exo_properties is specified as a dict , then the graph will try to load said properties from said exogenous representation { 'my_exo_id' : [ 'my_prop1' , 'my_prop2' ]]} In case you want your node to have a different id from serialized contents, via the content_filename parameter you can specify what is the filename of the node that you are adding, e.g. item_to_add = ItemNode('different_id') # content_filename is 'item_serialized_1.xz' graph.add_node_with_prop(item_to_add, ..., content_filename='item_serialized_1') In case you are adding a list of nodes, you can specify the filename for each node in the list. PARAMETER DESCRIPTION node Node(s) object(s) that needs to be added to the graph along with their properties TYPE: Union [ Node , List [ Node ]] exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] contents_dir The path containing items serialized with the Content Analyzer TYPE: str content_filename Filename(s) of the node(s) to add TYPE: Union [ str , List [ str ]] DEFAULT: None RAISES DESCRIPTION ValueError Exception raised when one of the node to add to the graph with their properties is not an ItemNode Source code in clayrs/recsys/graphs/nx_implementation/nx_full_graphs.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 def add_node_with_prop ( self , node : Union [ Node , List [ Node ]], exo_properties : Union [ Dict , set ], contents_dir : str , content_filename : Union [ str , List [ str ]] = None ): \"\"\" Adds one or multiple Node objects and its/their properties to the graph Since this is a Full Graph, no restriction are imposed and you can add any category of node together with its properties. In order to load properties in the graph, we must specify where contents are serialized and ***which properties to add*** (the following is the same for *item_exo_properties*): * If *exo_properties* is specified as a **set**, then the graph will try to load **all properties** from **said exogenous representation** ```python {'my_exo_id'} ``` * If *exo_properties* is specified as a **dict**, then the graph will try to load **said properties** from **said exogenous representation** ```python {'my_exo_id': ['my_prop1', 'my_prop2']]} ``` In case you want your node to have a different id from serialized contents, via the `content_filename` parameter you can specify what is the filename of the node that you are adding, e.g. ``` item_to_add = ItemNode('different_id') # content_filename is 'item_serialized_1.xz' graph.add_node_with_prop(item_to_add, ..., content_filename='item_serialized_1') ``` In case you are adding a list of nodes, you can specify the filename for each node in the list. Args: node: Node(s) object(s) that needs to be added to the graph along with their properties exo_properties: Set or Dict which contains representations to load from items. Use a `Set` if you want to load all properties from specific representations, or use a `Dict` if you want to choose which properties to load from specific representations contents_dir: The path containing items serialized with the Content Analyzer content_filename: Filename(s) of the node(s) to add Raises: ValueError: Exception raised when one of the node to add to the graph with their properties is not an ItemNode \"\"\" def node_prop_link_generator (): for n , id in zip ( progbar , content_filename ): item : Content = loaded_items . get ( id ) if item is not None : exo_props = self . _get_exo_props ( exo_properties , item ) single_item_prop_edges = [( n , PropertyNode ( prop_dict [ prop ]), { 'label' : prop }) for prop_dict in exo_props for prop in prop_dict ] else : single_item_prop_edges = [] yield from single_item_prop_edges if not isinstance ( node , list ): node = [ node ] if isinstance ( exo_properties , set ): exo_properties = dict . fromkeys ( exo_properties , None ) if content_filename is None : content_filename = [ n . value for n in node ] if not isinstance ( content_filename , list ): content_filename = [ content_filename ] loaded_items = LoadedContentsDict ( contents_dir , contents_to_load = set ( content_filename )) with get_progbar ( node ) as progbar : progbar . set_description ( \"Creating Node->Properties links\" ) self . _graph . add_edges_from (( tuple_to_add for tuple_to_add in node_prop_link_generator ()))","title":"Full Graph"},{"location":"recsys/graph_based/graphs/nx_full/#full-graph","text":"Please remember that this class is a subclass of NXTripartiteGraph , so it inherits all its methods. You can check their documentation as well!","title":"Full Graph"},{"location":"recsys/graph_based/graphs/nx_full/#clayrs.recsys.graphs.nx_implementation.nx_full_graphs.NXFullGraph","text":"Bases: NXTripartiteGraph , FullDiGraph Class that implements a Full graph through networkx library. Info A Full Graph is a graph which doesn't impose any particular restriction It creates a graph from an initial Rating object. Consider the following matrix representation of the Rating object +------+-----------+-------+ | User | Item | Score | +------+-----------+-------+ | u1 | Tenet | 4 | | u2 | Inception | 5 | | ... | ... | ... | +------+-----------+-------+ The graph will be created with the following interactions: 4 u1 -----> Tenet 5 u2 -----> Inception where u1 and u2 become User nodes and Tenet and Inception become Item nodes , with the edge weighted depending on the score given If the link_label parameter is specified, then each link between users and items will be labeled with the label specified (e.g. link_label='score' ): (4, 'score') u1 -------------> Tenet (5, 'score') u2 -------------> Inception Then the framework tries to load 'Tenet' and 'Inception' from the item_contents_dir and 'u1' and 'u2' from user_contents_dir if they are specified and if it succeeds, adds in the graph their loaded properties as specified in the item_exo_properties parameter and user_exo_properties . Load exogenous properties In order to load properties in the graph, we must specify where users (and/or) items are serialized and which properties to add (the following is the same for item_exo_properties ): If user_exo_properties is specified as a set , then the graph will try to load all properties from said exogenous representation { 'my_exo_id' } If user_exo_properties is specified as a dict , then the graph will try to load said properties from said exogenous representation { 'my_exo_id' : [ 'my_prop1' , 'my_prop2' ]]} PARAMETER DESCRIPTION source_frame The initial Ratings object needed to create the graph TYPE: Ratings DEFAULT: None item_exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] DEFAULT: None item_contents_dir The path containing items serialized with the Content Analyzer TYPE: str DEFAULT: None user_exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] DEFAULT: None user_contents_dir The path containing users serialized with the Content Analyzer TYPE: str DEFAULT: None link_label If specified, each link will be labeled with the given label. Default is None TYPE: str DEFAULT: None Source code in clayrs/recsys/graphs/nx_implementation/nx_full_graphs.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 def __init__ ( self , source_frame : Ratings = None , item_exo_properties : Union [ Dict , set ] = None , item_contents_dir : str = None , user_exo_properties : Union [ Dict , set ] = None , user_contents_dir : str = None , link_label : str = None ): NXTripartiteGraph . __init__ ( self , source_frame , item_exo_properties , item_contents_dir , link_label ) if user_exo_properties and not user_contents_dir : logger . warning ( \"`user_exo_properties` parameter set but `user_contents_dir` is None! \" \"No property will be loaded\" ) elif not user_exo_properties and user_contents_dir : logger . warning ( \"`user_contents_dir` parameter set but `user_exo_properties` is None! \" \"No property will be loaded\" ) if source_frame is not None and user_contents_dir is not None and user_exo_properties is not None : self . add_node_with_prop ([ UserNode ( user_id ) for user_id in set ( source_frame . user_id_column )], user_exo_properties , user_contents_dir )","title":"NXFullGraph"},{"location":"recsys/graph_based/graphs/nx_full/#clayrs.recsys.graphs.nx_implementation.nx_full_graphs.NXFullGraph.add_link","text":"Creates a weighted link connecting the 'start_node' to the 'final_node' Both nodes must be present in the graph before calling this method 'weight' and 'label' are optional parameters, if not specified default values will be used. PARAMETER DESCRIPTION start_node starting node of the link TYPE: object final_node ending node of the link TYPE: object weight weight of the link, default is 0.5 TYPE: float DEFAULT: None label label of the link, default is 'score_label' TYPE: str DEFAULT: None Source code in clayrs/recsys/graphs/nx_implementation/nx_full_graphs.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 def add_link ( self , start_node : Union [ Node , List [ Node ]], final_node : Union [ Node , List [ Node ]], weight : float = None , label : str = None , timestamp : str = None ): \"\"\" Creates a weighted link connecting the 'start_node' to the 'final_node' Both nodes must be present in the graph before calling this method 'weight' and 'label' are optional parameters, if not specified default values will be used. Args: start_node (object): starting node of the link final_node (object): ending node of the link weight (float): weight of the link, default is 0.5 label (str): label of the link, default is 'score_label' \"\"\" if not isinstance ( start_node , list ): start_node = [ start_node ] if not isinstance ( final_node , list ): final_node = [ final_node ] self . add_node ( start_node ) self . add_node ( final_node ) not_none_dict = {} if label is not None : not_none_dict [ 'label' ] = label if weight is not None : not_none_dict [ 'weight' ] = weight if timestamp is not None : not_none_dict [ 'timestamp' ] = timestamp self . _graph . add_edges_from ( zip ( start_node , final_node ), ** not_none_dict )","title":"add_link()"},{"location":"recsys/graph_based/graphs/nx_full/#clayrs.recsys.graphs.nx_implementation.nx_full_graphs.NXFullGraph.add_node","text":"Adds one or multiple Node objects to the graph. Since this is a Full Graph, any category of node is allowed No duplicates are allowed, but different category nodes with same id are (e.g. ItemNode('1') and UserNode('1') ) PARAMETER DESCRIPTION node Node(s) object(s) that needs to be added to the graph TYPE: Union [ Node , List [ Node ]] Source code in clayrs/recsys/graphs/nx_implementation/nx_full_graphs.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def add_node ( self , node : Union [ Node , List [ Node ]]): \"\"\" Adds one or multiple Node objects to the graph. Since this is a Full Graph, any category of node is allowed No duplicates are allowed, but different category nodes with same id are (e.g. `ItemNode('1')` and `UserNode('1')`) Args: node: Node(s) object(s) that needs to be added to the graph \"\"\" if not isinstance ( node , list ): node = [ node ] self . _graph . add_nodes_from ( node )","title":"add_node()"},{"location":"recsys/graph_based/graphs/nx_full/#clayrs.recsys.graphs.nx_implementation.nx_full_graphs.NXFullGraph.add_node_with_prop","text":"Adds one or multiple Node objects and its/their properties to the graph Since this is a Full Graph, no restriction are imposed and you can add any category of node together with its properties. In order to load properties in the graph, we must specify where contents are serialized and which properties to add (the following is the same for item_exo_properties ): If exo_properties is specified as a set , then the graph will try to load all properties from said exogenous representation { 'my_exo_id' } If exo_properties is specified as a dict , then the graph will try to load said properties from said exogenous representation { 'my_exo_id' : [ 'my_prop1' , 'my_prop2' ]]} In case you want your node to have a different id from serialized contents, via the content_filename parameter you can specify what is the filename of the node that you are adding, e.g. item_to_add = ItemNode('different_id') # content_filename is 'item_serialized_1.xz' graph.add_node_with_prop(item_to_add, ..., content_filename='item_serialized_1') In case you are adding a list of nodes, you can specify the filename for each node in the list. PARAMETER DESCRIPTION node Node(s) object(s) that needs to be added to the graph along with their properties TYPE: Union [ Node , List [ Node ]] exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] contents_dir The path containing items serialized with the Content Analyzer TYPE: str content_filename Filename(s) of the node(s) to add TYPE: Union [ str , List [ str ]] DEFAULT: None RAISES DESCRIPTION ValueError Exception raised when one of the node to add to the graph with their properties is not an ItemNode Source code in clayrs/recsys/graphs/nx_implementation/nx_full_graphs.py 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 def add_node_with_prop ( self , node : Union [ Node , List [ Node ]], exo_properties : Union [ Dict , set ], contents_dir : str , content_filename : Union [ str , List [ str ]] = None ): \"\"\" Adds one or multiple Node objects and its/their properties to the graph Since this is a Full Graph, no restriction are imposed and you can add any category of node together with its properties. In order to load properties in the graph, we must specify where contents are serialized and ***which properties to add*** (the following is the same for *item_exo_properties*): * If *exo_properties* is specified as a **set**, then the graph will try to load **all properties** from **said exogenous representation** ```python {'my_exo_id'} ``` * If *exo_properties* is specified as a **dict**, then the graph will try to load **said properties** from **said exogenous representation** ```python {'my_exo_id': ['my_prop1', 'my_prop2']]} ``` In case you want your node to have a different id from serialized contents, via the `content_filename` parameter you can specify what is the filename of the node that you are adding, e.g. ``` item_to_add = ItemNode('different_id') # content_filename is 'item_serialized_1.xz' graph.add_node_with_prop(item_to_add, ..., content_filename='item_serialized_1') ``` In case you are adding a list of nodes, you can specify the filename for each node in the list. Args: node: Node(s) object(s) that needs to be added to the graph along with their properties exo_properties: Set or Dict which contains representations to load from items. Use a `Set` if you want to load all properties from specific representations, or use a `Dict` if you want to choose which properties to load from specific representations contents_dir: The path containing items serialized with the Content Analyzer content_filename: Filename(s) of the node(s) to add Raises: ValueError: Exception raised when one of the node to add to the graph with their properties is not an ItemNode \"\"\" def node_prop_link_generator (): for n , id in zip ( progbar , content_filename ): item : Content = loaded_items . get ( id ) if item is not None : exo_props = self . _get_exo_props ( exo_properties , item ) single_item_prop_edges = [( n , PropertyNode ( prop_dict [ prop ]), { 'label' : prop }) for prop_dict in exo_props for prop in prop_dict ] else : single_item_prop_edges = [] yield from single_item_prop_edges if not isinstance ( node , list ): node = [ node ] if isinstance ( exo_properties , set ): exo_properties = dict . fromkeys ( exo_properties , None ) if content_filename is None : content_filename = [ n . value for n in node ] if not isinstance ( content_filename , list ): content_filename = [ content_filename ] loaded_items = LoadedContentsDict ( contents_dir , contents_to_load = set ( content_filename )) with get_progbar ( node ) as progbar : progbar . set_description ( \"Creating Node->Properties links\" ) self . _graph . add_edges_from (( tuple_to_add for tuple_to_add in node_prop_link_generator ()))","title":"add_node_with_prop()"},{"location":"recsys/graph_based/graphs/nx_tripartite/","text":"Tripartite Graph Please remember that this class is a subclass of NXBipartiteGraph , so it inherits all its methods. You can check their documentation as well! NXTripartiteGraph ( source_frame = None , item_exo_properties = None , item_contents_dir = None , link_label = None ) Bases: NXBipartiteGraph , TripartiteDiGraph Class that implements a Tripartite graph through networkx library. Info A Tripartite Graph is a graph which supports User nodes, Item nodes and Property nodes, but the latter can only be linked to Item nodes. If you need maximum flexibility, consider using a Full Graph It creates a graph from an initial Rating object. Consider the following matrix representation of the Rating object +------+-----------+-------+ | User | Item | Score | +------+-----------+-------+ | u1 | Tenet | 4 | | u2 | Inception | 5 | | ... | ... | ... | +------+-----------+-------+ The graph will be created with the following interactions: 4 u1 -----> Tenet 5 u2 -----> Inception where u1 and u2 become User nodes and Tenet and Inception become Item nodes , with the edge weighted depending on the score given If the link_label parameter is specified, then each link between users and items will be labeled with the label specified (e.g. link_label='score' ): (4, 'score') u1 -------------> Tenet (5, 'score') u2 -------------> Inception Then the framework tries to load 'Tenet' and 'Inception' from the item_contents_dir if it is specified and if succeeds, adds in the graph their loaded properties as specified in the item_exo_properties parameter. Load exogenous properties In order to load properties in the graph, we must specify where items are serialized and which properties to add : If item_exo_properties is specified as a set , then the graph will try to load all properties from said exogenous representation { 'my_exo_id' } If item_exo_properties is specified as a dict , then the graph will try to load said properties from said exogenous representation { 'my_exo_id' : [ 'my_prop1' , 'my_prop2' ]]} PARAMETER DESCRIPTION source_frame The initial Ratings object needed to create the graph TYPE: Ratings DEFAULT: None item_exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] DEFAULT: None item_contents_dir The path containing items serialized with the Content Analyzer TYPE: str DEFAULT: None link_label If specified, each link will be labeled with the given label. Default is None TYPE: str DEFAULT: None Source code in clayrs/recsys/graphs/nx_implementation/nx_tripartite_graphs.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def __init__ ( self , source_frame : Ratings = None , item_exo_properties : Union [ Dict , set ] = None , item_contents_dir : str = None , link_label : str = None ): NXBipartiteGraph . __init__ ( self , source_frame , link_label ) if item_exo_properties and not item_contents_dir : logger . warning ( \"`item_exo_properties` parameter set but `item_contents_dir` is None! \" \"No property will be loaded\" ) elif not item_exo_properties and item_contents_dir : logger . warning ( \"`item_contents_dir` parameter set but `item_exo_properties` is None! \" \"No property will be loaded\" ) if source_frame is not None and item_contents_dir is not None and item_exo_properties is not None : self . add_node_with_prop ([ ItemNode ( item_id ) for item_id in set ( source_frame . item_id_column )], item_exo_properties , item_contents_dir ) add_link ( start_node , final_node , weight = None , label = None , timestamp = None ) Creates a link connecting the start_node to the final_node . If two lists are passed, then the node in position \\(i\\) in the start_node list will be linked to the node in position \\(i\\) in the final_node list. If nodes to link do not exist, they will be added automatically to the graph. Please remember that since this is a Tripartite Graph, only User nodes , Item nodes and Property nodes can be added! And Property nodes can only be linked to Item nodes ! A link can be weighted with the weight parameter and labeled with the label parameter. A timestamp can also be specified via timestamp parameter. All three are optional parameters, so they are not required PARAMETER DESCRIPTION start_node Single Node object or a list of Node objects. They will be the 'head' of the link, since it's a directed graph TYPE: Union [ Node , List [ Node ]] final_node Single Node object or a list Node objects. They will be the 'tail' of the link, since it's a directed graph TYPE: object weight weight of the link, default is None (no weight) TYPE: float DEFAULT: None label label of the link, default is None (no label) TYPE: str DEFAULT: None timestamp timestamp of the link, default is None (no timestamp) TYPE: str DEFAULT: None RAISES DESCRIPTION ValueError Exception raised when Property nodes are tried to be linked with non-Item nodes Source code in clayrs/recsys/graphs/nx_implementation/nx_tripartite_graphs.py 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 def add_link ( self , start_node : Union [ Node , List [ Node ]], final_node : Union [ Node , List [ Node ]], weight : float = None , label : str = None , timestamp : str = None ): \"\"\" Creates a link connecting the `start_node` to the `final_node`. If two lists are passed, then the node in position $i$ in the `start_node` list will be linked to the node in position $i$ in the `final_node` list. If nodes to link do not exist, they will be added automatically to the graph. Please remember that since this is a Tripartite Graph, only *User nodes*, *Item nodes* and *Property nodes* can be added! And *Property nodes* can only be linked to *Item nodes*! A link can be weighted with the `weight` parameter and labeled with the `label` parameter. A timestamp can also be specified via `timestamp` parameter. All three are optional parameters, so they are not required Args: start_node: Single Node object or a list of Node objects. They will be the 'head' of the link, since it's a directed graph final_node (object): Single Node object or a list Node objects. They will be the 'tail' of the link, since it's a directed graph weight: weight of the link, default is None (no weight) label: label of the link, default is None (no label) timestamp: timestamp of the link, default is None (no timestamp) Raises: ValueError: Exception raised when Property nodes are tried to be linked with non-Item nodes \"\"\" def is_not_valid_link ( start_n : Node , final_n : Node ): return ( isinstance ( final_n , PropertyNode ) and not isinstance ( start_n , ItemNode )) or \\ ( isinstance ( start_n , PropertyNode ) and not isinstance ( final_n , ItemNode )) if not isinstance ( start_node , list ): start_node = [ start_node ] if not isinstance ( final_node , list ): final_node = [ final_node ] if any ( is_not_valid_link ( start_n , final_n ) for start_n , final_n in zip ( start_node , final_node )): raise ValueError ( \"Only item nodes can be linked to property nodes in a Tripartite Graph!\" ) self . add_node ( start_node ) self . add_node ( final_node ) not_none_dict = {} if label is not None : not_none_dict [ 'label' ] = label if weight is not None : not_none_dict [ 'weight' ] = weight if timestamp is not None : not_none_dict [ 'timestamp' ] = timestamp self . _graph . add_edges_from ( zip ( start_node , final_node ), ** not_none_dict ) add_node ( node ) Adds one or multiple Node objects to the graph. Since this is a Tripartite Graph, only User Node , Item Node and Property Node can be added! No duplicates are allowed, but different category nodes with same id are (e.g. ItemNode('1') and UserNode('1') ) PARAMETER DESCRIPTION node Node(s) object(s) that needs to be added to the graph TYPE: Union [ Node , List [ Node ]] RAISES DESCRIPTION ValueError Exception raised when one of the node to add to the graph is not a User, Item or Property node Source code in clayrs/recsys/graphs/nx_implementation/nx_tripartite_graphs.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def add_node ( self , node : Union [ Node , List [ Node ]]): \"\"\" Adds one or multiple Node objects to the graph. Since this is a Tripartite Graph, only `User Node`, `Item Node` and `Property Node` can be added! No duplicates are allowed, but different category nodes with same id are (e.g. `ItemNode('1')` and `UserNode('1')`) Args: node: Node(s) object(s) that needs to be added to the graph Raises: ValueError: Exception raised when one of the node to add to the graph is not a User, Item or Property node \"\"\" if not isinstance ( node , list ): node = [ node ] if any ( not isinstance ( n , ( UserNode , ItemNode , PropertyNode )) for n in node ): raise ValueError ( \"You can only add UserNodes or ItemNodes to a bipartite graph!\" ) self . _graph . add_nodes_from ( node ) add_node_with_prop ( node , item_exo_properties , item_contents_dir , item_filename = None ) Adds one or multiple Node objects and its/their properties to the graph. Since this is a Tripartite Graph, only Item Node are allowed to have properties! In order to load properties in the graph, we must specify where items are serialized and which properties to add : If item_exo_properties is specified as a set , then the graph will try to load all properties from said exogenous representation { 'my_exo_id' } If item_exo_properties is specified as a dict , then the graph will try to load said properties from said exogenous representation { 'my_exo_id' : [ 'my_prop1' , 'my_prop2' ]]} In case you want your node to have a different id from serialized contents, via the item_filename parameter you can specify what is the filename of the node that you are adding, e.g. item_to_add = ItemNode('different_id') # item_filename is 'item_serialized_1.xz' graph.add_node_with_prop(item_to_add, ..., item_filename='item_serialized_1') In case you are adding a list of nodes, you can specify the filename for each node in the list. PARAMETER DESCRIPTION node Node(s) object(s) that needs to be added to the graph along with their properties TYPE: Union [ ItemNode , List [ ItemNode ]] item_exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] item_contents_dir The path containing items serialized with the Content Analyzer TYPE: str item_filename Filename(s) of the node(s) to add TYPE: Union [ str , List [ str ]] DEFAULT: None RAISES DESCRIPTION ValueError Exception raised when one of the node to add to the graph with their properties is not an ItemNode Source code in clayrs/recsys/graphs/nx_implementation/nx_tripartite_graphs.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 def add_node_with_prop ( self , node : Union [ ItemNode , List [ ItemNode ]], item_exo_properties : Union [ Dict , set ], item_contents_dir : str , item_filename : Union [ str , List [ str ]] = None ): \"\"\" Adds one or multiple Node objects and its/their properties to the graph. Since this is a Tripartite Graph, only `Item Node` are allowed to have properties! In order to load properties in the graph, we must specify where items are serialized and ***which properties to add***: * If *item_exo_properties* is specified as a **set**, then the graph will try to load **all properties** from **said exogenous representation** ```python {'my_exo_id'} ``` * If *item_exo_properties* is specified as a **dict**, then the graph will try to load **said properties** from **said exogenous representation** ```python {'my_exo_id': ['my_prop1', 'my_prop2']]} ``` In case you want your node to have a different id from serialized contents, via the `item_filename` parameter you can specify what is the filename of the node that you are adding, e.g. ``` item_to_add = ItemNode('different_id') # item_filename is 'item_serialized_1.xz' graph.add_node_with_prop(item_to_add, ..., item_filename='item_serialized_1') ``` In case you are adding a list of nodes, you can specify the filename for each node in the list. Args: node: Node(s) object(s) that needs to be added to the graph along with their properties item_exo_properties: Set or Dict which contains representations to load from items. Use a `Set` if you want to load all properties from specific representations, or use a `Dict` if you want to choose which properties to load from specific representations item_contents_dir: The path containing items serialized with the Content Analyzer item_filename: Filename(s) of the node(s) to add Raises: ValueError: Exception raised when one of the node to add to the graph with their properties is not an ItemNode \"\"\" def node_prop_link_generator (): for n , id in zip ( progbar , item_filename ): item : Content = loaded_items . get ( id ) if item is not None : exo_props = self . _get_exo_props ( item_exo_properties , item ) single_item_prop_edges = [( n , PropertyNode ( prop_dict [ prop ]), { 'label' : prop }) for prop_dict in exo_props for prop in prop_dict ] else : single_item_prop_edges = [] yield from single_item_prop_edges if not isinstance ( node , list ): node = [ node ] if any ( not isinstance ( n , ItemNode ) for n in node ): raise ValueError ( \"Only item nodes can be linked to property nodes in a Tripartite Graph!\" ) if isinstance ( item_exo_properties , set ): item_exo_properties = dict . fromkeys ( item_exo_properties , None ) if item_filename is None : item_filename = [ n . value for n in node ] if not isinstance ( item_filename , list ): item_filename = [ item_filename ] loaded_items = LoadedContentsDict ( item_contents_dir , contents_to_load = set ( item_filename )) with get_progbar ( node ) as progbar : progbar . set_description ( \"Creating Item->Properties links\" ) self . _graph . add_edges_from (( tuple_to_add for tuple_to_add in node_prop_link_generator ())) property_nodes () property Returns a set of all Property nodes in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_tripartite_graphs.py 116 117 118 119 120 121 @property def property_nodes ( self ) -> Set [ PropertyNode ]: \"\"\" Returns a set of all *Property nodes* in the graph \"\"\" return set ( node for node in self . _graph . nodes if isinstance ( node , PropertyNode ))","title":"Tripartite Graph"},{"location":"recsys/graph_based/graphs/nx_tripartite/#tripartite-graph","text":"Please remember that this class is a subclass of NXBipartiteGraph , so it inherits all its methods. You can check their documentation as well!","title":"Tripartite Graph"},{"location":"recsys/graph_based/graphs/nx_tripartite/#clayrs.recsys.graphs.nx_implementation.nx_tripartite_graphs.NXTripartiteGraph","text":"Bases: NXBipartiteGraph , TripartiteDiGraph Class that implements a Tripartite graph through networkx library. Info A Tripartite Graph is a graph which supports User nodes, Item nodes and Property nodes, but the latter can only be linked to Item nodes. If you need maximum flexibility, consider using a Full Graph It creates a graph from an initial Rating object. Consider the following matrix representation of the Rating object +------+-----------+-------+ | User | Item | Score | +------+-----------+-------+ | u1 | Tenet | 4 | | u2 | Inception | 5 | | ... | ... | ... | +------+-----------+-------+ The graph will be created with the following interactions: 4 u1 -----> Tenet 5 u2 -----> Inception where u1 and u2 become User nodes and Tenet and Inception become Item nodes , with the edge weighted depending on the score given If the link_label parameter is specified, then each link between users and items will be labeled with the label specified (e.g. link_label='score' ): (4, 'score') u1 -------------> Tenet (5, 'score') u2 -------------> Inception Then the framework tries to load 'Tenet' and 'Inception' from the item_contents_dir if it is specified and if succeeds, adds in the graph their loaded properties as specified in the item_exo_properties parameter. Load exogenous properties In order to load properties in the graph, we must specify where items are serialized and which properties to add : If item_exo_properties is specified as a set , then the graph will try to load all properties from said exogenous representation { 'my_exo_id' } If item_exo_properties is specified as a dict , then the graph will try to load said properties from said exogenous representation { 'my_exo_id' : [ 'my_prop1' , 'my_prop2' ]]} PARAMETER DESCRIPTION source_frame The initial Ratings object needed to create the graph TYPE: Ratings DEFAULT: None item_exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] DEFAULT: None item_contents_dir The path containing items serialized with the Content Analyzer TYPE: str DEFAULT: None link_label If specified, each link will be labeled with the given label. Default is None TYPE: str DEFAULT: None Source code in clayrs/recsys/graphs/nx_implementation/nx_tripartite_graphs.py 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def __init__ ( self , source_frame : Ratings = None , item_exo_properties : Union [ Dict , set ] = None , item_contents_dir : str = None , link_label : str = None ): NXBipartiteGraph . __init__ ( self , source_frame , link_label ) if item_exo_properties and not item_contents_dir : logger . warning ( \"`item_exo_properties` parameter set but `item_contents_dir` is None! \" \"No property will be loaded\" ) elif not item_exo_properties and item_contents_dir : logger . warning ( \"`item_contents_dir` parameter set but `item_exo_properties` is None! \" \"No property will be loaded\" ) if source_frame is not None and item_contents_dir is not None and item_exo_properties is not None : self . add_node_with_prop ([ ItemNode ( item_id ) for item_id in set ( source_frame . item_id_column )], item_exo_properties , item_contents_dir )","title":"NXTripartiteGraph"},{"location":"recsys/graph_based/graphs/nx_tripartite/#clayrs.recsys.graphs.nx_implementation.nx_tripartite_graphs.NXTripartiteGraph.add_link","text":"Creates a link connecting the start_node to the final_node . If two lists are passed, then the node in position \\(i\\) in the start_node list will be linked to the node in position \\(i\\) in the final_node list. If nodes to link do not exist, they will be added automatically to the graph. Please remember that since this is a Tripartite Graph, only User nodes , Item nodes and Property nodes can be added! And Property nodes can only be linked to Item nodes ! A link can be weighted with the weight parameter and labeled with the label parameter. A timestamp can also be specified via timestamp parameter. All three are optional parameters, so they are not required PARAMETER DESCRIPTION start_node Single Node object or a list of Node objects. They will be the 'head' of the link, since it's a directed graph TYPE: Union [ Node , List [ Node ]] final_node Single Node object or a list Node objects. They will be the 'tail' of the link, since it's a directed graph TYPE: object weight weight of the link, default is None (no weight) TYPE: float DEFAULT: None label label of the link, default is None (no label) TYPE: str DEFAULT: None timestamp timestamp of the link, default is None (no timestamp) TYPE: str DEFAULT: None RAISES DESCRIPTION ValueError Exception raised when Property nodes are tried to be linked with non-Item nodes Source code in clayrs/recsys/graphs/nx_implementation/nx_tripartite_graphs.py 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 def add_link ( self , start_node : Union [ Node , List [ Node ]], final_node : Union [ Node , List [ Node ]], weight : float = None , label : str = None , timestamp : str = None ): \"\"\" Creates a link connecting the `start_node` to the `final_node`. If two lists are passed, then the node in position $i$ in the `start_node` list will be linked to the node in position $i$ in the `final_node` list. If nodes to link do not exist, they will be added automatically to the graph. Please remember that since this is a Tripartite Graph, only *User nodes*, *Item nodes* and *Property nodes* can be added! And *Property nodes* can only be linked to *Item nodes*! A link can be weighted with the `weight` parameter and labeled with the `label` parameter. A timestamp can also be specified via `timestamp` parameter. All three are optional parameters, so they are not required Args: start_node: Single Node object or a list of Node objects. They will be the 'head' of the link, since it's a directed graph final_node (object): Single Node object or a list Node objects. They will be the 'tail' of the link, since it's a directed graph weight: weight of the link, default is None (no weight) label: label of the link, default is None (no label) timestamp: timestamp of the link, default is None (no timestamp) Raises: ValueError: Exception raised when Property nodes are tried to be linked with non-Item nodes \"\"\" def is_not_valid_link ( start_n : Node , final_n : Node ): return ( isinstance ( final_n , PropertyNode ) and not isinstance ( start_n , ItemNode )) or \\ ( isinstance ( start_n , PropertyNode ) and not isinstance ( final_n , ItemNode )) if not isinstance ( start_node , list ): start_node = [ start_node ] if not isinstance ( final_node , list ): final_node = [ final_node ] if any ( is_not_valid_link ( start_n , final_n ) for start_n , final_n in zip ( start_node , final_node )): raise ValueError ( \"Only item nodes can be linked to property nodes in a Tripartite Graph!\" ) self . add_node ( start_node ) self . add_node ( final_node ) not_none_dict = {} if label is not None : not_none_dict [ 'label' ] = label if weight is not None : not_none_dict [ 'weight' ] = weight if timestamp is not None : not_none_dict [ 'timestamp' ] = timestamp self . _graph . add_edges_from ( zip ( start_node , final_node ), ** not_none_dict )","title":"add_link()"},{"location":"recsys/graph_based/graphs/nx_tripartite/#clayrs.recsys.graphs.nx_implementation.nx_tripartite_graphs.NXTripartiteGraph.add_node","text":"Adds one or multiple Node objects to the graph. Since this is a Tripartite Graph, only User Node , Item Node and Property Node can be added! No duplicates are allowed, but different category nodes with same id are (e.g. ItemNode('1') and UserNode('1') ) PARAMETER DESCRIPTION node Node(s) object(s) that needs to be added to the graph TYPE: Union [ Node , List [ Node ]] RAISES DESCRIPTION ValueError Exception raised when one of the node to add to the graph is not a User, Item or Property node Source code in clayrs/recsys/graphs/nx_implementation/nx_tripartite_graphs.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def add_node ( self , node : Union [ Node , List [ Node ]]): \"\"\" Adds one or multiple Node objects to the graph. Since this is a Tripartite Graph, only `User Node`, `Item Node` and `Property Node` can be added! No duplicates are allowed, but different category nodes with same id are (e.g. `ItemNode('1')` and `UserNode('1')`) Args: node: Node(s) object(s) that needs to be added to the graph Raises: ValueError: Exception raised when one of the node to add to the graph is not a User, Item or Property node \"\"\" if not isinstance ( node , list ): node = [ node ] if any ( not isinstance ( n , ( UserNode , ItemNode , PropertyNode )) for n in node ): raise ValueError ( \"You can only add UserNodes or ItemNodes to a bipartite graph!\" ) self . _graph . add_nodes_from ( node )","title":"add_node()"},{"location":"recsys/graph_based/graphs/nx_tripartite/#clayrs.recsys.graphs.nx_implementation.nx_tripartite_graphs.NXTripartiteGraph.add_node_with_prop","text":"Adds one or multiple Node objects and its/their properties to the graph. Since this is a Tripartite Graph, only Item Node are allowed to have properties! In order to load properties in the graph, we must specify where items are serialized and which properties to add : If item_exo_properties is specified as a set , then the graph will try to load all properties from said exogenous representation { 'my_exo_id' } If item_exo_properties is specified as a dict , then the graph will try to load said properties from said exogenous representation { 'my_exo_id' : [ 'my_prop1' , 'my_prop2' ]]} In case you want your node to have a different id from serialized contents, via the item_filename parameter you can specify what is the filename of the node that you are adding, e.g. item_to_add = ItemNode('different_id') # item_filename is 'item_serialized_1.xz' graph.add_node_with_prop(item_to_add, ..., item_filename='item_serialized_1') In case you are adding a list of nodes, you can specify the filename for each node in the list. PARAMETER DESCRIPTION node Node(s) object(s) that needs to be added to the graph along with their properties TYPE: Union [ ItemNode , List [ ItemNode ]] item_exo_properties Set or Dict which contains representations to load from items. Use a Set if you want to load all properties from specific representations, or use a Dict if you want to choose which properties to load from specific representations TYPE: Union [ Dict , set ] item_contents_dir The path containing items serialized with the Content Analyzer TYPE: str item_filename Filename(s) of the node(s) to add TYPE: Union [ str , List [ str ]] DEFAULT: None RAISES DESCRIPTION ValueError Exception raised when one of the node to add to the graph with their properties is not an ItemNode Source code in clayrs/recsys/graphs/nx_implementation/nx_tripartite_graphs.py 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 def add_node_with_prop ( self , node : Union [ ItemNode , List [ ItemNode ]], item_exo_properties : Union [ Dict , set ], item_contents_dir : str , item_filename : Union [ str , List [ str ]] = None ): \"\"\" Adds one or multiple Node objects and its/their properties to the graph. Since this is a Tripartite Graph, only `Item Node` are allowed to have properties! In order to load properties in the graph, we must specify where items are serialized and ***which properties to add***: * If *item_exo_properties* is specified as a **set**, then the graph will try to load **all properties** from **said exogenous representation** ```python {'my_exo_id'} ``` * If *item_exo_properties* is specified as a **dict**, then the graph will try to load **said properties** from **said exogenous representation** ```python {'my_exo_id': ['my_prop1', 'my_prop2']]} ``` In case you want your node to have a different id from serialized contents, via the `item_filename` parameter you can specify what is the filename of the node that you are adding, e.g. ``` item_to_add = ItemNode('different_id') # item_filename is 'item_serialized_1.xz' graph.add_node_with_prop(item_to_add, ..., item_filename='item_serialized_1') ``` In case you are adding a list of nodes, you can specify the filename for each node in the list. Args: node: Node(s) object(s) that needs to be added to the graph along with their properties item_exo_properties: Set or Dict which contains representations to load from items. Use a `Set` if you want to load all properties from specific representations, or use a `Dict` if you want to choose which properties to load from specific representations item_contents_dir: The path containing items serialized with the Content Analyzer item_filename: Filename(s) of the node(s) to add Raises: ValueError: Exception raised when one of the node to add to the graph with their properties is not an ItemNode \"\"\" def node_prop_link_generator (): for n , id in zip ( progbar , item_filename ): item : Content = loaded_items . get ( id ) if item is not None : exo_props = self . _get_exo_props ( item_exo_properties , item ) single_item_prop_edges = [( n , PropertyNode ( prop_dict [ prop ]), { 'label' : prop }) for prop_dict in exo_props for prop in prop_dict ] else : single_item_prop_edges = [] yield from single_item_prop_edges if not isinstance ( node , list ): node = [ node ] if any ( not isinstance ( n , ItemNode ) for n in node ): raise ValueError ( \"Only item nodes can be linked to property nodes in a Tripartite Graph!\" ) if isinstance ( item_exo_properties , set ): item_exo_properties = dict . fromkeys ( item_exo_properties , None ) if item_filename is None : item_filename = [ n . value for n in node ] if not isinstance ( item_filename , list ): item_filename = [ item_filename ] loaded_items = LoadedContentsDict ( item_contents_dir , contents_to_load = set ( item_filename )) with get_progbar ( node ) as progbar : progbar . set_description ( \"Creating Item->Properties links\" ) self . _graph . add_edges_from (( tuple_to_add for tuple_to_add in node_prop_link_generator ()))","title":"add_node_with_prop()"},{"location":"recsys/graph_based/graphs/nx_tripartite/#clayrs.recsys.graphs.nx_implementation.nx_tripartite_graphs.NXTripartiteGraph.property_nodes","text":"Returns a set of all Property nodes in the graph Source code in clayrs/recsys/graphs/nx_implementation/nx_tripartite_graphs.py 116 117 118 119 120 121 @property def property_nodes ( self ) -> Set [ PropertyNode ]: \"\"\" Returns a set of all *Property nodes* in the graph \"\"\" return set ( node for node in self . _graph . nodes if isinstance ( node , PropertyNode ))","title":"property_nodes()"},{"location":"recsys/methodology/abstract_methodology/","text":"Abstract methodology class Methodology ( only_greater_eq = None ) Bases: ABC Class which, given a train set and a test set , has the task to calculate which items must be used in order to generate a recommendation list The methodologies here implemented follow the 'Precision-Oriented Evaluation of Recommender Systems: An Algorithmic Comparison' paper Source code in clayrs/recsys/methodology.py 22 23 def __init__ ( self , only_greater_eq : float = None ): self . _threshold = only_greater_eq filter_all ( train_set , test_set , result_as_iter_dict = False ) Concrete method which calculates for all users of the test set which items must be used in order to generate a recommendation list It takes in input a train set and a test set and returns a single DataFrame or a generator of a python dictionary containing, for every user, all items which must be recommended based on the methodology chosen. PARAMETER DESCRIPTION train_set Ratings object which contains the train set of every user TYPE: Ratings test_set Ratings object which contains the test set of every user TYPE: Ratings result_as_iter_dict If True the output of the method will be a generator of a dictionary that, once evaluated, will contains users as a key and list of item that must be predicted as a value. EXAMPLE: `{'u1': ['i1', 'i2', 'i3'], 'u2': ['i1', 'i4'], ...}` TYPE: bool DEFAULT: False RETURNS DESCRIPTION Union [ pd . DataFrame , Dict [ str , Generator ]] A DataFrame or a generator of a python dictionary which contains all items which must be recommended to Union [ pd . DataFrame , Dict [ str , Generator ]] every user based on the methodology chosen. Source code in clayrs/recsys/methodology.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def filter_all ( self , train_set : Ratings , test_set : Ratings , result_as_iter_dict : bool = False ) -> Union [ pd . DataFrame , Dict [ str , Generator ]]: \"\"\" Concrete method which calculates for all users of the *test set* which items must be used in order to generate a recommendation list It takes in input a *train set* and a *test set* and returns a single DataFrame or a generator of a python dictionary containing, for every user, all items which must be recommended based on the methodology chosen. Args: train_set: `Ratings` object which contains the train set of every user test_set: `Ratings` object which contains the test set of every user result_as_iter_dict (bool): If True the output of the method will be a generator of a dictionary that, once evaluated, will contains users as a key and list of item that must be predicted as a value. EXAMPLE: `{'u1': ['i1', 'i2', 'i3'], 'u2': ['i1', 'i4'], ...}` Returns: A DataFrame or a generator of a python dictionary which contains all items which must be recommended to every user based on the methodology chosen. \"\"\" user_list = set ( test_set . user_id_column ) with get_progbar ( user_list ) as pbar : pbar . set_description ( f \"Filtering items based on { str ( self ) } \" ) filtered = { user_id : self . filter_single ( user_id , train_set , test_set ) for user_id in pbar } if not result_as_iter_dict : generator_expression = (( user_id , item_to_predict ) for user_id , all_items_to_pred in zip ( filtered . keys (), filtered . values ()) for item_to_predict in set ( all_items_to_pred )) filtered = pd . DataFrame ( generator_expression , columns = [ 'user_id' , 'item_id' ]) return filtered filter_single ( user_id , train_set , test_set ) abstractmethod Abstract method in which must be specified how to calculate which items must be part of the recommendation list of a single user Source code in clayrs/recsys/methodology.py 70 71 72 73 74 75 76 @abc . abstractmethod def filter_single ( self , user_id : str , train_set : Ratings , test_set : Ratings ) -> Generator : \"\"\" Abstract method in which must be specified how to calculate which items must be part of the recommendation list of a single user \"\"\" raise NotImplementedError","title":"Abstract Methodology class"},{"location":"recsys/methodology/abstract_methodology/#abstract-methodology-class","text":"","title":"Abstract methodology class"},{"location":"recsys/methodology/abstract_methodology/#clayrs.recsys.methodology.Methodology","text":"Bases: ABC Class which, given a train set and a test set , has the task to calculate which items must be used in order to generate a recommendation list The methodologies here implemented follow the 'Precision-Oriented Evaluation of Recommender Systems: An Algorithmic Comparison' paper Source code in clayrs/recsys/methodology.py 22 23 def __init__ ( self , only_greater_eq : float = None ): self . _threshold = only_greater_eq","title":"Methodology"},{"location":"recsys/methodology/abstract_methodology/#clayrs.recsys.methodology.Methodology.filter_all","text":"Concrete method which calculates for all users of the test set which items must be used in order to generate a recommendation list It takes in input a train set and a test set and returns a single DataFrame or a generator of a python dictionary containing, for every user, all items which must be recommended based on the methodology chosen. PARAMETER DESCRIPTION train_set Ratings object which contains the train set of every user TYPE: Ratings test_set Ratings object which contains the test set of every user TYPE: Ratings result_as_iter_dict If True the output of the method will be a generator of a dictionary that, once evaluated, will contains users as a key and list of item that must be predicted as a value. EXAMPLE: `{'u1': ['i1', 'i2', 'i3'], 'u2': ['i1', 'i4'], ...}` TYPE: bool DEFAULT: False RETURNS DESCRIPTION Union [ pd . DataFrame , Dict [ str , Generator ]] A DataFrame or a generator of a python dictionary which contains all items which must be recommended to Union [ pd . DataFrame , Dict [ str , Generator ]] every user based on the methodology chosen. Source code in clayrs/recsys/methodology.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 def filter_all ( self , train_set : Ratings , test_set : Ratings , result_as_iter_dict : bool = False ) -> Union [ pd . DataFrame , Dict [ str , Generator ]]: \"\"\" Concrete method which calculates for all users of the *test set* which items must be used in order to generate a recommendation list It takes in input a *train set* and a *test set* and returns a single DataFrame or a generator of a python dictionary containing, for every user, all items which must be recommended based on the methodology chosen. Args: train_set: `Ratings` object which contains the train set of every user test_set: `Ratings` object which contains the test set of every user result_as_iter_dict (bool): If True the output of the method will be a generator of a dictionary that, once evaluated, will contains users as a key and list of item that must be predicted as a value. EXAMPLE: `{'u1': ['i1', 'i2', 'i3'], 'u2': ['i1', 'i4'], ...}` Returns: A DataFrame or a generator of a python dictionary which contains all items which must be recommended to every user based on the methodology chosen. \"\"\" user_list = set ( test_set . user_id_column ) with get_progbar ( user_list ) as pbar : pbar . set_description ( f \"Filtering items based on { str ( self ) } \" ) filtered = { user_id : self . filter_single ( user_id , train_set , test_set ) for user_id in pbar } if not result_as_iter_dict : generator_expression = (( user_id , item_to_predict ) for user_id , all_items_to_pred in zip ( filtered . keys (), filtered . values ()) for item_to_predict in set ( all_items_to_pred )) filtered = pd . DataFrame ( generator_expression , columns = [ 'user_id' , 'item_id' ]) return filtered","title":"filter_all()"},{"location":"recsys/methodology/abstract_methodology/#clayrs.recsys.methodology.Methodology.filter_single","text":"Abstract method in which must be specified how to calculate which items must be part of the recommendation list of a single user Source code in clayrs/recsys/methodology.py 70 71 72 73 74 75 76 @abc . abstractmethod def filter_single ( self , user_id : str , train_set : Ratings , test_set : Ratings ) -> Generator : \"\"\" Abstract method in which must be specified how to calculate which items must be part of the recommendation list of a single user \"\"\" raise NotImplementedError","title":"filter_single()"},{"location":"recsys/methodology/all_items/","text":"All Items methodology AllItemsMethodology ( items_list ) Bases: Methodology Class which, given a train set and a test set , has the task to calculate which items must be used in order to generate a recommendation list With AllItemsMethodology, given a user \\(u\\) , items to recommend for \\(u\\) are all items that appear in 'items_list' parameter excluding those items that appear in the train set of \\(u\\) PARAMETER DESCRIPTION items_list Items set that must appear in the recommendation list of every user TYPE: Set [ str ] Source code in clayrs/recsys/methodology.py 246 247 248 def __init__ ( self , items_list : Set [ str ]): self . _items_list = items_list super ( AllItemsMethodology , self ) . __init__ ( None ) filter_single ( user_id , train_set , test_set ) Method that returns items that needs to be part of the recommendation list of a single user. Since it's the AllItems Methodology, all items that appear in the items_list parameter of the constructor will be returned, except for those that appear in the train set of the user passed as parameter PARAMETER DESCRIPTION user_id User of which we want to calculate items that must appear in its recommendation list TYPE: str train_set Ratings object which contains the train set of every user TYPE: Ratings test_set Ratings object which contains the test set of every user TYPE: Ratings Source code in clayrs/recsys/methodology.py 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 def filter_single ( self , user_id : str , train_set : Ratings , test_set : Ratings ) -> Generator : \"\"\" Method that returns items that needs to be part of the recommendation list of a single user. Since it's the AllItems Methodology, all items that appear in the `items_list` parameter of the constructor will be returned, except for those that appear in the *train set* of the user passed as parameter Args: user_id: User of which we want to calculate items that must appear in its recommendation list train_set: `Ratings` object which contains the train set of every user test_set: `Ratings` object which contains the test set of every user \"\"\" already_seen_items_it = ( interaction . item_id for interaction in train_set . get_user_interactions ( user_id )) filtered_items = yield from set ( self . _items_list ) - set ( already_seen_items_it ) return filtered_items","title":"AllItems"},{"location":"recsys/methodology/all_items/#all-items-methodology","text":"","title":"All Items methodology"},{"location":"recsys/methodology/all_items/#clayrs.recsys.AllItemsMethodology","text":"Bases: Methodology Class which, given a train set and a test set , has the task to calculate which items must be used in order to generate a recommendation list With AllItemsMethodology, given a user \\(u\\) , items to recommend for \\(u\\) are all items that appear in 'items_list' parameter excluding those items that appear in the train set of \\(u\\) PARAMETER DESCRIPTION items_list Items set that must appear in the recommendation list of every user TYPE: Set [ str ] Source code in clayrs/recsys/methodology.py 246 247 248 def __init__ ( self , items_list : Set [ str ]): self . _items_list = items_list super ( AllItemsMethodology , self ) . __init__ ( None )","title":"AllItemsMethodology"},{"location":"recsys/methodology/all_items/#clayrs.recsys.methodology.AllItemsMethodology.filter_single","text":"Method that returns items that needs to be part of the recommendation list of a single user. Since it's the AllItems Methodology, all items that appear in the items_list parameter of the constructor will be returned, except for those that appear in the train set of the user passed as parameter PARAMETER DESCRIPTION user_id User of which we want to calculate items that must appear in its recommendation list TYPE: str train_set Ratings object which contains the train set of every user TYPE: Ratings test_set Ratings object which contains the test set of every user TYPE: Ratings Source code in clayrs/recsys/methodology.py 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 def filter_single ( self , user_id : str , train_set : Ratings , test_set : Ratings ) -> Generator : \"\"\" Method that returns items that needs to be part of the recommendation list of a single user. Since it's the AllItems Methodology, all items that appear in the `items_list` parameter of the constructor will be returned, except for those that appear in the *train set* of the user passed as parameter Args: user_id: User of which we want to calculate items that must appear in its recommendation list train_set: `Ratings` object which contains the train set of every user test_set: `Ratings` object which contains the test set of every user \"\"\" already_seen_items_it = ( interaction . item_id for interaction in train_set . get_user_interactions ( user_id )) filtered_items = yield from set ( self . _items_list ) - set ( already_seen_items_it ) return filtered_items","title":"filter_single()"},{"location":"recsys/methodology/test_items/","text":"Test Items methodology TestItemsMethodology ( only_greater_eq = None ) Bases: Methodology Class which, given a train set and a test set , has the task to calculate which items must be used in order to generate a recommendation list With TestItemsMethodology, given a user \\(u\\) , items to recommend for \\(u\\) are all items that appear in the test set of every user excluding those items that appear in the train set of \\(u\\) If the only_greater_eq parameter is set, then only items with rating score \\(>=\\) only_greater_eq will be returned PARAMETER DESCRIPTION only_greater_eq float which acts as a filter, if specified only items with rating score \\(>=\\) only_greater_eq will be returned TYPE: float DEFAULT: None Source code in clayrs/recsys/methodology.py 146 147 148 149 def __init__ ( self , only_greater_eq : float = None ): super ( TestItemsMethodology , self ) . __init__ ( only_greater_eq ) self . _filtered_test_set_items : Optional [ Set ] = None filter_single ( user_id , train_set , test_set ) Method that returns items that need to be part of the recommendation list of a single user. Since it's the TestItems Methodology, all items that appear in the test set of every user will be returned, except for those that appear in the train set of the user passed as parameter PARAMETER DESCRIPTION user_id User of which we want to calculate items that must appear in its recommendation list TYPE: str train_set Ratings object which contains the train set of every user TYPE: Ratings test_set Ratings object which contains the test set of every user TYPE: Ratings Source code in clayrs/recsys/methodology.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def filter_single ( self , user_id : str , train_set : Ratings , test_set : Ratings ) -> Generator : \"\"\" Method that returns items that need to be part of the recommendation list of a single user. Since it's the TestItems Methodology, all items that appear in the *test set* of every user will be returned, except for those that appear in the *train set* of the user passed as parameter Args: user_id: User of which we want to calculate items that must appear in its recommendation list train_set: `Ratings` object which contains the train set of every user test_set: `Ratings` object which contains the test set of every user \"\"\" already_seen_items_it = ( interaction . item_id for interaction in train_set . get_user_interactions ( user_id )) filtered_test_set_items = test_set . item_id_column if self . _threshold is not None : if self . _filtered_test_set_items is None : self . _filtered_test_set_items = set ( self . _filter_only_greater_eq ( test_set )) filtered_test_set_items = self . _filtered_test_set_items filtered_items = yield from set ( filtered_test_set_items ) - set ( already_seen_items_it ) return filtered_items","title":"TestItems"},{"location":"recsys/methodology/test_items/#test-items-methodology","text":"","title":"Test Items methodology"},{"location":"recsys/methodology/test_items/#clayrs.recsys.TestItemsMethodology","text":"Bases: Methodology Class which, given a train set and a test set , has the task to calculate which items must be used in order to generate a recommendation list With TestItemsMethodology, given a user \\(u\\) , items to recommend for \\(u\\) are all items that appear in the test set of every user excluding those items that appear in the train set of \\(u\\) If the only_greater_eq parameter is set, then only items with rating score \\(>=\\) only_greater_eq will be returned PARAMETER DESCRIPTION only_greater_eq float which acts as a filter, if specified only items with rating score \\(>=\\) only_greater_eq will be returned TYPE: float DEFAULT: None Source code in clayrs/recsys/methodology.py 146 147 148 149 def __init__ ( self , only_greater_eq : float = None ): super ( TestItemsMethodology , self ) . __init__ ( only_greater_eq ) self . _filtered_test_set_items : Optional [ Set ] = None","title":"TestItemsMethodology"},{"location":"recsys/methodology/test_items/#clayrs.recsys.methodology.TestItemsMethodology.filter_single","text":"Method that returns items that need to be part of the recommendation list of a single user. Since it's the TestItems Methodology, all items that appear in the test set of every user will be returned, except for those that appear in the train set of the user passed as parameter PARAMETER DESCRIPTION user_id User of which we want to calculate items that must appear in its recommendation list TYPE: str train_set Ratings object which contains the train set of every user TYPE: Ratings test_set Ratings object which contains the test set of every user TYPE: Ratings Source code in clayrs/recsys/methodology.py 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 def filter_single ( self , user_id : str , train_set : Ratings , test_set : Ratings ) -> Generator : \"\"\" Method that returns items that need to be part of the recommendation list of a single user. Since it's the TestItems Methodology, all items that appear in the *test set* of every user will be returned, except for those that appear in the *train set* of the user passed as parameter Args: user_id: User of which we want to calculate items that must appear in its recommendation list train_set: `Ratings` object which contains the train set of every user test_set: `Ratings` object which contains the test set of every user \"\"\" already_seen_items_it = ( interaction . item_id for interaction in train_set . get_user_interactions ( user_id )) filtered_test_set_items = test_set . item_id_column if self . _threshold is not None : if self . _filtered_test_set_items is None : self . _filtered_test_set_items = set ( self . _filter_only_greater_eq ( test_set )) filtered_test_set_items = self . _filtered_test_set_items filtered_items = yield from set ( filtered_test_set_items ) - set ( already_seen_items_it ) return filtered_items","title":"filter_single()"},{"location":"recsys/methodology/test_ratings/","text":"Test Ratings methodology TestRatingsMethodology ( only_greater_eq = None ) Bases: Methodology Class which, given a train set and a test set , has the task to calculate which items must be used in order to generate a recommendation list With TestRatingsMethodology, given a user \\(u\\) , items to recommend for \\(u\\) are simply those items that appear in its test set If the only_greater_eq parameter is set, then only items with rating score \\(>=\\) only_greater_eq will be returned PARAMETER DESCRIPTION only_greater_eq float which acts as a filter, if specified only items with rating score \\(>=\\) only_greater_eq will be returned TYPE: float DEFAULT: None Source code in clayrs/recsys/methodology.py 99 100 def __init__ ( self , only_greater_eq : float = None ): super ( TestRatingsMethodology , self ) . __init__ ( only_greater_eq ) filter_single ( user_id , train_set , test_set ) Method that returns items that need to be part of the recommendation list of a single user. Since it's the TestRatings Methodology, only items that appear in the test set of the user will be returned. PARAMETER DESCRIPTION user_id User of which we want to calculate items that must appear in its recommendation list TYPE: str train_set Ratings object which contains the train set of every user TYPE: Ratings test_set Ratings object which contains the test set of every user TYPE: Ratings Source code in clayrs/recsys/methodology.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def filter_single ( self , user_id : str , train_set : Ratings , test_set : Ratings ) -> Generator : \"\"\" Method that returns items that need to be part of the recommendation list of a single user. Since it's the TestRatings Methodology, only items that appear in the *test set* of the user will be returned. Args: user_id: User of which we want to calculate items that must appear in its recommendation list train_set: `Ratings` object which contains the train set of every user test_set: `Ratings` object which contains the test set of every user \"\"\" user_test = test_set . get_user_interactions ( user_id ) if self . _threshold is not None : filtered_items = ( interaction . item_id for interaction in user_test if interaction . score >= self . _threshold ) else : # TestRatings just returns the test set of the user filtered_items = ( interaction . item_id for interaction in user_test ) return filtered_items","title":"TestRatings"},{"location":"recsys/methodology/test_ratings/#test-ratings-methodology","text":"","title":"Test Ratings methodology"},{"location":"recsys/methodology/test_ratings/#clayrs.recsys.TestRatingsMethodology","text":"Bases: Methodology Class which, given a train set and a test set , has the task to calculate which items must be used in order to generate a recommendation list With TestRatingsMethodology, given a user \\(u\\) , items to recommend for \\(u\\) are simply those items that appear in its test set If the only_greater_eq parameter is set, then only items with rating score \\(>=\\) only_greater_eq will be returned PARAMETER DESCRIPTION only_greater_eq float which acts as a filter, if specified only items with rating score \\(>=\\) only_greater_eq will be returned TYPE: float DEFAULT: None Source code in clayrs/recsys/methodology.py 99 100 def __init__ ( self , only_greater_eq : float = None ): super ( TestRatingsMethodology , self ) . __init__ ( only_greater_eq )","title":"TestRatingsMethodology"},{"location":"recsys/methodology/test_ratings/#clayrs.recsys.methodology.TestRatingsMethodology.filter_single","text":"Method that returns items that need to be part of the recommendation list of a single user. Since it's the TestRatings Methodology, only items that appear in the test set of the user will be returned. PARAMETER DESCRIPTION user_id User of which we want to calculate items that must appear in its recommendation list TYPE: str train_set Ratings object which contains the train set of every user TYPE: Ratings test_set Ratings object which contains the test set of every user TYPE: Ratings Source code in clayrs/recsys/methodology.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def filter_single ( self , user_id : str , train_set : Ratings , test_set : Ratings ) -> Generator : \"\"\" Method that returns items that need to be part of the recommendation list of a single user. Since it's the TestRatings Methodology, only items that appear in the *test set* of the user will be returned. Args: user_id: User of which we want to calculate items that must appear in its recommendation list train_set: `Ratings` object which contains the train set of every user test_set: `Ratings` object which contains the test set of every user \"\"\" user_test = test_set . get_user_interactions ( user_id ) if self . _threshold is not None : filtered_items = ( interaction . item_id for interaction in user_test if interaction . score >= self . _threshold ) else : # TestRatings just returns the test set of the user filtered_items = ( interaction . item_id for interaction in user_test ) return filtered_items","title":"filter_single()"},{"location":"recsys/methodology/training_items/","text":"Training Items methodology TrainingItemsMethodology ( only_greater_eq = None ) Bases: Methodology Class which, given a train set and a test set , has the task to calculate which items must be used in order to generate a recommendation list With TrainingItemsMethodology, given a user \\(u\\) , items to recommend for \\(u\\) are all items that appear in the 'train set' of every user excluding those items that appear in the 'train set' of \\(u\\) If the only_greater_eq parameter is set, then only items with rating score \\(>=\\) only_greater_eq will be returned PARAMETER DESCRIPTION only_greater_eq float which acts as a filter, if specified only items with rating score \\(>=\\) only_greater_eq will be returned TYPE: float DEFAULT: None Source code in clayrs/recsys/methodology.py 198 199 200 201 def __init__ ( self , only_greater_eq : float = None ): super ( TrainingItemsMethodology , self ) . __init__ ( only_greater_eq ) self . _filtered_train_set_items : Optional [ Set ] = None filter_single ( user_id , train_set , test_set ) Method that returns items that needs to be part of the recommendation list of a single user. Since it's the TrainingItems Methodology, all items that appear in the train set of every user will be returned, except for those that appear in the train set of the user passed as parameter PARAMETER DESCRIPTION user_id User of which we want to calculate items that must appear in its recommendation list TYPE: str train_set Ratings object which contains the train set of every user TYPE: Ratings test_set Ratings object which contains the test set of every user TYPE: Ratings Source code in clayrs/recsys/methodology.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 def filter_single ( self , user_id : str , train_set : Ratings , test_set : Ratings ) -> Generator : \"\"\" Method that returns items that needs to be part of the recommendation list of a single user. Since it's the TrainingItems Methodology, all items that appear in the *train set* of every user will be returned, except for those that appear in the *train set* of the user passed as parameter Args: user_id: User of which we want to calculate items that must appear in its recommendation list train_set: `Ratings` object which contains the train set of every user test_set: `Ratings` object which contains the test set of every user \"\"\" already_seen_items_it = ( interaction . item_id for interaction in train_set . get_user_interactions ( user_id )) filtered_train_set_items = train_set . item_id_column if self . _threshold is not None : if self . _filtered_train_set_items is None : self . _filtered_train_set_items = set ( self . _filter_only_greater_eq ( train_set )) filtered_train_set_items = self . _filtered_train_set_items filtered_items = yield from set ( filtered_train_set_items ) - set ( already_seen_items_it ) return filtered_items","title":"TrainingItems"},{"location":"recsys/methodology/training_items/#training-items-methodology","text":"","title":"Training Items methodology"},{"location":"recsys/methodology/training_items/#clayrs.recsys.TrainingItemsMethodology","text":"Bases: Methodology Class which, given a train set and a test set , has the task to calculate which items must be used in order to generate a recommendation list With TrainingItemsMethodology, given a user \\(u\\) , items to recommend for \\(u\\) are all items that appear in the 'train set' of every user excluding those items that appear in the 'train set' of \\(u\\) If the only_greater_eq parameter is set, then only items with rating score \\(>=\\) only_greater_eq will be returned PARAMETER DESCRIPTION only_greater_eq float which acts as a filter, if specified only items with rating score \\(>=\\) only_greater_eq will be returned TYPE: float DEFAULT: None Source code in clayrs/recsys/methodology.py 198 199 200 201 def __init__ ( self , only_greater_eq : float = None ): super ( TrainingItemsMethodology , self ) . __init__ ( only_greater_eq ) self . _filtered_train_set_items : Optional [ Set ] = None","title":"TrainingItemsMethodology"},{"location":"recsys/methodology/training_items/#clayrs.recsys.methodology.TrainingItemsMethodology.filter_single","text":"Method that returns items that needs to be part of the recommendation list of a single user. Since it's the TrainingItems Methodology, all items that appear in the train set of every user will be returned, except for those that appear in the train set of the user passed as parameter PARAMETER DESCRIPTION user_id User of which we want to calculate items that must appear in its recommendation list TYPE: str train_set Ratings object which contains the train set of every user TYPE: Ratings test_set Ratings object which contains the test set of every user TYPE: Ratings Source code in clayrs/recsys/methodology.py 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 def filter_single ( self , user_id : str , train_set : Ratings , test_set : Ratings ) -> Generator : \"\"\" Method that returns items that needs to be part of the recommendation list of a single user. Since it's the TrainingItems Methodology, all items that appear in the *train set* of every user will be returned, except for those that appear in the *train set* of the user passed as parameter Args: user_id: User of which we want to calculate items that must appear in its recommendation list train_set: `Ratings` object which contains the train set of every user test_set: `Ratings` object which contains the test set of every user \"\"\" already_seen_items_it = ( interaction . item_id for interaction in train_set . get_user_interactions ( user_id )) filtered_train_set_items = train_set . item_id_column if self . _threshold is not None : if self . _filtered_train_set_items is None : self . _filtered_train_set_items = set ( self . _filter_only_greater_eq ( train_set )) filtered_train_set_items = self . _filtered_train_set_items filtered_items = yield from set ( filtered_train_set_items ) - set ( already_seen_items_it ) return filtered_items","title":"filter_single()"},{"location":"recsys/partitioning/abstract_partitioning/","text":"Abstract Partitioning class Partitioning ( skip_user_error = True ) Bases: ABC Abstract class for partitioning technique. Each class must implement the split_single() method which specify how data for a single user will be split PARAMETER DESCRIPTION skip_user_error If set to True, users for which data can't be split will be skipped and only a warning will be logged when calling the split_all() method. Otherwise, a ValueError exception is raised TYPE: bool DEFAULT: True Source code in clayrs/recsys/partitioning.py 31 32 def __init__ ( self , skip_user_error : bool = True ): self . __skip_user_error = skip_user_error split_all ( ratings_to_split , user_id_list = None ) Concrete method that splits, for every user in the ratings_to_split parameter, the original ratings into train set and test set . If a user_id_list parameter is set, the method will do the splitting only for the users specified inside the list. The method returns two lists: The first contains all train set for each split (if the partitioning technique returns more than one split e.g. KFold) The second contains all test set for each split (if the partitioning technique returns more than one split e.g. KFold) Obviously the two lists will have the same length, and to the train set in position \\(i\\) corresponds the truth set at position \\(i\\) PARAMETER DESCRIPTION ratings_to_split Ratings object which contains the interactions of the users that must be splitted into train set and test set TYPE: Ratings user_id_list The set of users for which splitting will be done. If set, splitting will be performed only for users inside the list. Otherwise, splitting will be performed for all users in ratings_to_split parameter TYPE: Set [ str ] DEFAULT: None RAISES DESCRIPTION ValueError if skip_user_error=True in the constructor and for some users splitting can't be performed Source code in clayrs/recsys/partitioning.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def split_all ( self , ratings_to_split : Ratings , user_id_list : Set [ str ] = None ) -> Tuple [ List [ Ratings ], List [ Ratings ]]: \"\"\" Concrete method that splits, for every user in the `ratings_to_split` parameter, the original ratings into *train set* and *test set*. If a `user_id_list` parameter is set, the method will do the splitting only for the users specified inside the list. The method returns two lists: * The first contains all train set for each split (if the partitioning technique returns more than one split e.g. KFold) * The second contains all test set for each split (if the partitioning technique returns more than one split e.g. KFold) Obviously the two lists will have the same length, and to the *train set* in position $i$ corresponds the *truth set* at position $i$ Args: ratings_to_split: `Ratings` object which contains the interactions of the users that must be splitted into *train set* and *test set* user_id_list: The set of users for which splitting will be done. If set, splitting will be performed only for users inside the list. Otherwise, splitting will be performed for all users in `ratings_to_split` parameter Raises: ValueError: if `skip_user_error=True` in the constructor and for some users splitting can't be performed \"\"\" if user_id_list is None : user_id_list = set ( ratings_to_split . user_id_column ) # { # 0: {'train': {'u1': u1_interactions_train0, 'u2': u2_interactions_train0}}, # 'test': {'u1': u1_interactions_test0, 'u2': u2_interactions_test0}}, # # 1: {'train': {'u1': u1_interactions_train1, 'u2': u2_interactions_train1}}, # 'test': {'u1': u1_interactions_test1, 'u2': u2_interactions_test1} # } train_test_dict = defaultdict ( lambda : defaultdict ( list )) with get_progbar ( user_id_list ) as pbar : pbar . set_description ( \"Performing {} \" . format ( str ( self ))) for user_id in pbar : user_ratings = ratings_to_split . get_user_interactions ( user_id ) try : user_train_list , user_test_list = self . split_single ( user_ratings ) for split_number , ( single_train , single_test ) in enumerate ( zip ( user_train_list , user_test_list )): # we set for each split the train_set and test_set of every user u1 # eg. # train_test_dict[0]['train']['u1'] = u1_interactions_train0 # train_test_dict[0]['test']['u1'] = u1_interactions_test0 # train_test_dict[split_number]['train'][user_id] = single_train # train_test_dict[split_number]['test'][user_id] = single_test train_test_dict [ split_number ][ 'train' ] . extend ( single_train ) train_test_dict [ split_number ][ 'test' ] . extend ( single_test ) except ValueError as e : if self . skip_user_error : logger . warning ( str ( e ) + \" \\n The user {} will be skipped\" . format ( user_id )) continue else : raise e train_list = [ Ratings . from_list ( train_test_dict [ split ][ 'train' ]) for split in train_test_dict ] test_list = [ Ratings . from_list ( train_test_dict [ split ][ 'test' ]) for split in train_test_dict ] return train_list , test_list split_single ( user_ratings ) abstractmethod Abstract method in which each partitioning technique must specify how to split data for a single user PARAMETER DESCRIPTION user_ratings List of Interaction objects of a single user TYPE: List [ Interaction ] RETURNS DESCRIPTION Tuple [ List [ List [ Interaction ]], List [ List [ Interaction ]]] Two lists, where the first contains one list of Interaction objects for each split that will constitute the train set of the user, the second contains one list of Interaction objects for each split that will constitute the test set for the user Source code in clayrs/recsys/partitioning.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 @abc . abstractmethod def split_single ( self , user_ratings : List [ Interaction ]) -> Tuple [ List [ List [ Interaction ]], List [ List [ Interaction ]]]: \"\"\" Abstract method in which each partitioning technique must specify how to split data for a single user Args: user_ratings: List of `Interaction` objects of a single user Returns: Two lists, where the first contains one list of `Interaction` objects for each split that will constitute the *train set* of the user, the second contains one list of `Interaction` objects for each split that will constitute the *test set* for the user \"\"\" raise NotImplementedError","title":"Abstract Partitioning class"},{"location":"recsys/partitioning/abstract_partitioning/#abstract-partitioning-class","text":"","title":"Abstract Partitioning class"},{"location":"recsys/partitioning/abstract_partitioning/#clayrs.recsys.partitioning.Partitioning","text":"Bases: ABC Abstract class for partitioning technique. Each class must implement the split_single() method which specify how data for a single user will be split PARAMETER DESCRIPTION skip_user_error If set to True, users for which data can't be split will be skipped and only a warning will be logged when calling the split_all() method. Otherwise, a ValueError exception is raised TYPE: bool DEFAULT: True Source code in clayrs/recsys/partitioning.py 31 32 def __init__ ( self , skip_user_error : bool = True ): self . __skip_user_error = skip_user_error","title":"Partitioning"},{"location":"recsys/partitioning/abstract_partitioning/#clayrs.recsys.partitioning.Partitioning.split_all","text":"Concrete method that splits, for every user in the ratings_to_split parameter, the original ratings into train set and test set . If a user_id_list parameter is set, the method will do the splitting only for the users specified inside the list. The method returns two lists: The first contains all train set for each split (if the partitioning technique returns more than one split e.g. KFold) The second contains all test set for each split (if the partitioning technique returns more than one split e.g. KFold) Obviously the two lists will have the same length, and to the train set in position \\(i\\) corresponds the truth set at position \\(i\\) PARAMETER DESCRIPTION ratings_to_split Ratings object which contains the interactions of the users that must be splitted into train set and test set TYPE: Ratings user_id_list The set of users for which splitting will be done. If set, splitting will be performed only for users inside the list. Otherwise, splitting will be performed for all users in ratings_to_split parameter TYPE: Set [ str ] DEFAULT: None RAISES DESCRIPTION ValueError if skip_user_error=True in the constructor and for some users splitting can't be performed Source code in clayrs/recsys/partitioning.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 def split_all ( self , ratings_to_split : Ratings , user_id_list : Set [ str ] = None ) -> Tuple [ List [ Ratings ], List [ Ratings ]]: \"\"\" Concrete method that splits, for every user in the `ratings_to_split` parameter, the original ratings into *train set* and *test set*. If a `user_id_list` parameter is set, the method will do the splitting only for the users specified inside the list. The method returns two lists: * The first contains all train set for each split (if the partitioning technique returns more than one split e.g. KFold) * The second contains all test set for each split (if the partitioning technique returns more than one split e.g. KFold) Obviously the two lists will have the same length, and to the *train set* in position $i$ corresponds the *truth set* at position $i$ Args: ratings_to_split: `Ratings` object which contains the interactions of the users that must be splitted into *train set* and *test set* user_id_list: The set of users for which splitting will be done. If set, splitting will be performed only for users inside the list. Otherwise, splitting will be performed for all users in `ratings_to_split` parameter Raises: ValueError: if `skip_user_error=True` in the constructor and for some users splitting can't be performed \"\"\" if user_id_list is None : user_id_list = set ( ratings_to_split . user_id_column ) # { # 0: {'train': {'u1': u1_interactions_train0, 'u2': u2_interactions_train0}}, # 'test': {'u1': u1_interactions_test0, 'u2': u2_interactions_test0}}, # # 1: {'train': {'u1': u1_interactions_train1, 'u2': u2_interactions_train1}}, # 'test': {'u1': u1_interactions_test1, 'u2': u2_interactions_test1} # } train_test_dict = defaultdict ( lambda : defaultdict ( list )) with get_progbar ( user_id_list ) as pbar : pbar . set_description ( \"Performing {} \" . format ( str ( self ))) for user_id in pbar : user_ratings = ratings_to_split . get_user_interactions ( user_id ) try : user_train_list , user_test_list = self . split_single ( user_ratings ) for split_number , ( single_train , single_test ) in enumerate ( zip ( user_train_list , user_test_list )): # we set for each split the train_set and test_set of every user u1 # eg. # train_test_dict[0]['train']['u1'] = u1_interactions_train0 # train_test_dict[0]['test']['u1'] = u1_interactions_test0 # train_test_dict[split_number]['train'][user_id] = single_train # train_test_dict[split_number]['test'][user_id] = single_test train_test_dict [ split_number ][ 'train' ] . extend ( single_train ) train_test_dict [ split_number ][ 'test' ] . extend ( single_test ) except ValueError as e : if self . skip_user_error : logger . warning ( str ( e ) + \" \\n The user {} will be skipped\" . format ( user_id )) continue else : raise e train_list = [ Ratings . from_list ( train_test_dict [ split ][ 'train' ]) for split in train_test_dict ] test_list = [ Ratings . from_list ( train_test_dict [ split ][ 'test' ]) for split in train_test_dict ] return train_list , test_list","title":"split_all()"},{"location":"recsys/partitioning/abstract_partitioning/#clayrs.recsys.partitioning.Partitioning.split_single","text":"Abstract method in which each partitioning technique must specify how to split data for a single user PARAMETER DESCRIPTION user_ratings List of Interaction objects of a single user TYPE: List [ Interaction ] RETURNS DESCRIPTION Tuple [ List [ List [ Interaction ]], List [ List [ Interaction ]]] Two lists, where the first contains one list of Interaction objects for each split that will constitute the train set of the user, the second contains one list of Interaction objects for each split that will constitute the test set for the user Source code in clayrs/recsys/partitioning.py 42 43 44 45 46 47 48 49 50 51 52 53 54 55 @abc . abstractmethod def split_single ( self , user_ratings : List [ Interaction ]) -> Tuple [ List [ List [ Interaction ]], List [ List [ Interaction ]]]: \"\"\" Abstract method in which each partitioning technique must specify how to split data for a single user Args: user_ratings: List of `Interaction` objects of a single user Returns: Two lists, where the first contains one list of `Interaction` objects for each split that will constitute the *train set* of the user, the second contains one list of `Interaction` objects for each split that will constitute the *test set* for the user \"\"\" raise NotImplementedError","title":"split_single()"},{"location":"recsys/partitioning/hold_out/","text":"HoldOut partitioning technique HoldOutPartitioning ( train_set_size = 0.8 , shuffle = True , random_state = None , skip_user_error = True ) Bases: Partitioning Class that performs Hold-Out partitioning PARAMETER DESCRIPTION train_set_size Should be between 0.0 and 1.0 and represent the proportion of the ratings to hold in the train set for each user. TYPE: float DEFAULT: 0.8 random_state Controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls. TYPE: int DEFAULT: None shuffle Whether or not to shuffle the data before splitting. TYPE: bool DEFAULT: True skip_user_error If set to True, users for which data can't be split will be skipped and only a warning will be logged when calling the split_all() method. Otherwise, a ValueError exception is raised TYPE: bool DEFAULT: True Source code in clayrs/recsys/partitioning.py 208 209 210 211 212 213 214 215 216 def __init__ ( self , train_set_size : float = 0.8 , shuffle : bool = True , random_state : int = None , skip_user_error : bool = True ): self . _check_percentage ( train_set_size ) self . __train_set_size = train_set_size self . __test_set_size = ( 1 - train_set_size ) self . __random_state = random_state self . __shuffle = shuffle super () . __init__ ( skip_user_error ) split_single ( user_ratings ) Method which splits train set and test set the ratings of a single user by holding in the train set the percentage of data specified in train_set_size in the constructor PARAMETER DESCRIPTION user_ratings List of Interaction objects of a single user TYPE: List [ Interaction ] RETURNS DESCRIPTION Tuple [ List [ List [ Interaction ]], List [ List [ Interaction ]]] Two lists, where the first contains one list of Interaction objects that will constitute the train set of the user, the second contains one list of Interaction objects that will constitute the test set for the user Source code in clayrs/recsys/partitioning.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 def split_single ( self , user_ratings : List [ Interaction ]) -> Tuple [ List [ List [ Interaction ]], List [ List [ Interaction ]]]: \"\"\" Method which splits *train set* and *test set* the ratings of a single user by holding in the train set the percentage of data specified in `train_set_size` in the constructor Args: user_ratings: List of `Interaction` objects of a single user Returns: Two lists, where the first contains one list of `Interaction` objects that will constitute the *train set* of the user, the second contains one list of `Interaction` objects that will constitute the *test set* for the user \"\"\" interactions_train , interactions_test = train_test_split ( user_ratings , train_size = self . __train_set_size , test_size = self . __test_set_size , shuffle = self . __shuffle , random_state = self . __random_state ) user_train_list = [ interactions_train ] user_test_list = [ interactions_test ] return user_train_list , user_test_list","title":"Hold Out"},{"location":"recsys/partitioning/hold_out/#holdout-partitioning-technique","text":"","title":"HoldOut partitioning technique"},{"location":"recsys/partitioning/hold_out/#clayrs.recsys.HoldOutPartitioning","text":"Bases: Partitioning Class that performs Hold-Out partitioning PARAMETER DESCRIPTION train_set_size Should be between 0.0 and 1.0 and represent the proportion of the ratings to hold in the train set for each user. TYPE: float DEFAULT: 0.8 random_state Controls the shuffling applied to the data before applying the split. Pass an int for reproducible output across multiple function calls. TYPE: int DEFAULT: None shuffle Whether or not to shuffle the data before splitting. TYPE: bool DEFAULT: True skip_user_error If set to True, users for which data can't be split will be skipped and only a warning will be logged when calling the split_all() method. Otherwise, a ValueError exception is raised TYPE: bool DEFAULT: True Source code in clayrs/recsys/partitioning.py 208 209 210 211 212 213 214 215 216 def __init__ ( self , train_set_size : float = 0.8 , shuffle : bool = True , random_state : int = None , skip_user_error : bool = True ): self . _check_percentage ( train_set_size ) self . __train_set_size = train_set_size self . __test_set_size = ( 1 - train_set_size ) self . __random_state = random_state self . __shuffle = shuffle super () . __init__ ( skip_user_error )","title":"HoldOutPartitioning"},{"location":"recsys/partitioning/hold_out/#clayrs.recsys.partitioning.HoldOutPartitioning.split_single","text":"Method which splits train set and test set the ratings of a single user by holding in the train set the percentage of data specified in train_set_size in the constructor PARAMETER DESCRIPTION user_ratings List of Interaction objects of a single user TYPE: List [ Interaction ] RETURNS DESCRIPTION Tuple [ List [ List [ Interaction ]], List [ List [ Interaction ]]] Two lists, where the first contains one list of Interaction objects that will constitute the train set of the user, the second contains one list of Interaction objects that will constitute the test set for the user Source code in clayrs/recsys/partitioning.py 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 def split_single ( self , user_ratings : List [ Interaction ]) -> Tuple [ List [ List [ Interaction ]], List [ List [ Interaction ]]]: \"\"\" Method which splits *train set* and *test set* the ratings of a single user by holding in the train set the percentage of data specified in `train_set_size` in the constructor Args: user_ratings: List of `Interaction` objects of a single user Returns: Two lists, where the first contains one list of `Interaction` objects that will constitute the *train set* of the user, the second contains one list of `Interaction` objects that will constitute the *test set* for the user \"\"\" interactions_train , interactions_test = train_test_split ( user_ratings , train_size = self . __train_set_size , test_size = self . __test_set_size , shuffle = self . __shuffle , random_state = self . __random_state ) user_train_list = [ interactions_train ] user_test_list = [ interactions_test ] return user_train_list , user_test_list","title":"split_single()"},{"location":"recsys/partitioning/kfold/","text":"KFold partitioning technique KFoldPartitioning ( n_splits = 2 , shuffle = True , random_state = None , skip_user_error = True ) Bases: Partitioning Class that performs K-Fold partitioning PARAMETER DESCRIPTION n_splits Number of splits. Must be at least 2 TYPE: int DEFAULT: 2 shuffle Whether to shuffle the data before splitting into batches. Note that the samples within each split will not be shuffled. TYPE: bool DEFAULT: True random_state When shuffle is True, random_state affects the ordering of the indices, which controls the randomness of each fold. Otherwise, this parameter has no effect. Pass an int for reproducible output across multiple function calls. TYPE: int DEFAULT: None skip_user_error If set to True, users for which data can't be split will be skipped and only a warning will be logged when calling the split_all() method. Otherwise, a ValueError exception is raised TYPE: bool DEFAULT: True Source code in clayrs/recsys/partitioning.py 150 151 152 153 154 def __init__ ( self , n_splits : int = 2 , shuffle : bool = True , random_state : int = None , skip_user_error : bool = True ): self . __kf = KFold ( n_splits = n_splits , shuffle = shuffle , random_state = random_state ) super ( KFoldPartitioning , self ) . __init__ ( skip_user_error ) split_single ( user_ratings ) Method which splits in \\(k\\) splits both in train set and test set the ratings of a single user PARAMETER DESCRIPTION user_ratings List of Interaction objects of a single user TYPE: List [ Interaction ] RETURNS DESCRIPTION Tuple [ List [ List [ Interaction ]], List [ List [ Interaction ]]] Two lists, where the first contains one list of Interaction objects for each split that will constitute the train set of the user, the second contains one list of Interaction objects for each split that will constitute the test set for the user Source code in clayrs/recsys/partitioning.py 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 def split_single ( self , user_ratings : List [ Interaction ]) -> Tuple [ List [ List [ Interaction ]], List [ List [ Interaction ]]]: \"\"\" Method which splits in $k$ splits both in *train set* and *test set* the ratings of a single user Args: user_ratings: List of `Interaction` objects of a single user Returns: Two lists, where the first contains one list of `Interaction` objects for each split that will constitute the *train set* of the user, the second contains one list of `Interaction` objects for each split that will constitute the *test set* for the user \"\"\" split_result = self . __kf . split ( user_ratings ) user_train_list = [] user_test_list = [] # split_result contains index of the ratings which must constitutes train set and test set for train_set_indexes , test_set_indexes in split_result : user_interactions_train = [ user_ratings [ index ] for index in train_set_indexes ] user_interactions_test = [ user_ratings [ index ] for index in test_set_indexes ] user_train_list . append ( user_interactions_train ) user_test_list . append ( user_interactions_test ) return user_train_list , user_test_list","title":"KFold"},{"location":"recsys/partitioning/kfold/#kfold-partitioning-technique","text":"","title":"KFold partitioning technique"},{"location":"recsys/partitioning/kfold/#clayrs.recsys.KFoldPartitioning","text":"Bases: Partitioning Class that performs K-Fold partitioning PARAMETER DESCRIPTION n_splits Number of splits. Must be at least 2 TYPE: int DEFAULT: 2 shuffle Whether to shuffle the data before splitting into batches. Note that the samples within each split will not be shuffled. TYPE: bool DEFAULT: True random_state When shuffle is True, random_state affects the ordering of the indices, which controls the randomness of each fold. Otherwise, this parameter has no effect. Pass an int for reproducible output across multiple function calls. TYPE: int DEFAULT: None skip_user_error If set to True, users for which data can't be split will be skipped and only a warning will be logged when calling the split_all() method. Otherwise, a ValueError exception is raised TYPE: bool DEFAULT: True Source code in clayrs/recsys/partitioning.py 150 151 152 153 154 def __init__ ( self , n_splits : int = 2 , shuffle : bool = True , random_state : int = None , skip_user_error : bool = True ): self . __kf = KFold ( n_splits = n_splits , shuffle = shuffle , random_state = random_state ) super ( KFoldPartitioning , self ) . __init__ ( skip_user_error )","title":"KFoldPartitioning"},{"location":"recsys/partitioning/kfold/#clayrs.recsys.partitioning.KFoldPartitioning.split_single","text":"Method which splits in \\(k\\) splits both in train set and test set the ratings of a single user PARAMETER DESCRIPTION user_ratings List of Interaction objects of a single user TYPE: List [ Interaction ] RETURNS DESCRIPTION Tuple [ List [ List [ Interaction ]], List [ List [ Interaction ]]] Two lists, where the first contains one list of Interaction objects for each split that will constitute the train set of the user, the second contains one list of Interaction objects for each split that will constitute the test set for the user Source code in clayrs/recsys/partitioning.py 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 def split_single ( self , user_ratings : List [ Interaction ]) -> Tuple [ List [ List [ Interaction ]], List [ List [ Interaction ]]]: \"\"\" Method which splits in $k$ splits both in *train set* and *test set* the ratings of a single user Args: user_ratings: List of `Interaction` objects of a single user Returns: Two lists, where the first contains one list of `Interaction` objects for each split that will constitute the *train set* of the user, the second contains one list of `Interaction` objects for each split that will constitute the *test set* for the user \"\"\" split_result = self . __kf . split ( user_ratings ) user_train_list = [] user_test_list = [] # split_result contains index of the ratings which must constitutes train set and test set for train_set_indexes , test_set_indexes in split_result : user_interactions_train = [ user_ratings [ index ] for index in train_set_indexes ] user_interactions_test = [ user_ratings [ index ] for index in test_set_indexes ] user_train_list . append ( user_interactions_train ) user_test_list . append ( user_interactions_test ) return user_train_list , user_test_list","title":"split_single()"},{"location":"utils/report/","text":"Report class Report ( output_dir = '.' , ca_report_filename = 'ca_report' , rs_report_filename = 'rs_report' , eva_report_filename = 'eva_report' ) Class which will generate a YAML report for the whole experiment (or a part of it) depending on the objects passed to the yaml() function. A report will be generated for each module used ( Content Analyzer , RecSys , Evaluation ). PARAMETER DESCRIPTION output_dir Path of the folder where reports generated will be saved TYPE: str DEFAULT: '.' ca_report_filename Filename of the Content Analyzer report TYPE: str DEFAULT: 'ca_report' rs_report_filename Filename of the Recsys report TYPE: str DEFAULT: 'rs_report' eva_report_filename Filename of the evaluation report TYPE: str DEFAULT: 'eva_report' Source code in clayrs/utils/report.py 37 38 39 40 41 42 43 44 45 def __init__ ( self , output_dir : str = '.' , ca_report_filename : str = 'ca_report' , rs_report_filename : str = 'rs_report' , eva_report_filename : str = 'eva_report' ): self . _output_dir = output_dir self . _ca_report_filename = ca_report_filename self . _rs_report_filename = rs_report_filename self . _eva_report_filename = eva_report_filename yaml ( content_analyzer = None , original_ratings = None , partitioning_technique = None , recsys = None , eval_model = None ) Main module responsible of generating the YAML reports based on the objects passed to this function: If content_analyzer is set, then the report for the Content Analyzer will be produced If one between original_ratings , partitioning_technique , recsys is set, then the report for the recsys module will be produced. If eval_model is set, then the report for the evaluation module will be produced PLEASE NOTE : by setting the recsys parameter, the last experiment conducted will be documented! If no experiment is conducted in the current run, then a ValueError exception is raised! Same goes for the eval_model Examples: Generate a report for the Content Analyzer module >>> from clayrs import content_analyzer as ca >>> from clayrs import utils as ut >>> # movies_ca_config = ... # user defined configuration >>> content_a = ca . ContentAnalyzer ( movies_config ) >>> content_a . fit () # generate and serialize contents >>> ut . Report () . yaml ( content_analyzer = content_a ) # generate yaml Generate a partial report for the RecSys module >>> from clayrs import utils as ut >>> from clayrs import recsys as rs >>> ratings = ca . Ratings ( ca . CSVFile ( ratings_path )) >>> pt = rs . HoldOutPartitioning () >>> [ train ], [ test ] = pt . split_all ( ratings ) >>> ut . Report () . yaml ( original_ratings = ratings , partitioning_technique = pt ) Generate a full report for the RecSys module and evaluation module >>> from clayrs import utils as ut >>> from clayrs import recsys as rs >>> from clayrs import evaluation as eva >>> >>> # Generate recommendations >>> ratings = ca . Ratings ( ca . CSVFile ( ratings_path )) >>> pt = rs . HoldOutPartitioning () >>> [ train ], [ test ] = pt . split_all ( ratings ) >>> alg = rs . CentroidVector () >>> cbrs = rs . ContentBasedRS ( alg , train_set = train , items_directory = items_path ) >>> rank = cbrs . fit_rank ( test , n_recs = 10 ) >>> >>> # Evaluate recommendations and generate report >>> em = eva . EvalModel ([ rank ], [ test ], metric_list = [ eva . Precision (), eva . Recall ()]) >>> ut . Report () . yaml ( original_ratings = ratings , >>> partitioning_technique = pt , >>> recsys = cbrs , >>> eval_model = em ) PARAMETER DESCRIPTION content_analyzer ContentAnalyzer object used to generate complex representation in the experiment TYPE: ContentAnalyzer DEFAULT: None original_ratings Ratings object representing the original dataset TYPE: Ratings DEFAULT: None partitioning_technique Partitioning object used to split the original dataset TYPE: Partitioning DEFAULT: None recsys RecSys object used to produce recommendations/score predictions. Please note that the latest experiment run will be documented. If no experiment is run, then an exception is thrown TYPE: RecSys DEFAULT: None eval_model EvalModel object used to evaluate predictions generated. Please note that the latest evaluation run will be documented. If no evaluation is run, then an exception is thrown TYPE: EvalModel DEFAULT: None Source code in clayrs/utils/report.py 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 def yaml ( self , content_analyzer : ContentAnalyzer = None , original_ratings : Ratings = None , partitioning_technique : Partitioning = None , recsys : RecSys = None , eval_model : EvalModel = None ): \"\"\" Main module responsible of generating the `YAML` reports based on the objects passed to this function: * If `content_analyzer` is set, then the report for the Content Analyzer will be produced * If one between `original_ratings`, `partitioning_technique`, `recsys` is set, then the report for the recsys module will be produced. * If `eval_model` is set, then the report for the evaluation module will be produced **PLEASE NOTE**: by setting the `recsys` parameter, the last experiment conducted will be documented! If no experiment is conducted in the current run, then a `ValueError` exception is raised! * Same goes for the `eval_model` Examples: * Generate a report for the Content Analyzer module >>> from clayrs import content_analyzer as ca >>> from clayrs import utils as ut >>> # movies_ca_config = ... # user defined configuration >>> content_a = ca.ContentAnalyzer(movies_config) >>> content_a.fit() # generate and serialize contents >>> ut.Report().yaml(content_analyzer=content_a) # generate yaml * Generate a partial report for the RecSys module >>> from clayrs import utils as ut >>> from clayrs import recsys as rs >>> ratings = ca.Ratings(ca.CSVFile(ratings_path)) >>> pt = rs.HoldOutPartitioning() >>> [train], [test] = pt.split_all(ratings) >>> ut.Report().yaml(original_ratings=ratings, partitioning_technique=pt) * Generate a full report for the RecSys module and evaluation module >>> from clayrs import utils as ut >>> from clayrs import recsys as rs >>> from clayrs import evaluation as eva >>> >>> # Generate recommendations >>> ratings = ca.Ratings(ca.CSVFile(ratings_path)) >>> pt = rs.HoldOutPartitioning() >>> [train], [test] = pt.split_all(ratings) >>> alg = rs.CentroidVector() >>> cbrs = rs.ContentBasedRS(alg, train_set=train, items_directory=items_path) >>> rank = cbrs.fit_rank(test, n_recs=10) >>> >>> # Evaluate recommendations and generate report >>> em = eva.EvalModel([rank], [test], metric_list=[eva.Precision(), eva.Recall()]) >>> ut.Report().yaml(original_ratings=ratings, >>> partitioning_technique=pt, >>> recsys=cbrs, >>> eval_model=em) Args: content_analyzer: `ContentAnalyzer` object used to generate complex representation in the experiment original_ratings: `Ratings` object representing the original dataset partitioning_technique: `Partitioning` object used to split the original dataset recsys: `RecSys` object used to produce recommendations/score predictions. Please note that the latest experiment run will be documented. If no experiment is run, then an exception is thrown eval_model: `EvalModel` object used to evaluate predictions generated. Please note that the latest evaluation run will be documented. If no evaluation is run, then an exception is thrown \"\"\" def represent_none ( self , _ ): return self . represent_scalar ( 'tag:yaml.org,2002:null' , 'null' ) def dump_yaml ( output_dir , data ): with open ( output_dir , 'w' ) as yaml_file : pyaml . dump ( data , yaml_file , sort_dicts = False , safe = True ) # None values will be represented as 'null' in yaml file. # without this, they will simply be represented as an empty string pyaml . add_representer ( type ( None ), represent_none ) if content_analyzer is not None : ca_dict = self . _report_ca_module ( content_analyzer ) # create folder if it doesn't exist Path ( self . output_dir ) . mkdir ( parents = True , exist_ok = True ) output_dir = os . path . join ( self . output_dir , f ' { self . _ca_report_filename } .yml' ) dump_yaml ( output_dir , ca_dict ) if original_ratings is not None or partitioning_technique is not None or recsys is not None : rs_dict = self . _report_rs_module ( original_ratings , partitioning_technique , recsys ) # create folder if it doesn't exist Path ( self . output_dir ) . mkdir ( parents = True , exist_ok = True ) output_dir = os . path . join ( self . output_dir , f ' { self . _rs_report_filename } .yml' ) dump_yaml ( output_dir , rs_dict ) if eval_model is not None : eva_dict = self . _report_eva_module ( eval_model ) # create folder if it doesn't exist Path ( self . output_dir ) . mkdir ( parents = True , exist_ok = True ) output_dir = os . path . join ( self . output_dir , f ' { self . _eva_report_filename } .yml' ) dump_yaml ( output_dir , eva_dict )","title":"Report"},{"location":"utils/report/#report-class","text":"","title":"Report class"},{"location":"utils/report/#clayrs.utils.Report","text":"Class which will generate a YAML report for the whole experiment (or a part of it) depending on the objects passed to the yaml() function. A report will be generated for each module used ( Content Analyzer , RecSys , Evaluation ). PARAMETER DESCRIPTION output_dir Path of the folder where reports generated will be saved TYPE: str DEFAULT: '.' ca_report_filename Filename of the Content Analyzer report TYPE: str DEFAULT: 'ca_report' rs_report_filename Filename of the Recsys report TYPE: str DEFAULT: 'rs_report' eva_report_filename Filename of the evaluation report TYPE: str DEFAULT: 'eva_report' Source code in clayrs/utils/report.py 37 38 39 40 41 42 43 44 45 def __init__ ( self , output_dir : str = '.' , ca_report_filename : str = 'ca_report' , rs_report_filename : str = 'rs_report' , eva_report_filename : str = 'eva_report' ): self . _output_dir = output_dir self . _ca_report_filename = ca_report_filename self . _rs_report_filename = rs_report_filename self . _eva_report_filename = eva_report_filename","title":"Report"},{"location":"utils/report/#clayrs.utils.report.Report.yaml","text":"Main module responsible of generating the YAML reports based on the objects passed to this function: If content_analyzer is set, then the report for the Content Analyzer will be produced If one between original_ratings , partitioning_technique , recsys is set, then the report for the recsys module will be produced. If eval_model is set, then the report for the evaluation module will be produced PLEASE NOTE : by setting the recsys parameter, the last experiment conducted will be documented! If no experiment is conducted in the current run, then a ValueError exception is raised! Same goes for the eval_model Examples: Generate a report for the Content Analyzer module >>> from clayrs import content_analyzer as ca >>> from clayrs import utils as ut >>> # movies_ca_config = ... # user defined configuration >>> content_a = ca . ContentAnalyzer ( movies_config ) >>> content_a . fit () # generate and serialize contents >>> ut . Report () . yaml ( content_analyzer = content_a ) # generate yaml Generate a partial report for the RecSys module >>> from clayrs import utils as ut >>> from clayrs import recsys as rs >>> ratings = ca . Ratings ( ca . CSVFile ( ratings_path )) >>> pt = rs . HoldOutPartitioning () >>> [ train ], [ test ] = pt . split_all ( ratings ) >>> ut . Report () . yaml ( original_ratings = ratings , partitioning_technique = pt ) Generate a full report for the RecSys module and evaluation module >>> from clayrs import utils as ut >>> from clayrs import recsys as rs >>> from clayrs import evaluation as eva >>> >>> # Generate recommendations >>> ratings = ca . Ratings ( ca . CSVFile ( ratings_path )) >>> pt = rs . HoldOutPartitioning () >>> [ train ], [ test ] = pt . split_all ( ratings ) >>> alg = rs . CentroidVector () >>> cbrs = rs . ContentBasedRS ( alg , train_set = train , items_directory = items_path ) >>> rank = cbrs . fit_rank ( test , n_recs = 10 ) >>> >>> # Evaluate recommendations and generate report >>> em = eva . EvalModel ([ rank ], [ test ], metric_list = [ eva . Precision (), eva . Recall ()]) >>> ut . Report () . yaml ( original_ratings = ratings , >>> partitioning_technique = pt , >>> recsys = cbrs , >>> eval_model = em ) PARAMETER DESCRIPTION content_analyzer ContentAnalyzer object used to generate complex representation in the experiment TYPE: ContentAnalyzer DEFAULT: None original_ratings Ratings object representing the original dataset TYPE: Ratings DEFAULT: None partitioning_technique Partitioning object used to split the original dataset TYPE: Partitioning DEFAULT: None recsys RecSys object used to produce recommendations/score predictions. Please note that the latest experiment run will be documented. If no experiment is run, then an exception is thrown TYPE: RecSys DEFAULT: None eval_model EvalModel object used to evaluate predictions generated. Please note that the latest evaluation run will be documented. If no evaluation is run, then an exception is thrown TYPE: EvalModel DEFAULT: None Source code in clayrs/utils/report.py 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 def yaml ( self , content_analyzer : ContentAnalyzer = None , original_ratings : Ratings = None , partitioning_technique : Partitioning = None , recsys : RecSys = None , eval_model : EvalModel = None ): \"\"\" Main module responsible of generating the `YAML` reports based on the objects passed to this function: * If `content_analyzer` is set, then the report for the Content Analyzer will be produced * If one between `original_ratings`, `partitioning_technique`, `recsys` is set, then the report for the recsys module will be produced. * If `eval_model` is set, then the report for the evaluation module will be produced **PLEASE NOTE**: by setting the `recsys` parameter, the last experiment conducted will be documented! If no experiment is conducted in the current run, then a `ValueError` exception is raised! * Same goes for the `eval_model` Examples: * Generate a report for the Content Analyzer module >>> from clayrs import content_analyzer as ca >>> from clayrs import utils as ut >>> # movies_ca_config = ... # user defined configuration >>> content_a = ca.ContentAnalyzer(movies_config) >>> content_a.fit() # generate and serialize contents >>> ut.Report().yaml(content_analyzer=content_a) # generate yaml * Generate a partial report for the RecSys module >>> from clayrs import utils as ut >>> from clayrs import recsys as rs >>> ratings = ca.Ratings(ca.CSVFile(ratings_path)) >>> pt = rs.HoldOutPartitioning() >>> [train], [test] = pt.split_all(ratings) >>> ut.Report().yaml(original_ratings=ratings, partitioning_technique=pt) * Generate a full report for the RecSys module and evaluation module >>> from clayrs import utils as ut >>> from clayrs import recsys as rs >>> from clayrs import evaluation as eva >>> >>> # Generate recommendations >>> ratings = ca.Ratings(ca.CSVFile(ratings_path)) >>> pt = rs.HoldOutPartitioning() >>> [train], [test] = pt.split_all(ratings) >>> alg = rs.CentroidVector() >>> cbrs = rs.ContentBasedRS(alg, train_set=train, items_directory=items_path) >>> rank = cbrs.fit_rank(test, n_recs=10) >>> >>> # Evaluate recommendations and generate report >>> em = eva.EvalModel([rank], [test], metric_list=[eva.Precision(), eva.Recall()]) >>> ut.Report().yaml(original_ratings=ratings, >>> partitioning_technique=pt, >>> recsys=cbrs, >>> eval_model=em) Args: content_analyzer: `ContentAnalyzer` object used to generate complex representation in the experiment original_ratings: `Ratings` object representing the original dataset partitioning_technique: `Partitioning` object used to split the original dataset recsys: `RecSys` object used to produce recommendations/score predictions. Please note that the latest experiment run will be documented. If no experiment is run, then an exception is thrown eval_model: `EvalModel` object used to evaluate predictions generated. Please note that the latest evaluation run will be documented. If no evaluation is run, then an exception is thrown \"\"\" def represent_none ( self , _ ): return self . represent_scalar ( 'tag:yaml.org,2002:null' , 'null' ) def dump_yaml ( output_dir , data ): with open ( output_dir , 'w' ) as yaml_file : pyaml . dump ( data , yaml_file , sort_dicts = False , safe = True ) # None values will be represented as 'null' in yaml file. # without this, they will simply be represented as an empty string pyaml . add_representer ( type ( None ), represent_none ) if content_analyzer is not None : ca_dict = self . _report_ca_module ( content_analyzer ) # create folder if it doesn't exist Path ( self . output_dir ) . mkdir ( parents = True , exist_ok = True ) output_dir = os . path . join ( self . output_dir , f ' { self . _ca_report_filename } .yml' ) dump_yaml ( output_dir , ca_dict ) if original_ratings is not None or partitioning_technique is not None or recsys is not None : rs_dict = self . _report_rs_module ( original_ratings , partitioning_technique , recsys ) # create folder if it doesn't exist Path ( self . output_dir ) . mkdir ( parents = True , exist_ok = True ) output_dir = os . path . join ( self . output_dir , f ' { self . _rs_report_filename } .yml' ) dump_yaml ( output_dir , rs_dict ) if eval_model is not None : eva_dict = self . _report_eva_module ( eval_model ) # create folder if it doesn't exist Path ( self . output_dir ) . mkdir ( parents = True , exist_ok = True ) output_dir = os . path . join ( self . output_dir , f ' { self . _eva_report_filename } .yml' ) dump_yaml ( output_dir , eva_dict )","title":"yaml()"}]}