{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "4_evaluate_other_recs.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGfRczMXt-Tt"
   },
   "source": [
    "# Installation with pip\n",
    "Every dependency needed by the framework will be downloaded and installed automatically"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_z0TVVHmQ2sU",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "6054627f-1416-4dd2-fdcf-64adf3087837"
   },
   "source": [
    "! pip install clayrs"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/swapUniba/clayrs.git\n",
      "  Cloning https://github.com/swapUniba/clayrs.git to /tmp/pip-req-build-5teqbonp\n",
      "  Running command git clone -q https://github.com/swapUniba/clayrs.git /tmp/pip-req-build-5teqbonp\n",
      "  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "    Preparing wheel metadata ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting ekphrasis@ git+https://github.com/fucaja/ekphrasis.git#egg=ekphrasis\n",
      "  Cloning https://github.com/fucaja/ekphrasis.git to /tmp/pip-install-giz662q5/ekphrasis_160d1dddf52e4b67a944f4c70aa41f1c\n",
      "  Running command git clone -q https://github.com/fucaja/ekphrasis.git /tmp/pip-install-giz662q5/ekphrasis_160d1dddf52e4b67a944f4c70aa41f1c\n",
      "Requirement already satisfied: networkx~=2.6.3 in /usr/local/lib/python3.7/dist-packages (from clayrs==0.3.9) (2.6.3)\n",
      "Requirement already satisfied: numpy~=1.21.6 in /usr/local/lib/python3.7/dist-packages (from clayrs==0.3.9) (1.21.6)\n",
      "Collecting wn~=0.0.23\n",
      "  Downloading wn-0.0.23.tar.gz (31.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 31.6 MB 1.2 MB/s \n",
      "\u001B[?25hCollecting mysql~=0.0.3\n",
      "  Downloading mysql-0.0.3-py3-none-any.whl (1.2 kB)\n",
      "Requirement already satisfied: matplotlib~=3.2.2 in /usr/local/lib/python3.7/dist-packages (from clayrs==0.3.9) (3.2.2)\n",
      "Collecting mysql-connector-python~=8.0.20\n",
      "  Downloading mysql_connector_python-8.0.29-cp37-cp37m-manylinux1_x86_64.whl (25.2 MB)\n",
      "\u001B[K     |████████████████████████████████| 25.2 MB 1.5 MB/s \n",
      "\u001B[?25hCollecting pywsd~=1.2.4\n",
      "  Downloading pywsd-1.2.4.tar.gz (26.8 MB)\n",
      "\u001B[K     |████████████████████████████████| 26.8 MB 84.1 MB/s \n",
      "\u001B[?25hCollecting scipy~=1.7.3\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
      "\u001B[?25hCollecting gensim~=4.1.2\n",
      "  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 24.1 MB 125.9 MB/s \n",
      "\u001B[?25hCollecting tqdm~=4.62.2\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "\u001B[K     |████████████████████████████████| 76 kB 4.5 MB/s \n",
      "\u001B[?25hCollecting babelpy~=1.0.1\n",
      "  Downloading BabelPy-1.0.1.tar.gz (8.0 kB)\n",
      "Collecting pyaml~=21.10.1\n",
      "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
      "Collecting whoosh~=2.7.4\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n",
      "\u001B[K     |████████████████████████████████| 468 kB 54.4 MB/s \n",
      "\u001B[?25hCollecting SPARQLWrapper~=1.8.5\n",
      "  Downloading SPARQLWrapper-1.8.5-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: textblob~=0.15.3 in /usr/local/lib/python3.7/dist-packages (from clayrs==0.3.9) (0.15.3)\n",
      "Requirement already satisfied: scikit-learn==1.0.2 in /usr/local/lib/python3.7/dist-packages (from clayrs==0.3.9) (1.0.2)\n",
      "Collecting transformers~=4.15.0\n",
      "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.4 MB 43.4 MB/s \n",
      "\u001B[?25hCollecting torch~=1.10.1\n",
      "  Downloading torch-1.10.2-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001B[K     |██████████████████████████████▎ | 834.1 MB 1.2 MB/s eta 0:00:39tcmalloc: large alloc 1147494400 bytes == 0x3ad2c000 @  0x7f4957080615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
      "\u001B[K     |████████████████████████████████| 881.9 MB 1.8 kB/s \n",
      "\u001B[?25hCollecting spacy~=3.2.1\n",
      "  Downloading spacy-3.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001B[K     |████████████████████████████████| 6.0 MB 47.6 MB/s \n",
      "\u001B[?25hCollecting colorama~=0.4.4\n",
      "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: nltk~=3.5 in /usr/local/lib/python3.7/dist-packages (from clayrs==0.3.9) (3.7)\n",
      "Collecting PyYAML~=5.3.1\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "\u001B[K     |████████████████████████████████| 269 kB 57.3 MB/s \n",
      "\u001B[?25hCollecting sentence-transformers~=1.2.0\n",
      "  Downloading sentence-transformers-1.2.1.tar.gz (80 kB)\n",
      "\u001B[K     |████████████████████████████████| 80 kB 9.0 MB/s \n",
      "\u001B[?25hCollecting pandas==1.2.4\n",
      "  Downloading pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "\u001B[K     |████████████████████████████████| 9.9 MB 63.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from ekphrasis@ git+https://github.com/fucaja/ekphrasis.git#egg=ekphrasis->clayrs==0.3.9) (1.1.0)\n",
      "Collecting ujson\n",
      "  Downloading ujson-5.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45 kB)\n",
      "\u001B[K     |████████████████████████████████| 45 kB 3.1 MB/s \n",
      "\u001B[?25hCollecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001B[K     |████████████████████████████████| 53 kB 1.6 MB/s \n",
      "\u001B[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4->clayrs==0.3.9) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4->clayrs==0.3.9) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.2->clayrs==0.3.9) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.2->clayrs==0.3.9) (1.1.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim~=4.1.2->clayrs==0.3.9) (5.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.2.2->clayrs==0.3.9) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.2.2->clayrs==0.3.9) (1.4.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.2.2->clayrs==0.3.9) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib~=3.2.2->clayrs==0.3.9) (4.1.1)\n",
      "Collecting mysqlclient\n",
      "  Downloading mysqlclient-2.1.1.tar.gz (88 kB)\n",
      "\u001B[K     |████████████████████████████████| 88 kB 5.7 MB/s \n",
      "\u001B[?25hRequirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from mysql-connector-python~=8.0.20->clayrs==0.3.9) (3.17.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk~=3.5->clayrs==0.3.9) (7.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk~=3.5->clayrs==0.3.9) (2022.6.2)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.0.0->mysql-connector-python~=8.0.20->clayrs==0.3.9) (1.15.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers~=1.2.0->clayrs==0.3.9) (0.12.0+cu113)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.2 MB 62.5 MB/s \n",
      "\u001B[?25hRequirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (8.0.17)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (3.0.9)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (0.7.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (0.4.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (57.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (2.4.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (0.9.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (3.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (1.0.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (0.6.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (1.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (1.0.7)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (2.11.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (2.23.0)\n",
      "Collecting typing-extensions\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy~=3.2.1->clayrs==0.3.9) (2.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy~=3.2.1->clayrs==0.3.9) (3.8.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy~=3.2.1->clayrs==0.3.9) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy~=3.2.1->clayrs==0.3.9) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy~=3.2.1->clayrs==0.3.9) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy~=3.2.1->clayrs==0.3.9) (2.10)\n",
      "Collecting rdflib>=4.0\n",
      "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
      "\u001B[K     |████████████████████████████████| 482 kB 60.0 MB/s \n",
      "\u001B[?25hCollecting isodate\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001B[K     |████████████████████████████████| 41 kB 570 kB/s \n",
      "\u001B[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib>=4.0->SPARQLWrapper~=1.8.5->clayrs==0.3.9) (4.11.4)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001B[K     |████████████████████████████████| 101 kB 10.6 MB/s \n",
      "\u001B[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.3 MB 37.1 MB/s \n",
      "\u001B[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001B[K     |████████████████████████████████| 880 kB 50.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers~=4.15.0->clayrs==0.3.9) (3.7.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->ekphrasis@ git+https://github.com/fucaja/ekphrasis.git#egg=ekphrasis->clayrs==0.3.9) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy~=3.2.1->clayrs==0.3.9) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers~=1.2.0->clayrs==0.3.9) (7.1.2)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.13.0-cp37-cp37m-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 19.1 MB 1.3 MB/s \n",
      "\u001B[?25h  Downloading torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001B[K     |████████████████████████████████| 21.0 MB 1.1 MB/s \n",
      "\u001B[?25h  Downloading torchvision-0.11.3-cp37-cp37m-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001B[K     |████████████████████████████████| 23.2 MB 2.1 MB/s \n",
      "\u001B[?25hBuilding wheels for collected packages: clayrs, ekphrasis, babelpy, pywsd, PyYAML, sentence-transformers, wn, mysqlclient, sacremoses\n",
      "  Building wheel for clayrs (PEP 517) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for clayrs: filename=clayrs-0.3.9-py3-none-any.whl size=3541555 sha256=12c6cbd2e6bd7d3cf76fbc27448612220cc2107ef635591471e242f38a2e1afc\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-a33ozok_/wheels/d5/6e/24/11566e22b41b05b2b1d6d9b02e677e613e11929cfe7bf66fb5\n",
      "  Building wheel for ekphrasis (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for ekphrasis: filename=ekphrasis-0.5.1-py3-none-any.whl size=614879 sha256=8b8a38127a84e87f6db075e120d428c3e430992784e51fcae0ac663c58449444\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-a33ozok_/wheels/ba/6d/16/386c2ee4778a28420fcfea1a1aadf7bac121198ace6cc5d354\n",
      "  Building wheel for babelpy (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for babelpy: filename=BabelPy-1.0.1-py3-none-any.whl size=9723 sha256=bc06cb01a91e8b64e2c4dda07603bbaf3f664a9012c80bf6b4c1ee97a41b8971\n",
      "  Stored in directory: /root/.cache/pip/wheels/e4/28/f6/693a53d3dc6bf14eed8a13fdfba08737edc3bc03a5133e4a14\n",
      "  Building wheel for pywsd (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pywsd: filename=pywsd-1.2.4-py3-none-any.whl size=26940436 sha256=8628f28cc21e05fb733a89c385c625ef4cf116cf243263a64b8259c3e9c3186f\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/67/c0/6e6fa8456d1374b393328368316c3b33844cb4043bd225bc66\n",
      "  Building wheel for PyYAML (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44636 sha256=0a387abc999477298bb36ba7fdefb61a80fd80d04737fd03bf7f2fb0362104d9\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-1.2.1-py3-none-any.whl size=123299 sha256=7b119105f21bd61c8413a922cb682b27c50532ab64e891ab4d163a9dcc3d1542\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/f2/3a/b9159c4e43a6a4aa2751421ff5dfe69231fbcc91f7efbc4d2f\n",
      "  Building wheel for wn (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for wn: filename=wn-0.0.23-py3-none-any.whl size=31792926 sha256=e2e039af6cf27d1418ac307cbaf8df21d3db6579594c46fc7923a9c10d921bbf\n",
      "  Stored in directory: /root/.cache/pip/wheels/ec/47/17/409766c99dd470f34c512000b90b83f34747c2c975769654d7\n",
      "  Building wheel for mysqlclient (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for mysqlclient: filename=mysqlclient-2.1.1-cp37-cp37m-linux_x86_64.whl size=99978 sha256=6286ab20d8367c2c1917ca3c4f6dc42727a96c26ca86050f4562cdb1a0aae7fa\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/2d/67/2cb3f82e435fc8e055cb2761a15a0812bf086068f6fb835462\n",
      "  Building wheel for sacremoses (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=9922fe61d54293a62816129375c8c23c906fd3930399f96444f0b46989b4b56d\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
      "Successfully built clayrs ekphrasis babelpy pywsd PyYAML sentence-transformers wn mysqlclient sacremoses\n",
      "Installing collected packages: typing-extensions, tqdm, PyYAML, torch, tokenizers, scipy, sacremoses, isodate, huggingface-hub, wn, ujson, transformers, torchvision, sentencepiece, rdflib, pandas, mysqlclient, ftfy, colorama, whoosh, SPARQLWrapper, spacy, sentence-transformers, pywsd, pyaml, mysql-connector-python, mysql, gensim, ekphrasis, babelpy, clayrs\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.1.1\n",
      "    Uninstalling typing-extensions-4.1.1:\n",
      "      Successfully uninstalled typing-extensions-4.1.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.0\n",
      "    Uninstalling tqdm-4.64.0:\n",
      "      Successfully uninstalled tqdm-4.64.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0+cu113\n",
      "    Uninstalling torch-1.11.0+cu113:\n",
      "      Successfully uninstalled torch-1.11.0+cu113\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.12.0+cu113\n",
      "    Uninstalling torchvision-0.12.0+cu113:\n",
      "      Successfully uninstalled torchvision-0.12.0+cu113\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.5\n",
      "    Uninstalling pandas-1.3.5:\n",
      "      Successfully uninstalled pandas-1.3.5\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.3.1\n",
      "    Uninstalling spacy-3.3.1:\n",
      "      Successfully uninstalled spacy-3.3.1\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 3.6.0\n",
      "    Uninstalling gensim-3.6.0:\n",
      "      Successfully uninstalled gensim-3.6.0\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.10.2 which is incompatible.\n",
      "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.10.2 which is incompatible.\n",
      "en-core-web-sm 3.3.0 requires spacy<3.4.0,>=3.3.0.dev0, but you have spacy 3.2.4 which is incompatible.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001B[0m\n",
      "Successfully installed PyYAML-5.3.1 SPARQLWrapper-1.8.5 babelpy-1.0.1 clayrs-0.3.9 colorama-0.4.5 ekphrasis-0.5.1 ftfy-6.1.1 gensim-4.1.2 huggingface-hub-0.8.1 isodate-0.6.1 mysql-0.0.3 mysql-connector-python-8.0.29 mysqlclient-2.1.1 pandas-1.2.4 pyaml-21.10.1 pywsd-1.2.4 rdflib-6.1.1 sacremoses-0.0.53 scipy-1.7.3 sentence-transformers-1.2.1 sentencepiece-0.1.96 spacy-3.2.4 tokenizers-0.10.3 torch-1.10.2 torchvision-0.11.3 tqdm-4.62.3 transformers-4.15.0 typing-extensions-3.10.0.2 ujson-5.3.0 whoosh-2.7.4 wn-0.0.23\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "typing_extensions"
        ]
       }
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1MOZctwVyW5"
   },
   "source": [
    "# **! RESTART RUNTIME !**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTZB50Y3rN-8"
   },
   "source": [
    "# Correct order log and prints for IPython\n",
    "This is necessary only for IPython environments (Colab, Jupyter, etc.), since they mess up the order of  ```print``` and ```logging```\n",
    "\n",
    "```python\n",
    "# EXAMPLE of the issue\n",
    ">>> import logging\n",
    ">>> print(\"Should go first\")\n",
    ">>> logging.warning(\"Should go second\")\n",
    "WARNING:root:Should go second\n",
    "Should go first\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GOTUezxnqzn7"
   },
   "source": [
    "import functools\n",
    "print = functools.partial(print, flush=True)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVKotTbvf_rC"
   },
   "source": [
    "# Import and datasets download\n",
    "\n",
    "The framework is made of three modules:\n",
    "> 1.   Content Analyzer\n",
    "> 2.   Recommender System\n",
    "> 3.   Evaluation\n",
    "\n",
    "We import every module as a library and use classes and methods by using the dot notation:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SctkIBio9dhe"
   },
   "source": [
    "from clayrs import content_analyzer as ca\n",
    "from clayrs import recsys as rs\n",
    "from clayrs import evaluation as eva\n",
    "\n",
    "# Usage:\n",
    "# ...\n",
    "# ca.Ratings()\n",
    "# rs.ContentBasedRS()\n",
    "# eva.EvalModel()\n",
    "# ..."
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYjcSfTtCXEw"
   },
   "source": [
    "We use **Movielens 100k** as dataset, with items info expanded thanks to imdb"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HwEnaPj4pvCS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fc62732f-23e1-46c3-d369-57e0c78bf5c9"
   },
   "source": [
    "# Dataset: Movielens-100k\n",
    "\n",
    "# download items_info\n",
    "!wget https://raw.githubusercontent.com/swapUniba/clayrs/master/datasets/ml-100k/items_info.json\n",
    "\n",
    "# download users_info\n",
    "!wget https://raw.githubusercontent.com/swapUniba/clayrs/master/datasets/ml-100k/users_info.csv\n",
    "\n",
    "# download ratings\n",
    "!wget https://raw.githubusercontent.com/swapUniba/clayrs/master/datasets/ml-100k/ratings.csv"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-07-01 11:20:11--  https://raw.githubusercontent.com/swapUniba/clayrs/master/datasets/ml-100k/items_info.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2222967 (2.1M) [text/plain]\n",
      "Saving to: ‘items_info.json’\n",
      "\n",
      "items_info.json     100%[===================>]   2.12M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2022-07-01 11:20:12 (33.2 MB/s) - ‘items_info.json’ saved [2222967/2222967]\n",
      "\n",
      "--2022-07-01 11:20:12--  https://raw.githubusercontent.com/swapUniba/clayrs/master/datasets/ml-100k/users_info.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22667 (22K) [text/plain]\n",
      "Saving to: ‘users_info.csv’\n",
      "\n",
      "users_info.csv      100%[===================>]  22.14K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2022-07-01 11:20:12 (19.2 MB/s) - ‘users_info.csv’ saved [22667/22667]\n",
      "\n",
      "--2022-07-01 11:20:12--  https://raw.githubusercontent.com/swapUniba/clayrs/master/datasets/ml-100k/ratings.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1979206 (1.9M) [text/plain]\n",
      "Saving to: ‘ratings.csv’\n",
      "\n",
      "ratings.csv         100%[===================>]   1.89M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2022-07-01 11:20:12 (32.7 MB/s) - ‘ratings.csv’ saved [1979206/1979206]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBOImtHzxTlQ"
   },
   "source": [
    "### Check items file\n",
    "In this example, the file containing items info is a JSON where every entry corresponds to a movie.\n",
    "\n",
    "For every movie there are various information, such as *genres, directors, cast, etc.*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eAMUA6B6wSje",
    "outputId": "9ae4b933-657b-4fbf-9ca0-bc147be9a801"
   },
   "source": [
    "with open(\"items_info.json\", \"r\") as f:\n",
    "  # 25 lines but in these 23 lines there are only 2 entries:\n",
    "  # 'Toy Story', and 'Golden Eye'\n",
    "  for _ in range(25):\n",
    "    print(f.readline(), end='')\n"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\n",
      "    {\n",
      "        \"movielens_id\": \"1\",\n",
      "        \"imdb_id\": \"0114709\",\n",
      "        \"title\": \"Toy Story\",\n",
      "        \"plot\": \"A cowboy doll is profoundly threatened and jealous when a new spaceman figure supplants him as top toy in a boy's room.\",\n",
      "        \"genres\": \"Animation, Adventure, Comedy, Family, Fantasy\",\n",
      "        \"year\": \"1995\",\n",
      "        \"rating\": \"8.3\",\n",
      "        \"directors\": \"John Lasseter\",\n",
      "        \"cast\": \"Tom Hanks, Tim Allen, Don Rickles, Jim Varney, Wallace Shawn, John Ratzenberger, Annie Potts, John Morris, Erik von Detten, Laurie Metcalf, R. Lee Ermey, Sarah Rayne, Penn Jillette, Jack Angel, Spencer Aste, Greg Berg, Lisa Bradley, Kendall Cunningham, Debi Derryberry, Cody Dorkin, Bill Farmer, Craig Good, Gregory Grudt, Danielle Judovits, Sam Lasseter, Brittany Levenbrown, Sherry Lynn, Scott McAfee, Mickie McGowan, Ryan O'Donohue, Jeff Pidgeon, Patrick Pinney, Phil Proctor, Jan Rabson, Joe Ranft, Andrew Stanton, Shane Sweet, Wayne Allwine, Tony Anselmo, Jonathan Benair, Anthony Burch, John Lasseter, Billy West\",\n",
      "        \"dbpedia_uri\": \"http://dbpedia.org/resource/Toy_Story\",\n",
      "        \"dbpedia_label\": \"Toy Story\"\n",
      "    },\n",
      "    {\n",
      "        \"movielens_id\": \"2\",\n",
      "        \"imdb_id\": \"0113189\",\n",
      "        \"title\": \"GoldenEye\",\n",
      "        \"plot\": \"Years after a friend and fellow 00 agent is killed on a joint mission, a secret space based weapons program known as \\\"_GoldenEye_ (qv)\\\" is stolen. James Bond sets out to stop a Russian crime syndicate from using the weapon.\",\n",
      "        \"genres\": \"Action, Adventure, Thriller\",\n",
      "        \"year\": \"1995\",\n",
      "        \"rating\": \"7.2\",\n",
      "        \"directors\": \"Martin Campbell\",\n",
      "        \"cast\": \"Pierce Brosnan, Sean Bean, Izabella Scorupco, Famke Janssen, Joe Don Baker, Judi Dench, Robbie Coltrane, Tchéky Karyo, Gottfried John, Alan Cumming, Desmond Llewelyn, Samantha Bond, Michael Kitchen, Serena Gordon, Simon Kunz, Pavel Douglas, Olivier Lajous, Billy J. Mitchell, Constantine Gregory, Minnie Driver, Michelle Arthur, Ravil Isyanov, Vladimir Milanovich, Trevor Byfield, Peter Majer, Paul Bannon, Simone Bechtel, Martin Campbell, Mark Chapman, Kenneth Coombs, Simon Crane, Terrance Denville, Ian Durrant, Max Faulkner, Juliet Forester, Stefan Kopiecki, Jo Anna Lee, Derek Lyons, Wayne Michaels, Bhasker Patel, Paul Sacks, Michael G. Wilson\",\n",
      "        \"dbpedia_uri\": \"http://dbpedia.org/resource/GoldenEye\",\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrGycV8NxkwF"
   },
   "source": [
    "### Check users file\n",
    "In this example, the file containing users info is a CSV file where the first column is the *user id*, while the other columns are side information for that user (*gender, occupation, zip code*)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vUKLNAnMxEnh",
    "outputId": "1c4638bf-b7da-48df-e6a3-d67e269231a9"
   },
   "source": [
    "with open(\"users_info.csv\", \"r\") as f:\n",
    "\n",
    "  # print the header and the first 2 entries\n",
    "  for _ in range(3):\n",
    "    print(f.readline(), end='')"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "user_id,age,gender,occupation,zip_code\n",
      "1,24,M,technician,85711\n",
      "2,53,F,other,94043\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dteEOqLxkDGR"
   },
   "source": [
    "<a name=\"cell-id\"></a>\n",
    "### Check ratings\n",
    "In this example, the file containing the interactions between the users and the movies is a CSV, where every interaction is a rating in the **[1, 5]** Likert scale"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Q3FvQsaIkbtz",
    "outputId": "72d6f791-d7d3-44bc-8d87-c17fd394302a"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv('ratings.csv')"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       user_id  item_id  rating  timestamp\n",
       "0          196      242       3  881250949\n",
       "1          186      302       3  891717742\n",
       "2           22      377       1  878887116\n",
       "3          244       51       2  880606923\n",
       "4          166      346       1  886397596\n",
       "...        ...      ...     ...        ...\n",
       "99995      880      476       3  880175444\n",
       "99996      716      204       5  879795543\n",
       "99997      276     1090       1  874795795\n",
       "99998       13      225       2  882399156\n",
       "99999       12      203       3  879959583\n",
       "\n",
       "[100000 rows x 4 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-bc57ad0c-a841-4c55-9e8b-27b4bbadc8a4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "      <td>880175444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>874795795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc57ad0c-a841-4c55-9e8b-27b4bbadc8a4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bc57ad0c-a841-4c55-9e8b-27b4bbadc8a4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bc57ad0c-a841-4c55-9e8b-27b4bbadc8a4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilGpvNnPgHay"
   },
   "source": [
    "# Content Analyzer: representation of Items and export to json\n",
    "In order to define the *item representation*, the following parameters should be defined:\n",
    "*   ***source***: the path of the file containing items info\n",
    "*   ***id***: the field that uniquely identifies an item\n",
    "*   ***output_directory***: the path where serialized representations are saved\n",
    "\n",
    "There is also the optional parameter ***export_json***, which allows to create a file `contents.json` in the output directory containing the serialization of all representations of the content."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gORk6J3wqJGB"
   },
   "source": [
    "# Configuration of item representation \n",
    "movies_ca_config = ca.ItemAnalyzerConfig(\n",
    "    source=ca.JSONFile('items_info.json'),\n",
    "    id='movielens_id',\n",
    "    output_directory='movies_codified/',\n",
    "    export_json=True\n",
    ")"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfnkSpfTjuDq"
   },
   "source": [
    "<a name=\"ca_id\"></a>\n",
    "Each item can be represented using a set of fields.\n",
    "Every field can be **represented** using several techniques, such as *'tfidf'*, *'entity linking'*, *'embeddings'*, etc.\n",
    "\n",
    "It is possible to process the content of each field using a **Natural Language Processing (NLP) pipeline**.  \n",
    "It is also possible to assign a **custom id** for each generated representation, in order to allow a simpler reference in the recommendation phase. Both NLP pipeline and custom id are optional parameters.\n",
    "\n",
    "> In the following example, we process the *'plot'* field by performing **lemmatization** and **stopwords removal** through [NLTK](https://www.nltk.org/), and we represent it using **tfidf**:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YA8GfrkrqJ4S",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "30dd1f02-fbf2-43ab-acb9-2faea90d1863"
   },
   "source": [
    "movies_ca_config.add_single_config(\n",
    "    'plot',\n",
    "    ca.FieldConfig(ca.SkLearnTfIdf(),\n",
    "                   preprocessing=ca.NLTK(stopwords_removal=True, lemmatization=True)) \n",
    ")"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAgjyRfVYRqG"
   },
   "source": [
    "In this example, we also add an exogenous representation to the content by extracting the 'year' field from the local source \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m9KBOFO-XAJ2"
   },
   "source": [
    "movies_ca_config.add_single_exogenous(\n",
    "    ca.ExogenousConfig(ca.PropertiesFromDataset(field_name_list=['year']))\n",
    ")"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e24qhQVkXIc"
   },
   "source": [
    "At the end of the configuration step, we provide the configuration to the *'Content Analyzer'* and call the `fit()` method:\n",
    "\n",
    "*   The Content Analyzer will **represent** and **serialize** every item (and create the json file containing representations for every content).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yXU-Vuw2twuN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1cff3cfb-05bf-41ae-9ffb-4e1fbf35c725"
   },
   "source": [
    "content_analyzer = ca.ContentAnalyzer(config=movies_ca_config)\n",
    "content_analyzer.fit()"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[39mINFO\u001B[0m - Extracting exogenous properties from local dataset (exogenous_properties_retrieval.py:146)\n",
      "\u001B[39mINFO\u001B[0m - ***********   Processing field: plot   *********** (content_analyzer_main.py:186)\n",
      "\u001B[39mINFO\u001B[0m - Computing tf-idf with SkLearnTfIdf (tf_idf.py:95)\n",
      "Serializing contents:  100%|██████████| 1682/1682 [00:10<00:00]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrGYxny3g9sW"
   },
   "source": [
    "This is the JSON file which has been created:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RfdoIwichaaF",
    "outputId": "d5c8d330-8d0f-4a82-fe66-d0efe72f873e"
   },
   "source": [
    "with open('movies_codified/contents.json', 'r') as f:\n",
    "    for _ in range(11):\n",
    "      print(f.readline(), end='')"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\n",
      "    {\n",
      "        \"content_id\": \"1\",\n",
      "        \"Exo#0\": \"{'year': '1995'}\",\n",
      "        \"plot#0\": {\n",
      "            \"sparse_tfidf\": \"[[(0, 1024),0.1719365702112526],\\n [(0, 1729),0.31336848582007987],\\n [(0, 2160),0.3010691777558571],\\n [(0, 2721),0.25782007590969463],\\n [(0, 3752),0.2915290932564375],\\n [(0, 4769),0.1484604944785959],\\n [(0, 5439),0.31336848582007987],\\n [(0, 5932),0.2618948840931845],\\n [(0, 6417),0.3307033869191101],\\n [(0, 6655),0.3307033869191101],\\n [(0, 6853),0.25410006749357394],\\n [(0, 6909),0.2445599829941543],\\n [(0, 6941),0.31336848582007987]]\",\n",
      "            \"pos_word_tuples\": \"[(5932, 'room'), (1024, 'boy'), (6941, 'toy'), (6909, 'top'), (6655, 'supplants'), (2721, 'figure'), (6417, 'spaceman'), (4769, 'new'), (3752, 'jealous'), (6853, 'threaten'), (5439, 'profoundly'), (2160, 'doll'), (1729, 'cowboy')]\",\n",
      "            \"len_vocabulary\": 7614\n",
      "        }\n",
      "    },\n",
      "    {\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_3ff69ZhFj7"
   },
   "source": [
    "# [Optional] Content Analyzer: representation of Users and export to json\n",
    "In order to define the *'user representation'*, we could use the same process performed for *'item representation'*. In this case we don't want to represent in a complex way users, so this step is completely optional\n",
    "\n",
    "In this example, the ID for users is the column `user_id`.\n",
    "\n",
    "Also for users, it is ossible to export the representation in a ***json file***"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HhwOj4s-uzOk"
   },
   "source": [
    "#Configuration of user representation\n",
    "users_ca_config = ca.UserAnalyzerConfig(\n",
    "    ca.CSVFile('users_info.csv'),\n",
    "    id='user_id',\n",
    "    output_directory='users_codified/',\n",
    "    export_json=True\n",
    ")"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8xsWBz8eYHF"
   },
   "source": [
    "We also add an exogenous representation for each user by extracting the 'gender' field from the local source\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BELoRbCckKn",
    "outputId": "22b53b51-e609-461b-966a-5b8059c76ce8"
   },
   "source": [
    "users_ca_config.add_single_exogenous(\n",
    "    ca.ExogenousConfig(ca.PropertiesFromDataset(field_name_list=['gender']))\n",
    ")\n",
    "\n",
    "ca.ContentAnalyzer(config=users_ca_config).fit()"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[39mINFO\u001B[0m - Extracting exogenous properties from local dataset (exogenous_properties_retrieval.py:146)\n",
      "Serializing contents:  100%|██████████| 943/943 [00:04<00:00]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnhE2zqnfykN"
   },
   "source": [
    "This is the JSON file which has been created:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8avOGAFvgGQy",
    "outputId": "c5d4d4b8-e208-4b58-b321-d2c7f983f353"
   },
   "source": [
    "with open('users_codified/contents.json', 'r') as f:\n",
    "    for _ in range(9):\n",
    "      print(f.readline(), end='')"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\n",
      "    {\n",
      "        \"content_id\": \"1\",\n",
      "        \"Exo#0\": \"{'gender': 'M'}\"\n",
      "    },\n",
      "    {\n",
      "        \"content_id\": \"2\",\n",
      "        \"Exo#0\": \"{'gender': 'F'}\"\n",
      "    },\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dr0qljcRhpW6"
   },
   "source": [
    "# Recommender System: centroid vector algorithm and export to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ms6kU0TEr_ps"
   },
   "source": [
    "The Recommender System module needs information about users, items and ratings. \n",
    "\n",
    "The **Ratings** class allows you to import rating from a source file (or also from an existent dataframe) into a custom object.   **If** the source file contains users (U), items (I) and ratings (R) in this order, no additional parameters are needed, **otherwise**  the mapping must be explictly specified using:\n",
    "\n",
    "*   **'user_id'** column,\n",
    "*   **'item_id'** column,\n",
    "*   **'score'** column\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjxZ9yTnvVW-",
    "outputId": "bc0c0d84-2a57-4d86-9228-32a7de1b1221"
   },
   "source": [
    "ratings = ca.Ratings(ca.CSVFile('ratings.csv'))\n",
    "\n",
    "print(ratings)"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Importing ratings:  100%|██████████| 100000/100000 [00:00<00:00]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      user_id item_id  score\n",
      "0         196     242    3.0\n",
      "1         196     393    4.0\n",
      "2         196     381    4.0\n",
      "3         196     251    3.0\n",
      "4         196     655    5.0\n",
      "...       ...     ...    ...\n",
      "99995     941     919    5.0\n",
      "99996     941     273    3.0\n",
      "99997     941       1    5.0\n",
      "99998     941     294    4.0\n",
      "99999     941    1007    4.0\n",
      "\n",
      "[100000 rows x 3 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1SfXQx4y01u7"
   },
   "source": [
    "# (mapping by index) EQUIVALENT:\n",
    "#\n",
    "# ratings = ca.Ratings(\n",
    "#     ca.CSVFile('ratings.csv'),\n",
    "#     user_id_column=0,\n",
    "#     item_id_column=1,\n",
    "#     score_column=2\n",
    "# )"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ww9kKa3608pK"
   },
   "source": [
    "# (mapping by column name) EQUIVALENT:\n",
    "\n",
    "# ratings = ca.Ratings(\n",
    "#     ca.CSVFile('ratings.csv'),\n",
    "#     user_id_column='user_id',\n",
    "#     item_id_column='item_id',\n",
    "#     score_column='rating'\n",
    "# )"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9dYu-H9uUa5"
   },
   "source": [
    "The Recommender System also needs an algorithm for ranking or predicting items to users. In the following example we use the **CentroidVector** algorithm:\n",
    "\n",
    "*   It computes the centroid vector of the features of items *liked by the user*\n",
    "*   It computes the similarity between the centroid vector and unrated items\n",
    "\n",
    "The items liked by a user are those having a rating higher or equal than a specific **threshold**. If the threshold is not specified, the average score of all items liked by the user is used.\n",
    "\n",
    "The Recommender System leverages the representations defined by the Content Analyzer. In the current example, we use the representation of the field 'plot'. More representations could be adopted for a single field.\n",
    "\n",
    "\n",
    "```python\n",
    "# Example with multiple representations for a single field\n",
    "{\n",
    "  'plot': ['tfidf', 'word_embedding'],\n",
    "  'genre': 'doc_embedding',\n",
    "  ...\n",
    "}\n",
    "```\n",
    "\n",
    "Representations can be referenced using the **external id** (if specified, see [here](#ca_id)) or the **internal id**:\n",
    "\n",
    "\n",
    "```\n",
    "For the field 'plot':\n",
    "First representation created -> internal_id = 0\n",
    "Second representation created -> internal_id = 1\n",
    "...\n",
    "Nth representation created -> internal_id = n-1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GbblAapgmOL6"
   },
   "source": [
    "centroid_vec = rs.CentroidVector(\n",
    "    {'plot': 0}, # the first and only representation codifed for the 'plot' field\n",
    "    similarity=rs.CosineSimilarity()\n",
    ")\n",
    "\n",
    "# no threshold parameter specified, the average rating given by\n",
    "# the user wil be used"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before we can instantiate the recommender system, we should perform the splitting of the dataset: let's perform a **KFold with 2 splits**\n",
    "\n",
    "*   The output of the partition module are two lists. One containing the two train set (in this case), the other containing the two test set (in this case)"
   ],
   "metadata": {
    "id": "un-SstzA4iEY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "kf = rs.KFoldPartitioning(n_splits=2)\n",
    "train_list, test_list = kf.split_all(ratings)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmTecQWq4iuN",
    "outputId": "ddc1cefb-856f-447f-f1ad-1c92b182db44"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Performing KFoldPartitioning:  100%|██████████| 943/943 [00:00<00:00]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the ***cbrs*** must be fit before we can compute the rank:\n",
    "\n",
    "*   We could do this in two separate steps, by first calling the `fit(..)` method and then the `rank(...)` method \n",
    "\n",
    "*   Or by calling directly the `fit_rank(...)` method, which performs both in one step\n",
    "\n",
    "We use the second approach and we compute the rank for all users of our train set: we will use both the two train set and two test set obtained thanks to the KFold technique\n",
    "\n",
    "In order to compute a rank for all users, you simply do not specify the *user_id_list* parameter"
   ],
   "metadata": {
    "id": "ZNnqFrBZ4w7X"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "result_list = []\n",
    "\n",
    "for train_set, test_set in zip(train_list, test_list):\n",
    "  \n",
    "  cbrs = rs.ContentBasedRS(centroid_vec, train_set, 'movies_codified/')\n",
    "  rank_to_append = cbrs.fit_rank(test_set)\n",
    "\n",
    "  result_list.append(rank_to_append)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LdMCfW1Z493a",
    "outputId": "f9bfe67d-71d7-442f-f25e-bb27c4454ae2"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[39mINFO\u001B[0m - Don't worry if it looks stuck at first (recsys.py:469)\n",
      "\u001B[39mINFO\u001B[0m - First iterations will stabilize the estimated remaining time (recsys.py:470)\n",
      "Computing fit_rank for user 46:  100%|██████████| 943/943 [00:35<00:00]\n",
      "\u001B[39mINFO\u001B[0m - Don't worry if it looks stuck at first (recsys.py:469)\n",
      "\u001B[39mINFO\u001B[0m - First iterations will stabilize the estimated remaining time (recsys.py:470)\n",
      "Computing fit_rank for user 46:  100%|██████████| 943/943 [00:33<00:00]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIQtO-Ah1Ty8"
   },
   "source": [
    "Let's export each ranking generated to a csv file\n",
    "\n",
    "*   The `rank()` method (and the `fit_rank()` method) returns a **Rank** object, that has a useful exporting method `to_csv()`\n",
    "\n",
    "We will save also the *test set* of each split, we need them later on in the *EvalModel part*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2z88KA1D1Xni"
   },
   "source": [
    "# we save the result of each split numbered\n",
    "for i, rank_generated in enumerate(result_list, start=1):\n",
    "  rank_generated.to_csv(file_name=f'rank_split_{i}')\n",
    "\n",
    "# we save  the result of each split numbered\n",
    "for i, test_set in enumerate(test_list, start=1):\n",
    "  test_set.to_csv(file_name=f'truth_split_{i}')"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IG3B5sUloNF"
   },
   "source": [
    "We can import recommendations we just exported via pandas, or any other library which reads csv file (also the framework itself):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qU72C15hl03T",
    "outputId": "46a2cbfb-33ea-43dd-fc17-e06f84f27a64"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "rank_split_1 = pd.read_csv('rank_split_1.csv')\n",
    "rank_split_2 = pd.read_csv('rank_split_2.csv')\n",
    "\n",
    "print(\"Result for first split:\")\n",
    "print(rank_split_1)\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Result for second split:\")\n",
    "print(rank_split_2)"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result for first split:\n",
      "       user_id  item_id     score\n",
      "0          242     1137  0.026963\n",
      "1          242     1355  0.021795\n",
      "2          242      283  0.017970\n",
      "3          242     1357  0.016461\n",
      "4          242      305  0.013593\n",
      "...        ...      ...       ...\n",
      "50235       46      151  0.009158\n",
      "50236       46      262  0.008790\n",
      "50237       46      690  0.008159\n",
      "50238       46      748  0.007369\n",
      "50239       46     1062  0.000000\n",
      "\n",
      "[50240 rows x 3 columns]\n",
      "----------------------------------------\n",
      "Result for second split:\n",
      "       user_id  item_id     score\n",
      "0          242     1152  0.032814\n",
      "1          242     1011  0.018523\n",
      "2          242      331  0.017506\n",
      "3          242      268  0.015312\n",
      "4          242      306  0.012405\n",
      "...        ...      ...       ...\n",
      "49755       46       50  0.015880\n",
      "49756       46      286  0.013479\n",
      "49757       46      100  0.010144\n",
      "49758       46        7  0.009986\n",
      "49759       46      125  0.000000\n",
      "\n",
      "[49760 rows x 3 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VlytYEsAEEh"
   },
   "source": [
    "# Evaluation module: evaluation of external recommendations\n",
    "\n",
    "Recommendations can be evaluated with several metrics using the **EvalModel** module of the framework. The nice part of it is that it can evaluate easily also (multiple) recommendations generated via external tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_oXZn3QAEEp"
   },
   "source": [
    "The Evaluation module needs the following parameters:\n",
    "\n",
    "*   A list of computed rank/predictions (in case multiple splits must be evaluated)\n",
    "*   A list of truths (in case multiple splits must be evaluated)\n",
    "*   List of metrics to compute\n",
    "\n",
    "Obviously the list of computed rank/predictions and list of truths must have the same length, and the rank/prediction in position $i$ will be compared with the truth at position $i$\n",
    "\n",
    "Let's suppose we have recommendations (and related truths) generated via other tools in a csv format. We first import them into the framework and then pass them to the EvalModel class\n",
    "\n",
    "*   In this case we will use the recommendations generated earlier in the RecSys phase of this colab, but they are simple csv files and they could be the output of any other tool!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Importing split 1\")\n",
    "rank_1 = ca.Ratings(ca.CSVFile('rank_split_1.csv'))\n",
    "truth_1 = ca.Ratings(ca.CSVFile('truth_split_1.csv'))\n",
    "\n",
    "print(\"Importing split 2\")\n",
    "rank_2 = ca.Ratings(ca.CSVFile('rank_split_2.csv'))\n",
    "truth_2 = ca.Ratings(ca.CSVFile('truth_split_2.csv'))\n",
    "\n",
    "# since multiple splits, we wrap ranks and truths in lists\n",
    "imported_ranks = [rank_1, rank_2]\n",
    "imported_truths = [truth_1, truth_2]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRiA2LiiCRzU",
    "outputId": "f3cf2ec3-4028-49ee-c356-f3b3485ffe75"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Importing split 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Importing ratings:  100%|██████████| 50240/50240 [00:00<00:00]\n",
      "Importing ratings:  100%|██████████| 50240/50240 [00:00<00:00]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Importing split 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "Importing ratings:  100%|██████████| 49760/49760 [00:00<00:00]\n",
      "Importing ratings:  100%|██████████| 49760/49760 [00:00<00:00]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are ready to instantiate the EvalModel class\n",
    "\n",
    "*   We also need to define a metric list, suppose we want to compute ***Pearson Correlation***, ***MRR*** and ***NDCG***\n",
    "\n"
   ],
   "metadata": {
    "id": "DQDcSQJmDxQM"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SVtf_pFAAEEp"
   },
   "source": [
    "em = eva.EvalModel(\n",
    "    result_list,\n",
    "    test_list,\n",
    "    metric_list=[\n",
    "        eva.Correlation('pearson'),\n",
    "        eva.MRR(),\n",
    "        eva.NDCG()\n",
    "    ]\n",
    ")"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoFTI1T83TVV"
   },
   "source": [
    "The fit() method returns two pandas DataFrame: the first one contains the metrics aggregated for the system, while the second contains the metrics computed for each user (where possible)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o9QXMFl02iDK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e9634179-3fd1-44a0-cab1-cca42a482998"
   },
   "source": [
    "sys_result, users_result =  em.fit()"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001B[39mINFO\u001B[0m - Performing evaluation on metrics chosen (eval_model.py:133)\n",
      "Performing NDCG:  100%|██████████| 3/3 [00:03<00:00]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the DataFrame which contains system results, the results are also grouped by splits"
   ],
   "metadata": {
    "id": "Fq8kTXb11SvG"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "yIpALBnr4Azi",
    "outputId": "e9b84936-8245-47c0-9ee1-6ec7774e11a8"
   },
   "source": [
    "sys_result"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              pearson       MRR      NDCG\n",
       "user_id                                  \n",
       "sys - fold1  0.049921  0.767457  0.923095\n",
       "sys - fold2  0.033437  0.768762  0.922108\n",
       "sys - mean   0.041679  0.768110  0.922601"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-151c4ba1-7db4-404f-9766-be01b5882620\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pearson</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sys - fold1</th>\n",
       "      <td>0.049921</td>\n",
       "      <td>0.767457</td>\n",
       "      <td>0.923095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys - fold2</th>\n",
       "      <td>0.033437</td>\n",
       "      <td>0.768762</td>\n",
       "      <td>0.922108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys - mean</th>\n",
       "      <td>0.041679</td>\n",
       "      <td>0.768110</td>\n",
       "      <td>0.922601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-151c4ba1-7db4-404f-9766-be01b5882620')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-151c4ba1-7db4-404f-9766-be01b5882620 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-151c4ba1-7db4-404f-9766-be01b5882620');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "R_-unvKt4BzC",
    "outputId": "f7444772-113f-493c-ebe3-93c9d7d56300"
   },
   "source": [
    "users_result"
   ],
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          pearson      NDCG\n",
       "user_id                    \n",
       "1       -0.039960  0.921503\n",
       "10       0.126505  0.968621\n",
       "100     -0.044637  0.889017\n",
       "101      0.221615  0.914853\n",
       "102     -0.005116  0.920276\n",
       "...           ...       ...\n",
       "95       0.082709  0.919818\n",
       "96       0.169951  0.955528\n",
       "97       0.144300  0.950852\n",
       "98       0.260989  0.912445\n",
       "99       0.109784  0.926987\n",
       "\n",
       "[943 rows x 2 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-49ce2aa1-e137-488b-8a42-c5efe34753d6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pearson</th>\n",
       "      <th>NDCG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.039960</td>\n",
       "      <td>0.921503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.126505</td>\n",
       "      <td>0.968621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.044637</td>\n",
       "      <td>0.889017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.221615</td>\n",
       "      <td>0.914853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-0.005116</td>\n",
       "      <td>0.920276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.082709</td>\n",
       "      <td>0.919818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.169951</td>\n",
       "      <td>0.955528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.144300</td>\n",
       "      <td>0.950852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.260989</td>\n",
       "      <td>0.912445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.109784</td>\n",
       "      <td>0.926987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49ce2aa1-e137-488b-8a42-c5efe34753d6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-49ce2aa1-e137-488b-8a42-c5efe34753d6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-49ce2aa1-e137-488b-8a42-c5efe34753d6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBeOgvjY2ECV"
   },
   "source": [
    "# Other modules: export splitted dataset and methodology module\n",
    "\n",
    "*    During recommendation phase we have already seen how to split the dataset. We will see a further example on how to split the dataset by considering only some users and how to export said splitted dataset.\n",
    "*    A peculiar parameter may be changed in the recommendation phase, the `methodology` parameter: it enables you to choose which items need to be predicted using a specific methodology. We'll see how to use it manually and how to export its output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6rHhaW-AXN_"
   },
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDYYVUWM2hZi"
   },
   "source": [
    "In this example we split with a KFold all the users having a **mean average score >= 3.5**:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81yNWR0p2baT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f68a07fb-a70c-459a-f402-131055953a0c"
   },
   "source": [
    "import statistics\n",
    "\n",
    "# valid_users will contain all users that have a mean average score given >= 3.5\n",
    "valid_users = set()\n",
    "\n",
    "all_users = set(ratings.user_id_column)\n",
    "for u in all_users:\n",
    "  user_ratings = ratings.get_user_interactions(u)\n",
    "  all_users_scores = [user_interaction.score for user_interaction in user_ratings]\n",
    "  if statistics.mean(all_users_scores) >= 3.5:\n",
    "    valid_users.add(u)\n",
    "\n",
    "\n",
    "# Print the length of the two sets to check that they are different\n",
    "print(f\"n_valid_users = {len(valid_users)}\")\n",
    "print(f\"n_all_users = {len(all_users)}\")"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n_valid_users = 575\n",
      "n_all_users = 943\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8SeA6PTI411J",
    "outputId": "1a335cfe-695d-427f-8666-6eb56b1e1d6c"
   },
   "source": [
    "part_technique = rs.KFoldPartitioning(n_splits=3)\n",
    "\n",
    "train_list, test_list = part_technique.split_all(ratings,\n",
    "                                                 user_id_list=valid_users)"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Performing KFoldPartitioning:  100%|██████████| 575/575 [00:00<00:00]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "puqxwcMo_41H"
   },
   "source": [
    "We can check the training and test set of the first split:  \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_zxUsgcE_zGv",
    "outputId": "c6bfe2bf-25fa-4bd6-dd43-d27dce59c6d3"
   },
   "source": [
    "first_train = train_list[0]\n",
    "first_test = test_list[0]\n",
    "\n",
    "print(\"First split - train set:\\n\")\n",
    "print(first_train)\n",
    "print(\"--------------------------------\")\n",
    "print(\"\\nFirst split - test set:\\n\")\n",
    "print(first_test)"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First split - train set:\n",
      "\n",
      "      user_id item_id  score\n",
      "0         242    1137    5.0\n",
      "1         242    1152    5.0\n",
      "2         242     305    5.0\n",
      "3         242     291    3.0\n",
      "4         242    1357    5.0\n",
      "...       ...     ...    ...\n",
      "36817      46     125    4.0\n",
      "36818      46     245    3.0\n",
      "36819      46     332    4.0\n",
      "36820      46     748    5.0\n",
      "36821      46     262    5.0\n",
      "\n",
      "[36822 rows x 3 columns]\n",
      "--------------------------------\n",
      "\n",
      "First split - test set:\n",
      "\n",
      "      user_id item_id  score\n",
      "0         242     934    5.0\n",
      "1         242     361    5.0\n",
      "2         242     306    5.0\n",
      "3         242       1    4.0\n",
      "4         242     111    4.0\n",
      "...       ...     ...    ...\n",
      "18680      46     100    4.0\n",
      "18681      46     305    5.0\n",
      "18682      46     300    3.0\n",
      "18683      46      93    4.0\n",
      "18684      46     286    5.0\n",
      "\n",
      "[18685 rows x 3 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Each object in the two lists is a **Rating** object, which has a useful exporting method `to_csv()`"
   ],
   "metadata": {
    "id": "_jmsk35NJWQ3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "first_train.to_csv(file_name='exported_split_train')\n",
    "first_test.to_csv(file_name='exported_split_test')"
   ],
   "metadata": {
    "id": "JHuPP2bxJjED"
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "st2i48dXBpZ3"
   },
   "source": [
    "## Methodology module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NknvogOFCLp7"
   },
   "source": [
    "During recommendation phase, it is also possible to specify an optional parameter in the `rank()` or `fit_rank()` method, called ***methodology***, for choosing which items must be ranked.\n",
    "For each target user **u**, the following 4 different methodologies are available for defining those lists:\n",
    "\n",
    "1.   **TestRatings** (default): the list of items to be evaluated consists of items rated by u in the test set\n",
    "2.   **TestItems**: every item in the test set of every user except those in the training set of the target user will be predicted\n",
    "3.   **TrainingItems**: every item in the training set of every user will be predicted except those in the training set of the target user\n",
    "4.   **AllItems**: the whole set of items, except those in the training set of the target user, will be predicted\n",
    "\n",
    "More information on [this paper](https://repositorio.uam.es/bitstream/handle/10486/665121/precision-oriented_bellogin_recsys_2011_ps.pdf;jsessionid=85982302D4DA9FF4DD7F21E4AC4F3391?sequence=1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you have multiple splits you need to iterate over your train set and test set, since the `filter_all()` method of each methodology works on a single pair of train set and test set\n",
    "\n"
   ],
   "metadata": {
    "id": "xbBAXD5ZMVIp"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjtUGJoiEhpo",
    "outputId": "156b8b05-e6cb-4f91-ac5c-d7b578369ba2"
   },
   "source": [
    "test_r = rs.TestRatingsMethodology().filter_all(first_train, first_test)\n",
    "\n",
    "train_i = rs.TrainingItemsMethodology().filter_all(first_train, first_test)"
   ],
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Filtering items based on TestRatingsMethodology:  100%|██████████| 575/575 [00:00<00:00]\n",
      "Filtering items based on TrainingItemsMethodology:  100%|██████████| 575/575 [00:00<00:00]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4R1xu8mCF6sK"
   },
   "source": [
    "The output of the `filter_all()` method is a list of pandas DataFrame (one for every split in the split_list), so they can easily be exported to .csv, .tsv, etc.\n",
    "\n",
    "Let's check the item to predict with the test ratings methodology for the first split:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyGcZ-50Hgrj",
    "outputId": "8e3fdee2-06ae-400c-df15-d47f00480bcc"
   },
   "source": [
    "print(test_r)"
   ],
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      user_id item_id\n",
      "0         242     111\n",
      "1         242     934\n",
      "2         242    1355\n",
      "3         242       1\n",
      "4         242     306\n",
      "...       ...     ...\n",
      "18680      46     127\n",
      "18681      46       7\n",
      "18682      46     288\n",
      "18683      46     300\n",
      "18684      46     286\n",
      "\n",
      "[18685 rows x 2 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Report module"
   ],
   "metadata": {
    "id": "XHYkCpFUgBtZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Via the `Report` class, you can generate several ***yml*** files containing all the parameters passed to key classes and functions during your experiment.\n",
    "\n",
    "The mentioned class is very flexible and it is able to document various parts of the experiment, based on the module you use:\n",
    "\n",
    "* You can document how you preprocessed items and complexly represented them via the *Content Analyzer*\n",
    "* Or maybe the experimental setup of your recommendation pipeline by passing key objects of it to the Report class\n",
    "* And lastly how you evaluated your recommender systems and on which metrics\n",
    "\n",
    "The aim is to give you all the tools to ***reproduce*** the experiment also in a different experimental setup"
   ],
   "metadata": {
    "id": "thWR8EOugHZg"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we import the utils package which contains the `Report` class"
   ],
   "metadata": {
    "id": "kWFlxu9jirze"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from clayrs import utils as ut"
   ],
   "metadata": {
    "id": "jDEHRrXAgDXU"
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then you can instantiate the Report class. It needs the following parameters:\n",
    "* ***output_dir***: where the reports generated will be stored, by default it points to the current directory **('.')**\n",
    "* ***ca_report_filename***: how to rename the report of the content analyzer (if one is generated). Default is **'ca_report'**\n",
    "* ***rs_report_filename***: how to rename the report of the recsys module (if one is generated). Default is **'rs_report'**\n",
    "* ***eva_report_filename***: how to rename the report of the evaluation module (if one is generated). Default is **'eva_report'**"
   ],
   "metadata": {
    "id": "UQUiYnnjiyAq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# in this case we are satisfied with the default parameters\n",
    "rep = ut.Report()"
   ],
   "metadata": {
    "id": "X_Vnei_dixcb"
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then simply call the *yaml()* method which will produce the three yaml reports.\n",
    "\n",
    "\n",
    "> You need to pass to it the objects instantiated and used to execute your experiment. For the recsys module and the evaluation module you first need to perform the actual experiment before you are able to obtain a report for them\n",
    "\n",
    "All the parameters of the function are *optional* so that you decide for which module a yaml report must be produced, in case you performed a partial experiment and only used *some* of the modules offered by the framework"
   ],
   "metadata": {
    "id": "KWsICicGkeVF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# In this case we generate a full report for the three modules used in the\n",
    "# experiment in this notebook\n",
    "rep.yaml(content_analyzer=content_analyzer,\n",
    "         original_ratings=ratings,\n",
    "         partitioning_technique=kf,\n",
    "         recsys=cbrs,\n",
    "         eval_model=em)"
   ],
   "metadata": {
    "id": "D-liANM5kTn_"
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The three yml files are generated in the current directory"
   ],
   "metadata": {
    "id": "TA7sgavnlpum"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "assert os.path.isfile('ca_report.yml')\n",
    "assert os.path.isfile('rs_report.yml')\n",
    "assert os.path.isfile('eva_report.yml')"
   ],
   "metadata": {
    "id": "Ms8KI8WAlyNO"
   },
   "execution_count": 37,
   "outputs": []
  }
 ]
}
